/*******************************************************************************
 * Copyright (c) 2000, 2017 IBM Corp. and others
 *
 * This program and the accompanying materials are made available under
 * the terms of the Eclipse Public License 2.0 which accompanies this
 * distribution and is available at https://www.eclipse.org/legal/epl-2.0/
 * or the Apache License, Version 2.0 which accompanies this distribution and
 * is available at https://www.apache.org/licenses/LICENSE-2.0.
 *
 * This Source Code may also be made available under the following
 * Secondary Licenses when the conditions for such availability set
 * forth in the Eclipse Public License, v. 2.0 are satisfied: GNU
 * General Public License, version 2 with the GNU Classpath
 * Exception [1] and GNU General Public License, version 2 with the
 * OpenJDK Assembly Exception [2].
 *
 * [1] https://www.gnu.org/software/classpath/license.html
 * [2] http://openjdk.java.net/legal/assembly-exception.html
 *
 * SPDX-License-Identifier: EPL-2.0 OR Apache-2.0
 *******************************************************************************/

//On zOS XLC linker can't handle files with same name at link time
//This workaround with pragma is needed. What this does is essentially
//give a different name to the codesection (csect) for this file. So it
//doesn't conflict with another file with same name.
#pragma csect(CODE,"TRJ9ZTreeEvalBase#C")
#pragma csect(STATIC,"TRJ9ZTreeEvalBase#S")
#pragma csect(TEST,"TRJ9ZTreeEvalBase#T")

#include <algorithm>
#include <limits.h>
#include <math.h>
#include <stdint.h>
#include "j9.h"
#include "j9cfg.h"
#include "j9consts.h"
#include "j9modron.h"
#include "thrdsup.h"
#include "thrtypes.h"
#include "codegen/AheadOfTimeCompile.hpp"
#include "codegen/CodeGenerator.hpp"
#include "codegen/CodeGenerator_inlines.hpp"
#include "codegen/Machine.hpp"
#include "codegen/TreeEvaluator.hpp"
#include "compile/ResolvedMethod.hpp"
#include "compile/VirtualGuard.hpp"
#include "env/CompilerEnv.hpp"
#include "env/IO.hpp"
#include "env/jittypes.h"
#include "env/VMJ9.h"
#include "il/DataTypes.hpp"
#include "il/Node.hpp"
#include "il/Node_inlines.hpp"
#include "il/Symbol.hpp"
#include "il/TreeTop.hpp"
#include "il/TreeTop_inlines.hpp"
#include "il/symbol/LabelSymbol.hpp"
#include "il/symbol/MethodSymbol.hpp"
#include "il/symbol/ResolvedMethodSymbol.hpp"
#include "il/symbol/RegisterMappedSymbol.hpp"
#include "il/symbol/ParameterSymbol.hpp"
#include "il/symbol/StaticSymbol.hpp"
#include "infra/Bit.hpp"
#include "ras/Delimiter.hpp"
#include "ras/DebugCounter.hpp"
#include "trj9/env/VMJ9.h"
#include "trj9/z/codegen/J9S390PrivateLinkage.hpp"
#include "trj9/z/codegen/J9S390Snippet.hpp"
#include "trj9/z/codegen/J9S390CHelperLinkage.hpp"
#include "z/codegen/BinaryCommutativeAnalyser.hpp"
#include "z/codegen/S390J9CallSnippet.hpp"
#include "z/codegen/ForceRecompilationSnippet.hpp"
#include "z/codegen/ReduceSynchronizedFieldLoad.hpp"
#include "z/codegen/S390Evaluator.hpp"
#include "z/codegen/S390GenerateInstructions.hpp"
#include "z/codegen/S390HelperCallSnippet.hpp"
#include "z/codegen/S390Instruction.hpp"
#include "z/codegen/S390Recompilation.hpp"
#include "z/codegen/TRSystemLinkage.hpp"
#include "runtime/J9Profiler.hpp"
#include "z/codegen/S390Register.hpp"

//#define TRACE_EVAL
#if defined(TRACE_EVAL)
//
// this is a handy thing to turn on if you want to figure out what the common
// code generator is mapping nodes to and what is really being driven through
// evaluation.
// It is not on by default (too noisy and expensive) but can be enabled
// by just defining TRACE_EVAL for this file
//
// If we wanted to enable this by default, it would make sense to create a
// new 'phase' for debugging that could be queried and to have the macro
// be a test of the tracing before making a function call out, e.g.
// instead of PRINT_ME(...) we would have:
// if (compilation->getOutFile() != NULL && compilation->getTraceEval())
//   {
//     print("iadd", compilation->getOutFile());
//   }
// and then traceEval would be a forced no-inline method
//
// Add another version of PRINT_ME, undef EVAL_BLOCK to go back to the old one
#define EVAL_BLOCK
#if defined (EVAL_BLOCK)
#define PRINT_ME(string,node,cg) TR::Delimiter evalDelimiter(cg->comp(), cg->comp()->getOption(TR_TraceCG), "EVAL", string)
#else
void
PRINT_ME(char * string, TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Compilation * compilation = cg->comp();
   TR::FILE *outFile = compilation->getOutFile();
   if (outFile != NULL)
      {
      diagnostic("EVAL: %s\n", string);
      }
   }
#endif
#else
#define PRINT_ME(string,node,cg)
#endif

#define INSN_HEAP cg->trHeapMemory()

/*
 * List of functions that is needed by J9 Specific Evaluators that were moved from codegen.
 * Since other evaluators in codegen still calls these, extern here in order to call them.
 */
extern void updateReferenceNode(TR::Node * node, TR::Register * reg);
extern void killRegisterIfNotLocked(TR::CodeGenerator * cg, TR::RealRegister::RegNum reg, TR::Instruction * instr , TR::RegisterDependencyConditions * deps = NULL);
extern TR::Register * iDivRemGenericEvaluator(TR::Node * node, TR::CodeGenerator * cg, bool isDivision, TR::MemoryReference * divchkDivisorMR);
extern TR::Instruction * generateS390CompareOps(TR::Node * node, TR::CodeGenerator * cg, TR::InstOpCode::S390BranchCondition fBranchOpCond, TR::InstOpCode::S390BranchCondition rBranchOpCond, TR::LabelSymbol * targetLabel);


/* Moved from Codegen to FE */
///////////////////////////////////////////////////////////////////////////////////
// Generate code to perform a comparisson and branch to a snippet.
// This routine is used mostly by bndchk evaluator.
//
// The comparisson type is determined by the choice of CMP operators:
//   - fBranchOp:  Operator used for forward operation ->  A fCmp B
//   - rBranchOp:  Operator user for reverse operation ->  B rCmp A <=> A fCmp B
//
// TODO - avoid code duplication, this routine may be able to merge with the one
//        above which has the similiar logic.
///////////////////////////////////////////////////////////////////////////////////
TR::Instruction *
generateS390CompareBranchLabel(TR::Node * node, TR::CodeGenerator * cg, TR::InstOpCode::Mnemonic branchOp, TR::InstOpCode::S390BranchCondition fBranchOpCond, TR::InstOpCode::S390BranchCondition rBranchOpCond,
   TR::LabelSymbol * label)
   {
   return generateS390CompareOps(node, cg, fBranchOpCond, rBranchOpCond, label);
   }

/* Moved from Codegen to FE since only wrtbarEvaluator calls this function */
static TR::Register *
allocateWriteBarrierInternalPointerRegister(TR::CodeGenerator * cg, TR::Node * sourceChild)
   {
   TR::Register * sourceRegister;

   if (sourceChild->getRegister() != NULL && !cg->canClobberNodesRegister(sourceChild))
      {
      if (!sourceChild->getRegister()->containsInternalPointer())
         {
         sourceRegister = cg->allocateCollectedReferenceRegister();
         }
      else
         {
         sourceRegister = cg->allocateRegister();
         sourceRegister->setPinningArrayPointer(sourceChild->getRegister()->getPinningArrayPointer());
         sourceRegister->setContainsInternalPointer();
         }
      generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), sourceChild, sourceRegister, sourceChild->getRegister());
      }
   else
      {
      sourceRegister = cg->evaluate(sourceChild);
      }

   return sourceRegister;
   }


extern TR::Register *
doubleMaxMinHelper(TR::Node *node, TR::CodeGenerator *cg, bool isMaxOp)
   {
   TR_ASSERT(node->getNumChildren() >= 1  || node->getNumChildren() <= 2, "node has incorrect number of children");

   /* ===================== Allocating Registers  ===================== */

   TR::Register      * v16           = cg->allocateRegister(TR_VRF);
   TR::Register      * v17           = cg->allocateRegister(TR_VRF);
   TR::Register      * v18           = cg->allocateRegister(TR_VRF);

   /* ===================== Generating instructions  ===================== */

   /* ====== LD FPR0,16(GPR5)       Load a ====== */
   TR::Register      * v0      = cg->fprClobberEvaluate(node->getFirstChild());

   /* ====== LD FPR2, 0(GPR5)       Load b ====== */
   TR::Register      * v2      = cg->evaluate(node->getSecondChild());

   /* ====== WFTCIDB V16,V0,X'F'     a == NaN ====== */
   generateVRIeInstruction(cg, TR::InstOpCode::VFTCI, node, v16, v0, 0xF, 8, 3);

   /* ====== For Max: WFCHE V17,V0,V2     Compare a >= b ====== */
   if(isMaxOp)
      {
      generateVRRcInstruction(cg, TR::InstOpCode::VFCH, node, v17, v0, v2, 0, 8, 3);
      }
   /* ====== For Min: WFCHE V17,V0,V2     Compare a <= b ====== */
   else
      {
      generateVRRcInstruction(cg, TR::InstOpCode::VFCH, node, v17, v2, v0, 0, 8, 3);
      }

   /* ====== VO V16,V16,V17     (a >= b) || (a == NaN) ====== */
   generateVRRcInstruction(cg, TR::InstOpCode::VO, node, v16, v16, v17, 0, 0, 0);

   /* ====== For Max: WFTCIDB V17,V0,X'800'     a == +0 ====== */
   if(isMaxOp)
    {
       generateVRIeInstruction(cg, TR::InstOpCode::VFTCI, node, v17, v0, 0x800, 8, 3);
    }
   /* ====== For Min: WFTCIDB V17,V0,X'400'     a == -0 ====== */
   else
    {
       generateVRIeInstruction(cg, TR::InstOpCode::VFTCI, node, v17, v0, 0x400, 8, 3);
    }
   /* ====== WFTCIDB V18,V2,X'C00'       b == 0 ====== */
   generateVRIeInstruction(cg, TR::InstOpCode::VFTCI, node, v18, v2, 0xC00, 8, 3);

   /* ====== VN V17,V17,V18     (a == -0) && (b == 0) ====== */
   generateVRRcInstruction(cg, TR::InstOpCode::VN, node, v17, v17, v18, 0, 0, 0);

   /* ====== VO V16,V16,V17     (a >= b) || (a == NaN) || ((a == -0) && (b == 0)) ====== */
   generateVRRcInstruction(cg, TR::InstOpCode::VO, node, v16, v16, v17, 0, 0, 0);

   /* ====== VSEL V0,V0,V2,V16 ====== */
   generateVRReInstruction(cg, TR::InstOpCode::VSEL, node, v0, v0, v2, v16);

   /* ===================== Deallocating Registers  ===================== */
   cg->stopUsingRegister(v2);
   cg->stopUsingRegister(v16);
   cg->stopUsingRegister(v17);
   cg->stopUsingRegister(v18);

   node->setRegister(v0);

   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());

   return node->getRegister();
   }


/**
 * This evaluator is used to perform string toUpper and toLower conversion.
 *
 * This JIT HW optimized conversion helper is deisgned to convert strings that contains only valid characters, as
 * specified by the ranges below:
 *
 * 1. Lower case English letters a-z [0x61, 0x7a] and their corresponding A-Z range [0x41, 0x5a]
 * 2. Lower case Latin letters [0xe0, 0xfe], excluding the multiplication sign 0xf7. The corresponding capital Latin letters are in [0xc0, 0xde] excluding the division sign 0xd7
 *
 * Invalid char range is defined as:
 * A). For both toUpper and toLower conversion, a string contains invalid char if it contains anything above 0x00ff.
 *
 * If a string contains characters (char above 0x00fe), HW optimized routine will return NULL and fall back to the software implementation, which is able to convert a broader range of characters.
 *
 * This helper is broken up into 6 sections:
 * 1. Setup
 *       Registers
 *       Ranges for vector char search
 *       Dependencies
 *       Zero out registers
 * 2. Length calculations
 *       Align to 16
 *       Get residue (if any)
 * 3. Process residue (since < 16 is probably the most common case)
 * 4. Process 16 bytes at a time in a loop
 * 5. Handle invalid codepoints
 * 6. Cleanup
 *
 * This does not support discontiguous arrays (..no reason we can't) and the check is done in ILGen/Walker
 */
extern TR::Register *
caseConversionHelper(TR::Node *node, TR::CodeGenerator *cg, bool isToUpper, bool isCompressedString)
   {
   #define iComment(str) if (debug) debug->addInstructionComment(cursor, (str));

   // Usually just 2 children...
   TR_ASSERT(node->getNumChildren() >= 1  || node->getNumChildren() <= 2, "node has incorrect number of children");


   /* ===================== Step 1: SETUP  =====================*/


   TR::Register      * rSrcBase      = cg->evaluate(node->getFirstChild());      // Source object
   TR::Register      * rTgtBase      = cg->evaluate(node->getSecondChild());     // Target object

   TR::Register      * rSrcValIdx    = cg->allocateRegister();                   // Used to iterate over input (and output since they overlap)
   TR::Register      * rSrcVal       = cg->allocateRegister();                   // The actual char array storing the contents of j.l.S.value of input String
   TR::Register      * rTgtVal       = cg->allocateRegister();                   // The actual char array storing the contents of j.l.S.value of output String

   TR::Register      * rLen          = cg->allocateRegister();                   // Number of code-points j.l.S.value.length. Not to be confused with length of the String
   TR::Register      * rResidue      = cg->allocateRegister();                   // Residue after alignment of length to 16
   TR::Register      * rLoopCounter    = rLen;

   TR::Register      * vTmp          = cg->allocateRegister(TR_VRF);             // Temp buffer to store result of VSTRC
   TR::Register      * vCaseBuf      = cg->allocateRegister(TR_VRF);             // upper or lower case depending on context
   TR::Register      * vBuf          = cg->allocateRegister(TR_VRF);             // Temp buffer used to store output of upper/lower case conversion
   TR::Register      * vAlphaRange   = cg->allocateRegister(TR_VRF);             // Alpha range char: the upper/lower limit that VSTRC should be used for comparison
   TR::Register      * vAlphaCntrl   = cg->allocateRegister(TR_VRF);             // Alpha range control : the control bits (refer to zPoPs) to let VSTRC know what kind of comparison to make (lt/gt/eq etc)
   TR::Register      * vInvalidRange = cg->allocateRegister(TR_VRF);             // Invalid code-point range: the "mu" code-point and everyone above 0xFE
   TR::Register      * vInvalidCntrl = cg->allocateRegister(TR_VRF);             // Invalid code-point control
   TR::Register      * vOffset       = cg->allocateRegister(TR_VRF);             // Constant positive integral offset between upper/lower code-points for Unicode

   TR_Debug          * debug         = cg->getDebug();
   TR::Compilation   * comp          = cg->comp();

   const int          sizeOfVector                  = 16;                        // in Bytes. Should really make this dynamic (i.e read from some machine() query since this can increase in future)
   const int          numPostDeps                   = 15;
   const int          caseOffset                    = 0x20;
   const int          elementSizeMask               = (isCompressedString) ? 0x0 : 0x1;    // byte or halfword

   TR::Instruction*   cursor                        = NULL;
   bool               usesCompressedrefs            = comp->useCompressedPointers();
   int32_t            shiftAmount                   = TR::Compiler->om.compressedReferenceShift();
   const int          offsetOfContigField           = cg->fej9()->getOffsetOfContiguousArraySizeField();
   const int          offsetOfDiscontigField        = cg->fej9()->getOffsetOfDiscontiguousArraySizeField();
   const bool         is64                          = TR::Compiler->target.is64Bit();

   TR::RegisterDependencyConditions * regDeps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, numPostDeps, cg);

   regDeps->addPostCondition(rSrcVal       ,TR::RealRegister::AssignAny);
   regDeps->addPostCondition(rSrcBase      ,TR::RealRegister::AssignAny);
   regDeps->addPostCondition(rTgtBase      ,TR::RealRegister::AssignAny);
   regDeps->addPostCondition(rTgtVal       ,TR::RealRegister::AssignAny);
   regDeps->addPostCondition(rSrcValIdx    ,TR::RealRegister::AssignAny);

   regDeps->addPostCondition(rLen          ,TR::RealRegister::AssignAny);
   regDeps->addPostCondition(rResidue      ,TR::RealRegister::AssignAny);

   regDeps->addPostCondition(vTmp          ,TR::RealRegister::AssignAny);
   regDeps->addPostCondition(vCaseBuf      ,TR::RealRegister::AssignAny);
   regDeps->addPostCondition(vBuf          ,TR::RealRegister::AssignAny);

   regDeps->addPostCondition(vOffset       ,TR::RealRegister::AssignAny);
   regDeps->addPostCondition(vAlphaRange   ,TR::RealRegister::AssignAny);
   regDeps->addPostCondition(vAlphaCntrl   ,TR::RealRegister::AssignAny);

   regDeps->addPostCondition(vInvalidRange ,TR::RealRegister::AssignAny);
   regDeps->addPostCondition(vInvalidCntrl ,TR::RealRegister::AssignAny);

   if (cg->supportsHighWordFacility() &&
           !comp->getOption(TR_DisableHighWordRA) &&
           TR::Compiler->target.is64Bit())
      {
      rResidue->setIs64BitReg(true);
      rLen->setIs64BitReg(true);
      rSrcValIdx->setIs64BitReg(true);
      rTgtVal->setIs64BitReg(true);
      rSrcVal->setIs64BitReg(true);
      }

   // byte [] java.lang.String.value   the raw byte array
   // int     java.lang.String.count   the count i.e num of characters. A Unicode point is 1 character. Surrogate's are 2 characters.
   // valueConentOffset                the offset of actual content in a char array.
   int32_t stringValOffset, stringCountOffset, valueContentOffset;

   // TODO (Filip): This is a workaround for Java 829 performance as we switched to using a byte[] backing array in String*. Remove this workaround once obsolete.
   TR_OpaqueClassBlock *stringClass = cg->fej9()->getClassFromSignature("Ljava/lang/String;", strlen("Ljava/lang/String;"), comp->getCurrentMethod(), true);

   if (cg->fej9()->getInstanceFieldOffset(stringClass, "value", "[B") != ~0)
      {
      stringValOffset = cg->fej9()->getInstanceFieldOffsetIncludingHeader("Ljava/lang/String;", "value", "[B", comp->getCurrentMethod());
      }
   else
      {
      stringValOffset = cg->fej9()->getInstanceFieldOffsetIncludingHeader("Ljava/lang/String;", "value", "[C", comp->getCurrentMethod());
      }

   stringCountOffset  = cg->fej9()->getInstanceFieldOffsetIncludingHeader("Ljava/lang/String;", "count", "I" , comp->getCurrentMethod());
   valueContentOffset = TR::Compiler->om.contiguousArrayHeaderSizeInBytes();

   TR::LabelSymbol * processNext16Bytes = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * doneLabel          = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * handleInvalidChars = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * coreLoopSetup      = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   // Load this.value for source string and target string
   if (usesCompressedrefs)
      {
      cursor =               generateRXInstruction          (cg, TR::InstOpCode::LLGF, node, rSrcVal, generateS390MemoryReference(rSrcBase, stringValOffset, cg));
      if (shiftAmount != 0 ) generateRSInstruction          (cg, TR::InstOpCode::SLLG, node, rSrcVal, rSrcVal, shiftAmount);

      cursor =               generateRXInstruction          (cg, TR::InstOpCode::LLGF, node, rTgtVal, generateS390MemoryReference(rTgtBase, stringValOffset, cg));
      if (shiftAmount != 0 ) generateRSInstruction          (cg, TR::InstOpCode::SLLG, node, rTgtVal, rTgtVal, shiftAmount);
      }
   else
      {
      cursor =               generateRXInstruction          (cg, TR::InstOpCode::getLoadOpCode(), node, rSrcVal, generateS390MemoryReference(rSrcBase, stringValOffset, cg));
      cursor =               generateRXInstruction          (cg, TR::InstOpCode::getLoadOpCode(), node, rTgtVal, generateS390MemoryReference(rTgtBase, stringValOffset, cg));
      }                                                                                                                                                                                iComment("<- output.value");

   // Load this.count. Skip 0 check since since that in done in Java
   cursor =                  generateRXInstruction          (cg, is64 ? TR::InstOpCode::LLGF : TR::InstOpCode::L, node, rLen, generateS390MemoryReference(rSrcBase, stringCountOffset, cg));                     iComment("<- input.count");

   // Bail out if string is larger than INT_MAX32/2 since # string to # byte conversion will cause overflow.
   // We could have used 64 bit reg instructions and reg for 31bit JVM with proper sign/zero extension,
   // but using this keeps the icache footprint down by a little bit. Also enables us to use the HPRs.
   if (!is64)
      {
      cursor =               generateRIInstruction          (cg, TR::InstOpCode::TMLH, node, rLen, (uint16_t) 0x8000);
      cursor =               generateS390BranchInstruction  (cg, TR::InstOpCode::BRC , TR::InstOpCode::COND_MASK2, node, handleInvalidChars);
      cursor->setStartInternalControlFlow();
      }

   // Update output.count
   cursor =                  generateRXInstruction          (cg, TR::InstOpCode::ST, node, rLen, generateS390MemoryReference(rTgtBase, stringCountOffset, cg));                                              iComment("<- output.count");

   // Conservatively zero out the ranges but we definitely need to zero out the control.
                             generateVRIaInstruction		(cg, TR::InstOpCode::VGBM, node, vAlphaRange  , 0, 0 /*unused*/);
                             generateVRIaInstruction		(cg, TR::InstOpCode::VGBM, node, vAlphaCntrl  , 0, 0 /*unused*/);
                             generateVRIaInstruction		(cg, TR::InstOpCode::VGBM, node, vInvalidCntrl, 0, 0 /*unused*/);
                             generateVRIaInstruction		(cg, TR::InstOpCode::VGBM, node, vInvalidRange, 0, 0 /*unused*/);


   /* ===================== Step 1: Setup  (alphabet and control ranges) =====================*/
   /*
    * alphaRange   = isToUpper ? 0x0061007a00e000f600f800feL : 0x0041005a00c000d600d800deL;
    * alphaCntrl   =             0xa000c000a000c00000a000c0L;
    *
    * invalidRange =             0x00ff00ff00000000L
    * invalidCntrl =             0x2000200000000000L
    *
    *  This works like x <= val AND val <= y OR m <= val AND val <= n where x, y, m, n are valid alphabet range chars and
    *  val = any element sized val in vector buffer
    *  For the invalid case, we do p = val OR p > q; where p and q are the invalid ranges and val = any element sized val in vector buffer
    *
    *  The following vAlphaRange, vInvalidRange, and vAlphaCntrl setup instructions load 16 byte ranges used for
    *  our VSTRC's without reading from memory.
    *  Encode ranges within the instructions instead of loading from memory since that will need relocation for AOT
    *  Problem with this setup is the inability to reduce WAW's by annulling in h/w.
    */
   cursor =                  generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vAlphaRange, isToUpper ? 0x617a : 0x415a, 0x0);
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vAlphaRange, isToUpper ? 0xe0f6 : 0xc0d6, 0x1);
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vAlphaRange, isToUpper ? 0xf8fe : 0xd8de, 0x2);       iComment("alphabet ranges");
   if(!isCompressedString)
      {
                             generateVRRaInstruction        (cg, TR::InstOpCode::VUPLH, node, vAlphaRange, vAlphaRange, 0, 0, 0, 0);
      }

   if(isCompressedString)
      {
      cursor =               generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vAlphaCntrl, 0xa0c0, 0x0);            iComment("alphabet control. >='s and <='s");
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vAlphaCntrl, 0xa0c0, 0x1);
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vAlphaCntrl, 0xa0c0, 0x2);
      }
   else
      {
      cursor =               generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vAlphaCntrl, 0xa000, 0x0);            iComment("alphabet control. >='s and <='s");
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vAlphaCntrl, 0xc000, 0x1);
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vAlphaCntrl, 0xa000, 0x2);
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vAlphaCntrl, 0xc000, 0x3);
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vAlphaCntrl, 0xa000, 0x4);
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vAlphaCntrl, 0xc000, 0x5);
      }

   // Can't toUpper \u00df (capital sharp s) nor \u00b5 (mu). Applicable to both compressed and decompressed toUpper.
   // \u00df  toUpper becomes -> \u0053 \u0053
   // \u00b5  toUpper becomes -> \u039c
   if(isToUpper && isCompressedString)
      {
       // Compressed string toUpper
       cursor =              generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidRange, 0xdfdf, 0x0);         iComment("invalid alphabet range");
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidRange, 0xb5b5, 0x1);

       cursor =              generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidCntrl, 0x8080, 0x0);           iComment("invalid alphabet range control");
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidCntrl, 0x8080, 0x1);
      }
   else if(isToUpper && !isCompressedString)
      {
       // Decompressed string toUpper
       cursor =              generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidRange, 0xdfdf, 0x0);          iComment("invalid alphabet range");
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidRange, 0xb5b5, 0x1);
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidRange, 0xffff, 0x2);
                             generateVRRaInstruction        (cg, TR::InstOpCode::VUPLH, node, vInvalidRange, vInvalidRange, 0, 0, 0, 0);


       cursor =              generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidCntrl, 0x8000, 0x0);           iComment("invalid alphabet range control");
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidCntrl, 0x8000, 0x1);
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidCntrl, 0x8000, 0x2);
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidCntrl, 0x8000, 0x3);
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidCntrl, 0x2000, 0x4);
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidCntrl, 0x2000, 0x5);
      }
   else if(!isToUpper && !isCompressedString)
      {
       // Decompressed strings toLower. Only need to make sure that no character is above 0xff
      cursor =               generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidRange, 0x00ff, 0x0);              iComment("invalid alphabet range");
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidRange, 0x00ff, 0x1);

      cursor =               generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidCntrl, 0x2000, 0x0);              iComment("invalid alphabet control");
                             generateVRIaInstruction        (cg, TR::InstOpCode::VLEIH, node, vInvalidCntrl, 0x2000, 0x1);
      }

   // Constant used to convert to upper/lower for Unicode code-points. This is a vector of halfwords 0x0020.
   cursor =                  generateVRIaInstruction        (cg, TR::InstOpCode::VREPI, node, vOffset, static_cast<uint16_t>(caseOffset), elementSizeMask);         iComment("offset to add/subtract lower<->upper conv");


   /* ===================== Step 2: Length calculations (rResidue and 16-byte alignment) =====================*/


   // Add string val offset to save additions in core loop
   cursor =                  generateRXInstruction          (cg, TR::InstOpCode::getLoadAddressOpCode(), node, rSrcVal, generateS390MemoryReference(rSrcVal, NULL, valueContentOffset, cg), cursor);    iComment("source.val += strValOffset + source.offset");
   cursor =                  generateRXInstruction          (cg, TR::InstOpCode::getLoadAddressOpCode(), node, rTgtVal, generateS390MemoryReference(rTgtVal, valueContentOffset, cg), cursor);          iComment("tgt.val += strValOffset");

   // The core loop works in multiples of 16 so we need to align the length to 16, and also load the rResidue so we can operate on them separately
   if(!isCompressedString)
      {
       // convert num_of_char to num_of_bytes we need to process
      cursor =               generateRSInstruction          (cg, TR::InstOpCode::getShiftLeftLogicalSingleOpCode(), node, rLen, rLen, 1);                                                                  iComment("string length : char -> bytes");
      }
   cursor =                  generateRRInstruction          (cg, TR::InstOpCode::getLoadRegOpCode(), node, rResidue, rLen);
   cursor =                  generateRILInstruction         (cg, TR::InstOpCode::NILF, node, rResidue, 0xF);                                                                                                 iComment("calc residue (can eq length if length < 16)");
   cursor =                  generateS390BranchInstruction  (cg, TR::InstOpCode::BRC , TR::InstOpCode::COND_BZ, node, coreLoopSetup);                                                                            iComment("len perfect multiple of 16, goto main loop (rare)");

   // We already set start ICF at the branch after the TMLH so don't do it here, to prevent nested ICF issues
   if (is64)
      cursor->setStartInternalControlFlow();

   // VLL and VSTL are provided with an index not with a count (length) so we need to offset by 1.
   cursor =                 generateRILInstruction          (cg, TR::InstOpCode::getSubtractLogicalImmOpCode(), node, rResidue, 1);                                                                         iComment("adjust residue for VLL/VSTL (length -> index)");

   /* ===================== Step 3: Residue processing =====================*/


   // This is the core case conv logic. Since we unroll the loop to a multiple of 16, we need to handle residue here.
   // Residue is also length if length < 16
   // We could have handled residue in the hot-loop by using VSTL always, but that comes at the expense of having a VLGV + mul x 2 in the hot-path

   // Process residue
   cursor =                  generateVRSbInstruction        (cg, TR::InstOpCode::VLL, node, vBuf, rResidue, generateS390MemoryReference(rSrcVal, 0, cg));                                                    iComment("====== PROCESS RESIDUE ======");

   // Check for invalid characters
   if(!isCompressedString)
      {
      cursor =               generateVRRdInstruction        (cg, TR::InstOpCode::VSTRC, node, vTmp, vBuf, vInvalidRange, vInvalidCntrl, 0x1, elementSizeMask);                                                           iComment("check for invalid codepoints");
      cursor =               generateS390BranchInstruction  (cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_CC1, node, handleInvalidChars);
      }

   // Check for alphabets that whose case we can convert
   cursor =                  generateVRRdInstruction        (cg, TR::InstOpCode::VSTRC, node, vTmp, vBuf, vAlphaRange, vAlphaCntrl, 0x4, elementSizeMask);                                                               iComment("search for case to convert");
   cursor =                  generateVRRcInstruction        (cg, isToUpper ? TR::InstOpCode::VS : TR::InstOpCode::VA, node, vCaseBuf, vBuf, vOffset, 0x0, 0x0, elementSizeMask);                                             iComment("offset for case conversion");

   // Merge the case converted characters with the non-case converted characters and write to output String
   cursor =                  generateVRReInstruction        (cg, TR::InstOpCode::VSEL, node, vCaseBuf, vCaseBuf, vBuf, vTmp);                                                                                iComment("only replace converted chars");
   cursor =                  generateVRSbInstruction        (cg, TR::InstOpCode::VSTL, node, vCaseBuf, rResidue, generateS390MemoryReference(rTgtVal, 0, cg), 0);

   // If len =< 16 then we're done else continue to main loop that does 16 byte at a time
   cursor =                  generateRIEInstruction         (cg, is64 ? TR::InstOpCode::CGIJ : TR::InstOpCode::CIJ, node, rLen, (int8_t) sizeOfVector, doneLabel, TR::InstOpCode::COND_BNH);                         iComment("len <= 16 ? we're done..")
   cursor =                  generateRILInstruction         (cg, is64 ? TR::InstOpCode::ALGFI : TR::InstOpCode::ALFI, node, rResidue, 1);                                                                        iComment("re-adjust residue for VLL/VSTL (length -> index)");

   /* ===================== Step 4.0: Setup for core-loop =====================*/

   // lazy evaluation done for loop counter since it isn't needed for strlen < 16
   cursor =                  generateS390LabelInstruction   (cg, TR::InstOpCode::LABEL, node, coreLoopSetup);                                                                                                iComment("====== LOOP SETUP ======");
   cursor =                  generateRSInstruction          (cg, TR::InstOpCode::getShiftRightLogicalSingleOpCode(), node, rLen, rLen, 4);                                                 iComment("reduce len to multiple of 16 (loop counter)");

   // We do this so we can move src index and target index together. It also saves the need of an additional register at the cost of an extra cycle.
   // The index will begin at 0 and increment in multiples of 16
   cursor =                  generateRXInstruction          (cg, TR::InstOpCode::getLoadAddressOpCode(), node, rSrcVal, generateS390MemoryReference(rSrcVal, rResidue, 0, cg));                            iComment("source.val += residue");
   cursor =                  generateRXInstruction          (cg, TR::InstOpCode::getLoadAddressOpCode(), node, rTgtVal, generateS390MemoryReference(rTgtVal, rResidue, 0 ,cg));                            iComment("tgt.val += residue");

   // Start with index=0 into the src array
   cursor =                  generateRRInstruction          (cg, TR::InstOpCode::getXORRegOpCode(), node, rSrcValIdx, rSrcValIdx);                                                                         iComment("reset srx/tgt index");

   /* ===================== Step 4: Core loop - 16 byte at a time processing =====================*/

   cursor =                  generateS390LabelInstruction   (cg, TR::InstOpCode::LABEL, node, processNext16Bytes);                                                                                           iComment("====== CORE LOOP ======");
   cursor =                  generateVRXInstruction         (cg, TR::InstOpCode::VL, node, vBuf, generateS390MemoryReference(rSrcVal, rSrcValIdx, 0, cg));

   // Check for invalid characters
   if(!isCompressedString)
      {
      cursor =               generateVRRdInstruction        (cg, TR::InstOpCode::VSTRC, node, vTmp, vBuf, vInvalidRange, vInvalidCntrl, 0x1 , elementSizeMask);                                                          iComment("check for invalid codepoints");
      cursor =               generateS390BranchInstruction  (cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_CC1, node, handleInvalidChars);
      }

   // Check for alphabets whose case we can convert
   cursor =                  generateVRRdInstruction        (cg, TR::InstOpCode::VSTRC, node, vTmp, vBuf, vAlphaRange, vAlphaCntrl, 0x4, elementSizeMask);                                                               iComment("search for case to convert");
   cursor =                  generateVRRcInstruction        (cg, isToUpper ? TR::InstOpCode::VS : TR::InstOpCode::VA, node, vCaseBuf, vBuf, vOffset, 0x0, 0x0, elementSizeMask);                                             iComment("offset for case conversion");

   // Merge the case converted characters with the non-case converted characters and write to output String
   cursor =                  generateVRReInstruction        (cg, TR::InstOpCode::VSEL, node, vCaseBuf, vCaseBuf, vBuf, vTmp);                                                                                iComment("only replace converted chars");
   cursor =                  generateVRXInstruction         (cg, TR::InstOpCode::VST, node, vCaseBuf, generateS390MemoryReference(rTgtVal, rSrcValIdx, 0, cg), 0, cursor);

   // Increment source index by 16, decrement loop counter by 1 and start over if needed
   cursor =                  generateRXInstruction          (cg, TR::InstOpCode::getLoadAddressOpCode(), node, rSrcValIdx, generateS390MemoryReference(rSrcValIdx, sizeOfVector, cg), cursor);             iComment("src/dst index + = 16");
   cursor =                  generateS390BranchInstruction  (cg, TR::InstOpCode::BRCT, node, rLoopCounter, processNext16Bytes);                                                                              iComment("iter-- and branch if not 0");

   cursor =                  generateS390BranchInstruction  (cg, TR::InstOpCode::BRC , TR::InstOpCode::COND_BRC, node, doneLabel);                                                                               iComment("skip over invalid char handling");

   /* ===================== Step 5: Invalid codepoint (and discontiguous array) handling - return null reference to Java =====================*/

   cursor =                  generateS390LabelInstruction   (cg, TR::InstOpCode::LABEL, node, handleInvalidChars);                                                                                           iComment("====== INVALID CHAR HANDLING ======");
   cg->generateDebugCounter(isToUpper? "z13/simd/toUpper/null" : "z13/simd/toLower/null", 1, TR::DebugCounter::Cheap);

   cursor =                  generateRRInstruction          (cg, TR::InstOpCode::getXORRegOpCode(), node, rTgtBase, rTgtBase);


   /* ===================== Step 6: Done - Perform cleanup =====================*/

   cursor =                  generateS390LabelInstruction   (cg, TR::InstOpCode::LABEL, node, doneLabel);
   cursor->setEndInternalControlFlow();
   cursor->setDependencyConditions(regDeps);

   cg->stopUsingRegister(rSrcVal);
   cg->stopUsingRegister(rTgtVal);
   cg->stopUsingRegister(rSrcValIdx);

   cg->stopUsingRegister(rLen);
   cg->stopUsingRegister(rResidue);

   cg->stopUsingRegister(vTmp);
   cg->stopUsingRegister(vCaseBuf);
   cg->stopUsingRegister(vBuf);
   cg->stopUsingRegister(vAlphaRange);
   cg->stopUsingRegister(vOffset);
   cg->stopUsingRegister(vAlphaCntrl);
   cg->stopUsingRegister(vInvalidRange);
   cg->stopUsingRegister(vInvalidCntrl);


   node->setRegister(rTgtBase);

   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());

   return node->getRegister();
   #undef iComment
   }

extern TR::Register *
inlineToUpper(TR::Node *node, TR::CodeGenerator *cg, bool isCompressedString)
   {
   cg->generateDebugCounter("z13/simd/toUpper", 1, TR::DebugCounter::Free);
   return caseConversionHelper(node, cg, true, isCompressedString);
   }

extern TR::Register *
inlineToLower(TR::Node *node, TR::CodeGenerator *cg, bool isCompressedString)
   {
   cg->generateDebugCounter("z13/simd/toLower", 1, TR::DebugCounter::Free);
   return caseConversionHelper(node, cg, false, isCompressedString);
   }

extern TR::Register *
inlineDoubleMax(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->generateDebugCounter("z13/simd/doubleMax", 1, TR::DebugCounter::Free);
   return doubleMaxMinHelper(node, cg, true);
   }

extern TR::Register *
inlineDoubleMin(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->generateDebugCounter("z13/simd/doubleMin", 1, TR::DebugCounter::Free);
   return doubleMaxMinHelper(node, cg, false);
   }


/*
 * J9 S390 specific tree evaluator table overrides
 */
extern void TEMPORARY_initJ9S390TreeEvaluatorTable(TR::CodeGenerator *cg)
   {
   TR_TreeEvaluatorFunctionPointer *tet = cg->getTreeEvaluatorTable();

   tet[TR::wrtbar] =                TR::TreeEvaluator::wrtbarEvaluator;
   tet[TR::wrtbari] =               TR::TreeEvaluator::iwrtbarEvaluator;
   tet[TR::monent] =                TR::TreeEvaluator::monentEvaluator;
   tet[TR::monexit] =               TR::TreeEvaluator::monexitEvaluator;
   tet[TR::monexitfence] =          TR::TreeEvaluator::monexitfenceEvaluator;
   tet[TR::asynccheck] =            TR::TreeEvaluator::asynccheckEvaluator;
   tet[TR::instanceof] =            TR::TreeEvaluator::instanceofEvaluator;
   tet[TR::checkcast] =             TR::TreeEvaluator::checkcastEvaluator;
   tet[TR::checkcastAndNULLCHK] =   TR::TreeEvaluator::checkcastAndNULLCHKEvaluator;
   tet[TR::New] =                   TR::TreeEvaluator::newObjectEvaluator;
   tet[TR::variableNew] =           TR::TreeEvaluator::newObjectEvaluator;
   tet[TR::newarray] =              TR::TreeEvaluator::newArrayEvaluator;
   tet[TR::anewarray] =             TR::TreeEvaluator::anewArrayEvaluator;
   tet[TR::variableNewArray] =      TR::TreeEvaluator::anewArrayEvaluator;
   tet[TR::multianewarray] =        TR::TreeEvaluator::multianewArrayEvaluator;
   tet[TR::arraylength] =           TR::TreeEvaluator::arraylengthEvaluator;
   tet[TR::ResolveCHK] =            TR::TreeEvaluator::resolveCHKEvaluator;
   tet[TR::DIVCHK] =                TR::TreeEvaluator::DIVCHKEvaluator;
   tet[TR::BNDCHK] =                TR::TreeEvaluator::BNDCHKEvaluator;
   tet[TR::ArrayCopyBNDCHK] =       TR::TreeEvaluator::ArrayCopyBNDCHKEvaluator;
   tet[TR::BNDCHKwithSpineCHK] =    TR::TreeEvaluator::BNDCHKwithSpineCHKEvaluator;
   tet[TR::SpineCHK] =              TR::TreeEvaluator::BNDCHKwithSpineCHKEvaluator;
   tet[TR::ArrayStoreCHK] =         TR::TreeEvaluator::ArrayStoreCHKEvaluator;
   tet[TR::ArrayCHK] =              TR::TreeEvaluator::ArrayCHKEvaluator;
   tet[TR::MethodEnterHook] =       TR::TreeEvaluator::conditionalHelperEvaluator;
   tet[TR::MethodExitHook] =        TR::TreeEvaluator::conditionalHelperEvaluator;

   tet[TR::tstart] = TR::TreeEvaluator::tstartEvaluator;
   tet[TR::tfinish] = TR::TreeEvaluator::tfinishEvaluator;
   tet[TR::tabort] = TR::TreeEvaluator::tabortEvaluator;

   }


TR::Instruction *
J9::Z::TreeEvaluator::genLoadForObjectHeaders(TR::CodeGenerator *cg, TR::Node *node, TR::Register *reg, TR::MemoryReference *tempMR, TR::Instruction *iCursor)
   {
#if defined(J9VM_INTERP_COMPRESSED_OBJECT_HEADER)
   return generateRXInstruction(cg, TR::InstOpCode::LLGF, node, reg, tempMR, iCursor);
#else
   return generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, reg, tempMR, iCursor);
#endif
   }

TR::Instruction *
J9::Z::TreeEvaluator::genLoadForObjectHeadersMasked(TR::CodeGenerator *cg, TR::Node *node, TR::Register *reg, TR::MemoryReference *tempMR, TR::Instruction *iCursor)
   {
   // Bit-mask for masking J9Object header to extract J9Class
   uint16_t mask = 0xFF00;
   TR::Compilation *comp = cg->comp();
   bool disabled = comp->getOption(TR_DisableZ13) || comp->getOption(TR_DisableZ13LoadAndMask);

#if defined(J9VM_INTERP_COMPRESSED_OBJECT_HEADER)
   if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z13) && !disabled)
      {
      iCursor = generateRXYInstruction(cg, TR::InstOpCode::LLZRGF, node, reg, tempMR, iCursor);
      cg->generateDebugCounter("z13/LoadAndMask", 1, TR::DebugCounter::Free);
      }
   else
      {
      // Zero out top 32 bits and load the unmasked J9Class
      iCursor = generateRXInstruction(cg, TR::InstOpCode::LLGF, node, reg, tempMR, iCursor);

      // Now mask it to get the actual pointer
      iCursor = generateRIInstruction(cg, TR::InstOpCode::NILL, node, reg, mask, iCursor);
      }
#else
   if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z13))
      {
      iCursor = generateRXYInstruction(cg, TR::InstOpCode::getLoadAndMaskOpCode(), node, reg, tempMR, iCursor);
      cg->generateDebugCounter("z13/LoadAndMask", 1, TR::DebugCounter::Free);
      }
   else
      {
      iCursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, reg, tempMR, iCursor);
      iCursor = generateRIInstruction(cg, TR::InstOpCode::NILL,           node, reg, mask,   iCursor);
      }
#endif

   return iCursor;
   }

// max number of cache slots used by checkcat/instanceof
#define NUM_PICS 3

static inline TR::Instruction *
genNullTest(TR::CodeGenerator * cg, TR::Node * node, TR::Register * tgtReg, TR::Register * srcReg, TR::Instruction * cursor)
   {
   TR::Instruction * iRet;

   static_assert(NULLVALUE == 0, "NULLVALUE is assumed to be zero here");
   iRet = generateRRInstruction(cg, TR::InstOpCode::getLoadTestRegOpCode(), node, tgtReg, srcReg, cursor);

   return iRet;
   }

static TR::Instruction *
genTestIsSuper(TR::CodeGenerator * cg, TR::Node * node,
   TR::Register * objClassReg, TR::Register * castClassReg,
   TR::Register * scratch1Reg, TR::Register * scratch2Reg, TR::Register * resultReg,
   TR::Register * litPoolBaseReg, int32_t castClassDepth,
   TR::LabelSymbol * failLabel, TR::LabelSymbol * trueLabel, TR::LabelSymbol * callHelperLabel,
   TR::RegisterDependencyConditions * conditions, TR::Instruction * cursor,
   bool addDataSnippetAsSecondaryCache,
   TR::Register * classObjectClazzSnippetReg,
   TR::Register * instanceOfClazzSnippetReg
   )
   {
   TR::Compilation *comp = cg->comp();
   TR_Debug * debugObj = cg->getDebug();

   int32_t superClassOffset = castClassDepth * TR::Compiler->om.sizeofReferenceAddress();
   bool outOfBound = (superClassOffset > MAX_IMMEDIATE_VAL || superClassOffset < MIN_IMMEDIATE_VAL) ? true : false;
   // For the scenario where a call to Class.isInstance() is converted to instanceof,
   // we need to load the class depth at runtime because we don't have it at compile time
   bool dynamicCastClass = (castClassDepth == -1);
   bool eliminateSuperClassArraySizeCheck = (!dynamicCastClass && (castClassDepth < cg->comp()->getOptions()->_minimumSuperclassArraySize));


#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
   // objClassReg contains the class offset, so we may need to
   // convert this offset to a real J9Class pointer
#endif
   if (dynamicCastClass)
      {
      TR::LabelSymbol * notInterfaceLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR_ASSERT((node->getOpCodeValue() == TR::instanceof &&
            node->getSecondChild()->getOpCodeValue() != TR::loadaddr), "genTestIsSuper: castClassDepth == -1 is only supported for transformed isInstance calls.");

      // check if cast class is an interface
      cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, scratch1Reg,
            generateS390MemoryReference(castClassReg, offsetof(J9Class, romClass), cg), cursor);

      cursor = generateRXInstruction(cg, TR::InstOpCode::L, node, scratch1Reg,
            generateS390MemoryReference(scratch1Reg, offsetof(J9ROMClass, modifiers), cg), cursor);


      TR_ASSERT(((J9AccInterface | J9AccClassArray) < UINT_MAX && (J9AccInterface | J9AccClassArray) > 0),
            "genTestIsSuper::(J9AccInterface | J9AccClassArray) is not a 32-bit number\n");

      cursor = generateRILInstruction(cg, TR::InstOpCode::NILF, node, scratch1Reg, (int32_t) (J9AccInterface | J9AccClassArray), cursor);

      if (debugObj)
         debugObj->addInstructionComment(cursor, "Check if castClass is an interface or class array and jump to helper sequence");

      // insert snippet check
      if ( addDataSnippetAsSecondaryCache )
         {
        cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, notInterfaceLabel, cursor);
         // classObjectClazzSnippet and instanceOfClazzSnippet stores values of currentObject and cast Object when
        // the the helper call returns success.
         // test if class is interface of not.
         // if interface, we do the following.
         //
         // insert isntanceof site snippet test
         // cmp objectClassReg, classObjectClazzSnippet
         // jne helper call
         // cmp castclassreg, instanceOfClazzSnippet
         // je true_label
         // jump to outlined label
         // test jitInstanceOf results
         // JE fail_label        // instanceof result is not true
         //
         // the following will be done at the end of instanceof evaluation when we do helperCall
         // cmp snippet1 with value -1
         // jne true_label         // snippet already updated
         // update classObjectClazzSnippet, instanceOfClazzSnippet with object class and instance of class
         // jmp true_label
         //NO need for cache test for z, if it is dynamic we will already have failed cache test if we got here.
         cursor = generateRXInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, objClassReg, generateS390MemoryReference(classObjectClazzSnippetReg,0,cg), cursor);
         cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, callHelperLabel, cursor);
         cursor = generateRXInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, castClassReg, generateS390MemoryReference(instanceOfClazzSnippetReg,0,cg), cursor);
         cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, trueLabel, cursor);
         cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, callHelperLabel, cursor);
         cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, notInterfaceLabel, cursor);
         }
      else
         {
        cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, callHelperLabel, cursor);
         }
      }


   TR::InstOpCode::Mnemonic loadOp;
   int32_t bytesOffset;

   if (TR::Compiler->target.is64Bit())
      {
      loadOp = TR::InstOpCode::LLGH;
      bytesOffset = 6;
      }
   else
      {
      loadOp = TR::InstOpCode::LLH;
      bytesOffset = 2;
      }

   if (dynamicCastClass)
      {
      cursor = generateRXInstruction(cg, loadOp, node, scratch2Reg,
            generateS390MemoryReference(castClassReg, offsetof(J9Class, classDepthAndFlags) + bytesOffset, cg), cursor);

      TR_ASSERT(sizeof(((J9Class*)0)->classDepthAndFlags) == sizeof(uintptr_t),
            "genTestIsSuper::J9Class->classDepthAndFlags is wrong size\n");
      }

   if (!eliminateSuperClassArraySizeCheck)
      {
      if (resultReg)
         {
         cursor = generateRIInstruction(cg, TR::InstOpCode::LHI, node, resultReg, 0, cursor);
         }

      cursor = generateRXInstruction(cg, loadOp, node, scratch1Reg,
            generateS390MemoryReference(objClassReg, offsetof(J9Class, classDepthAndFlags) + bytesOffset, cg) , cursor);
      TR_ASSERT(sizeof(((J9Class*)0)->classDepthAndFlags) == sizeof(uintptr_t),
                  "genTestIsSuper::J9Class->classDepthAndFlags is wrong size\n");

      bool generateCompareAndBranchIsPossible = false;

      if (dynamicCastClass)
         generateCompareAndBranchIsPossible = true;
      else if (outOfBound)
         {
         if (TR::Compiler->target.is64Bit())
            {
            cursor = genLoadLongConstant(cg, node, castClassDepth, scratch2Reg, cursor, conditions, litPoolBaseReg);
            }
         else
            {
            cursor = generateLoad32BitConstant(cg, node, castClassDepth, scratch2Reg, false, cursor, conditions, litPoolBaseReg);
            }
         generateCompareAndBranchIsPossible = true;
         }
      else
         {
         cursor = generateRIInstruction(cg, TR::InstOpCode::getCmpHalfWordImmOpCode(), node, scratch1Reg, castClassDepth, cursor);
         }

      if (generateCompareAndBranchIsPossible)
         cursor = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, scratch1Reg, scratch2Reg, TR::InstOpCode::COND_BNH, failLabel, false, false);
      else
         cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, failLabel, cursor);

      if (debugObj)
         debugObj->addInstructionComment(cursor, "Fail if depth(obj) > depth(castClass)");

      }

   if (resultReg)
      {
      cursor = generateRIInstruction(cg, TR::InstOpCode::LHI, node, resultReg, 1, cursor);
      }
#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
   // objClassReg contains the class offset, so we may need to
   // convert this offset to a real J9Class pointer
#endif
   cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, scratch1Reg,
               generateS390MemoryReference(objClassReg, offsetof(J9Class, superclasses), cg), cursor);

   if (outOfBound || dynamicCastClass)
      {
      if (TR::Compiler->target.is64Bit())
         {
         cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, scratch2Reg, scratch2Reg, 3, cursor);
         }
      else
         {
         cursor = generateRSInstruction(cg, TR::InstOpCode::SLL, node, scratch2Reg, 2, cursor);
         }
#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
      // castClassReg contains the class offset, but the memory reference below will
      // generate a J9Class pointer. We may need to convert this pointer to an offset
#endif
      cursor = generateRXInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, castClassReg,
                  generateS390MemoryReference(scratch1Reg, scratch2Reg, 0, cg), cursor);
      }
   else
      {
#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
      // castClassReg contains the class offset, but the memory reference below will
      // generate a J9Class pointer. We may need to convert this pointer to an offset
#endif
      cursor = generateRXInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, castClassReg,
                  generateS390MemoryReference(scratch1Reg, superClassOffset, cg), cursor);
      }

   if (debugObj)
      debugObj->addInstructionComment(cursor, "Check if objClass is subclass of castClass");

   return cursor;
   }

// Checks for the scenario where a call to Class.isInstance() is converted to instanceof,
// and we need to load the j9class of the cast class at runtime because we don't have it at compile time
static bool isDynamicCastClassPointer(TR::Node * castOrInstanceOfNode)
   {
   if (castOrInstanceOfNode->getOpCodeValue() == TR::instanceof)
      {
      TR::Node * castClassNode = castOrInstanceOfNode->getSecondChild();
      TR_OpaqueClassBlock* castClassAddr = TR::TreeEvaluator::getCastClassAddress(castClassNode);

      bool isUnresolved = castOrInstanceOfNode->getOpCode().hasSymbolReference() && castOrInstanceOfNode->getSymbolReference()->isUnresolved();

      // came from transformed call isInstance to node instanceof, can't resolve at compile time
      return !castClassAddr && !isUnresolved;
      }
   return false;
   }

/*
 * generate test if object class is reference array
 * testerReg = load (objectClassReg+offset_romClass)
 * andImmediate with J9AccClassArray(0x10000)
 * MASK6 failLabel(If not Array we Fail)
 * testerReg = load (objectClassReg + leafcomponent_offset)
 * testerReg = load (objectClassReg + offset_romClass)
 * testerReg = load (objectClassReg + offset_modifiers)
 * andImmediate with J9AccClassInternalPrimitiveType(0x20000)
 * MASK6 trueLabel(if equal we fail, not equal we succeed)
 */
static void genIsReferenceArrayTest(TR::Node        *node,
                                    TR::Register    *objectClassReg,
                                    TR::Register    *scratchReg1,
                                    TR::Register    *scratchReg2,
                                    TR::Register    *resultReg,
                                    TR::LabelSymbol *failLabel,
                                    TR::LabelSymbol *trueLabel,
                                    bool needsResult,
                                    bool trueFallThrough,
                                    TR::CodeGenerator *cg)
   {
      if (needsResult)
         {
            generateRIInstruction(cg, TR::InstOpCode::LHI, node, resultReg, 0);
         }
      generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, scratchReg1,
                            generateS390MemoryReference(objectClassReg, offsetof(J9Class,romClass), cg));
      generateRXInstruction(cg, TR::InstOpCode::L, node, scratchReg1,
                            generateS390MemoryReference(scratchReg1, offsetof(J9ROMClass, modifiers), cg));
      generateRILInstruction(cg, TR::InstOpCode::NILF, node, scratchReg1, J9AccClassArray);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, failLabel);

      generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, scratchReg1,
                            generateS390MemoryReference(objectClassReg, offsetof(J9ArrayClass,componentType), cg));
      generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, scratchReg1,
                            generateS390MemoryReference(scratchReg1, offsetof(J9Class,romClass), cg));
      generateRXInstruction(cg, TR::InstOpCode::L, node, scratchReg1,
                            generateS390MemoryReference(scratchReg1, offsetof(J9ROMClass, modifiers), cg));
      generateRILInstruction(cg, TR::InstOpCode::NILF, node, scratchReg1, J9AccClassInternalPrimitiveType);

      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, failLabel);
      if (needsResult)
         {
         generateRIInstruction(cg, TR::InstOpCode::LHI, node, resultReg, 1);
         }
      if (!trueFallThrough)
         {
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, trueLabel);
         }
   }
// only need a helper call if the class is not super and not final, otherwise
// it can be determined without a call-out
static bool needHelperCall(TR::Node * castOrInstanceOfNode, bool testCastClassIsSuper, bool isFinalClass)
   {
   return (!testCastClassIsSuper || isDynamicCastClassPointer(castOrInstanceOfNode)) && !isFinalClass;
   }

static bool needTestCache(bool cachingEnabled, bool needsHelperCall, bool superClassTest)
   {
   return cachingEnabled && needsHelperCall && !superClassTest;
   }

static TR::Register * establishLitPoolBaseReg(TR::Node * castOrInstanceOfNode, TR::CodeGenerator * cg)
   {
   if (castOrInstanceOfNode->getNumChildren() != 3)
      {
      return NULL;
      }
   else
      {
      TR::Node* litPoolBaseChild = castOrInstanceOfNode->getLastChild();
      TR_ASSERT((litPoolBaseChild->getOpCodeValue()==TR::aload) || (litPoolBaseChild->getOpCodeValue()==TR::aRegLoad),
         "Literal pool base child expected\n");
      return cg->evaluate(litPoolBaseChild);
      }
   }

// this is messy and a rough approximation - there can be no more than 10
// post dependencies in instance-of.
static int maxInstanceOfPostDependencies()
   {
   return 10;
   }

// similarly yucky... instanceof takes 2 parms and kills the return address
bool killedByInstanceOfHelper(int32_t regIndex, TR::Node * node, TR::CodeGenerator * cg)
   {
   if (regIndex == -1)
      {
      return false; // not mapped to a specific register
      }
   int realReg = cg->getGlobalRegister(regIndex);

#if defined(TR_TARGET_64BIT)
   bool needsHelperCall = false;
#if defined(J9ZOS390)
   if (cg->comp()->getOption(TR_EnableRMODE64))
#endif
      {
      TR::Node * castClassNode = node->getSecondChild();
      TR::SymbolReference * castClassSymRef = castClassNode->getSymbolReference();
      bool testCastClassIsSuper = TR::TreeEvaluator::instanceOfOrCheckCastNeedSuperTest(node, cg);
      bool isFinalClass = (castClassSymRef == NULL) ? false : castClassSymRef->isNonArrayFinal(cg->comp());
      needsHelperCall = needHelperCall(node, testCastClassIsSuper, isFinalClass);
      }

#endif

   if (realReg == TR::RealRegister::GPR1 ||
       realReg == TR::RealRegister::GPR2 ||
       realReg == cg->getReturnAddressRegister()
#if defined(TR_TARGET_64BIT)
       || (needsHelperCall &&
#if defined(J9ZOS390)
           cg->comp()->getOption(TR_EnableRMODE64) &&
#endif
           realReg == cg->getEntryPointRegister())
#endif
      )
      {
      return true;
      }
   else
      {
      return false;
      }
   }

static bool generateInlineTest(TR::CodeGenerator * cg, TR::Node * node, TR::Node * castClassNode,
                               TR::Register * objClassReg, TR::Register * resultReg,
                               TR::Register * scratchReg, TR::Register * litPoolReg,
                               bool needsResult, TR::LabelSymbol * falseLabel,
                               TR::LabelSymbol * trueLabel, TR::LabelSymbol * doneLabel, bool isCheckCast, int32_t maxNum_PICS = NUM_PICS)
   {
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   TR_OpaqueClassBlock* guessClassArray[NUM_PICS];
   TR_OpaqueClassBlock* castClassAddr = TR::TreeEvaluator::getCastClassAddress(castClassNode);
   uint8_t num_PICs = 0, i;

   if (!castClassAddr)
      {
      return false;
      }

   if (isCheckCast)
      {
      TR_OpaqueClassBlock *tempGuessClassArray[NUM_PICS];
      uint8_t numberOfGuessClasses = TR::TreeEvaluator::interpreterProfilingInstanceOfOrCheckCastInfo(cg, node, tempGuessClassArray);
      if (numberOfGuessClasses > 0)
         {
         for (i = 0; i < numberOfGuessClasses; i++)
            {
            if (instanceOfOrCheckCast((J9Class*)tempGuessClassArray[i], (J9Class*)castClassAddr))
               {
               guessClassArray[num_PICs++] = tempGuessClassArray[i];
               if (maxNum_PICS == num_PICs) break;
               }
            }
         }
      }
   else
      {
      num_PICs = TR::TreeEvaluator::interpreterProfilingInstanceOfOrCheckCastInfo(cg, node, guessClassArray);
      }

   // defect 92901
   // if test fails, in case of checkcast, there is no need to generate inline check for guess value
   if (num_PICs == 0)
      return false;

   bool result_bool;
   TR::LabelSymbol *result_label;
   TR::Instruction * unloadableConstInstr[NUM_PICS];
   num_PICs = ((num_PICs > maxNum_PICS) ? maxNum_PICS : num_PICs);
   for (i = 0; i < num_PICs; i++)
      {
      dumpOptDetails(comp, "inline test with guess class address of %p\n", guessClassArray[i]);
      if (cg->needClassAndMethodPointerRelocations())
         unloadableConstInstr[i] = generateRegLitRefInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, scratchReg,(uintptrj_t) guessClassArray[i], TR_ClassPointer, NULL, NULL, NULL);
      else
         unloadableConstInstr[i] = generateRILInstruction(cg, TR::InstOpCode::LARL, node, scratchReg, (uintptrj_t)guessClassArray[i]);

      if (fej9->isUnloadAssumptionRequired((TR_OpaqueClassBlock *)(guessClassArray[i]), comp->getCurrentMethod()))
         comp->getStaticPICSites()->push_front(unloadableConstInstr[i]);

      if (cg->wantToPatchClassPointer(guessClassArray[i], node))
         comp->getStaticHCRPICSites()->push_front(unloadableConstInstr[i]);

      result_bool = instanceOfOrCheckCast((J9Class*)(guessClassArray[i]), (J9Class*)castClassAddr);
      result_label = (falseLabel != trueLabel ) ? (result_bool ? trueLabel : falseLabel) : doneLabel;

      if (needsResult)
         generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, resultReg, (int32_t)result_bool);
      generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpLogicalRegOpCode(), node, objClassReg, scratchReg, TR::InstOpCode::COND_BE, result_label);

      }
   return true;
   }
static void
generateTestBitFlag(
      TR::CodeGenerator *cg,
      TR::Node *node,
      TR::Register *mdReg,
      int32_t offset,
      int32_t size,
      uint64_t bitFlag)
   {
   TR::MemoryReference * tempMR;
   int shiftForFlag = TR::TreeEvaluator::checkNonNegativePowerOfTwo((int64_t) bitFlag);
   TR_ASSERT(shiftForFlag > 0, "generateTestBitFlag: flag is assumed to be power of 2\n");

   // point offset to the end of the word we point to, so we can make a byte comparison using tm
   offset += size - 1;

   // TM tests the bits for one byte, so we calculate several displacements for different flags
   //  Even though TM does not require the flag to be a power of two, the following code and the previous assumption require it
   if (shiftForFlag < 8)
      {
      tempMR = generateS390MemoryReference(mdReg, offset, cg);
      }
   else if (shiftForFlag < 16)
      {
      tempMR = generateS390MemoryReference(mdReg, offset - 1, cg);
      bitFlag = bitFlag >> 8;
      }
   else if (shiftForFlag < 24)
      {
      tempMR = generateS390MemoryReference(mdReg, offset - 2, cg);
      bitFlag = bitFlag >> 16;
      }
   else if (shiftForFlag < 32)
      {
      tempMR = generateS390MemoryReference(mdReg, offset - 3, cg);
      bitFlag = bitFlag >> 24;
      }
#if defined(TR_TARGET_64BIT)
   else if (shiftForFlag < 40)
      {
      tempMR = generateS390MemoryReference(mdReg, offset - 4, cg);
      bitFlag = bitFlag >> 32;
      }
   else if (shiftForFlag < 48)
      {
      tempMR = generateS390MemoryReference(mdReg, offset - 5, cg);
      bitFlag = bitFlag >> 40;
      }
   else if (shiftForFlag < 56)
      {
      tempMR = generateS390MemoryReference(mdReg, offset - 6, cg);
      bitFlag = bitFlag >> 48;
      }
   else if (shiftForFlag < 64)
      {
      tempMR = generateS390MemoryReference(mdReg, offset - 7, cg);
      bitFlag = bitFlag >> 56;
      }
#endif
   else
      {
      TR_ASSERT(0, "generateTestBitFlag: flag size assumption incorrect\n");
      }

   generateSIInstruction(cg, TR::InstOpCode::TM, node, tempMR, (uint32_t) bitFlag);
   }

static void
VMnonNullSrcWrtBarCardCheckEvaluator(
      TR::Node * node,
      TR::Register * owningObjectReg,
      TR::Register * srcReg,
      TR::Register *temp1Reg,
      TR::Register *temp2Reg,
      TR::LabelSymbol *doneLabel,
      TR::SymbolReference *wbRef ,
      TR::RegisterDependencyConditions *conditions,
      TR::CodeGenerator *cg,
      bool doCompileTimeCheckForHeapObj = true)
   {
   TR::Compilation * comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   TR_WriteBarrierKind gcMode = comp->getOptions()->getGcMode();
   bool doWrtBar = (gcMode == TR_WrtbarOldCheck || gcMode == TR_WrtbarCardMarkAndOldCheck || gcMode == TR_WrtbarAlways);
   //We need to do a runtime check on cardmarking for gencon policy if our owningObjReg is in tenure
   bool doCrdMrk = (gcMode == TR_WrtbarCardMarkAndOldCheck);

   TR_ASSERT(srcReg != NULL, "VMnonNullSrcWrtBarCardCheckEvaluator: Cannot send in a null source object...look at the fcn name\n");
   TR_ASSERT(doWrtBar == true,"VMnonNullSrcWrtBarCardCheckEvaluator: Invalid call to VMnonNullSrcWrtBarCardCheckEvaluator\n");

   TR::Node * wrtbarNode = NULL;
   TR::LabelSymbol * helperSnippetLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   if (node->getOpCodeValue() == TR::wrtbari || node->getOpCodeValue() == TR::wrtbar)
      wrtbarNode = node;
   else if (node->getOpCodeValue() == TR::ArrayStoreCHK)
      wrtbarNode = node->getFirstChild();
   if (gcMode != TR_WrtbarAlways)
      {
      bool is64Bit = TR::Compiler->target.is64Bit();
      bool isConstantHeapBase = !comp->getOptions()->isVariableHeapBaseForBarrierRange0();
      bool isConstantHeapSize = !comp->getOptions()->isVariableHeapSizeForBarrierRange0();
      int32_t shiftAmount = TR::Compiler->om.compressedReferenceShift();
      TR::InstOpCode::Mnemonic opLoadReg = TR::InstOpCode::getLoadRegOpCode();
      TR::InstOpCode::Mnemonic opSubtractReg = TR::InstOpCode::getSubstractRegOpCode();
      TR::InstOpCode::Mnemonic opSubtract = TR::InstOpCode::getSubstractOpCode();
      TR::InstOpCode::Mnemonic opCmpLog = TR::InstOpCode::getCmpLogicalOpCode();
      uintptrj_t heapSize = (uintptrj_t) comp->getOptions()->getHeapSizeForBarrierRange0();
      uintptrj_t heapBase = (uintptrj_t) comp->getOptions()->getHeapBaseForBarrierRange0();
      bool disableSrcObjCheck = true; //cg->comp()->getOption(TR_DisableWrtBarSrcObjCheck);
      bool constantHeapCase = ((!comp->compileRelocatableCode()) && isConstantHeapBase && isConstantHeapSize && shiftAmount == 0 && (!is64Bit || TR::Compiler->om.generateCompressedObjectHeaders()));
      if (constantHeapCase)
         {
         if (!doCrdMrk && !disableSrcObjCheck)
            {
            uintptrj_t heapSum = heapBase + heapSize;
            generateRRInstruction(cg, opLoadReg, node, temp1Reg, owningObjectReg);
            generateRILInstruction(cg, TR::InstOpCode::IILF, node, temp2Reg, heapSum);
            generateRRInstruction(cg, opSubtractReg, node, temp1Reg, temp2Reg);
            generateRRInstruction(cg, opSubtractReg, node, temp2Reg, srcReg);
            generateRRInstruction(cg, is64Bit ? TR::InstOpCode::NGR : TR::InstOpCode::NR, node, temp1Reg, temp2Reg);
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_CC1, node, doneLabel);
            }
         else
            {
            generateRRInstruction(cg, opLoadReg, node, temp1Reg, owningObjectReg); //copy owning into temp
            generateRILInstruction(cg, is64Bit ? TR::InstOpCode::SLGFI : TR::InstOpCode::SLFI, node, temp1Reg, heapBase); //temp = temp - heapbase
            generateS390CompareAndBranchInstruction(cg, is64Bit ? TR::InstOpCode::CLG: TR::InstOpCode::CL, node, temp1Reg, heapSize, TR::InstOpCode::COND_BH, doneLabel, false);
            }
         }
      else
         {
         TR::MemoryReference * offset = generateS390MemoryReference(cg->getMethodMetaDataRealRegister(), offsetof(J9VMThread, heapBaseForBarrierRange0), cg);
         TR::MemoryReference * size = generateS390MemoryReference(cg->getMethodMetaDataRealRegister(), offsetof(J9VMThread, heapSizeForBarrierRange0), cg);
         generateRRInstruction(cg, opLoadReg, node, temp1Reg, owningObjectReg);
         generateRXInstruction(cg, opSubtract, node, temp1Reg, offset);
         generateRXInstruction(cg, opCmpLog, node, temp1Reg, size);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BH, node, doneLabel);
         }

      TR::LabelSymbol *noChkLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

      if (!TR::Options::getCmdLineOptions()->realTimeGC())
         {
         bool isDefinitelyNonHeapObj = false, isDefinitelyHeapObj = false;
         if (wrtbarNode != NULL && doCompileTimeCheckForHeapObj)
            {
            isDefinitelyNonHeapObj = wrtbarNode->isNonHeapObjectWrtBar();
            isDefinitelyHeapObj = wrtbarNode->isHeapObjectWrtBar();
            }
         if (doCrdMrk && !isDefinitelyNonHeapObj)
            {
            TR::LabelSymbol *srcObjChkLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
            // CompileTime check for heap object
            // SRLG r2, rHeapAddr, cardSize
            // L    r1, cardTableVirtualStartOffset(metaData)
            // LHI  r3,0x1
            // STC  r3,0x0(r1,r2)
            uintptr_t cardSize = comp->getOptions()->getGcCardSize();
            int32_t shiftValue = TR::TreeEvaluator::checkNonNegativePowerOfTwo((int32_t) cardSize);
            TR::Register * mdReg, *cardOffReg;
            cardOffReg = temp1Reg;
            if (!comp->getOption(TR_Enable390FreeVMThreadReg))
               mdReg = cg->getMethodMetaDataRealRegister();
            else
               mdReg = cg->getVMThreadRegister();

            // If conditions are NULL, we handle early assignment here.
            // O.w. caller is responsible for handling early assignment and making sure GPR1, GPR2 and RAREG are
            // available in conditions
            TR_ASSERT(shiftValue > 0,"VMnonNullSrcWrtBarCardCheckEvaluator: Card size must be power of 2");
            static_assert(CARD_DIRTY <= MAX_IMMEDIATE_VAL, "VMCardCheckEvaluator: CARD_DIRTY flag is assumed to be small enough for an imm op");

            // If it is tarok balanced policy, we must generate card marking sequence.
            //
            TR_WriteBarrierKind gcMode = comp->getOptions()->getGcMode();
            if (!(gcMode == TR_WrtbarCardMarkIncremental || gcMode == TR_WrtbarRealTime))
               {
               generateTestBitFlag(cg, node, mdReg, offsetof(J9VMThread, privateFlags), sizeof(UDATA), J9_PRIVATE_FLAGS_CONCURRENT_MARK_ACTIVE);
               // If the flag is not set, then we skip card marking
               generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, srcObjChkLabel);
               }
            // dirty(activeCardTableBase + temp3Reg >> card_size_shift)
            if (TR::Compiler->target.is64Bit())
               generateRSInstruction(cg, TR::InstOpCode::SRLG, node, cardOffReg, cardOffReg, shiftValue);
            else
               generateRSInstruction(cg, TR::InstOpCode::SRL, node, cardOffReg, shiftValue);

            generateRXInstruction(cg, TR::InstOpCode::getAddOpCode(), node, cardOffReg,
                                  generateS390MemoryReference(mdReg, offsetof(J9VMThread, activeCardTableBase), cg));
            // Store the flag to the card's byte.
            generateSIInstruction(cg, TR::InstOpCode::MVI, node, generateS390MemoryReference(cardOffReg,0x0,cg), CARD_DIRTY);

            if (!disableSrcObjCheck)
               generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, noChkLabel);
            // If condition is NULL, the early assignment is handled by caller.
            // If not, early assignment handled here
            generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, srcObjChkLabel, conditions);
            }
         }
      else
         TR_ASSERT(0, "card marking not supported for RT");

      //Either if cardmarking is not on at compile time or runtime, we want to test srcobj because if its not in nursery, then
      //we don't have to do wrtbarrier
      if (!disableSrcObjCheck && !(!doCrdMrk && constantHeapCase))
         {
         generateRRInstruction(cg, opLoadReg, node, temp1Reg, srcReg);
         if (constantHeapCase)
            {
            generateRILInstruction(cg, is64Bit ? TR::InstOpCode::SLGFI : TR::InstOpCode::SLFI, node, temp1Reg, heapBase);
            generateS390CompareAndBranchInstruction(cg, is64Bit ? TR::InstOpCode::CLG: TR::InstOpCode::CL, node, temp1Reg, heapSize, TR::InstOpCode::COND_BL, doneLabel, false);
            }
         else
            {
            TR::MemoryReference *offset = generateS390MemoryReference(cg->getMethodMetaDataRealRegister(),
                  offsetof(J9VMThread, heapBaseForBarrierRange0), cg);
            TR::MemoryReference *size = generateS390MemoryReference(cg->getMethodMetaDataRealRegister(),
                  offsetof(J9VMThread, heapSizeForBarrierRange0), cg);
            generateRXInstruction(cg, opSubtract, node, temp1Reg, offset);
            generateRXInstruction(cg, opCmpLog, node, temp1Reg, size);
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BL, node, doneLabel);
            }
         }
      //If cardmarking is on at compile time (mode=wrtbaroldcrdmrkcheck) then need a label for when cardmarking is done
      //in which case we need to skip the srcobj check
      if (doCrdMrk)
         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, noChkLabel, conditions);

      // inline checking remembered bit for generational or (gencon+cardmarking is inlined).
      static_assert(J9_OBJECT_HEADER_REMEMBERED_MASK_FOR_TEST <= 0xFF, "The constant is too big");
      int32_t offsetToAgeBits =  TR::Compiler->om.offsetOfHeaderFlags() + 3;
#if defined(J9VM_INTERP_FLAGS_IN_CLASS_SLOT) && defined(TR_TARGET_64BIT) && !defined(J9VM_INTERP_COMPRESSED_OBJECT_HEADER)
      offsetToAgeBits += 4;
#endif
      TR::MemoryReference * tempMR = generateS390MemoryReference(owningObjectReg, offsetToAgeBits, cg);
      generateSIInstruction(cg, TR::InstOpCode::TM, node, tempMR, J9_OBJECT_HEADER_REMEMBERED_MASK_FOR_TEST);
      //Need to do wrtbarrer, go to the snippet
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK8, node, helperSnippetLabel);
      }
   else
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, helperSnippetLabel);

   //Create a snipper to make the call so the fall through path is to doneLabel, we expect to call the helper less, this would remove a
   //branch
   cg->addSnippet(new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, helperSnippetLabel, wbRef, doneLabel));
   }

static void
VMCardCheckEvaluator(
      TR::Node * node,
      TR::Register * owningObjectReg,
      TR::Register * tempReg,
      TR::RegisterDependencyConditions * conditions,
      TR::CodeGenerator * cg,
      bool clobberDstReg,
      TR::LabelSymbol *doneLabel = NULL,
      bool doCompileTimeCheckForHeapObj = true)
   {
   if (!TR::Options::getCmdLineOptions()->realTimeGC())
      {
      TR::Node * wrtbarNode = NULL;
      if (node->getOpCodeValue() == TR::wrtbari || node->getOpCodeValue() == TR::wrtbar)
         wrtbarNode = node;
      else if (node->getOpCodeValue() == TR::ArrayStoreCHK)
         wrtbarNode = node->getFirstChild();

      // CompileTime check for heap object
      bool isDefinitelyNonHeapObj = false, isDefinitelyHeapObj = false;

      if (wrtbarNode != NULL && doCompileTimeCheckForHeapObj)
         {
         isDefinitelyNonHeapObj = wrtbarNode->isNonHeapObjectWrtBar();
         isDefinitelyHeapObj = wrtbarNode->isHeapObjectWrtBar();
         }

      // Make sure we really should be here
      TR::Compilation * comp = cg->comp();

      // 83613: We used to do inline CM for Old&CM Objects.
      // However, since all Old objects will go through the wrtbar helper,
      // which will CM too, our inline CM would become redundant.
      TR_ASSERT( (comp->getOptions()->getGcMode()==TR_WrtbarCardMark || comp->getOptions()->getGcMode()==TR_WrtbarCardMarkIncremental) && !isDefinitelyNonHeapObj,
         "VMCardCheckEvaluator: Invalid call to cardCheckEvaluator\n");
      TR_ASSERT(doneLabel, "VMCardCheckEvaluator: doneLabel must be defined\n");
      TR_ASSERT((conditions && tempReg || clobberDstReg), "VMCardCheckEvaluator: Either a tempReg must be sent in to be used, or we should be able to clobber the owningObjReg\n");
      TR_ASSERT(!(clobberDstReg && tempReg), "VMCardCheckEvaluator: If owningObjReg is clobberable, don't allocate a tempReg\n");

      // We do not card-mark non-heap objects.
      if (!isDefinitelyNonHeapObj)
         {
         // SRLG r2, rHeapAddr, cardSize
         // L    r1, cardTableVirtualStartOffset(metaData)
         // LHI  r3,0x1
         // STC  r3,0x0(r1,r2)

         uintptr_t cardSize = comp->getOptions()->getGcCardSize();
         int32_t shiftValue = TR::TreeEvaluator::checkNonNegativePowerOfTwo((int32_t) cardSize);

         TR::Register * mdReg, *cardOffReg;
         if (!comp->getOption(TR_Enable390FreeVMThreadReg))
            mdReg = cg->getMethodMetaDataRealRegister();
         else
            mdReg = cg->getVMThreadRegister();

         if (!clobberDstReg)
            cardOffReg = tempReg;
         else if (clobberDstReg)
            cardOffReg = owningObjectReg;

         TR_ASSERT(shiftValue > 0,"VMCardCheckEvaluator: Card size must be power of 2");
         static_assert(CARD_DIRTY <= MAX_IMMEDIATE_VAL, "VMCardCheckEvaluator: CARD_DIRTY flag is assumed to be small enough for an imm op");

         // If it is tarok balanced policy, we must generate card marking sequence.
         TR_WriteBarrierKind gcMode = comp->getOptions()->getGcMode();
         if (!(gcMode == TR_WrtbarCardMarkIncremental || gcMode == TR_WrtbarRealTime))
            {
            generateTestBitFlag(cg, node, mdReg, offsetof(J9VMThread, privateFlags), sizeof(UDATA), J9_PRIVATE_FLAGS_CONCURRENT_MARK_ACTIVE);
            // If the flag is not set, then we skip card marking
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, doneLabel);
            }

         // cardOffReg (Temp) = owningObjectReg - heapBaseForBarrierRange0
         // Defect 91242 - If we can clobber the destination reg, then use owningObjectReg instead of cardOffReg.
         if (!clobberDstReg)
            generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, cardOffReg, owningObjectReg);
         generateRXInstruction(cg, TR::InstOpCode::getSubstractOpCode(), node, cardOffReg,
                               generateS390MemoryReference(mdReg, offsetof(J9VMThread, heapBaseForBarrierRange0), cg));

         // Unless we know it's definitely a heap object, we need to check if offset
         // from base is less than heap size to determine if object resides in heap.
         if (!isDefinitelyHeapObj)
            {
            // if (cardOffReg(Temp) >= heapSizeForBarrierRage0), object not in the heap
            generateRXInstruction(cg, TR::InstOpCode::getCmpLogicalOpCode(), node, cardOffReg,
                                      generateS390MemoryReference(mdReg, offsetof(J9VMThread, heapSizeForBarrierRange0), cg));
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNL, node, doneLabel);
            }

         // dirty(activeCardTableBase + temp3Reg >> card_size_shift)
         if (TR::Compiler->target.is64Bit())
            generateRSInstruction(cg, TR::InstOpCode::SRLG, node, cardOffReg, cardOffReg, shiftValue);
         else
            generateRSInstruction(cg, TR::InstOpCode::SRL, node, cardOffReg, shiftValue);

         //add the ActiveCardTableBase to the card offset
         generateRXInstruction(cg, TR::InstOpCode::getAddOpCode(), node, cardOffReg,
                generateS390MemoryReference(mdReg, offsetof(J9VMThread, activeCardTableBase), cg));
         // Store the flag to the card's byte.
         generateSIInstruction(cg, TR::InstOpCode::MVI, node, generateS390MemoryReference(cardOffReg, 0x0, cg), CARD_DIRTY);
         }
      }
   else
      TR_ASSERT(0, "VMCardCheckEvaluator not supported for RT");
   }

static void
VMwrtbarEvaluator(
      TR::Node * node,
      TR::Register * srcReg,
      TR::Register * owningObjectReg,
      bool srcNonNull,
      TR::CodeGenerator * cg)
   {
   TR::Instruction * cursor;
   TR::Compilation * comp = cg->comp();
   TR_WriteBarrierKind gcMode = comp->getOptions()->getGcMode();
   bool doWrtBar = (gcMode == TR_WrtbarOldCheck || gcMode == TR_WrtbarCardMarkAndOldCheck || gcMode == TR_WrtbarAlways);
   bool doCrdMrk = ((gcMode == TR_WrtbarCardMark ||gcMode == TR_WrtbarCardMarkAndOldCheck || gcMode == TR_WrtbarCardMarkIncremental )&& !node->isNonHeapObjectWrtBar());

   // See VM Design 2048 for when wrtbar can be skipped, as determined by VP.
   if ( (node->getOpCode().isWrtBar() && node->skipWrtBar()) ||
        ((node->getOpCodeValue() == TR::ArrayStoreCHK) && node->getFirstChild()->getOpCode().isWrtBar() && node->getFirstChild()->skipWrtBar() ) )
      return;
   TR::RegisterDependencyConditions * conditions;
   TR::LabelSymbol * doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   if (doWrtBar)
      conditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 4, cg);
   else
      conditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 1, cg);

   if (doWrtBar) // generational or gencon
      {
      TR::SymbolReference * wbRef = NULL;
      if (gcMode == TR_WrtbarAlways)
         wbRef = comp->getSymRefTab()->findOrCreateWriteBarrierStoreSymbolRef();
      else // use jitWriteBarrierStoreGenerational for both generational and gencon, becaues we inline card marking.
         {
         static char *disable = feGetEnv("TR_disableGenWrtBar");
         wbRef = disable ?
            comp->getSymRefTab()->findOrCreateWriteBarrierStoreSymbolRef() :
            comp->getSymRefTab()->findOrCreateWriteBarrierStoreGenerationalSymbolRef();
         }
      TR::Register *epReg, *raReg;
      epReg = cg->allocateRegister();
      raReg = cg->allocateRegister();
      conditions->addPostCondition(raReg, cg->getReturnAddressRegister());
      conditions->addPostCondition(owningObjectReg, TR::RealRegister::GPR1);
      conditions->addPostCondition(srcReg, TR::RealRegister::GPR2);
      conditions->addPostCondition(epReg, cg->getEntryPointRegister());
      cg->addVMThreadPostCondition(conditions, NULL);
      if (srcNonNull == false)
         {
         // If object is NULL, done
         static_assert(NULLVALUE == 0, "NULLVALUE is assumed to be zero here");
         generateRRInstruction(cg, TR::InstOpCode::getLoadTestRegOpCode(), node, srcReg, srcReg);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, doneLabel);
         }
      // Inlines cardmarking and remembered bit check for gencon.
      VMnonNullSrcWrtBarCardCheckEvaluator(node, owningObjectReg, srcReg, epReg, raReg, doneLabel, wbRef, conditions, cg, false);
      cg->stopUsingRegister(epReg);
      cg->stopUsingRegister(raReg);
      }
   else if (doCrdMrk)  // -Xgc:optavgpause, concurrent marking only
      {
      conditions->addPostCondition(owningObjectReg, TR::RealRegister::AssignAny);
      cg->addVMThreadPostCondition(conditions, NULL);
      VMCardCheckEvaluator(node, owningObjectReg, NULL, conditions, cg, true, doneLabel);
      }
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, conditions);
   }

///////////////////////////////////////////////////////////////////////////////////////
//  wrtbarEvaluator:  direct write barrier store checks for new space in old space
//    reference store the first child is the value as in TR::astore.  The second child is
//    the address of the object that must be checked for old space the symbol reference
//    holds addresses, flags and offsets as in TR::astore
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::wrtbarEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("wrtbar", node, cg);
   TR::Node * owningObjectChild = node->getSecondChild();
   TR::Node * sourceChild = node->getFirstChild();
   TR::Compilation * comp = cg->comp();
   bool doWrtBar = (comp->getOptions()->getGcMode() == TR_WrtbarOldCheck ||
      comp->getOptions()->getGcMode() == TR_WrtbarCardMarkAndOldCheck ||
      comp->getOptions()->getGcMode() == TR_WrtbarAlways);
   bool doCrdMrk = ((comp->getOptions()->getGcMode() == TR_WrtbarCardMark ||
      comp->getOptions()->getGcMode() == TR_WrtbarCardMarkIncremental ||
      comp->getOptions()->getGcMode() == TR_WrtbarCardMarkAndOldCheck) && !node->isNonHeapObjectWrtBar());

   TR::Register * owningObjectRegister = NULL;
   TR::Register * sourceRegister = NULL;
   bool canSkip = false;

   if ((node->getOpCode().isWrtBar() && node->skipWrtBar()) ||
       ((node->getOpCodeValue() == TR::ArrayStoreCHK) &&
        node->getFirstChild()->getOpCode().isWrtBar() &&
        node->getFirstChild()->skipWrtBar()))
      {
      canSkip = true;
      }

   if ((doWrtBar || doCrdMrk) && !canSkip)
      {
      owningObjectRegister = cg->gprClobberEvaluate(owningObjectChild);
      }
   else
      {
      owningObjectRegister = cg->evaluate(owningObjectChild);
      }

   if (canSkip)
      {
      sourceRegister = cg->evaluate(sourceChild);
      }
   else
      {
      sourceRegister = allocateWriteBarrierInternalPointerRegister(cg, sourceChild);
      }

   // we need to evaluate all the children first before we generate memory reference
   // since it will screw up the code sequence for patching when we do symbol resolution
   TR::MemoryReference * tempMR = generateS390MemoryReference(node, cg);
   TR::Instruction * instr = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, sourceRegister, tempMR);

   // When a new object is stored into an old object, we need to invoke jitWriteBarrierStore
   // helper to update the remembered sets for GC.  Helper call is needed only if the object
   // is in old space or is scanned (black). Since the checking involves control flow, we delay
   // the code gen for write barrier for RA cannot handle control flow.

   VMwrtbarEvaluator(node, sourceRegister, owningObjectRegister, sourceChild->isNonNull(), cg);

   cg->decReferenceCount(sourceChild);
   cg->decReferenceCount(owningObjectChild);
   cg->stopUsingRegister(sourceRegister);
   if (owningObjectRegister) cg->stopUsingRegister(owningObjectRegister);
   tempMR->stopUsingMemRefRegister(cg);
   return NULL;
   }

///////////////////////////////////////////////////////////////////////////////////////
// iwrtbarEvaluator: indirect write barrier store checks for new space in old space
//    reference store.  The first two children are as in TR::astorei.  The third child
//    is address of the beginning of the destination object.  For putfield this will often
//    be the same as the first child (when the offset is on the symbol reference.
//    But for array references, children 1 and 3 will be quite different although
//    child 1's subtree will contain a reference to child 3's subtree
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::iwrtbarEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("iwrtbar", node, cg);
   TR::Node * owningObjectChild = node->getChild(2);
   TR::Node * sourceChild = node->getSecondChild();
   TR::Compilation *comp = cg->comp();
   bool adjustRefCnt = false;
   bool usingCompressedPointers = false;
   if (comp->useCompressedPointers() &&
       (node->getSymbolReference()->getSymbol()->getDataType() == TR::Address) &&
       (node->getSecondChild()->getDataType() != TR::Address))
      {
      // pattern match the sequence
      //     iwrtbar f     iwrtbar f         <- node
      //       aload O       aload O
      //     value           l2i
      //                       lshr
      //                         lsub        <- translatedNode
      //                           a2l
      //                             value   <- sourceChild
      //                           lconst HB
      //                         iconst shftKonst
      //
      // -or- if the field is known to be null
      // iwrtbar f
      //    aload O
      //    l2i
      //      a2l
      //        value  <- sourceChild
      //
      ////usingCompressedPointers = true;

      TR::Node *translatedNode = sourceChild;
      if (translatedNode->getOpCodeValue() == TR::l2i)
         translatedNode = translatedNode->getFirstChild();
      if (translatedNode->getOpCode().isRightShift()) // optional
         translatedNode = translatedNode->getFirstChild();

      bool usingLowMemHeap = false;
      if (TR::Compiler->vm.heapBaseAddress() == 0 ||
             sourceChild->isNull())
         usingLowMemHeap = true;

      if (translatedNode->getOpCode().isSub() || usingLowMemHeap)
         usingCompressedPointers = true;

      if (usingCompressedPointers)
         {
         adjustRefCnt = true;
         ///node->getFirstChild()->incReferenceCount();
         while ((sourceChild->getNumChildren() > 0) && (sourceChild->getOpCodeValue() != TR::a2l))
            sourceChild = sourceChild->getFirstChild();
         if (sourceChild->getOpCodeValue() == TR::a2l)
            sourceChild = sourceChild->getFirstChild();
         // artificially bump up the refCount on the value so
         // that different registers are allocated for the actual
         // and compressed values. this is done so that the VMwrtbarEvaluator
         // uses the uncompressed value
         //
         sourceChild->incReferenceCount();
         }
      }

   bool doWrtBar = (comp->getOptions()->getGcMode() == TR_WrtbarOldCheck ||
      comp->getOptions()->getGcMode() == TR_WrtbarCardMarkAndOldCheck ||
      comp->getOptions()->getGcMode() == TR_WrtbarAlways);
   bool doCrdMrk = ((comp->getOptions()->getGcMode() == TR_WrtbarCardMark ||
      comp->getOptions()->getGcMode() == TR_WrtbarCardMarkIncremental ||
      comp->getOptions()->getGcMode() == TR_WrtbarCardMarkAndOldCheck) && !node->isNonHeapObjectWrtBar());

   TR::Register * owningObjectRegister = NULL;

   bool canSkip = false;
   if ((node->getOpCode().isWrtBar() && node->skipWrtBar()) ||
       ((node->getOpCodeValue() == TR::ArrayStoreCHK) &&
        node->getFirstChild()->getOpCode().isWrtBar() &&
        node->getFirstChild()->skipWrtBar()))
      {
      canSkip = true;
      }

   if ((doWrtBar || doCrdMrk) && !canSkip)
      {
      owningObjectRegister = cg->gprClobberEvaluate(owningObjectChild);
      }
   else
      {
//    cg->decReferenceCount(owningObjectChild);
      owningObjectRegister = owningObjectChild->getRegister();
//    owningObjectRegister = cg->evaluate(owningObjectChild);
      }

   //Don't need to clobber evaluate
   //TR::Register * sourceRegister = allocateWriteBarrierInternalPointerRegister(cg, sourceChild);
   TR::Register *sourceRegister = cg->evaluate(sourceChild);
   TR::Register * compressedRegister = sourceRegister;
   if (usingCompressedPointers)
      compressedRegister = cg->evaluate(node->getSecondChild());

   // we need to evaluate all the children first before we generate memory reference
   // since it will screw up the code sequence for patching when we do symbol resolution
   TR::MemoryReference * tempMR = generateS390MemoryReference(node, cg);

   TR::InstOpCode::Mnemonic storeOp = usingCompressedPointers ? TR::InstOpCode::ST : TR::InstOpCode::getStoreOpCode();
   TR::Instruction * instr = generateRXInstruction(cg, storeOp, node, compressedRegister, tempMR);

   // When a new object is stored into an old object, we need to invoke jitWriteBarrierStore
   // helper to update the remembered sets for GC.  Helper call is needed only if the object
   // is in old space or is scanned (black). Since the checking involves control flow, we delay
   // the code gen for write barrier since RA cannot handle control flow.

   VMwrtbarEvaluator(node, sourceRegister, owningObjectRegister, sourceChild->isNonNull(), cg);

   ///if (adjustRefCnt)
   ///   cg->decReferenceCount(node->getFirstChild());

   if (comp->useCompressedPointers())
      node->setStoreAlreadyEvaluated(true);
   cg->decReferenceCount(sourceChild);
   if (usingCompressedPointers)
      {
      cg->decReferenceCount(node->getSecondChild());
      cg->recursivelyDecReferenceCount(owningObjectChild);
      }
   else
      cg->decReferenceCount(owningObjectChild);
   if (owningObjectRegister) cg->stopUsingRegister(owningObjectRegister);
   cg->stopUsingRegister(sourceRegister);
   ///if (usingCompressedPointers)
   ///   tempMR->decNodeReferenceCounts(cg);
   ///else
   tempMR->stopUsingMemRefRegister(cg);

   return NULL;
   }




///////////////////////////////////////////////////////////////////////////////////////
// monentEvaluator:  acquire lock for synchronising method
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::monentEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("monent", node, cg);

   return TR::TreeEvaluator::VMmonentEvaluator(node, cg);
   }

///////////////////////////////////////////////////////////////////////////////////////
// monexitEvaluator:  release lock for synchronising method
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::monexitEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("monexit", node, cg);
   return TR::TreeEvaluator::VMmonexitEvaluator(node, cg);
   }

///////////////////////////////////////////////////////////////////////////////////////
// monexitfence -- do nothing, just a placeholder for live monitor meta data
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::monexitfenceEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("monexitfence", node, cg);
   return NULL;
   }

///////////////////////////////////////////////////////////////////////////////////////
// asynccheckEvaluator: GC point
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::asynccheckEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("asynccheck", node, cg);
   // used by asynccheck
   // The child contains an inline test.
   //
   TR::Node * testNode = node->getFirstChild();
   TR::Node * firstChild = testNode->getFirstChild();
   TR::Node * secondChild = testNode->getSecondChild();
   TR::Compilation *comp = cg->comp();
   intptrj_t value = TR::Compiler->target.is64Bit() ? secondChild->getLongInt() : secondChild->getInt();

   TR_ASSERT( testNode->getOpCodeValue() == (TR::Compiler->target.is64Bit() ? TR::lcmpeq : TR::icmpeq), "asynccheck bad format");
   TR_ASSERT( secondChild->getOpCode().isLoadConst() && secondChild->getRegister() == NULL, "asynccheck bad format");

   TR::LabelSymbol * snippetLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::Instruction * gcPoint;

   TR::LabelSymbol * reStartLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   // (0)  asynccheck #4[0x004d7a88]Method[jitCheckAsyncMessages]
   // (1)    icmpeq
   // (1)      iload #281[0x00543138] MethodMeta[stackOverflowMark]+28
   // (1)      iconst -1

   if (TR::Compiler->target.is32Bit() &&
       (firstChild->getOpCodeValue() == TR::iload) &&
       firstChild->getRegister() == NULL && value < 0)
      {
      // instead of comparing to the value itself, we can compare to 0
      // and, if the value is less than zero, we know it must be an async-check
      // since non-code addresses are always positive in 31-bit 390 code so the only
      // negative address we could have would be the 'bogus' -1 address to force
      // async-check.
      // (the VM ensures that all malloc'ed storage has the high-order-bit cleared)
      TR::Register * testRegister = cg->allocateRegister();
      TR::MemoryReference * tempMR = generateS390MemoryReference(firstChild, cg);

      TR_ASSERT( getIntegralValue(secondChild) == -1, "asynccheck bad format");
      TR_ASSERT(  TR::Compiler->target.is32Bit(), "ICM can be used for 32bit code-gen only!");

      static char * dontUseTM = feGetEnv("TR_DONTUSETMFORASYNC");
      if (comp->getOption(TR_DisableOOL))
         {
         reStartLabel->setEndInternalControlFlow();
         }
      if (firstChild->getReferenceCount()>1 || dontUseTM)
         {
         generateRSInstruction(cg, TR::InstOpCode::ICM, firstChild, testRegister, (uint32_t) 0xF, tempMR);
         gcPoint = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BL, node, snippetLabel);
         if (comp->getOption(TR_DisableOOL))
            gcPoint->setStartInternalControlFlow();
         }
      else
         {
         generateSIInstruction(cg, TR::InstOpCode::TM, firstChild, tempMR, 0xFF);
         gcPoint = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BO, node, snippetLabel);
         if (comp->getOption(TR_DisableOOL))
            gcPoint->setStartInternalControlFlow();
         }

      firstChild->setRegister(testRegister);
      tempMR->stopUsingMemRefRegister(cg);
      }
   else
      {

      if (comp->getOption(TR_DisableOOL))
         {
         reStartLabel->setEndInternalControlFlow();
         }
      if (value >= MIN_IMMEDIATE_VAL && value <= MAX_IMMEDIATE_VAL)
         {
         if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10))
            {
            TR::MemoryReference * tempMR = generateS390MemoryReference(firstChild, cg);

            if (tempMR->getIndexRegister() != NULL && tempMR->getBaseRegister() != NULL)
               {
               TR::SymbolReference * symRef = firstChild->getSymbolReference();
               TR::Symbol * symbol = symRef->getSymbol();
               TR::Register * src1Reg = NULL;
               if (firstChild->getDataType() == TR::Address &&
                   !symbol->isInternalPointer() &&
                   !symbol->isNotCollected()    &&
                   !symbol->isAddressOfClassObject())
                  {
                  src1Reg = cg->allocateCollectedReferenceRegister();
                  }
               else
                  {
                  src1Reg = cg->allocateRegister();
                  }
               generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), firstChild, src1Reg, tempMR);

               updateReferenceNode(firstChild, src1Reg);
               firstChild->setRegister(src1Reg);

               generateRIInstruction(cg, TR::InstOpCode::getCmpHalfWordImmOpCodeFromNode(firstChild), node, src1Reg, value);
               }
            else
               {
               generateSILInstruction(cg, TR::InstOpCode::getCmpHalfWordImmToMemOpCodeFromNode(firstChild), node, tempMR, value);
               }
            tempMR->stopUsingMemRefRegister(cg);
            }
         else
            {
            TR::Register * src1Reg = cg->evaluate(firstChild);

            generateRIInstruction(cg, TR::InstOpCode::getCmpHalfWordImmOpCodeFromNode(firstChild), node, src1Reg, value);
            }
         }
      else
         {
         TR::Register * src1Reg = cg->evaluate(firstChild);
         TR::Register * tempReg = cg->evaluate(secondChild);
         generateRRInstruction(cg, TR::InstOpCode::getCmpRegOpCodeFromNode(firstChild), node, src1Reg, tempReg);
         }
      gcPoint = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, snippetLabel);
      if (comp->getOption(TR_DisableOOL))
         gcPoint->setStartInternalControlFlow();
      }

   TR::RegisterDependencyConditions * dependencies = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 2, cg);
   TR::Register * rRA = cg->allocateRegister();
   // only 64bit zLinux and zOS trampoline requires rEP
#if defined(TR_TARGET_64BIT)
   TR::Register * rEP = NULL;
#if defined(J9ZOS390)
   if (comp->getOption(TR_EnableRMODE64))
#endif
      {
      rEP = cg->allocateRegister();
      dependencies->addPostCondition(rEP, cg->getEntryPointRegister());
      }
#endif

   dependencies->addPostCondition(rRA, cg->getReturnAddressRegister());

   if (!comp->getOption(TR_DisableOOL))
      {
      TR_Debug * debugObj = cg->getDebug();
      if (debugObj)
         debugObj->addInstructionComment(gcPoint, "Branch to OOL asyncCheck sequence");

      // starts OOL sequence, replacing the helper call snippet
      TR_S390OutOfLineCodeSection *outlinedHelperCall = NULL;
      outlinedHelperCall = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(snippetLabel, reStartLabel, cg);
      cg->getS390OutOfLineCodeSectionList().push_front(outlinedHelperCall);
      outlinedHelperCall->swapInstructionListsWithCompilation();

      // snippetLabel : OOL Start label
      TR::Instruction * cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, snippetLabel);
      if (debugObj)
         debugObj->addInstructionComment(cursor, "Denotes start of OOL asyncCheck sequence");

      // BRASL R14, VMHelper, gc stack map on BRASL
      gcPoint = generateDirectCall(cg, node, false, node->getSymbolReference(), dependencies, cursor);
      gcPoint->setDependencyConditions(dependencies);

      cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, reStartLabel);
      if (debugObj)
         debugObj->addInstructionComment(cursor, "Denotes end of OOL asyncCheck sequence: return to mainline");

      // Done using OOL with manual code generation
      outlinedHelperCall->swapInstructionListsWithCompilation();
      cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, reStartLabel);
      if (debugObj)
         debugObj->addInstructionComment(cursor, "OOL asyncCheck return label");
      }
   else
      {
      TR::Snippet * snippet = new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, snippetLabel, node->getSymbolReference(), reStartLabel);
      cg->addSnippet(snippet);
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, reStartLabel, dependencies);
      }

   gcPoint->setNeedsGCMap(0x0000FFFF);

   cg->decReferenceCount(firstChild);
   cg->decReferenceCount(secondChild);
   cg->decReferenceCount(testNode);
#if defined(TR_TARGET_64BIT)
#if defined(J9ZOS390)
   if (comp->getOption(TR_EnableRMODE64))
#endif
      {
      cg->stopUsingRegister(rEP);
      }
#endif
   cg->stopUsingRegister(rRA);

   return NULL;

   }


///////////////////////////////////////////////////////////////////////////////////////
// instanceofEvaluator: symref is the class object, cp index is in the "int" field,
//   child is the object reference
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::instanceofEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Compilation *comp = cg->comp();
   PRINT_ME("instanceof", node, cg);
   if (comp->getOption(TR_OptimizeForSpace) || comp->getOption(TR_DisableInlineInstanceOf))
      {
      TR::ILOpCodes opCode = node->getOpCodeValue();
      TR::S390CHelperLinkage *helperLink =  static_cast<TR::S390CHelperLinkage*>(cg->getLinkage(TR_CHelper));
      TR::Node::recreate(node, TR::icall);
      TR::Register * targetRegister = helperLink->buildDirectDispatch(node);
      for (auto i=0; i < node->getNumChildren(); i++)
         cg->decReferenceCount(node->getChild(i));
      TR::Node::recreate(node, opCode);
      return targetRegister;
      }
   else
      {
      return TR::TreeEvaluator::VMinstanceOfEvaluator(node, cg);
      }
   }

static void
generateNullChkSnippet(
      TR::Node *node,
      TR::CodeGenerator *cg)
   {
   TR::Compilation *comp = cg->comp();
   TR::LabelSymbol * snippetLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::S390BranchInstruction * brInstr = (TR::S390BranchInstruction*) generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, snippetLabel);
   brInstr->setExceptBranchOp();

   TR::SymbolReference *symRef = comp->getSymRefTab()->findOrCreateNullCheckSymbolRef(comp->getMethodSymbol());
   cg->addSnippet(new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, snippetLabel, symRef));
   }

///////////////////////////////////////////////////////////////////////////////////////
//  checkcastEvaluator - checkcast
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::checkcastEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Compilation *comp = cg->comp();
   PRINT_ME("checkcast", node, cg);
   if (comp->getOption(TR_OptimizeForSpace) || comp->getOption(TR_DisableInlineCheckCast))
      {
      TR::ILOpCodes opCode = node->getOpCodeValue();
      TR::Node * objNode = node->getFirstChild();
      bool needsNullTest         = !objNode->isNonNull() && !node->chkIsReferenceNonNull();
      bool isCheckcastAndNullChk = (opCode == TR::checkcastAndNULLCHK);

      // Do null check if needed
      if (needsNullTest && isCheckcastAndNullChk)
         {
         TR::Register * objReg = cg->evaluate(objNode);
         generateRRInstruction(cg, TR::InstOpCode::getLoadTestRegOpCode(), node, objReg, objReg);
         // find the bytecodeInfo of the compacted NULLCHK
         TR::Node *nullChkInfo = comp->findNullChkInfo(node);
         generateNullChkSnippet(nullChkInfo, cg);
         }

      // call helper to do checkcast
      TR::Node::recreate(node, TR::call);
      TR::Register * targetRegister = directCallEvaluator(node, cg);
      TR::Node::recreate(node, opCode);
      return targetRegister;
      }
   else
      {
      return TR::TreeEvaluator::VMcheckcastEvaluator(node, cg);
      }
   }

///////////////////////////////////////////////////////////////////////////////////////
//  checkcastAndNULLCHKEvaluator - checkcastAndNULLCHK
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::checkcastAndNULLCHKEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return checkcastEvaluator(node, cg);
   }

/**   \brief Generates helper call sequence for all VMNew nodes.
 *  
 *    \param node
 *       A new allocation node for which helper call is going to be generated
 *
 *    \param cg
 *       The code generator used to generate the instructions.
 *
 *    \param doInlineAllocation
 *       A boolean to notify if we have generated inline allocation sequence or not
 *
 *    \param
 *       A register to store return value from helper
 *
 *    \return
 *       A register that contains return value from helper.
 *    
 *    \details
 *       Generates a helper call sequence for all new allocation nodes. It also handles special cases where we need to generate 64-bit extended children of call node
 */
TR::Register *
J9::Z::TreeEvaluator::generateHelperCallForVMNewEvaluators(TR::Node *node, TR::CodeGenerator *cg, bool doInlineAllocation, TR::Register *resReg)
   {
   TR::S390CHelperLinkage *helperLink = static_cast<TR::S390CHelperLinkage*>(cg->getLinkage(TR_CHelper));
   TR::ILOpCodes opCode = node->getOpCodeValue();
   TR::Node *helperCallNode = TR::Node::createWithSymRef(node, TR::acall, (opCode == TR::New || opCode == TR::variableNew)  ? 1 : 2, node->getSymbolReference());
   TR::Node *firstChild = node->getFirstChild();
   if (!(opCode == TR::New || opCode == TR::variableNew))
      {
      // For 64 bit target we need to make sure we use whole 64 bit register even for loading integers as helper expects arguments like that
      // For these scenarios where children of original node is 32-bit we generate a following helper call node
      // acall
      //   #IF (firstChild ->iconst || iRegLoad ) && 64-bit platform
      //   -> i2l
      //       -> firstChild
      //   #ELSE
      //   ->firstChild
      //   #ENDIF
      //   #IF (secondChild -> iconst || iRegLoad) && 64-bit platform
      //   -> i2l
      //       -> secondChild
      //   #ELSE
      //   ->secondChild
      //   #ENDIF
      // If we generate i2l node, we need to artificially set reference count of node to 1.
      // After helper call is generated we decrese reference count of this node so that a register will be marked dead for RA. 
      TR::Node *secondChild = node->getSecondChild();
      if (TR::Compiler->target.is64Bit())
         {
         if (firstChild->getOpCode().isLoadConst() || firstChild->getOpCodeValue() == TR::iRegLoad)
            {
            firstChild = TR::Node::create(TR::i2l, 1, firstChild);
            firstChild->setReferenceCount(1);
            }
         if (secondChild->getOpCode().isLoadConst() || secondChild->getOpCodeValue() == TR::iRegLoad)
            {
            secondChild = TR::Node::create(TR::i2l, 1, secondChild);
            secondChild->setReferenceCount(1);
            }
         }
      helperCallNode->setChild(1, secondChild);
      }
   helperCallNode->setChild(0, firstChild);
   resReg = helperLink->buildDirectDispatch(helperCallNode, resReg);
   for (auto i=0; i < helperCallNode->getNumChildren(); i++)
      {
      if (helperCallNode->getChild(i)->getOpCodeValue() == TR::i2l)
         cg->decReferenceCount(helperCallNode->getChild(i));
      }
   // For some cases, we can not generate inline allocation sequence such as variableNew*. In these cases only helper call is generated.
   // So for these cases we need to decrease reference count of node here.
   if (!doInlineAllocation)
      {
      node->setRegister(resReg);
      for (auto i=0; i<node->getNumChildren(); i++)
         cg->decReferenceCount(node->getChild(i));
      }
   return resReg;
   }

///////////////////////////////////////////////////////////////////////////////////////
// newObjectEvaluator: new symref is the class object
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::newObjectEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("newObject", node, cg);
   if (cg->comp()->suppressAllocationInlining())
      return generateHelperCallForVMNewEvaluators(node, cg);
   else
      return TR::TreeEvaluator::VMnewEvaluator(node, cg);
   }

///////////////////////////////////////////////////////////////////////////////////////
// newArrayEvaluator: new array of primitives
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::newArrayEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("newArray", node, cg);
   if (cg->comp()->suppressAllocationInlining())
      return generateHelperCallForVMNewEvaluators(node, cg);
   else
      return TR::TreeEvaluator::VMnewEvaluator(node, cg);
   }

///////////////////////////////////////////////////////////////////////////////////////
// newArrayEvaluator: new array of objects
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::anewArrayEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("anewArray", node, cg);
   if (cg->comp()->suppressAllocationInlining())
      return generateHelperCallForVMNewEvaluators(node, cg);
   else
      return TR::TreeEvaluator::VMnewEvaluator(node, cg);
   }

///////////////////////////////////////////////////////////////////////////////////////
// multianewArrayEvaluator:  multi-dimensional new array of objects
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::multianewArrayEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("multianewArray", node, cg);
   TR::ILOpCodes opCode = node->getOpCodeValue();
   TR::Node::recreate(node, TR::acall);
   TR::Register * targetRegister = directCallEvaluator(node, cg);
   TR::Node::recreate(node, opCode);
   return targetRegister;
   }


TR::Register *
J9::Z::TreeEvaluator::arraylengthEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(cg->fe());
   TR::Register *objectReg = cg->evaluate(node->getFirstChild());
   TR::Register *lengthReg = cg->allocateRegister();

   TR::MemoryReference *contiguousArraySizeMR = generateS390MemoryReference(objectReg, fej9->getOffsetOfContiguousArraySizeField(), cg);
   TR::MemoryReference *discontiguousArraySizeMR = generateS390MemoryReference(objectReg, fej9->getOffsetOfDiscontiguousArraySizeField(), cg);

   // Load the Contiguous Array Size and test if it's zero.
   generateRSInstruction(cg, TR::InstOpCode::ICM, node, lengthReg, (uint32_t) 0xF, contiguousArraySizeMR);

   if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z196))
      {
      // Conditionally load from discontiguousArraySize if contiguousArraySize is zero
      generateRSInstruction(cg, TR::InstOpCode::LOC, node, lengthReg, 0x8, discontiguousArraySizeMR);
      }
   else
      {
      TR::LabelSymbol * oolStartLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol * oolReturnLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

      // Branch to OOL if contiguous array size is zero
      TR::Instruction * temp = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, oolStartLabel);

      TR_S390OutOfLineCodeSection *outlinedDiscontigPath = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(oolStartLabel,oolReturnLabel,cg);
      cg->getS390OutOfLineCodeSectionList().push_front(outlinedDiscontigPath);
      outlinedDiscontigPath->swapInstructionListsWithCompilation();

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, oolStartLabel);

      if (cg->getDebug())
         {
         cg->getDebug()->addInstructionComment(temp, "Start of OOL arraylength sequence");
         }

      // Load from discontiguousArraySize if contiguousArraySize is zero
      generateRXInstruction(cg, TR::InstOpCode::L, node, lengthReg, discontiguousArraySizeMR);

      TR::Instruction* returnInsturction = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, oolReturnLabel);

      if (cg->getDebug())
         {
         cg->getDebug()->addInstructionComment(returnInsturction, "End of OOL arraylength sequence");
         }

      outlinedDiscontigPath->swapInstructionListsWithCompilation();

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, oolReturnLabel);
      }

   cg->decReferenceCount(node->getFirstChild());
   node->setRegister(lengthReg);
   return lengthReg;
   }


///////////////////////////////////////////////////////////////////////////////////////
// resolveCHKEvaluator - Resolve check a static, field or method. child 1 is reference
//   to be resolved. Symbolref indicates failure action/destination
///////////////////////////////////////////////////////////////////////////////////////
   TR::Register *
J9::Z::TreeEvaluator::resolveCHKEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("resolveCHK", node, cg);
   // No code is generated for the resolve check. The child will reference an
   // unresolved symbol and all check handling is done via the corresponding
   // snippet.
   //
   TR::Node * firstChild = node->getFirstChild();
   bool fixRefCount = false;
   if (cg->comp()->useCompressedPointers())
      {
      // for stores under ResolveCHKs, artificially bump
      // down the reference count before evaluation (since stores
      // return null as registers)
      //
      if (node->getFirstChild()->getOpCode().isStoreIndirect() &&
            node->getFirstChild()->getReferenceCount() > 1)
         {
         node->getFirstChild()->decReferenceCount();
         fixRefCount = true;
         }
      }
   cg->evaluate(firstChild);
   if (fixRefCount)
      firstChild->incReferenceCount();

   cg->decReferenceCount(firstChild);
   return NULL;
   }


///////////////////////////////////////////////////////////////////////////////////////
// DIVCHKEvaluator - Divide by zero check. child 1 is the divide. Symbolref indicates
//    failure action/destination
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::DIVCHKEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("DIVCHK", node, cg);
   TR::Compilation *comp = cg->comp();
   TR::Node * secondChild = node->getFirstChild()->getSecondChild();
   TR::DataType dtype = secondChild->getType();
   bool constDivisor = secondChild->getOpCode().isLoadConst();
   TR::Snippet * snippet;
   TR::LabelSymbol * snippetLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::Instruction * cursor = NULL;   // Point to instruction that will assign targetReg
   TR::MemoryReference * divisorMr = NULL;

   bool divisorIsFieldAccess = false;
   bool willUseIndexAndBaseReg = false;
   if (secondChild->getNumChildren() != 0 &&
       secondChild->getOpCode().isMemoryReference() &&
       secondChild->getReferenceCount() == 1 &&
       secondChild->getRegister() == NULL)
      {
      divisorIsFieldAccess = (secondChild->getFirstChild()->getOpCodeValue() != TR::aladd &&
                              secondChild->getFirstChild()->getOpCodeValue() != TR::aiadd);
      // Defect 151061
      // The following comes from com/ibm/oti/vm/BootstrapClassLoader.addPackage
      // in hello world with a compressed pointers build
      //
      // [0x0000020007522994] (  0)  DIVCHK #11[0x000002000752293c]  Method[jitThrowArithmeticException]
      // [0x0000020007522904] (  2)    irem   <flags:"0x8000" (simpleDivCheck )/>
      // [0x000002000752262c] (  1)      iand   <flags:"0x1100" (X>=0 cannotOverflow )/>
      //                      (  3)        ==>icall at [0x00000200075223f8] (in GPR_0049)   <flags:"0x30" (arithmeticPreference invalid8BitGlobalRegister vmThreadRequired )/>
      // [0x00000200075225f4] (  1)        iconst 0x7fffffff   <flags:"0x104" (X!=0 X>=0 )/>
      // [0x00000200075228cc] (  1)      iiload #251[0x000002000745c940]+12  Shadow[<array-size>]   <flags:"0x1100" (X>=0 cannotOverflow )/>
      // [0x00000200074665d0] (  1)        l2a
      // [0x000002000745c908] (  1)          lshl   <flags:"0x800" (compressionSequence )/>
      //                      (  2)            ==>iu2l at [0x000002000745c8d0] (in GPR_0072)   <flags:"0x4" (X!=0 )/>
      // [0x000002000745c860] (  2)            iconst 1
      //
      // When generating a memref, because of the shift=1, the memref will use the same register
      // for the base and index register in order to avoid generating a shift instruction
      // But CLGHSI cannot take a memref which uses the index reg

      willUseIndexAndBaseReg = secondChild->getFirstChild() != NULL &&
         secondChild->getFirstChild()->getOpCodeValue() == TR::l2a &&
         secondChild->getFirstChild()->getFirstChild() != NULL &&
         secondChild->getFirstChild()->getFirstChild()->chkCompressionSequence() &&
         TR::Compiler->om.compressedReferenceShiftOffset() == 1;
      }

   bool disableS390CompareAndTrap = comp->getOption(TR_DisableTraps);

   // Try to compare directly to memory if if the child is a field access (load with no index reg)
   if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10) && divisorIsFieldAccess &&
       !willUseIndexAndBaseReg &&
       (node->getFirstChild()->getOpCodeValue() == TR::idiv ||
        node->getFirstChild()->getOpCodeValue() == TR::irem))
      {
      divisorMr = generateS390MemoryReference(secondChild, cg);

      TR::InstOpCode::Mnemonic op = (dtype.isInt64())? TR::InstOpCode::CLGHSI : TR::InstOpCode::CLFHSI;
      generateSILInstruction(cg, op, node, divisorMr, 0);
      cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, snippetLabel);

      cursor->setExceptBranchOp();

      TR::Snippet * snippet = new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, snippetLabel, node->getSymbolReference());
      cg->addSnippet(snippet);
      }
   else if (cg->getHasResumableTrapHandler() && !disableS390CompareAndTrap)
      {
      if (dtype.isInt64() && TR::Compiler->target.is32Bit() && !cg->use64BitRegsOn32Bit())
         {
         TR::Register * tempReg = cg->allocateRegister(TR_GPR);
         TR::RegisterPair * srcRegPair = (TR::RegisterPair *) cg->evaluate(secondChild);
         TR::Register * sLowOrder = srcRegPair->getLowOrder();
         TR::Register * sHighOrder = srcRegPair->getHighOrder();

         generateRRInstruction(cg, TR::InstOpCode::LR, node, tempReg, sLowOrder);
         generateRRInstruction(cg, TR::InstOpCode::OR, node, tempReg, sHighOrder);

         TR::S390RIEInstruction* cursor =
            new (cg->trHeapMemory()) TR::S390RIEInstruction(TR::InstOpCode::CLFIT, node, tempReg, (int16_t)0, TR::InstOpCode::COND_BE, cg);
         cursor->setExceptBranchOp();
         cg->setCanExceptByTrap(true);
         cursor->setNeedsGCMap(0x0000FFFF);
         if (TR::Compiler->target.isZOS()) killRegisterIfNotLocked(cg, TR::RealRegister::GPR4, cursor);
         cg->stopUsingRegister(tempReg);
         }
      else
         {
         TR::InstOpCode::Mnemonic op = (dtype.isInt64())? TR::InstOpCode::CLGIT : TR::InstOpCode::CLFIT;
         TR::Register * srcReg = cg->evaluate(secondChild);
         TR::S390RIEInstruction* cursor =
            new (cg->trHeapMemory()) TR::S390RIEInstruction(op, node, srcReg, (int16_t)0, TR::InstOpCode::COND_BE, cg);
         cursor->setExceptBranchOp();
         cg->setCanExceptByTrap(true);
         cursor->setNeedsGCMap(0x0000FFFF);
         if (TR::Compiler->target.isZOS()) killRegisterIfNotLocked(cg, TR::RealRegister::GPR4, cursor);
         }
      }
   // z9 legacy instructions
   else
      {
      // Generate explicit div by 0 test and snippet to jump to
      if (!constDivisor || (dtype.isInt32() && secondChild->getInt() == 0) || (dtype.isInt64() && secondChild->getLongInt() == 0))
         {
         // if divisor is a constant of zero, branch to the snippet to throw exception
         if (constDivisor)
            {
            cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, snippetLabel);
            cursor->setExceptBranchOp();
            }
         else
            {
            // if divisor is non-constant, need explicit test for 0
            if (dtype.isInt64() && TR::Compiler->target.is32Bit() && !cg->use64BitRegsOn32Bit())
               {
               TR::Register * tempReg = cg->allocateRegister(TR_GPR);

               TR::RegisterPair * srcRegPair = (TR::RegisterPair *) cg->evaluate(secondChild);
               TR::Register * sLowOrder = srcRegPair->getLowOrder();
               TR::Register * sHighOrder = srcRegPair->getHighOrder();

               // We should use SRDA by 0 to set condition code here
               generateRRInstruction(cg, TR::InstOpCode::LR, node, tempReg, sLowOrder);
               generateRRInstruction(cg, TR::InstOpCode::OR, node, tempReg, sHighOrder);
               generateRRInstruction(cg, TR::InstOpCode::LTR, node, tempReg, tempReg);
               cg->stopUsingRegister(tempReg);

               cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, snippetLabel);
               cursor->setExceptBranchOp();
               }
            else
               {
               TR::Register * srcReg;
               srcReg = cg->evaluate(secondChild);
               TR::InstOpCode::Mnemonic op = TR::InstOpCode::LTR;
               if ((TR::Compiler->target.is64Bit() || cg->use64BitRegsOn32Bit()) && dtype.isInt64())
                  {
                  op = TR::InstOpCode::LTGR;
                  }
               generateRRInstruction(cg, op, node, srcReg, srcReg);
               cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, snippetLabel);
               cursor->setExceptBranchOp();
               }
            }
         TR::Snippet * snippet = new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, snippetLabel, node->getSymbolReference());
         cg->addSnippet(snippet);
         }
      }

   if (divisorMr)
      {
      switch (node->getFirstChild()->getOpCodeValue())
         {
         case TR::idiv:
            iDivRemGenericEvaluator(node->getFirstChild(), cg, true, divisorMr);
            break;
         case TR::irem:
            iDivRemGenericEvaluator(node->getFirstChild(), cg, false, divisorMr);
            break;
         }
      divisorMr->stopUsingMemRefRegister(cg);
      }
   else
      {
      cg->evaluate(node->getFirstChild());
      }
   cg->decReferenceCount(node->getFirstChild());

   return NULL;
   }


///////////////////////////////////////////////////////////////////////////////////////
// BNDCHKEvaluator - Array bounds check, checks that child 1 > child 2 >= 0
//   (child 1 is bound, 2 is index). Symbolref indicates failure action/destination
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::BNDCHKEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("BNDCHK", node, cg);
   TR::Node * firstChild = node->getFirstChild();
   TR::Node * secondChild = node->getSecondChild();
   TR::LabelSymbol * boundCheckFailureLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::Snippet * snippet;
   bool swap;
   TR::Instruction* cursor = NULL;
   TR::Compilation *comp = cg->comp();

   TR::Register * arrayLengthReg = firstChild->getRegister();
   TR::Register * arrayIndexReg = secondChild->getRegister();

   // skip l2i. Grab the low order register if it's a register pair.
   bool skipArrayLengthReg = false;
   bool skipArrayIndexReg = false;
   if (firstChild->getOpCodeValue() == TR::l2i &&
           firstChild->isSingleRefUnevaluated() &&
           firstChild->getFirstChild() &&
           firstChild->getFirstChild()->getRegister())
      {
      arrayLengthReg = firstChild->getFirstChild()->getRegister();
      skipArrayLengthReg = true;
      if(arrayLengthReg->getRegisterPair())
         {
         arrayLengthReg = arrayLengthReg->getRegisterPair()->getLowOrder();
         }
      }

   if (secondChild->getOpCodeValue() == TR::l2i &&
           secondChild->isSingleRefUnevaluated() &&
           secondChild->getFirstChild() &&
           secondChild->getFirstChild()->getRegister())
      {
      arrayIndexReg = secondChild->getFirstChild()->getRegister();
      skipArrayIndexReg = true;
      if(arrayIndexReg->getRegisterPair())
         {
         arrayIndexReg = arrayIndexReg->getRegisterPair()->getLowOrder();
         }
      }

   // use CLRT (RR) if possible
   bool useS390CompareAndTrap = !comp->getOption(TR_DisableTraps) && cg->getHasResumableTrapHandler();

   if (useS390CompareAndTrap &&
       (arrayIndexReg != NULL && arrayLengthReg != NULL))
      {
      //arrayIndex/arrayLength are max uint32, so 31 bit logical compare even in 64 bit JIT
      // The optimizer does not always fold away the BNDCHK if the index is a negative constant.
      // Explicit index<0 check is not needed here because negative array index is interpreted
      // as a large positive by the CLRT instruction.

      // ** Generate a NOP LR R0,R0.  The signal handler has to walk backwards to pattern match
      // the trap instructions.  All trap instructions besides CRT/CLRT are 6-bytes in length.
      // Insert 2-byte NOP in front of the 4-byte CLRT to ensure we do not mismatch accidentally.
      cursor = new (cg->trHeapMemory()) TR::S390NOPInstruction(TR::InstOpCode::NOP, 2, node, cg);

      TR::Instruction* cursor = generateRRFInstruction(cg, TR::InstOpCode::CLRT,
                                      node, arrayIndexReg, arrayLengthReg,
                                      getMaskForBranchCondition(TR::InstOpCode::COND_BNLR), true);
      cursor->setExceptBranchOp();
      cursor->setNeedsGCMap(0x0000FFFF);
      cg->setCanExceptByTrap(true);

      if (TR::Compiler->target.isZOS()) killRegisterIfNotLocked(cg, TR::RealRegister::GPR4, cursor);

      if (skipArrayLengthReg)
         {
         cg->decReferenceCount(firstChild->getFirstChild());
         }
      if (skipArrayIndexReg)
         {
         cg->decReferenceCount(secondChild->getFirstChild());
         }
      cg->decReferenceCount(firstChild);
      cg->decReferenceCount(secondChild);

      return NULL;
      }
   else
      {
      // Perform a bound check.
      //
      // Value propagation or profile-directed optimization may have determined
      // that the array bound is a constant, and lowered TR::arraylength into an
      // iconst. In this case, make sure that the constant is the second child.
      //
      // Only type of scenario where first/second children are const is if we need it to force a branch
      //  otherwise simplifier should have cleaned it up

      /**
       *       Both Length and Index are constants
       */
      if (firstChild->getOpCode().isLoadConst() && secondChild->getOpCode().isLoadConst())
         {
         int64_t secondChildConstValue = secondChild->get64bitIntegralValue();
         if (firstChild->getInt() > secondChildConstValue && secondChildConstValue >= 0)
            {
            //nothing to do since inside limit
            }
         else
            {
            // We must evaluate the non-const child if it has not been evaluated
            //
            if (!firstChild->getOpCode().isLoadConst() && firstChild->getRegister() == NULL)
               {
               cg->evaluate(firstChild);
               }

            // Check will always fail, just jump to failure snippet
            cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, boundCheckFailureLabel);
            cg->addSnippet(new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, boundCheckFailureLabel, node->getSymbolReference()));
            cursor->setExceptBranchOp();
            }
         cg->decReferenceCount(firstChild);
         cg->decReferenceCount(secondChild);
         return NULL;
         }

      /**
       *       One of Length and Index is a constant
       */
      bool isForward = false;
      TR::Node * constNode = NULL;
      TR::Node * nonConstNode = NULL;
      bool oneConst = false; // exactly one child is a constant
      TR::Node * skippedL2iNode = NULL;

      if (firstChild->getOpCode().isLoadConst() || secondChild->getOpCode().isLoadConst())
         {
         oneConst = true;
         if (firstChild->getOpCode().isLoadConst())
            {
            isForward = false;
            constNode = firstChild;
            nonConstNode = secondChild;
            }
         else
            {
            isForward = true;
            constNode = secondChild;
            nonConstNode = firstChild;
            }

         skippedL2iNode = NULL;
         if (nonConstNode->getOpCodeValue() == TR::l2i &&
             nonConstNode->getRegister() == NULL &&
             nonConstNode->getReferenceCount() ==1)
            {
            skippedL2iNode = nonConstNode;
            nonConstNode = nonConstNode->getFirstChild();
            }
         }

      int64_t value = -1;
      int32_t constValue = -1;
      if (constNode)
         {
         value = getIntegralValue(constNode);
         constValue = constNode->getInt();
         }

      // always fail the BNDCHK if the index is negative.
      bool alwaysFailBNDCHK = oneConst && (constValue < 0) && isForward;

      if (oneConst &&
         constValue <= MAX_UNSIGNED_IMMEDIATE_VAL &&    // CLFIT takes 16bit unsigned immediate
         (constValue & 0xFF00) != 0xB900 &&             // signal handler might get confused with CLR (opcode 0xB973), etc
         useS390CompareAndTrap)
         {
         // Any constValue <= MAX_UNSIGNED_IMMEDIATE_VAL is taken here.
         // The length is assumed to be non-negative and is within [0, max_uint32] range.
         // The index can be negative or [0, max_uint32]. An unconditional bransh is generated if it's negative.
         // No need to use unconditional BRC because it requires a proceeding NO-OP instruction for proper signal
         // handling. And NOP+BRC is of the same length as CLFIT.
         TR::Register * testRegister = cg->evaluate(nonConstNode);
         TR::InstOpCode::S390BranchCondition bc = alwaysFailBNDCHK ? TR::InstOpCode::COND_BRC :
                                                                     isForward ? TR::InstOpCode::COND_BNH :
                                                                                 TR::InstOpCode::COND_BNL ;

         TR::Instruction* cursor = generateRIEInstruction(cg, TR::InstOpCode::CLFIT,
                                                          node, testRegister, (int16_t)constValue, bc);


         cursor->setExceptBranchOp();
         cg->setCanExceptByTrap(true);
         cursor->setNeedsGCMap(0x0000FFFF);

         if (TR::Compiler->target.isZOS())
            {
            killRegisterIfNotLocked(cg, TR::RealRegister::GPR4, cursor);
            }

         if (skippedL2iNode)
            {
            cg->decReferenceCount(skippedL2iNode);
            }
         cg->decReferenceCount(constNode);
         cg->decReferenceCount(nonConstNode);

         return NULL;
         }
      else if (useS390CompareAndTrap &&
              (  (firstChild->getOpCode().isLoadVar() && firstChild->isSingleRefUnevaluated()) ||
                 (secondChild->getOpCode().isLoadVar() && secondChild->isSingleRefUnevaluated())) &&
              cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_zEC12))
         {
         // Assume 1st child is the memory operand.
         TR::Node * memChild = firstChild;
         TR::Node * regChild = secondChild;
         TR::InstOpCode::S390BranchCondition compareCondition = TR::InstOpCode::COND_BNL;

         // Check if first child is really the memory operand
         if (!(firstChild->getOpCode().isLoadVar() && firstChild->isSingleRefUnevaluated()))
            {
            // Nope... the second child is!
            memChild = secondChild;
            regChild = firstChild;
            compareCondition = TR::InstOpCode::COND_BNH;
            }

         // Ensure register operand is evaluated into register
         if (regChild->getRegister() == NULL)
            cg->evaluate(regChild);

         TR::InstOpCode::Mnemonic opCode = (regChild->getDataType()==TR::Int64) ? TR::InstOpCode::CLGT :
                                                                                  TR::InstOpCode::CLT;
         cursor = generateRSYInstruction(cg, opCode,
                                         node, regChild->getRegister(),
                                         getMaskForBranchCondition(compareCondition),
                                         generateS390MemoryReference(memChild, cg));
         cursor->setExceptBranchOp();
         cg->setCanExceptByTrap(true);
         cursor->setNeedsGCMap(0x0000FFFF);

         if (TR::Compiler->target.isZOS())
            killRegisterIfNotLocked(cg, TR::RealRegister::GPR4, cursor);

         cg->decReferenceCount(memChild);
         cg->decReferenceCount(regChild);

         return NULL;
         }
      else if (oneConst)
         {
         TR::Register * testRegister = cg->evaluate(nonConstNode);
         TR::InstOpCode::S390BranchCondition bc = alwaysFailBNDCHK ? TR::InstOpCode::COND_BRC :
                                                                     isForward ? TR::InstOpCode::COND_BNH :
                                                                                 TR::InstOpCode::COND_BNL;
         TR::Instruction* cursor = NULL;

         if (alwaysFailBNDCHK)
            {
            cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, bc, node, boundCheckFailureLabel);
            }
         else
            {
            cursor = generateS390CompareAndBranchInstruction(cg,
                                                             TR::InstOpCode::CL,
                                                             node,
                                                             testRegister,
                                                             constValue,
                                                             bc,
                                                             boundCheckFailureLabel, false, true);
            }

         cursor->setExceptBranchOp();

         if (skippedL2iNode)
            {
            cg->decReferenceCount(skippedL2iNode);
            }
         cg->decReferenceCount(constNode);
         cg->decReferenceCount(nonConstNode);
         }


      // We assume that there is no GRA stuff hanging of this node
      TR_ASSERT( node->getNumChildren() < 3,"BNDCHK Eval: We are not expecting a third child on BNDCHK trees");

      /**
       *       Neither Length nor Index is constant
       */
      if (!oneConst)
         {
         // logical compare child1 (bound) and child2 (index).
         // Logical because all neg # > any pos # in unsigned form - for check that index > 0.
         // if child1 <= child2, branch on not high,
         // if the operands are switched, i.e.  compare child2 < child1, branch on high
         TR_S390BinaryCommutativeAnalyser temp(cg);
         temp.genericAnalyser(node, TR::InstOpCode::CLR, TR::InstOpCode::CL, TR::InstOpCode::LR, true);
         swap = temp.getReversedOperands();

         // There should be no register attached to the BNDCHK node, otherwise
         // the register would be kept live longer than it should.
         node->unsetRegister();
         cg->decReferenceCount(firstChild);
         cg->decReferenceCount(secondChild);

         // Generate compare code, find out if ops were reversed
         // MASK10 - reversed.  MASK12 - not reversed.
         TR::InstOpCode::Mnemonic brOp = TR::InstOpCode::BRC;
         TR::InstOpCode::S390BranchCondition brCond = (swap) ? TR::InstOpCode::COND_BNL : TR::InstOpCode::COND_BNH;
         cursor = generateS390BranchInstruction(cg, brOp, brCond, node, boundCheckFailureLabel);
         cursor->setExceptBranchOp();
         }

         cg->addSnippet(new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, boundCheckFailureLabel, node->getSymbolReference()));
      }

   return NULL;
   }



///////////////////////////////////////////////////////////////////////////////////////
// ArrayCopyBNDCHKEvaluator - Array bounds check for arraycopy, checks that child 1 >= child 2
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::ArrayCopyBNDCHKEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("ArrayCopyBNDCHK", node, cg);
   // Check that first child >= second child
   //
   // If the first child is a constant and the second isn't, swap the children.
   //
   TR::Node * firstChild = node->getFirstChild();
   TR::Node * secondChild = node->getSecondChild();
   TR::LabelSymbol * boundCheckFailureLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::Instruction * instr = NULL;
   bool useCIJ = false;
   TR::Compilation *comp = cg->comp();

   bool skipL2iArrayTargetLengthReg = false;
   bool skipL2iArrayCopyLengthReg = false;
   TR::Register * arrayTargetLengthReg = NULL;
   TR::Register * arrayCopyLengthReg = NULL;

   arrayTargetLengthReg = firstChild->getRegister();
   arrayCopyLengthReg = secondChild->getRegister();

   if (firstChild->getOpCodeValue() == TR::l2i &&
       firstChild->getFirstChild()->getRegister() != NULL &&
       firstChild->getReferenceCount() == 1 &&
       arrayTargetLengthReg == NULL)
      {
      skipL2iArrayTargetLengthReg = true;
      arrayTargetLengthReg = firstChild->getFirstChild()->getRegister();
      }

   if (secondChild->getOpCodeValue() == TR::l2i &&
       secondChild->getFirstChild()->getRegister() != NULL &&
       secondChild->getReferenceCount() == 1 &&
       arrayCopyLengthReg == NULL)
      {
      skipL2iArrayCopyLengthReg = true;
      arrayCopyLengthReg = secondChild->getFirstChild()->getRegister();
      }

   bool disableS390CompareAndTrap = comp->getOption(TR_DisableTraps);
   static const char*disableS390CompareAndBranch = feGetEnv("TR_DISABLES390CompareAndBranch");
   if (cg->getHasResumableTrapHandler() &&
       !disableS390CompareAndTrap &&
       arrayTargetLengthReg != NULL &&
       arrayCopyLengthReg != NULL )
      {
      //arrayIndex/arrayLength are max uint32, so 31 bit compare even in 64 bit JIT

      // Generate a NOP LR R0,R0.  The signal handler has to walk backwards to pattern match
      // the trap instructions.  All trap instructions besides CRT/CLRT are 6-bytes in length.
      // Insert 2-byte NOP in front of the 4-byte CRT to ensure we do not mismatch accidentally.
      TR::Instruction *cursor = new (cg->trHeapMemory()) TR::S390NOPInstruction(TR::InstOpCode::NOP, 2, node, cg);

      cursor = new (cg->trHeapMemory()) TR::S390RRFInstruction(TR::InstOpCode::CRT, node, arrayCopyLengthReg, arrayTargetLengthReg, getMaskForBranchCondition(TR::InstOpCode::COND_BH), true, cg);

      cursor->setExceptBranchOp();
      cg->setCanExceptByTrap(true);
      cursor->setNeedsGCMap(0x0000FFFF);
      if (TR::Compiler->target.isZOS()) killRegisterIfNotLocked(cg, TR::RealRegister::GPR4, cursor);

      if (skipL2iArrayTargetLengthReg)
         {
         cg->decReferenceCount(firstChild->getFirstChild());
         }
      if (skipL2iArrayCopyLengthReg)
         {
         cg->decReferenceCount(secondChild->getFirstChild());
         }
      cg->decReferenceCount(firstChild);
      cg->decReferenceCount(secondChild);

      return NULL;
      }
   else
      {
      if (firstChild->getOpCode().isLoadConst())
         {
         if (secondChild->getOpCode().isLoadConst())
            {
            if (firstChild->getInt() < secondChild->getInt())
               {
               // Check will always fail, just jump to failure snippet
               //
               instr = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, boundCheckFailureLabel);
               instr->setExceptBranchOp();
               }
            else
               {
               // Check will always succeed, no need for an instruction
               //
               instr = NULL;
               }
            cg->decReferenceCount(firstChild);
            cg->decReferenceCount(secondChild);
            }
         else
            {
            int32_t arrayTargetLengthConst = firstChild->getInt();

            // CIT uses 16-bit immediates
            if (cg->getHasResumableTrapHandler() &&
                arrayTargetLengthConst <= MAX_IMMEDIATE_VAL &&
                arrayTargetLengthConst >= MIN_IMMEDIATE_VAL &&
                (arrayTargetLengthConst & 0xFF00) != 0xB900 && // signal handler might get confused with CRT (opcode 0xB972), etc
                !disableS390CompareAndTrap )
               {
               if (arrayCopyLengthReg == NULL)
                  {
                  arrayCopyLengthReg = cg->evaluate(secondChild);
                  }

               TR::S390RIEInstruction* cursor =
                  new (cg->trHeapMemory()) TR::S390RIEInstruction(TR::InstOpCode::CIT, node, arrayCopyLengthReg, (int16_t)arrayTargetLengthConst, TR::InstOpCode::COND_BH, cg);
               cursor->setExceptBranchOp();
               cursor->setNeedsGCMap(0x0000FFFF);
               cg->setCanExceptByTrap(true);
               if (TR::Compiler->target.isZOS()) killRegisterIfNotLocked(cg, TR::RealRegister::GPR4, cursor);

               if (skipL2iArrayCopyLengthReg)
                  {
                  cg->decReferenceCount(secondChild->getFirstChild());
                  }
               cg->decReferenceCount(firstChild);
               cg->decReferenceCount(secondChild);

               return NULL;
               }
            // check if we can use Compare-and-Branch at least
            else if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10) &&
                     arrayTargetLengthConst <= MAX_IMMEDIATE_BYTE_VAL &&
                     arrayTargetLengthConst >= MIN_IMMEDIATE_BYTE_VAL &&
                     !disableS390CompareAndBranch)
               {
               useCIJ = true;
               if (arrayCopyLengthReg == NULL)
                  {
                  arrayCopyLengthReg = cg->evaluate(secondChild);
                  }

               TR::Instruction* cursor =
                       generateS390CompareAndBranchInstruction(cg,
                                                               TR::InstOpCode::C,
                                                               node,
                                                               arrayCopyLengthReg,
                                                               arrayTargetLengthConst,
                                                               TR::InstOpCode::COND_BH,
                                                               boundCheckFailureLabel,
                                                               false,
                                                               false,
                                                               NULL,
                                                               NULL);
               cursor->setExceptBranchOp();

               if (skipL2iArrayCopyLengthReg)
                  {
                  cg->decReferenceCount(secondChild->getFirstChild());
                  }
               cg->decReferenceCount(firstChild);
               cg->decReferenceCount(secondChild);
               }
            // z9 Instructions
            else
               {
               node->swapChildren();
               instr = generateS390CompareBranchLabel(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BH, TR::InstOpCode::COND_BL, boundCheckFailureLabel);
               node->swapChildren();
               instr->setExceptBranchOp();
               }
            }
         }
      else
         {
         // The first child is not loadConstant
         // CIT uses 16-bit immediates
         if (secondChild->getOpCode().isLoadConst() &&
             cg->getHasResumableTrapHandler() &&
             secondChild->getInt() <= MAX_IMMEDIATE_VAL &&
             secondChild->getInt() >= MIN_IMMEDIATE_VAL &&
             (secondChild->getInt() & 0xFF00) != 0xB900 && // signal handler might get confused with CRT (opcode 0xB972), etc
             !disableS390CompareAndTrap )
            {
            int32_t arrayCopyLengthConst = secondChild->getInt();
            if (arrayTargetLengthReg == NULL)
               {
               arrayTargetLengthReg = cg->evaluate(firstChild);
               }

            TR::S390RIEInstruction* cursor =
               new (cg->trHeapMemory()) TR::S390RIEInstruction(TR::InstOpCode::CIT, node, arrayTargetLengthReg, (int16_t)arrayCopyLengthConst, TR::InstOpCode::COND_BL, cg);
            cursor->setExceptBranchOp();
            cursor->setNeedsGCMap(0x0000FFFF);
            cg->setCanExceptByTrap(true);
            if (TR::Compiler->target.isZOS()) killRegisterIfNotLocked(cg, TR::RealRegister::GPR4, cursor);

            if (skipL2iArrayTargetLengthReg)
               {
               cg->decReferenceCount(firstChild->getFirstChild());
               }
            cg->decReferenceCount(firstChild);
            cg->decReferenceCount(secondChild);

            return NULL;
            }
         // check if we can use Compare-and-Branch at least
         else if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10) &&
                  secondChild->getOpCode().isLoadConst() &&
                  secondChild->getInt() <= MAX_IMMEDIATE_BYTE_VAL &&
                  secondChild->getInt() >= MIN_IMMEDIATE_BYTE_VAL &&
                  !disableS390CompareAndBranch)
            {
            int32_t arrayCopyLengthConst = secondChild->getInt();
            if (arrayTargetLengthReg == NULL)
               {
               arrayTargetLengthReg = cg->evaluate(firstChild);
               }

            useCIJ = true;
            TR::Instruction* cursor =
                    generateS390CompareAndBranchInstruction(cg,
                                                            TR::InstOpCode::C,
                                                            node,
                                                            arrayTargetLengthReg,
                                                            arrayCopyLengthConst,
                                                            TR::InstOpCode::COND_BL,
                                                            boundCheckFailureLabel,
                                                            false,
                                                            false,
                                                            NULL,
                                                            NULL);

            cursor->setExceptBranchOp();

            if (skipL2iArrayTargetLengthReg)
               {
               cg->decReferenceCount(firstChild->getFirstChild());
               }
            cg->decReferenceCount(firstChild);
            cg->decReferenceCount(secondChild);
            }
         // z9
         else
            {
            instr = generateS390CompareOps(node, cg, TR::InstOpCode::COND_BL, TR::InstOpCode::COND_BH, boundCheckFailureLabel);

            instr->setExceptBranchOp();
            }
         }

      if (instr || useCIJ)
         {
         cg->addSnippet(new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, boundCheckFailureLabel, node->getSymbolReference()));
         }
      }

   return NULL;
   }


TR::Register *
J9::Z::TreeEvaluator::BNDCHKwithSpineCHKEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   bool needsBoundCheck = (node->getOpCodeValue() == TR::BNDCHKwithSpineCHK);
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   TR::Node *loadOrStoreChild = node->getFirstChild();
   TR::Node *baseArrayChild = node->getSecondChild();
   TR::Node *arrayLengthChild;
   TR::Node *indexChild;

   if (needsBoundCheck)
      {
      arrayLengthChild = node->getChild(2);
      indexChild = node->getChild(3);
      }
   else
      {
      arrayLengthChild = NULL;
      indexChild = node->getChild(2);
      }

   if (comp->getOption(TR_TraceCG))
      traceMsg(comp,"loadOrStoreChild: %p baseArrayChild: %p arrayLengthChild: %p indexChild: %p\n",loadOrStoreChild, baseArrayChild, arrayLengthChild, indexChild);

   // Order of evaluation dictates that the value to be stored needs to be evaluated first.
   if (loadOrStoreChild->getOpCode().isStore() && !loadOrStoreChild->getRegister())
      {
      TR::Node *valueChild = loadOrStoreChild->getSecondChild();
      cg->evaluate(valueChild);
      }

   TR::Register *baseArrayReg = cg->evaluate(baseArrayChild);
   preEvaluateEscapingNodesForSpineCheck(node, cg);

   // Generate the SpinCheck.
   TR::MemoryReference *contiguousArraySizeMR = generateS390MemoryReference(baseArrayReg, fej9->getOffsetOfContiguousArraySizeField(), cg);
   TR::MemoryReference *discontiguousArraySizeMR = generateS390MemoryReference(baseArrayReg, fej9->getOffsetOfDiscontiguousArraySizeField(), cg);

   bool doLoadOrStore = false;
   bool doAddressComputation = true;

   TR::Register* loadOrStoreReg = NULL;
   TR_Debug * debugObj = cg->getDebug();

   TR::LabelSymbol * oolStartLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * oolReturnLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::Register *indexReg = cg->evaluate(indexChild);
   TR::Register *valueReg = NULL;

   TR::Instruction * branchToOOL;

   if (needsBoundCheck)
      {
      generateRXInstruction(cg, TR::InstOpCode::CL, node, indexReg, contiguousArraySizeMR);

      // OOL Will actually throw the AIOB if necessary.
      branchToOOL = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNL, node, oolStartLabel);
      if (debugObj)
         debugObj->addInstructionComment(branchToOOL, "Start of OOL BNDCHKwithSpineCHK sequence");
      }
   else
      {
      // Load the Contiguous Array Size and test if it's zero.
      TR::Register *tmpReg = cg->allocateRegister();
      generateRSInstruction(cg, TR::InstOpCode::ICM, node, tmpReg, (uint32_t) 0xF, contiguousArraySizeMR);
      cg->stopUsingRegister(tmpReg);

      // Branch to OOL if contiguous array size is zero.
      branchToOOL = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, oolStartLabel);
      if (debugObj)
         debugObj->addInstructionComment(branchToOOL, "Start of OOL BNDCHKwithSpineCHK sequence");
      }

   // For reference stores, only evaluate the array element address because the store cannot
   // happen here (it must be done via the array store check).
   //
   // For primitive stores, evaluate them now.
   //
   // For loads, evaluate them now.
   //
   TR::Node * actualLoadOrStoreChild = loadOrStoreChild;
   TR::Node * evaluateConversionNode = loadOrStoreChild; // We want to match the top most conversion node and evaluate that.

   bool doLoadDecompress = false;

   // Top-level check whether a decompression sequence is necessary, because the first child
   // may have been created by a PRE temp.
   //
   if ((loadOrStoreChild->getOpCodeValue() == TR::aload || loadOrStoreChild->getOpCodeValue() == TR::aRegLoad) &&
       node->isSpineCheckWithArrayElementChild() && TR::Compiler->target.is64Bit() && comp->useCompressedPointers())
      {
      doLoadDecompress = true;
      }

   while (actualLoadOrStoreChild->getOpCode().isConversion() ||
          ( ( actualLoadOrStoreChild->getOpCode().isAdd() || actualLoadOrStoreChild->getOpCode().isSub() ||
              actualLoadOrStoreChild->getOpCode().isLeftShift() || actualLoadOrStoreChild->getOpCode().isRightShift()) &&
            actualLoadOrStoreChild->containsCompressionSequence()))
      {
      // If we find a compression sequence, then reset the topmost conversion node to the child of the compression sequence.
      // i.e.  lshl
      //          i2l <--- set evaluateConversionNode to this node
      //
      if (! (actualLoadOrStoreChild->getOpCode().isConversion()))
         {
         evaluateConversionNode = actualLoadOrStoreChild->getFirstChild();
         }
      actualLoadOrStoreChild = actualLoadOrStoreChild->getFirstChild();
      }

   TR::Node * evaluatedNode = NULL;

   if (actualLoadOrStoreChild->getOpCode().isStore())
      {
      if (actualLoadOrStoreChild->getReferenceCount() > 1)
         {
         TR_ASSERT(actualLoadOrStoreChild->getOpCode().isWrtBar(), "Opcode must be wrtbar");
         loadOrStoreReg = cg->evaluate(actualLoadOrStoreChild->getFirstChild());
         cg->decReferenceCount(actualLoadOrStoreChild->getFirstChild());
         evaluatedNode = actualLoadOrStoreChild->getFirstChild();
         }
      else
         {
         loadOrStoreReg = cg->evaluate(actualLoadOrStoreChild);
         valueReg = actualLoadOrStoreChild->getSecondChild()->getRegister();
         evaluatedNode = actualLoadOrStoreChild;
         }
      }
   else
      {
      evaluatedNode = evaluateConversionNode;
      loadOrStoreReg = cg->evaluate(evaluateConversionNode);
      }

   if (comp->getOption(TR_TraceCG))
      traceMsg(comp,"Identified actualLoadOrStoreChild: %p and evaluated node: %p\n",actualLoadOrStoreChild, evaluatedNode);
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, oolReturnLabel);

   if (loadOrStoreChild != evaluatedNode)
      cg->evaluate(loadOrStoreChild);

   // ---------------------------------------------
   // OOL Sequence to handle arraylet calculations.
   // ---------------------------------------------
   TR_S390OutOfLineCodeSection *outlinedDiscontigPath = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(oolStartLabel,oolReturnLabel,cg);
   cg->getS390OutOfLineCodeSectionList().push_front(outlinedDiscontigPath);
   outlinedDiscontigPath->swapInstructionListsWithCompilation();
   TR::Instruction * cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, oolStartLabel);

   // get the correct liveLocals from the OOL entry branch instruction, so the GC maps can be correct in OOL slow path
   cursor->setLiveLocals(branchToOOL->getLiveLocals());

   // Generate BNDCHK code.
   if (needsBoundCheck)
      {
      TR::LabelSymbol * boundCheckFailureLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

      // Check if contiguous arraysize is zero first.  If not, throw AIOB
      TR::MemoryReference* contiguousArraySizeMR2 = generateS390MemoryReference(*contiguousArraySizeMR, 0, cg);
      TR::Register *tmpReg = cg->allocateRegister();
      cursor = generateRSInstruction(cg, TR::InstOpCode::ICM, node, tmpReg, (uint32_t) 0xF, contiguousArraySizeMR2, cursor);
      cg->stopUsingRegister(tmpReg);

      // Throw AIOB if continuousArraySizeMR is zero.
      cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, boundCheckFailureLabel, cursor);
      cursor->setExceptBranchOp();

      // Don't use CompareAndTrap to save the load of discontiguousArraySize into a register
      cursor = generateRXInstruction(cg, TR::InstOpCode::CL, node, indexReg, discontiguousArraySizeMR, cursor);

      cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNL, node, boundCheckFailureLabel, cursor);
      cursor->setExceptBranchOp();
      cg->addSnippet(new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, boundCheckFailureLabel, node->getSymbolReference()));
      }

   // TODO: Generate Arraylet calculation.
   TR::DataType dt = loadOrStoreChild->getDataType();
   int32_t elementSize = 0;
   if (dt == TR::Address)
      {
      elementSize = TR::Compiler->om.sizeofReferenceField();
      }
   else
      {
      elementSize = TR::Symbol::convertTypeToSize(dt);
      }

   int32_t spinePointerSize = (TR::Compiler->target.is64Bit() && !comp->useCompressedPointers()) ? 8 : 4;
   int32_t arrayHeaderSize = TR::Compiler->om.discontiguousArrayHeaderSizeInBytes();
   int32_t arrayletMask = fej9->getArrayletMask(elementSize);

   // Load the arraylet from the spine.
   int32_t spineShift = fej9->getArraySpineShift(elementSize);
   int32_t spinePtrShift = TR::TreeEvaluator::checkNonNegativePowerOfTwo(spinePointerSize);
   int32_t elementShift = TR::TreeEvaluator::checkNonNegativePowerOfTwo(elementSize);
   TR::Register* tmpReg = cg->allocateRegister();
   if (TR::Compiler->target.is64Bit())
      {
      if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_zEC12))
         {
         cursor = generateRIEInstruction(cg, TR::InstOpCode::RISBGN, node, tmpReg, indexReg,(32+spineShift-spinePtrShift), (128+63-spinePtrShift),(64-spineShift+spinePtrShift),cursor);
         }
      else if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10))
         {
         cursor = generateRIEInstruction(cg, TR::InstOpCode::RISBG, node, tmpReg, indexReg,(32+spineShift-spinePtrShift), (128+63-spinePtrShift),(64-spineShift+spinePtrShift),cursor);
         }
      else
         {
         cursor = generateRRInstruction(cg, TR::InstOpCode::LGFR, node, tmpReg, indexReg, cursor);
         cursor = generateRSInstruction(cg, TR::InstOpCode::SRAG, node, tmpReg, tmpReg, spineShift, cursor);
         cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, tmpReg, tmpReg, spinePtrShift, cursor);
         }
      }
   else
      {
      cursor = generateRRInstruction(cg, TR::InstOpCode::LR, node, tmpReg, indexReg, cursor);
      cursor = generateRSInstruction(cg, TR::InstOpCode::SRA, node, tmpReg, tmpReg, spineShift, cursor);
      cursor = generateRSInstruction(cg, TR::InstOpCode::SLL, node, tmpReg, tmpReg, spinePtrShift, cursor);
      }

   // Load Arraylet pointer from Spine
   //   Pointer is compressed on 64-bit CmpRefs
   bool useCompressedPointers = TR::Compiler->target.is64Bit() && comp->useCompressedPointers();
   TR::MemoryReference * spineMR = generateS390MemoryReference(baseArrayReg, tmpReg, arrayHeaderSize, cg);
   cursor = generateRXInstruction(cg, (useCompressedPointers)?TR::InstOpCode::LLGF:TR::InstOpCode::getLoadOpCode(), node, tmpReg, spineMR, cursor);

   // Handle the compress shifting and addition of heap base.
   if (useCompressedPointers)
      {
      // Shift by compressed pointers shift amount if necessary.
      uint32_t cmpRefsShift = TR::Compiler->om.compressedReferenceShift();
      if (cmpRefsShift == 1)
         {
         TR::MemoryReference *cmpRefsShift1MR = generateS390MemoryReference(tmpReg, tmpReg, 0, cg);
         cursor = generateRXInstruction(cg, TR::InstOpCode::LA, node, tmpReg, cmpRefsShift1MR, cursor);
         }
      else if (cmpRefsShift >= 2)
         {
         cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, tmpReg, tmpReg, cmpRefsShift, cursor);
         }

      // Add heapbase value if necessary.
      uintptrj_t heapBaseValue = TR::Compiler->vm.heapBaseAddress();
      if (heapBaseValue != 0)
         cursor = generateRegLitRefInstruction(cg, TR::InstOpCode::AG, node, tmpReg, (int64_t)heapBaseValue, NULL, cursor, NULL, false);
      }

   // Calculate the offset with the arraylet for the index.
   TR::Register* tmpReg2 = cg->allocateRegister();
   TR::MemoryReference *arrayletMR;
   if (TR::Compiler->target.is64Bit())
      {
      if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_zEC12))
         {
         cursor = generateRIEInstruction(cg, TR::InstOpCode::RISBGN, node, tmpReg2, indexReg,(64-spineShift- elementShift), (128+63-elementShift),(elementShift),cursor);
         }
      else if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10))
         {
         cursor = generateRIEInstruction(cg, TR::InstOpCode::RISBG, node, tmpReg2, indexReg,(64-spineShift- elementShift), (128+63-elementShift),(elementShift),cursor);
         }
      else
         {
         cursor = generateRRInstruction(cg, TR::InstOpCode::LGFR, node, tmpReg2, indexReg, cursor);
         cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, tmpReg2, tmpReg2, 64-spineShift, cursor);
         cursor = generateRSInstruction(cg, TR::InstOpCode::SRLG, node, tmpReg2, tmpReg2, 64-spineShift - elementShift, cursor);
         }
      }
   else
      {
      generateShiftAndKeepSelected31Bit(node, cg, tmpReg2, indexReg, 32-spineShift - elementShift, 31-elementShift, elementShift, true, false);
      }

   arrayletMR = generateS390MemoryReference(tmpReg, tmpReg2, 0, cg);
   cg->stopUsingRegister(tmpReg);
   cg->stopUsingRegister(tmpReg2);

   if (!actualLoadOrStoreChild->getOpCode().isStore())
      {
      TR::InstOpCode::Mnemonic op = TR::InstOpCode::BAD;

      TR::MemoryReference *highArrayletMR = NULL;
      TR::Register *highRegister = NULL;
      bool clearHighOrderBitsForUnsignedHalfwordLoads = false;

      // If we're not loading an array shadow then this must be an effective
      // address computation on the array element (for a write barrier).
      if ((!actualLoadOrStoreChild->getOpCode().hasSymbolReference() ||
           !actualLoadOrStoreChild->getSymbolReference()->getSymbol()->isArrayShadowSymbol()) &&
          !node->isSpineCheckWithArrayElementChild())
         {
         op = TR::InstOpCode::LA;
         }
      else
         {
         switch (dt)
            {
            case TR::Int8:   if (loadOrStoreChild->isUnsignedLoad())
                               op = (TR::Compiler->target.is64Bit() ? TR::InstOpCode::LLGC : TR::InstOpCode::LLC);
                            else
                               op = (TR::Compiler->target.is64Bit() ? TR::InstOpCode::LGB : TR::InstOpCode::LB);
                            break;
            case TR::Int16:  if (actualLoadOrStoreChild->getOpCode().isShort())
                               {
                               op = TR::InstOpCode::getLoadHalfWordOpCode();
                               }
                            else
                               {
                               if (TR::Compiler->target.is64Bit())
                                  {
                                  op = TR::InstOpCode::LLGH;
                                  }
                               else
                                  {
                                  op = TR::InstOpCode::LLH;
                                  }
                               }
                            break;
            case TR::Int32:
                            if (loadOrStoreChild->isUnsignedLoad())
                               op = (TR::Compiler->target.is64Bit() ? TR::InstOpCode::LLGF : TR::InstOpCode::L);
                            else
                               op = (TR::Compiler->target.is64Bit() ? TR::InstOpCode::LGF : TR::InstOpCode::L);
                            break;
            case TR::Int64:
                            if (TR::Compiler->target.is64Bit())
                               op = TR::InstOpCode::LG;
                            else
                               {
                               TR_ASSERT(loadOrStoreReg->getRegisterPair(), "expecting a register pair");

                               op = TR::InstOpCode::L;
                               highArrayletMR = generateS390MemoryReference(*arrayletMR, 4, cg);
                               highRegister = loadOrStoreReg->getHighOrder();
                               loadOrStoreReg = loadOrStoreReg->getLowOrder();
                               }
                            break;

            case TR::Float:  op = TR::InstOpCode::LE; break;
            case TR::Double: op = TR::InstOpCode::LD; break;

            case TR::Address:
                            if (TR::Compiler->target.is32Bit())
                               op = TR::InstOpCode::L;
                            else if (comp->useCompressedPointers())
                               op = TR::InstOpCode::LLGF;
                            else
                               op = TR::InstOpCode::LG;
                            break;

            default:
                            TR_ASSERT(0, "unsupported array element load type");
            }
         }
      cursor = generateRXInstruction(cg, op, node, loadOrStoreReg, arrayletMR, cursor);

      if (doLoadDecompress)
         {
         TR_ASSERT( dt == TR::Address, "Expecting loads with decompression trees to have data type TR::Address");

         // Shift by compressed pointers shift amount if necessary.
         //
         uint32_t cmpRefsShift = TR::Compiler->om.compressedReferenceShift();
         if (cmpRefsShift == 1)
            {
            TR::MemoryReference *cmpRefsShift1MR = generateS390MemoryReference(loadOrStoreReg, loadOrStoreReg, 0, cg);
            cursor = generateRXInstruction(cg, TR::InstOpCode::LA, node, loadOrStoreReg, cmpRefsShift1MR, cursor);
            }
         else if (cmpRefsShift >= 2)
            {
            cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, loadOrStoreReg, loadOrStoreReg, cmpRefsShift, cursor);
            }

         // Add heapbase value if necessary.
         uintptrj_t heapBaseValue = TR::Compiler->vm.heapBaseAddress();
         if (heapBaseValue != 0)
            cursor = generateRegLitRefInstruction(cg, TR::InstOpCode::AG, node, loadOrStoreReg, (int64_t)heapBaseValue, NULL, cursor, NULL, false);
         }

      if (highArrayletMR)
         {
         cursor = generateRXInstruction(cg, op, node, highRegister, highArrayletMR, cursor);
         }
      // We may need to clear the upper 16-bits of a unsign halfword load.
      if (clearHighOrderBitsForUnsignedHalfwordLoads)
         cursor = generateRIInstruction(cg, TR::InstOpCode::NILH, node, loadOrStoreReg, (int16_t)0x0000, cursor);
      }
   else
      {
      if (dt != TR::Address)
         {
         TR::InstOpCode::Mnemonic op;
         bool needStore = true;

         switch (dt)
            {
            case TR::Int8:   op = TR::InstOpCode::STC; break;
            case TR::Int16:  op = TR::InstOpCode::STH; break;
            case TR::Int32:  op = TR::InstOpCode::ST; break;
            case TR::Int64:
               if (TR::Compiler->target.is64Bit())
                  {
                  op = TR::InstOpCode::STG;
                  }
               else
                  {
                  TR_ASSERT(valueReg->getRegisterPair(), "value must be a register pair");
                  cursor = generateRXInstruction(cg, TR::InstOpCode::ST, node,  valueReg->getLowOrder(), arrayletMR, cursor);
                  cursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, valueReg->getHighOrder(), generateS390MemoryReference(*arrayletMR,4,cg), cursor);
                  needStore = false;
                  }
               break;

            case TR::Float:  op = TR::InstOpCode::STE; break;
            case TR::Double: op = TR::InstOpCode::STD; break;

            default:
               TR_ASSERT(0, "unsupported array element store type");
               op = TR::InstOpCode::BAD;
            }

         if (needStore)
            cursor = generateRXInstruction(cg, op, node, valueReg, arrayletMR, cursor);
         }
      else
         {
         TR_ASSERT(0, "OOL reference stores not supported yet");
         }
      }


   cursor = generateS390BranchInstruction(cg,TR::InstOpCode::BRC,TR::InstOpCode::COND_BRC,node,oolReturnLabel, cursor);
   if (debugObj)
      debugObj->addInstructionComment(cursor, "End of OOL BNDCHKwithSpineCHK sequence");

   outlinedDiscontigPath->swapInstructionListsWithCompilation();

   cg->decReferenceCount(loadOrStoreChild);
   cg->decReferenceCount(baseArrayChild);
   cg->decReferenceCount(indexChild);
   if (arrayLengthChild)
      cg->recursivelyDecReferenceCount(arrayLengthChild);

   return NULL;
   }

static void
VMarrayStoreCHKEvaluator(
      TR::Node * node,
      TR::S390CHelperLinkage *helperLink,
      TR::Node *callNode,
      TR::Register * srcReg,
      TR::Register * owningObjectReg,
      TR::Register * t1Reg,
      TR::Register * t2Reg,
      TR::Register * litPoolBaseReg,
      TR::Register * owningObjectRegVal,
      TR::Register * srcRegVal,
      TR::LabelSymbol * wbLabel,
      TR::RegisterDependencyConditions * conditions,
      TR::CodeGenerator * cg)
   {
   TR::LabelSymbol * helperCallLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * startOOLLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * exitOOLLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * exitPointLabel = wbLabel;
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());

   TR_S390OutOfLineCodeSection *arrayStoreCHKOOL;
   TR_Debug * debugObj = cg->getDebug();

   TR::InstOpCode::Mnemonic loadOp;
   TR::Instruction * cursor;
   TR::Instruction * gcPoint;
   TR::S390PrivateLinkage * linkage = TR::toS390PrivateLinkage(cg->getLinkage());
   int bytesOffset;

   TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node, owningObjectRegVal, generateS390MemoryReference(owningObjectReg, (int32_t) TR::Compiler->om.offsetOfObjectVftField(), cg), NULL);
   TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node,          srcRegVal, generateS390MemoryReference(         srcReg, (int32_t) TR::Compiler->om.offsetOfObjectVftField(), cg), NULL);

   // may need to convert the class offset from t1Reg into a J9Class pointer
   cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, t1Reg, generateS390MemoryReference(owningObjectRegVal, (int32_t) offsetof(J9ArrayClass, componentType), cg));

   // check if obj.class(in t1Reg) == array.componentClass in t2Reg
#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
   cursor = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::CR, node, t1Reg, srcRegVal, TR::InstOpCode::COND_BER, wbLabel, false, false);
#else
   cursor = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpLogicalRegOpCode(), node, t1Reg, srcRegVal, TR::InstOpCode::COND_BE, wbLabel, false, false);
#endif

   if (debugObj)
      debugObj->addInstructionComment(cursor, "Check if src.type == array.type");

   intptrj_t objectClass = (intptrj_t) fej9->getSystemClassFromClassName("java/lang/Object", 16, true);
   /*
    * objectClass is used for Object arrays check optimization: when we are storing to Object arrays we can skip all other array store checks
    * However, TR_J9SharedCacheVM::getSystemClassFromClassName can return 0 when it's impossible to relocate j9class later for AOT loads
    * in that case we don't want to generate the Object arrays check
    */
   bool doObjectArrayCheck = objectClass != NULL;

   if (doObjectArrayCheck && (cg->wantToPatchClassPointer((TR_OpaqueClassBlock*)objectClass, node) || cg->needClassAndMethodPointerRelocations()))
      {
      if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10) && cg->isLiteralPoolOnDemandOn())
         {
         TR::S390ConstantDataSnippet * targetsnippet;
         if (TR::Compiler->target.is64Bit())
            {
            targetsnippet = cg->findOrCreate8ByteConstant(node, (int64_t)objectClass);
            cursor = (TR::S390RILInstruction *) generateRILInstruction(cg, TR::InstOpCode::CLGRL, node, t1Reg, targetsnippet, 0);
            }
         else
            {
            targetsnippet = cg->findOrCreate4ByteConstant(node, (int32_t)objectClass);
            cursor = (TR::S390RILInstruction *) generateRILInstruction(cg, TR::InstOpCode::CLRL, node, t1Reg, targetsnippet, 0);
            }

         if(comp->getOption(TR_EnableHCR))
            comp->getSnippetsToBePatchedOnClassRedefinition()->push_front(targetsnippet);
         if (cg->needClassAndMethodPointerRelocations())
            {
            targetsnippet->setReloType(TR_ClassPointer);
            AOTcgDiag4(comp, "generateRegLitRefInstruction constantDataSnippet=%x symbolReference=%x symbol=%x reloType=%x\n",
                  targetsnippet, targetsnippet->getSymbolReference(), targetsnippet->getSymbolReference()->getSymbol(), TR_ClassPointer);
            }
         }
      else
         {
         if (cg->needClassAndMethodPointerRelocations())
            {
            generateRegLitRefInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, t2Reg,(uintptrj_t) objectClass, TR_ClassPointer, conditions, NULL, NULL);
            }
         else
            {
            genLoadAddressConstantInSnippet(cg, node, (intptr_t)objectClass, t2Reg, cursor, conditions, litPoolBaseReg, true);
            }

#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
         generateRRInstruction(cg, TR::InstOpCode::CR, node, t1Reg, t2Reg);
#else
         generateRRInstruction(cg, TR::InstOpCode::getCmpLogicalRegOpCode(), node, t1Reg, t2Reg);
#endif
         }
      }
   else if (doObjectArrayCheck)
      {
      // make sure that t1Reg contains the class offset and not the J9Class pointer
      if (TR::Compiler->target.is64Bit())
         generateS390ImmOp(cg, TR::InstOpCode::getCmpLogicalOpCode(), node, t1Reg, t1Reg, (int64_t) objectClass, conditions, litPoolBaseReg);
      else
         generateS390ImmOp(cg, TR::InstOpCode::getCmpLogicalOpCode(), node, t1Reg, t1Reg, (int32_t) objectClass, conditions, litPoolBaseReg);
      }

   // Bringing back tests from outlined keeping only helper call in outlined section
   // TODO Attching helper call predependency to BRASL instruction and combine ICF conditions with post dependency conditions of
   // helper call should fix the issue of unnecessary spillings in ICF. Currently bringing the tests back to main line here but
   // check performance of both case.
   cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, wbLabel);
   if (debugObj)
      debugObj->addInstructionComment(cursor, "Check if array.type is type object, if yes jump to wbLabel");

   generateRXInstruction(cg, TR::InstOpCode::getCmpLogicalOpCode(), node, t1Reg,
      generateS390MemoryReference(srcRegVal, offsetof(J9Class, castClassCache), cg));

   cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, wbLabel);
   if (debugObj)
      debugObj->addInstructionComment(cursor, "Check if src.class(in t1Reg).castClassCache == array.componentClass");

   // Check to see if array-type is a super-class of the src object
   if (TR::Compiler->target.is64Bit())
      {
      loadOp = TR::InstOpCode::LLGH;
      bytesOffset = 6;
      }
   else
      {
      loadOp = TR::InstOpCode::LLH;
      bytesOffset = 2;
      }

   // Get array element depth
   cursor = generateRXInstruction(cg, loadOp, node, owningObjectRegVal,
      generateS390MemoryReference(t1Reg, offsetof(J9Class, classDepthAndFlags) + bytesOffset, cg));

   // Get src depth
   cursor = generateRXInstruction(cg, loadOp, node, t2Reg,
      generateS390MemoryReference(srcRegVal, offsetof(J9Class, classDepthAndFlags) + bytesOffset, cg));

   TR_ASSERT(sizeof(((J9Class*)0)->classDepthAndFlags) == sizeof(uintptr_t),
      "VMarrayStoreCHKEvaluator::J9Class->classDepthAndFlags is wrong size\n");

   // Check super class values
   static_assert(J9_JAVA_CLASS_DEPTH_MASK == 0xffff, "VMarrayStoreCHKEvaluator::J9_JAVA_CLASS_DEPTH_MASK should have be 16 bit of ones");

   // Compare depths and makes sure depth(src) >= depth(array-type)
   generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, owningObjectRegVal, t2Reg, TR::InstOpCode::COND_BH, helperCallLabel, false, false);
   if (debugObj)
      debugObj->addInstructionComment(cursor, "Failure if depth(src) < depth(array-type)");

   if (TR::Compiler->target.is64Bit())
      {
      generateRSInstruction(cg, TR::InstOpCode::SLLG, node, owningObjectRegVal, owningObjectRegVal, 3);
      }
   else
      {
      generateRSInstruction(cg, TR::InstOpCode::SLL, node, owningObjectRegVal, 2);
      }

   generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, t2Reg,
      generateS390MemoryReference(srcRegVal, offsetof(J9Class, superclasses), cg));

   generateRXInstruction(cg, TR::InstOpCode::getCmpLogicalOpCode(), node, t1Reg,
      generateS390MemoryReference(t2Reg, owningObjectRegVal, 0, cg));

   cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, wbLabel);
   if (debugObj)
      debugObj->addInstructionComment(cursor, "Check if src.type is subclass");
   cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, helperCallLabel);
   // FAIL
   arrayStoreCHKOOL = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(helperCallLabel,wbLabel,cg);
   cg->getS390OutOfLineCodeSectionList().push_front(arrayStoreCHKOOL);
   arrayStoreCHKOOL->swapInstructionListsWithCompilation();
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, helperCallLabel);
   TR::Register *dummyResReg = helperLink->buildDirectDispatch(callNode);
   if (dummyResReg)
      cg->stopUsingRegister(dummyResReg);
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, wbLabel);
   arrayStoreCHKOOL->swapInstructionListsWithCompilation();
   }

///////////////////////////////////////////////////////////////////////////////////////
// ArrayStoreCHKEvaluator - Array store check. child 1 is object, 2 is array.
//   Symbolref indicates failure action/destination
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::ArrayStoreCHKEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   // Note: we take advantages of the register conventions of the helpers by limiting register usages on
   //       the fast-path (most likely 4 registers; at most, 6 registers)

   TR::Compilation * comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   TR::Node * firstChild = node->getFirstChild();
   TR_WriteBarrierKind gcMode = comp->getOptions()->getGcMode();
   // As arguments to ArrayStoreCHKEvaluator helper function is children of first child,
   // We need to create a dummy call node for helper call with children containing arguments to helper call. 
   bool doWrtBar = (gcMode == TR_WrtbarOldCheck ||
                    gcMode == TR_WrtbarCardMarkAndOldCheck ||
                    gcMode == TR_WrtbarAlways);

   bool doCrdMrk = ((gcMode == TR_WrtbarCardMark || gcMode == TR_WrtbarCardMarkAndOldCheck || gcMode == TR_WrtbarCardMarkIncremental) && !firstChild->isNonHeapObjectWrtBar());

   TR::Node * litPoolBaseChild=NULL;
   TR::Node * sourceChild = firstChild->getSecondChild();
   TR::Node * classChild  = firstChild->getChild(2);

   bool nopASC = false;
   if (comp->performVirtualGuardNOPing() && node->getArrayStoreClassInNode() &&
      !comp->getOption(TR_DisableOOL) && !fej9->classHasBeenExtended(node->getArrayStoreClassInNode()))
      nopASC = true;

   bool usingCompressedPointers = false;
   if (comp->useCompressedPointers() && firstChild->getOpCode().isIndirect())
      {
       // pattern match the sequence
       //     iistore f     iistore f         <- node
       //       aload O       aload O
       //     value           l2i
       //                       lshr
       //                         lsub
       //                           a2l
       //                             value   <- sourceChild
       //                           lconst HB
       //                         iconst shftKonst
       //
       // -or- if the field is known to be null
       // iistore f
       //    aload O
       //    l2i
       //      a2l
       //        value  <- valueChild
       //
      TR::Node *translatedNode = sourceChild;
      if (translatedNode->getOpCode().isConversion())
         translatedNode = translatedNode->getFirstChild();
      if (translatedNode->getOpCode().isRightShift()) // optional
         translatedNode = translatedNode->getFirstChild();

      bool usingLowMemHeap = false;
      if (TR::Compiler->vm.heapBaseAddress() == 0 ||
             sourceChild->isNull())
         usingLowMemHeap = true;

      if (translatedNode->getOpCode().isSub() || usingLowMemHeap)
         usingCompressedPointers = true;

      if (usingCompressedPointers)
         {
         while ((sourceChild->getNumChildren() > 0) &&
                  (sourceChild->getOpCodeValue() != TR::a2l))
            sourceChild = sourceChild->getFirstChild();
         if (sourceChild->getOpCodeValue() == TR::a2l)
            sourceChild = sourceChild->getFirstChild();
         // artificially bump up the refCount on the value so
         // that different registers are allocated for the actual
         // and compressed values
         //
         sourceChild->incReferenceCount();
         }
      }
   TR::Node * memRefChild = firstChild->getFirstChild();

   TR::Register * srcReg, * classReg, * txReg, * tyReg, * baseReg, * indexReg, *litPoolBaseReg=NULL,*memRefReg;
   TR::MemoryReference * mr1, * mr2;
   TR::LabelSymbol * wbLabel, * doneLabel, * simpleStoreLabel;
   TR::RegisterDependencyConditions * conditions;
   TR::S390PrivateLinkage * linkage = TR::toS390PrivateLinkage(cg->getLinkage());
   TR::Register * tempReg = NULL;
   TR::Instruction *cursor;

   wbLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   simpleStoreLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   txReg = cg->allocateRegister();
   tyReg = cg->allocateRegister();

   TR::Register * owningObjectRegVal = cg->allocateRegister();
   TR::Register * srcRegVal = cg->allocateRegister();

   // dst reg is read-only when we don't do wrtbar or crdmark
   // if destination node is the same as source node we also
   // need to create a copy because destination & source
   // are 1st and 2nd arguments to the call and as such
   // they need to be in 2 different registers
   if (doWrtBar || doCrdMrk || (classChild==sourceChild))
      {
      classReg = cg->gprClobberEvaluate(classChild);
      // evaluate using load and test
      if (sourceChild->getOpCode().isLoadVar() && sourceChild->getRegister()==NULL && !sourceChild->isNonNull())
         {
            srcReg = cg->allocateCollectedReferenceRegister();

            generateRXYInstruction(cg, TR::InstOpCode::getLoadTestOpCode(), sourceChild, srcReg, generateS390MemoryReference(sourceChild, cg));

            sourceChild->setRegister(srcReg);
         }
      else
         {
            srcReg = cg->gprClobberEvaluate(sourceChild);
         }
      }
   else
      {
      classReg = cg->evaluate(classChild);
      srcReg = cg->evaluate(sourceChild);
      }
   TR::Node *callNode = TR::Node::createWithSymRef(node, TR::call, 2, node->getSymbolReference());
   callNode->setChild(0, sourceChild);
   callNode->setChild(1, classChild);
   mr1 = generateS390MemoryReference(firstChild, cg);

   TR::Register *compressedReg = srcReg;
   if (usingCompressedPointers)
      compressedReg = cg->evaluate(firstChild->getSecondChild());

   //  We need deps to setup args for arrayStoreCHK helper and/or wrtBAR helper call.
   //  We need 2 more regs for inline version of arrayStoreCHK (txReg & tyReg).  We use RA/EP for these
   //  We then need two extra regs for memref for the actual store.
   //  A seventh, eigth and ninth post dep may be needed to manufacture imm values
   //  used by the inlined version of arrayStoreCHK
   //  The tenth post dep may be needed to generateDirectCall if it creates a RegLitRefInstruction.
   conditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 11, cg);
   conditions->addPostCondition(classReg, linkage->getIntegerArgumentRegister(0));
   conditions->addPostCondition(srcReg, linkage->getIntegerArgumentRegister(1));
   if (usingCompressedPointers)
      {
      conditions->addPostConditionIfNotAlreadyInserted(compressedReg, TR::RealRegister::AssignAny);
      }
   conditions->addPostCondition(txReg,  linkage->getReturnAddressRegister());
   conditions->addPostCondition(tyReg,  linkage->getEntryPointRegister());
   conditions->addPostCondition(srcRegVal,  TR::RealRegister::AssignAny);
   conditions->addPostCondition(owningObjectRegVal,  TR::RealRegister::AssignAny);

   doneLabel->setEndInternalControlFlow();
   TR::Instruction *current = cg->getAppendInstruction();
   TR_ASSERT( current != NULL, "Could not get current instruction");

   if (node->getNumChildren()==2)
      {
      litPoolBaseChild=node->getSecondChild();
      TR_ASSERT((litPoolBaseChild->getOpCodeValue()==TR::aload) || (litPoolBaseChild->getOpCodeValue()==TR::aRegLoad),
              "Literal pool base child expected\n");
      litPoolBaseReg=cg->evaluate(litPoolBaseChild);
      conditions->addPostCondition(litPoolBaseReg, TR::RealRegister::AssignAny);
      }

   if (!sourceChild->isNonNull())
      {
      // If we have an actionable wrtbar and a NULL ptr, branch around the wrt bar
      // as it needs not be exec'd
      generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpOpCodeFromNode(sourceChild), node, srcReg, 0, TR::InstOpCode::COND_BE, (doWrtBar || doCrdMrk)?simpleStoreLabel:wbLabel, false, true);
      }
   TR::S390CHelperLinkage *helperLink = static_cast<TR::S390CHelperLinkage*>(cg->getLinkage(TR_CHelper));
   if (nopASC)
      {
      // Speculatively NOP the array store check if VP is able to prove that the ASC
      // would always succeed given the current state of the class hierarchy.
      //
      TR::LabelSymbol * oolASCLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR_VirtualGuard *virtualGuard = TR_VirtualGuard::createArrayStoreCheckGuard(comp, node, node->getArrayStoreClassInNode());
      TR::Instruction *vgnopInstr = generateVirtualGuardNOPInstruction(cg, node, virtualGuard->addNOPSite(), NULL, oolASCLabel);

      // nopASC assumes OOL is enabled
      TR_S390OutOfLineCodeSection *outlinedSlowPath = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(oolASCLabel, wbLabel, cg);
      cg->getS390OutOfLineCodeSectionList().push_front(outlinedSlowPath);
      outlinedSlowPath->swapInstructionListsWithCompilation();

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, oolASCLabel);
      TR::Register *dummyResReg = helperLink->buildDirectDispatch(callNode);
      if (dummyResReg)
         cg->stopUsingRegister(dummyResReg);

      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, wbLabel);
      outlinedSlowPath->swapInstructionListsWithCompilation();
      }
   else
      VMarrayStoreCHKEvaluator(node, helperLink, callNode, srcReg, classReg, txReg, tyReg, litPoolBaseReg, owningObjectRegVal, srcRegVal, wbLabel, conditions, cg);

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, wbLabel);

   if (mr1->getBaseRegister())
      {
      conditions->addPostConditionIfNotAlreadyInserted(mr1->getBaseRegister(), TR::RealRegister::AssignAny);
      }
   if (mr1->getIndexRegister())
      {
      conditions->addPostConditionIfNotAlreadyInserted(mr1->getIndexRegister(), TR::RealRegister::AssignAny);
      }

   if (usingCompressedPointers)
      generateRXInstruction(cg, TR::InstOpCode::ST, node, compressedReg, mr1);
   else
      generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, srcReg, mr1);

   if (doWrtBar)
      {
      TR::SymbolReference *wbRef ;
      if (gcMode == TR_WrtbarCardMarkAndOldCheck || gcMode == TR_WrtbarOldCheck)
         wbRef = comp->getSymRefTab()->findOrCreateWriteBarrierStoreGenerationalSymbolRef(comp->getMethodSymbol());
      else
         wbRef = comp->getSymRefTab()->findOrCreateWriteBarrierStoreSymbolRef(comp->getMethodSymbol());

      // Cardmarking is not inlined for gencon. Consider doing so when perf issue arises.
      VMnonNullSrcWrtBarCardCheckEvaluator(firstChild, classReg, srcReg, tyReg, txReg, doneLabel, wbRef, conditions, cg, false);
      }
   else if (doCrdMrk)
      {
      VMCardCheckEvaluator(firstChild, classReg, NULL, conditions, cg, true, doneLabel);
      }

   // Store for case where we have a NULL ptr detected at runtime and
   // branchec around the wrtbar
   //
   // For the non-NULL case we chose to simply exec the ST twice as this is
   // cheaper than branching around the a single ST inst.
   //
   if (!sourceChild->isNonNull() && (doWrtBar || doCrdMrk))
      {
      // As we could hit a gc when doing the gencon wrtbar, we have to not
      // re-do the ST.  We must branch around the second store.
      //
      if (doWrtBar)
         {
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, doneLabel);
         }

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, simpleStoreLabel);

      mr2 = generateS390MemoryReference(*mr1, 0, cg);
      if (usingCompressedPointers)
         generateRXInstruction(cg, TR::InstOpCode::ST, node, compressedReg, mr2);
      else
         generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, srcReg, mr2);
      }

   cg->addVMThreadPostCondition(conditions, NULL);
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, conditions);

   if (comp->useCompressedPointers() && firstChild->getOpCode().isIndirect())
      firstChild->setStoreAlreadyEvaluated(true);

   cg->decReferenceCount(sourceChild);
   cg->decReferenceCount(classChild);
   if (litPoolBaseChild!=NULL) cg->decReferenceCount(litPoolBaseChild);
   cg->decReferenceCount(firstChild);
   if (usingCompressedPointers)
      {
      cg->decReferenceCount(firstChild->getSecondChild());
      cg->stopUsingRegister(compressedReg);
      }
   mr1->stopUsingMemRefRegister(cg);
   cg->stopUsingRegister(txReg);
   cg->stopUsingRegister(tyReg);
   cg->stopUsingRegister(classReg);
   cg->stopUsingRegister(srcReg);
   cg->stopUsingRegister(owningObjectRegVal);
   cg->stopUsingRegister(srcRegVal);

   if (tempReg)
      {
      cg->stopUsingRegister(tempReg);
      }

   // determine where internal control flow begins by looking for the first branch
   // instruction after where the label instruction would have been inserted
   TR::Instruction *next = current->getNext();
   while(next != NULL && !next->isBranchOp())
      next = next->getNext();
   TR_ASSERT( next != NULL, "Could not find branch instruction where internal control flow begins");
   next->setStartInternalControlFlow();

   return NULL;
   }

///////////////////////////////////////////////////////////////////////////////////////
// ArrayCHKEvaluator -  Array compatibility check. child 1 is object1, 2 is object2.
//    Symbolref indicates failure action/destination
///////////////////////////////////////////////////////////////////////////////////////
TR::Register *
J9::Z::TreeEvaluator::ArrayCHKEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("ArrayCHK", node, cg);
   return TR::TreeEvaluator::VMarrayCheckEvaluator(node, cg);
   }



TR::Register *
J9::Z::TreeEvaluator::conditionalHelperEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("conditionalHelper", node, cg);
   // used by methodEnterhook, and methodExitHook
   // Decrement the reference count on the constant placeholder parameter to
   // the MethodEnterHook call.  An evaluation isn't necessary because the
   // constant value isn't used here.
   //
   if (node->getOpCodeValue() == TR::MethodEnterHook)
      {
      if (node->getSecondChild()->getOpCode().isCall() && node->getSecondChild()->getNumChildren() > 1)
         {
         cg->decReferenceCount(node->getSecondChild()->getFirstChild());
         }
      }

   // The child contains an inline test.
   //
   TR::Node * testNode = node->getFirstChild();
   TR::Node * firstChild = testNode->getFirstChild();
   TR::Node * secondChild = testNode->getSecondChild();
   TR::Register * src1Reg = cg->evaluate(firstChild);
   if (secondChild->getOpCode().isLoadConst())
      // &&
      //       secondChild->getRegister() == NULL)
      {
      int32_t value = secondChild->getInt();
      TR::Node * firstChild = testNode->getFirstChild();

      if (value >= MIN_IMMEDIATE_VAL && value <= MAX_IMMEDIATE_VAL)
         {
         generateRIInstruction(cg, TR::InstOpCode::CHI, node, src1Reg, value);
         }
      else
         {
         TR::Register * tempReg = cg->evaluate(secondChild);
         generateRRInstruction(cg, TR::InstOpCode::CR, node, src1Reg, tempReg);
         }
      }
   else
      {
      TR::Register * src2Reg = cg->evaluate(secondChild);
      generateRRInstruction(cg, TR::InstOpCode::CR, node, src1Reg, src2Reg);
      }

   TR::LabelSymbol * snippetLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::Instruction * gcPoint;

   TR::Register * tempReg1 = cg->allocateRegister();
   TR::Register * tempReg2 = cg->allocateRegister();
   TR::RegisterDependencyConditions * dependencies = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 2, cg);
   dependencies->addPostCondition(tempReg1, cg->getEntryPointRegister());
   dependencies->addPostCondition(tempReg2, cg->getReturnAddressRegister());
   snippetLabel->setEndInternalControlFlow();
   gcPoint = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, testNode->getOpCodeValue() == TR::icmpeq ?  TR::InstOpCode::COND_BE : TR::InstOpCode::COND_BNE, node, snippetLabel);
   gcPoint->setStartInternalControlFlow();

   TR::LabelSymbol * reStartLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::Snippet * snippet = new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, snippetLabel, node->getSymbolReference(), reStartLabel);
   cg->addSnippet(snippet);
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, reStartLabel, dependencies);

   gcPoint->setNeedsGCMap(0x0000FFFF);

   cg->decReferenceCount(firstChild);
   cg->decReferenceCount(secondChild);
   cg->decReferenceCount(testNode);
   cg->stopUsingRegister(tempReg1);
   cg->stopUsingRegister(tempReg2);

   return NULL;
   }




// genCoreInstanceofEvaluator is used by if instanceof and instanceof routines.
// The routine generates the 'core' code for instanceof evaluation. It requires a true and false label
// (which are the same and are just fall-through labels if no branching is required) as well as
// a boolean to indicate if the result should be calculated and returned in a register.
// The code also needs to indicate if the fall-through case if for 'true' or 'false'.
TR::Register *
J9::Z::TreeEvaluator::VMgenCoreInstanceofEvaluator(TR::Node * node, TR::CodeGenerator * cg, TR::LabelSymbol * falseLabel, TR::LabelSymbol * trueLabel, bool needsResult, bool trueFallThrough, TR::RegisterDependencyConditions* baseConditions, bool isIfInstanceof)
   {
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   TR::LabelSymbol * doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * continueLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::Instruction * gcPoint = NULL;

   //Two DataSnippet is used in genTestIsSuper for secondaryCacheSites.
   TR::S390WritableDataSnippet *classObjectClazzSnippet = NULL;
   TR::S390WritableDataSnippet *instanceOfClazzSnippet = NULL;

   if (trueLabel == NULL)
      {
      trueLabel = doneLabel;
      }
   if (falseLabel == NULL)
      {
      falseLabel = doneLabel;
      }

   TR::Node * objectNode      = node->getFirstChild();
   TR::Node * castClassNode   = node->getSecondChild();
   TR::SymbolReference * castClassSymRef = castClassNode->getSymbolReference();

   bool testEqualClass        = instanceOfOrCheckCastNeedEqualityTest(node, cg);
   bool testCastClassIsSuper  = instanceOfOrCheckCastNeedSuperTest(node, cg);
   bool isFinalClass          = (castClassSymRef == NULL) ? false : castClassSymRef->isNonArrayFinal(comp);
   bool needsHelperCall       = needHelperCall(node, testCastClassIsSuper, isFinalClass);
   bool testCache             = needTestCache(true, needsHelperCall, testCastClassIsSuper);
   bool performReferenceArrayTestInline = false;
   if (TR::TreeEvaluator::instanceOfOrCheckCastIsFinalArray(node, cg))
      {
      testEqualClass = true;
      testCastClassIsSuper = false;
      needsHelperCall = false;
      testCache = false;
      }
   else if (TR::TreeEvaluator::instanceOfOrCheckCastIsJavaLangObjectArray(node, cg)) // array of Object
      {
      testEqualClass = false;
      testCastClassIsSuper = false;
      needsHelperCall = false;
      testCache = false;
      performReferenceArrayTestInline = true;
      }

   //bool testPackedArray       = instanceOfOrCheckCastPackedArrayTest(node, cg);

   // came from transformed call isInstance to node instanceof, can't resolve at compile time
   bool dynamicClassPointer = isDynamicCastClassPointer(node) && testCastClassIsSuper;
   bool addDataSnippetForSuperTest = isIfInstanceof && dynamicClassPointer && comp->getOption(TR_EnableOnsiteCacheForSuperClassTest);
   TR::Register * objectClazzSnippetReg = NULL;
   TR::Register * instanceOfClazzSnippetReg = NULL;

   TR::LabelSymbol *callHelper = NULL;
   if (dynamicClassPointer)
      {
      testCache = true;
      callHelper = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      //callHelper = new (cg->trHeapMemory()) TR::LabelSymbol(cg);
      }

   TR::Register * objectReg    = objectNode->getRegister();
   TR::Register * castClassReg = castClassNode->getRegister();
   TR_ASSERT(objectReg && castClassReg,
      "TR::TreeEvaluator::VMgenCoreInstanceofEvaluator: objectNode and castClassNode are assumed to beevaluated\n");

   TR::Register * litPoolReg   = establishLitPoolBaseReg(node, cg);

   TR::Register * resultReg;
   TR::Register * callResult   = NULL;
   TR::Register * objectCopyReg = NULL;
   TR::Register * castClassCopyReg = NULL;

   TR::Register * scratch1Reg = NULL;
   TR::Register * scratch2Reg = NULL;
   TR::Register * objClassReg = cg->allocateRegister();

   bool nullTestRequired = !objectNode->isNonNull() && !node->chkIsReferenceNonNull();
   bool nullCCSet        = false;

   TR::RegisterDependencyConditions* conditions;

   dumpOptDetails(comp, "\nInstanceOf: testEqual:%d testSuper: %d testCache: %d needsHelper:%d, dynamicClassPointer:%d falseLabel:%p trueLabel:%p",
      testEqualClass, testCastClassIsSuper, testCache, needsHelperCall, dynamicClassPointer, falseLabel, trueLabel);
   dumpOptDetails(comp, "\nInstanceOf: addDataSnippetForSuperTest: %d, performReferenceArrayTestInline: %d, true fall through:%d need result:%d\n", addDataSnippetForSuperTest, performReferenceArrayTestInline, trueFallThrough, needsResult);
   if (baseConditions)
      {
      conditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(baseConditions, 16, maxInstanceOfPostDependencies(), cg);
      }
   else
      {
      conditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(16, 16, cg);
      }

   if (needsResult)
      {
      resultReg = cg->allocateRegister();
      }
   else
      {
      resultReg = NULL;
      }

   if (litPoolReg)
      {
      conditions->addPostCondition(litPoolReg, TR::RealRegister::AssignAny);
      }

   cg->addVMThreadPostCondition(conditions, NULL);

   if (nullTestRequired && needsResult)
      {
      generateRIInstruction(cg, TR::InstOpCode::LHI, node, resultReg, 0);
      }

   if (needsHelperCall)
      {
      // No GC point needed (confirmed with GAC)
      // the call will kill the parms, so copy them if required and ensure
      // they are in fixed registers
      bool objNodeNull = objectNode->getRegister() == NULL;
      if ((!objNodeNull &&  !cg->canClobberNodesRegister(objectNode)) || (!objNodeNull))
         {
         objectCopyReg = cg->allocateRegister();
         if (nullTestRequired)
            {
            genNullTest(cg, objectNode, objectCopyReg, objectReg, NULL);
            nullCCSet = true;
            }
         else
            {
            generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, objectCopyReg, objectReg);
            }
         conditions->addPostCondition(objectCopyReg, TR::RealRegister::GPR2);
         conditions->addPostConditionIfNotAlreadyInserted(objectReg, TR::RealRegister::AssignAny);
         callResult = objectCopyReg;
         }
      else
         {
         conditions->addPostCondition(objectReg, TR::RealRegister::GPR2);
         callResult = objectReg;
         }

      bool classCastNodeNull = castClassNode->getRegister() == NULL;
      if ((!classCastNodeNull && !cg->canClobberNodesRegister(castClassNode)) || (!classCastNodeNull))
         {
         castClassCopyReg = cg->allocateRegister();
         generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, castClassCopyReg, castClassReg);
         conditions->addPostCondition(castClassCopyReg, TR::RealRegister::GPR1);
         conditions->addPostConditionIfNotAlreadyInserted(castClassReg, TR::RealRegister::AssignAny);
         }
      else
         {
         conditions->addPostConditionIfNotAlreadyInserted(castClassReg, TR::RealRegister::GPR1);
         }

      if (needsResult)
         {
         conditions->addPostCondition(resultReg, TR::RealRegister::AssignAny);
         }
      conditions->addPostCondition(objClassReg, cg->getReturnAddressRegister());
      }
   else
      {
      conditions->addPostConditionIfNotAlreadyInserted(castClassReg, TR::RealRegister::AssignAny);
      if (needsResult)
         {
         conditions->addPostCondition(resultReg, TR::RealRegister::AssignAny);
         }
      conditions->addPostCondition(objClassReg, TR::RealRegister::AssignAny);
      conditions->addPostConditionIfNotAlreadyInserted(objectReg, TR::RealRegister::AssignAny);
      }

   if (testCastClassIsSuper || testCache)
      {
      int32_t castClassDepth = castClassSymRef->classDepth(comp);
      int32_t superClassOffset = castClassDepth * TR::Compiler->om.sizeofReferenceAddress();
      bool outOfBound = (superClassOffset > MAX_IMMEDIATE_VAL || superClassOffset < MIN_IMMEDIATE_VAL || dynamicClassPointer) ? true : false;
      // we don't use scratch2Reg when we do testCastClassIsSuper without testCache (unless it's outOfBound case)
      if (testCache || outOfBound)
         {
         scratch2Reg = cg->allocateRegister();
         conditions->addPostCondition(scratch2Reg, TR::RealRegister::AssignAny);
         }
      scratch1Reg = cg->allocateRegister();

      TR::RealRegister::RegNum scratch1RegAssignment;
#if defined(TR_TARGET_64BIT)
#if defined(J9ZOS390)
      if (comp->getOption(TR_EnableRMODE64))
#endif
         {
         // On 64-bit systems trampolines may kill the EP register so we need to add it to post-dependencies. If there
         // is no OOL path we need to assign any real register to scratch1Reg.
         scratch1RegAssignment = (needsHelperCall) ?  cg->getEntryPointRegister() : TR::RealRegister::AssignAny;
         }
#elif !defined(TR_TARGET_64BIT) || (defined(TR_TARGET_64BIT) && defined(J9ZOS390))
#if (defined(TR_TARGET_64BIT) && defined(J9ZOS390))
      else if (!comp->getOption(TR_EnableRMODE64))
#endif
         {
         scratch1RegAssignment = TR::RealRegister::AssignAny;
         }
#endif
      conditions->addPostCondition(scratch1Reg, scratch1RegAssignment);
      }
#if defined(TR_TARGET_64BIT)
   else if ( needsHelperCall
#if defined(J9ZOS390)
             && comp->getOption(TR_EnableRMODE64)
#endif
           )
      {
      //on zLinux and zOS trampoline may kill EP reg so we need to add it to post conditions
      // when there is an OOL path, we cannot have an unused virtual register, so adding EP to a temp register
      TR::Register * dummyReg = cg->allocateRegister();
      conditions->addPostCondition(dummyReg, cg->getEntryPointRegister());
      dummyReg->setPlaceholderReg();
      cg->stopUsingRegister(dummyReg);
      }
#endif

   if ( performReferenceArrayTestInline )
      {
      if (scratch1Reg == NULL)
         {
         scratch1Reg = cg->allocateRegister();
         conditions->addPostCondition(scratch1Reg, TR::RealRegister::AssignAny);
         }
      }

   if (nullTestRequired)
      {
      // NULL instanceof X is false
      dumpOptDetails(comp, "InstanceOf: Generate NULL Branch\n");
      if (!nullCCSet)
         {
         genNullTest(cg, objectNode, objectReg, objectReg, NULL);
         }
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, falseLabel);
      }

   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/MethodEntry", comp->signature()),1,TR::DebugCounter::Undetermined);
   // this load could have been done after the equality test
   // but that would mean we would have a larger delay for the superclass
   // test. This is presupposing the equality test will not typically match
   TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node, objClassReg, generateS390MemoryReference(objectReg, (int32_t) TR::Compiler->om.offsetOfObjectVftField(), cg), NULL);

   if (performReferenceArrayTestInline)
      {
      // We expect the Array Test to either return True or False, There is no helper.
      // Following debug counter gives staistics about how many Array Test We have.
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/ArrayTest", comp->signature()),1,TR::DebugCounter::Undetermined);
      genIsReferenceArrayTest(node, objClassReg, scratch1Reg, scratch2Reg, needsResult ? resultReg : NULL, falseLabel, trueLabel, needsResult, trueFallThrough, cg);
      }

   if (testCache)
      {
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/Profiled", comp->signature()),1,TR::DebugCounter::Undetermined);
      generateInlineTest(cg, node, castClassNode, objClassReg, resultReg, scratch1Reg, litPoolReg, needsResult, falseLabel, trueLabel, doneLabel, false);
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/ProfiledFail", comp->signature()),1,TR::DebugCounter::Undetermined);

      TR::LabelSymbol * doneTestCacheLabel  = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
      // For the memory reference below, we may need to convert the
      // class offset from objClassReg into a J9Class pointer
#endif
      TR::MemoryReference * cacheMR = generateS390MemoryReference(objClassReg, offsetof(J9Class, castClassCache), cg);

      generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, scratch2Reg, cacheMR);

      //clearing last bit of cached value, which is a cached result of instanceof
      //(0: true, 1: false), we will need to check it below
      //Following Debug Counter is there just to match Total Debug Counters in new evaluator
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/CacheTest", comp->signature()),1,TR::DebugCounter::Undetermined);
      if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_zEC12))
         {
         auto i1 = TR::Compiler->target.is64Bit() ? 0 : 32;

         generateRIEInstruction(cg, TR::InstOpCode::RISBGN, node, scratch1Reg, scratch2Reg, i1, 62|0x80, 0);
         }
      else if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10))
         {
         auto i1 = TR::Compiler->target.is64Bit() ? 0 : 32;

         generateRIEInstruction(cg, TR::InstOpCode::RISBG, node, scratch1Reg, scratch2Reg, i1, 62|0x80, 0);
         }
      else
         {
         generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, scratch1Reg, 0xFFFE);
         generateRRInstruction(cg, TR::InstOpCode::getAndRegOpCode(), node, scratch1Reg, scratch2Reg);
         }

#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
      // May need to convert the J9Class pointer from scratch1Reg
      // into a class offset
#endif
      TR_ASSERT(needsHelperCall, "expecting a helper call after the testCache");
      generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, castClassReg, scratch1Reg, TR::InstOpCode::COND_BNE, doneTestCacheLabel, false, false);
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/CacheClassSuccess", comp->signature()),1,TR::DebugCounter::Undetermined);
      if (needsResult)
         {
         // For cases when cached value has a result (ie: instanceof)
         // value at offsetof(J9Class, castClassCache) is actually j9class + last bit is set for the result of instanceof:
         // 1: false, 0: true, so we need to check and set resultsReg the opposite (0: false, 1: true)

         if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z196))
            {
            generateRRInstruction(cg, TR::InstOpCode::getSubstractRegOpCode(), node, scratch1Reg, scratch2Reg);
            generateRIEInstruction(cg, TR::InstOpCode::AHIK, node, resultReg, scratch1Reg, 1);
            }
         else
            {
            generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, scratch1Reg, 0x1);
            generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, resultReg, scratch2Reg);
            generateRRInstruction(cg, TR::InstOpCode::getOrRegOpCode(), node, scratch1Reg, resultReg);
            generateRRInstruction(cg, TR::InstOpCode::getXORRegOpCode(), node, resultReg, scratch1Reg);
            }

         if (falseLabel != trueLabel)
            {
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, falseLabel);
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, trueLabel);
            }
         else
            {
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, doneLabel);
            }
         }
      else
         {
         if (falseLabel != trueLabel)
            {
            generateRIInstruction(cg, TR::InstOpCode::TMLL, node, scratch2Reg, 0x1);
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, trueLabel);
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, falseLabel);
            }
         else
            {
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, doneLabel);
            }
         }

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneTestCacheLabel);
      }

   if (testEqualClass)
      {
      if (needsResult)
         {
         generateRIInstruction(cg, TR::InstOpCode::LHI, node, resultReg, 1);
         }
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/Equality", comp->signature()),1,TR::DebugCounter::Undetermined);
      generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, objClassReg, castClassReg, TR::InstOpCode::COND_BE, trueLabel, false, false);
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/EqualityFail", comp->signature()),1,TR::DebugCounter::Undetermined);
      }

   if (testCastClassIsSuper)
      {
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/Profiled", comp->signature()),1,TR::DebugCounter::Undetermined);
      generateInlineTest(cg, node, castClassNode, objClassReg, resultReg, scratch1Reg, litPoolReg, needsResult, continueLabel, trueLabel, doneLabel, false, 1);
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/ProfileFail", comp->signature()),1,TR::DebugCounter::Undetermined);
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, continueLabel);
      if (needsResult && !testEqualClass)
         {
         generateRIInstruction(cg, TR::InstOpCode::LHI, node, resultReg, 1);
         }
      int32_t castClassDepth = castClassSymRef->classDepth(comp);

      if ( addDataSnippetForSuperTest )
         {
         if (TR::Compiler->target.is64Bit())
            {
            classObjectClazzSnippet = (TR::S390WritableDataSnippet * )cg->Create8ByteConstant(node, -1, true);
            instanceOfClazzSnippet = (TR::S390WritableDataSnippet * )cg->Create8ByteConstant(node, -1, true);
            }
         else
            {
            classObjectClazzSnippet = (TR::S390WritableDataSnippet * )cg->Create4ByteConstant(node, -1, true);
            instanceOfClazzSnippet = (TR::S390WritableDataSnippet * )cg->Create4ByteConstant(node, -1, true);
            }
         if ( classObjectClazzSnippet == NULL || instanceOfClazzSnippet == NULL )
            {
            addDataSnippetForSuperTest = false;
            }
         else
            {
            objectClazzSnippetReg = cg->allocateRegister();
            instanceOfClazzSnippetReg = cg->allocateRegister();
            conditions->addPostCondition(objectClazzSnippetReg, TR::RealRegister::AssignAny);
            conditions->addPostCondition(instanceOfClazzSnippetReg, TR::RealRegister::AssignAny);
            generateRILInstruction(cg, TR::InstOpCode::LARL, node, objectClazzSnippetReg, classObjectClazzSnippet, 0);
            generateRILInstruction(cg, TR::InstOpCode::LARL, node, instanceOfClazzSnippetReg, instanceOfClazzSnippet, 0);
            }
         }
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/SuperClassTest", comp->signature()),1,TR::DebugCounter::Undetermined);
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/MethodExit", comp->signature()),1,TR::DebugCounter::Undetermined);
      genTestIsSuper(cg, node, objClassReg, castClassReg, scratch1Reg, scratch2Reg, needsResult ? resultReg : NULL, litPoolReg, castClassDepth, falseLabel, trueLabel, callHelper, conditions, NULL, addDataSnippetForSuperTest, objectClazzSnippetReg, instanceOfClazzSnippetReg);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, trueLabel);
      }

   if (scratch1Reg)
      cg->stopUsingRegister(scratch1Reg);
   if (scratch2Reg)
      cg->stopUsingRegister(scratch2Reg);

   if ((testCastClassIsSuper || !needsHelperCall)&& !performReferenceArrayTestInline)
       {
       if (needsResult)
          {
          generateRIInstruction(cg, TR::InstOpCode::LHI, node, resultReg, 0);
          }
       if (trueLabel != falseLabel)
          {
          dumpOptDetails(comp, "InstanceOf: if instanceof\n");
          if (trueFallThrough)
             {
             generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, falseLabel);
             }
          }
       }
   //If snippetAdded is true, we need to do Helper call, and when we comeback, we need to use the result to update
   //the dataSnippet that is added.
   if (needsHelperCall)
      {
      TR::LabelSymbol *doneOOLLabel = NULL;
      TR_Debug * debugObj = cg->getDebug();
      TR::Register * tempObjectClassReg = NULL;

      //jump here from genTestIsSuper
      TR_S390OutOfLineCodeSection *outlinedSlowPath = NULL;
      if (dynamicClassPointer)
         {
         if (falseLabel != trueLabel)
            {
            if (trueFallThrough)
               doneOOLLabel = trueLabel;
            else
               doneOOLLabel = falseLabel;
            }
         else
            doneOOLLabel = doneLabel;

         outlinedSlowPath =
               new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(callHelper, doneOOLLabel,cg);
         cg->getS390OutOfLineCodeSectionList().push_front(outlinedSlowPath);
         outlinedSlowPath->swapInstructionListsWithCompilation();
         TR::Instruction *temp = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, callHelper);

         if (debugObj)
            debugObj->addInstructionComment(temp, "Denotes start of OOL checkCast sequence");

         }
      if ( addDataSnippetForSuperTest )
         {
         tempObjectClassReg = cg->allocateRegister();
         generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, tempObjectClassReg, objClassReg);
         }
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOf/(%s)/Helper", comp->signature()),1,TR::DebugCounter::Undetermined);
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/Helper", comp->signature()),1,TR::DebugCounter::Undetermined);
      generateDirectCall(cg, node, false, node->getSymbolReference(), conditions);

      // this is annoying but since the result from the call has the same reg
      // as the 2nd parm (object reg), we end up having to make a copy to
      // get the result into the resultReg
      // If the false and true labels are the same, there is no branching required,
      // otherwise, need to branch to the right spot.
      if ( needsResult )
         {
         generateRRInstruction(cg, TR::InstOpCode::getLoadTestRegOpCode(), node, resultReg, callResult);
         }
      else
         {
         generateRRInstruction(cg, TR::InstOpCode::getLoadTestRegOpCode(), node, callResult, callResult);
         }

      //when Snippet is Added, do Update the dataSnippet with the result of the call. only when the callResult is true.
      if( addDataSnippetForSuperTest )
         {
         //when Snippet is Added, do Update the dataSnippet with the result of the call. only when the callResult is true.
         /* pseudocode for z
         * BRC to end of this block if callResult is 0
         * load -1 to temp Register
         * compare with "-1 loded register", dataSnippet1, and if not update datasnippet with objectClassReg(Compare and Swap instr)
         * if we didnot update, we don't update the next one->branch out to doneUpdateSnippetLabel
         * store dataSnippet2, castClassReg.//if we did update 1, we need to update both.
         * TestcallResultReg again to use in branch Instr
         * */

         TR::LabelSymbol *doneUpdateSnippetLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, doneUpdateSnippetLabel);
         TR::Register * tempNeg1LoadedRegister = cg->allocateRegister();
         //we do not need post condtion since this code resides in OOL only.

         generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, tempNeg1LoadedRegister, -1);

         comp->getSnippetsToBePatchedOnClassUnload()->push_front(classObjectClazzSnippet);
         comp->getSnippetsToBePatchedOnClassUnload()->push_front(instanceOfClazzSnippet);
         generateRSInstruction(cg, TR::InstOpCode::getCmpAndSwapOpCode(), node, tempNeg1LoadedRegister, tempObjectClassReg, generateS390MemoryReference(objectClazzSnippetReg, 0, cg));
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, doneUpdateSnippetLabel);

         generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, castClassReg, generateS390MemoryReference(instanceOfClazzSnippetReg, 0, cg));
         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneUpdateSnippetLabel);
         cg->stopUsingRegister(tempNeg1LoadedRegister);
         cg->stopUsingRegister(tempObjectClassReg);

         generateRRInstruction(cg, TR::InstOpCode::getLoadTestRegOpCode(), node, callResult, callResult);//condition code needs to be re-set. this is secondCache specific so included in this block.

         }

      if (falseLabel != trueLabel)
         {
         dumpOptDetails(comp, "InstanceOf: if instanceof\n");
         if (trueFallThrough)
            {
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, falseLabel);
            }
         else
            {
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, trueLabel);
            }
         }

      if (dynamicClassPointer )
         {
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, doneOOLLabel);
         outlinedSlowPath->swapInstructionListsWithCompilation();
         }
      }

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, conditions);

   if (needsResult)
      node->setRegister(resultReg);

   cg->decReferenceCount(objectNode);
   cg->decReferenceCount(castClassNode);

   cg->stopUsingRegister(objClassReg);
   if (litPoolReg)
      cg->stopUsingRegister(litPoolReg);
   if (objectCopyReg)
      cg->stopUsingRegister(objectCopyReg);
   if (castClassCopyReg)
      cg->stopUsingRegister(castClassCopyReg);
   if (objectClazzSnippetReg)
      cg->stopUsingRegister(objectClazzSnippetReg);
   if (instanceOfClazzSnippetReg)
      cg->stopUsingRegister(instanceOfClazzSnippetReg);

   if (callResult)
      cg->stopUsingRegister(callResult);

   return resultReg;
   }

static TR::Register *
reservationLockEnter(TR::Node *node, int32_t lwOffset, TR::Register *objectClassReg, TR::CodeGenerator *cg, TR::S390CHelperLinkage *helperLink)
   {
   TR::Register *objReg, *monitorReg, *metaReg, *valReg, *tempReg;
   TR::Register *EPReg, *returnAddressReg;
   TR::LabelSymbol *resLabel, *callLabel, *doneLabel;
   TR::Instruction *instr;
   TR::Instruction *startICF = NULL;
   TR::Compilation * comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   int numICFDeps = 6 + (comp->getOptions()->enableDebugCounters() ? 4: 0);
   TR::RegisterDependencyConditions *ICFConditions =
      new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, numICFDeps, cg);

   if (objectClassReg)
      objReg = objectClassReg;
   else
      objReg = node->getFirstChild()->getRegister();

   if (!comp->getOption(TR_Enable390FreeVMThreadReg))
      metaReg = cg->getMethodMetaDataRealRegister();
   else
      metaReg = cg->getVMThreadRegister();

   monitorReg = cg->allocateRegister();
   valReg = cg->allocateRegister();
   tempReg = cg->allocateRegister();

   resLabel = generateLabelSymbol(cg);
   callLabel = generateLabelSymbol(cg);
   doneLabel = generateLabelSymbol(cg);

   // TODO - primitive monitores are disabled. Enable it after testing
   //TR::TreeEvaluator::isPrimitiveMonitor(node, cg);
   //
   TR::LabelSymbol *helperReturnOOLLabel, *doneOOLLabel = NULL;
   TR_S390OutOfLineCodeSection *outlinedSlowPath = NULL;
   TR_Debug *debugObj = cg->getDebug();
   TR::Snippet *snippet = NULL;

   // This is just for test. (may not work in all cases)
   static bool enforcePrimitive = feGetEnv("EnforcePrimitiveLockRes")? 1 : 0;
   bool isPrimitive = enforcePrimitive ? 1 : node->isPrimitiveLockedRegion();

   // Opcodes:
   bool use64b = true;
   if (TR::Compiler->target.is64Bit() && fej9->generateCompressedLockWord())
      use64b = false;
   else if (!TR::Compiler->target.is64Bit())
      use64b = false;
   TR::InstOpCode::Mnemonic loadOp = use64b ? TR::InstOpCode::LG : TR::InstOpCode::L;
   TR::InstOpCode::Mnemonic loadRegOp = use64b ? TR::InstOpCode::LGR : TR::InstOpCode::LR;
   TR::InstOpCode::Mnemonic orImmOp = TR::InstOpCode::OILF;
   TR::InstOpCode::Mnemonic compareOp = use64b ? TR::InstOpCode::CGR : TR::InstOpCode::CR;
   TR::InstOpCode::Mnemonic compareImmOp = use64b ? TR::InstOpCode::CG : TR::InstOpCode::C;
   TR::InstOpCode::Mnemonic addImmOp = use64b ? TR::InstOpCode::AGHI : TR::InstOpCode::AHI;
   TR::InstOpCode::Mnemonic storeOp = use64b ? TR::InstOpCode::STG : TR::InstOpCode::ST;
   TR::InstOpCode::Mnemonic xorOp = use64b ? TR::InstOpCode::XGR : TR::InstOpCode::XR;
   TR::InstOpCode::Mnemonic casOp = use64b ? TR::InstOpCode::CSG : TR::InstOpCode::CS;
   TR::InstOpCode::Mnemonic loadImmOp = use64b ? TR::InstOpCode::LGHI : TR::InstOpCode::LHI ;
   TR::InstOpCode::Mnemonic andOp = use64b ? TR::InstOpCode::NGR : TR::InstOpCode::NR;

   //ICF RA constraints
   //////////////
   ICFConditions->addPostConditionIfNotAlreadyInserted(objReg, TR::RealRegister::AssignAny);
   ICFConditions->addPostConditionIfNotAlreadyInserted(monitorReg, TR::RealRegister::AssignAny);
   ICFConditions->addPostConditionIfNotAlreadyInserted(valReg, TR::RealRegister::AssignAny);
   ICFConditions->addPostConditionIfNotAlreadyInserted(tempReg, TR::RealRegister::AssignAny);
   //////////////

   // Main path instruction sequence (non-primitive).
   //    L     monitorReg, #lwOffset(objectReg)
   //    LR    valReg,     metaReg
   //    OILF  valReg,     LR-Bit
   //    CRJ   valReg,     monitorReg, MASK6, callLabel
   //    AHI   monitorReg, INC_DEC_VALUE
   //    ST    monitorReg, #lwOffset(objectReg)

   // load monitor reg
   generateRXInstruction(cg, loadOp, node, monitorReg, generateS390MemoryReference(objReg, lwOffset, cg));
   // load r13|LOCK_RESERVATION_BIT
   generateRRInstruction(cg, loadRegOp, node, valReg, metaReg);
   generateRILInstruction(cg, orImmOp, node, valReg, LOCK_RESERVATION_BIT);

   // Jump to OOL path if lock is not reserved (monReg != r13|LOCK_RESERVATION_BIT)
   instr = generateS390CompareAndBranchInstruction(cg, compareOp, node, valReg, monitorReg,
      TR::InstOpCode::COND_BNE, resLabel, false, false);

   if (!comp->getOption(TR_DisableOOL))
      {
      helperReturnOOLLabel = generateLabelSymbol(cg);
      doneOOLLabel = generateLabelSymbol(cg);
      if (debugObj)
         debugObj->addInstructionComment(instr, "Branch to OOL reservation enter sequence");
      outlinedSlowPath = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(resLabel, doneOOLLabel, cg);
      cg->getS390OutOfLineCodeSectionList().push_front(outlinedSlowPath);
      }
   else
      {
      TR_ASSERT(0, "Not implemented- Lock reservation with Disable OOL yet.");
      //Todo: Call VM helper maybe?
      }

   cg->generateDebugCounter("LockEnt/LR/LRSuccessfull", 1, TR::DebugCounter::Undetermined);
   if (!isPrimitive)
      {
      generateRIInstruction  (cg, addImmOp, node, monitorReg, (uintptrj_t) LOCK_INC_DEC_VALUE);
      generateRXInstruction(cg, storeOp, node, monitorReg, generateS390MemoryReference(objReg, lwOffset, cg));
      }

   if (outlinedSlowPath) // Means we have OOL
      {
      TR::LabelSymbol *reserved_checkLabel = generateLabelSymbol(cg);
      outlinedSlowPath->swapInstructionListsWithCompilation(); // Toggle instruction list
      TR::Instruction *temp = generateS390LabelInstruction(cg,TR::InstOpCode::LABEL,node,resLabel);
      if (debugObj)
         {
         if (isPrimitive)
            debugObj->addInstructionComment(temp, "Denotes start of OOL primitive reservation enter sequence");
         else
            debugObj->addInstructionComment(temp, "Denotes start of OOL non-primitive reservation enter sequence");
         }
      // XXX: Temporary fix, OOL instruction stream does not pick up live locals or monitors correctly.
      TR_ASSERT(!temp->getLiveLocals() && !temp->getLiveMonitors(), "Expecting first OOL instruction to not have live locals/monitors info");
      temp->setLiveLocals(instr->getLiveLocals());
      temp->setLiveMonitors(instr->getLiveMonitors());

      // Non-Primitive lockReservation enter sequence:         Primitive lockReservation enter sequence:

      // CIJ   monitorReg, 0, MASK6, checkLabel                TODO - Add Primitive lockReservation enter sequence
      // AHI   valReg, INC_DEC_VALUE
      // XR    monitorReg, monitorReg
      // CS    monitorReg, valReg, #lwOffset(objectReg)
      // BRC   MASK6, callHelper
      // BRC   returnLabel
      // checkLabel:
      // LGFI  tempReg, LOCK_RES_NON_PRIMITIVE_ENTER_MASK
      // NR    tempReg, monitorReg
      // CRJ   tempReg, valReg, MASK6, callHelper
      // AHI   monitorReg, INC_DEC_VALUE
      // ST    monitorReg, #lwOffset(objectReg)
      // BRC   returnLabel
      // callHelper:
      // BRASL R14, jitMonitorEntry
      //returnLabel:

      // Avoid CAS in case lock value is not zero
      startICF = generateS390CompareAndBranchInstruction(cg, compareImmOp, node, monitorReg, 0, TR::InstOpCode::COND_BNE, reserved_checkLabel, false);
      instr->setStartInternalControlFlow();
      if (!isPrimitive)
         {
         generateRIInstruction  (cg, addImmOp, node, valReg, (uintptrj_t) LOCK_INC_DEC_VALUE);
         }
      // Try to acquire the lock using CAS
      generateRRInstruction(cg, xorOp, node, monitorReg, monitorReg);
      generateRSInstruction(cg, casOp, node, monitorReg, valReg, generateS390MemoryReference(objReg, lwOffset, cg));
      // Call VM helper if the CAS fails (contention)
      instr = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, callLabel);

      cg->generateDebugCounter("LockEnt/LR/CASSuccessfull", 1, TR::DebugCounter::Undetermined);

      // Lock is acquired successfully
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, helperReturnOOLLabel);

      generateS390LabelInstruction(cg,TR::InstOpCode::LABEL,node,reserved_checkLabel);
      // Mask the counter
      // Mask is 8 bit value which will be sign extended, We will be using cheaper instruction like LGHI or LHI
      generateRIInstruction(cg, loadImmOp, node, tempReg, ~(isPrimitive ? LOCK_RES_PRIMITIVE_ENTER_MASK : LOCK_RES_NON_PRIMITIVE_ENTER_MASK));
      generateRRInstruction(cg, andOp, node, tempReg, monitorReg);

      // Call VM helper if the R13 != (masked MonReg)
      generateS390CompareAndBranchInstruction(cg, compareOp,node, tempReg, valReg,
         TR::InstOpCode::COND_BNE, callLabel, false, false);

      cg->generateDebugCounter("LockEnt/LR/Recursive", 1, TR::DebugCounter::Undetermined);

      // Recursive lock. Increment the counter
      if (!isPrimitive)
         {
         generateRIInstruction  (cg, addImmOp, node, monitorReg, (uintptrj_t) LOCK_INC_DEC_VALUE);
         generateRXInstruction(cg, storeOp, node, monitorReg, generateS390MemoryReference(objReg, lwOffset, cg));
         }
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, helperReturnOOLLabel);
      // call to jithelper
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, callLabel);
      cg->generateDebugCounter("LockEnt/LR/VMHelper", 1, TR::DebugCounter::Undetermined);
      uintptrj_t returnAddress = (uintptrj_t) (node->getSymbolReference()->getMethodAddress());

      // We are calling helper within ICF so we need to combine dependency from ICF and helper call at merge label
      TR::RegisterDependencyConditions *deps = NULL;
      helperLink->buildDirectDispatch(node, &deps);
      TR::RegisterDependencyConditions *mergeConditions = mergeConditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(ICFConditions, deps, cg);
      // OOL return label
      instr = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, helperReturnOOLLabel, mergeConditions);
      if (debugObj)
         {
         debugObj->addInstructionComment(instr, "OOL reservation enter VMHelper return label");
         }
      instr->setEndInternalControlFlow();

      instr = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, doneOOLLabel);
      if (debugObj)
         {
         if (isPrimitive)
            debugObj->addInstructionComment(instr, "Denotes end of OOL primitive reservation enter sequence: return to mainline");
         else
            debugObj->addInstructionComment(instr, "Denotes end of OOL non-primitive reservation enter sequence: return to mainline");
         }

      outlinedSlowPath->swapInstructionListsWithCompilation(); // Toggle instruction list

      instr = generateS390LabelInstruction(cg,TR::InstOpCode::LABEL,node,doneOOLLabel);
      if (debugObj)
         debugObj->addInstructionComment(instr, "OOL reservation enter return label");
      generateS390LabelInstruction(cg,TR::InstOpCode::LABEL,node, doneLabel);
      }
   else
      {
      TR_ASSERT(0, "Not implemented:Lock reservation with Disable OOL.");
      }
   if (monitorReg)
      cg->stopUsingRegister(monitorReg);
   if (valReg)
      cg->stopUsingRegister(valReg);
   if (tempReg)
      cg->stopUsingRegister(tempReg);

   cg->decReferenceCount(node->getFirstChild());
   return NULL;
   }

static TR::Register *
reservationLockExit(TR::Node *node, int32_t lwOffset, TR::Register *objectClassReg, TR::CodeGenerator *cg, TR::S390CHelperLinkage *helperLink )
   {
   TR::Register *objReg, *monitorReg, *metaReg, *valReg, *tempReg;
   TR::Register *EPReg, *returnAddressReg;
   TR::LabelSymbol *resLabel, *callLabel, *doneLabel;
   TR::Instruction *instr;
   TR::Instruction *startICF = NULL;
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());

   int numICFDeps = 6 + (comp->getOptions()->enableDebugCounters() ? 4: 0);
   TR::RegisterDependencyConditions *ICFConditions =
      new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, numICFDeps, cg);
   if (objectClassReg)
      objReg = objectClassReg;
   else
      objReg = node->getFirstChild()->getRegister();

   if (!comp->getOption(TR_Enable390FreeVMThreadReg))
      metaReg = cg->getMethodMetaDataRealRegister();
   else
      metaReg = cg->getVMThreadRegister();

   monitorReg = cg->allocateRegister();
   valReg = cg->allocateRegister();
   tempReg = cg->allocateRegister();


   //ICF RA constraints
   //////////////
   ICFConditions->addPostConditionIfNotAlreadyInserted(objReg, TR::RealRegister::AssignAny);
   ICFConditions->addPostConditionIfNotAlreadyInserted(monitorReg, TR::RealRegister::AssignAny);
   ICFConditions->addPostConditionIfNotAlreadyInserted(valReg, TR::RealRegister::AssignAny);
   ICFConditions->addPostConditionIfNotAlreadyInserted(tempReg, TR::RealRegister::AssignAny);

   resLabel = generateLabelSymbol(cg);
   callLabel = generateLabelSymbol(cg);
   doneLabel = generateLabelSymbol(cg);

   TR::LabelSymbol *helperReturnOOLLabel, *doneOOLLabel = NULL;
   TR_S390OutOfLineCodeSection *outlinedSlowPath = NULL;
   TR_Debug *debugObj = cg->getDebug();
   TR::Snippet *snippet = NULL;
   static bool enforcePrimitive = feGetEnv("EnforcePrimitiveLockRes")? 1 : 0;
   bool isPrimitive = enforcePrimitive ? 1 : node->isPrimitiveLockedRegion();

   // Opcodes:
   bool use64b = true;
   if (TR::Compiler->target.is64Bit() && fej9->generateCompressedLockWord())
      use64b = false;
   else if (!TR::Compiler->target.is64Bit())
      use64b = false;
   TR::InstOpCode::Mnemonic loadOp = use64b ? TR::InstOpCode::LG : TR::InstOpCode::L;
   TR::InstOpCode::Mnemonic loadRegOp = use64b ? TR::InstOpCode::LGR : TR::InstOpCode::LR;
   TR::InstOpCode::Mnemonic orImmOp = TR::InstOpCode::OILF;
   TR::InstOpCode::Mnemonic compareOp = use64b ? TR::InstOpCode::CGR : TR::InstOpCode::CR;
   TR::InstOpCode::Mnemonic compareImmOp = use64b ? TR::InstOpCode::CG : TR::InstOpCode::C;
   TR::InstOpCode::Mnemonic addImmOp = use64b ? TR::InstOpCode::AGHI : TR::InstOpCode::AHI;
   TR::InstOpCode::Mnemonic storeOp = use64b ? TR::InstOpCode::STG : TR::InstOpCode::ST;
   TR::InstOpCode::Mnemonic xorOp = use64b ? TR::InstOpCode::XGR : TR::InstOpCode::XR;
   TR::InstOpCode::Mnemonic casOp = use64b ? TR::InstOpCode::CSG : TR::InstOpCode::CS;
   TR::InstOpCode::Mnemonic loadImmOp = use64b ? TR::InstOpCode::LGHI : TR::InstOpCode::LHI;
   TR::InstOpCode::Mnemonic andOp = use64b ? TR::InstOpCode::NGR : TR::InstOpCode::NR;
   TR::InstOpCode::Mnemonic andImmOp = TR::InstOpCode::NILF;

   // Main path instruction sequence (non-primitive).
   //   L     monitorReg, #lwOffset(objectReg)
   //   LR    valReg, metaReg
   //   OILF  valReg, INC_DEC_VALUE | LR-Bit
   //   CRJ   valReg, monitorReg, BNE, callLabel
   //   AHI   valReg, -INC_DEC_VALUE
   //   ST    valReg, #lwOffset(objectReg)

   generateRXInstruction(cg, loadOp, node, monitorReg, generateS390MemoryReference(objReg, lwOffset, cg));
   if (!isPrimitive)
      {
      generateRRInstruction(cg, loadRegOp, node, tempReg, metaReg);
      generateRILInstruction(cg, orImmOp, node, tempReg, LOCK_RESERVATION_BIT + LOCK_INC_DEC_VALUE);
      instr = generateS390CompareAndBranchInstruction(cg, compareOp, node, tempReg, monitorReg,
         TR::InstOpCode::COND_BNE, resLabel, false, false);
      cg->generateDebugCounter("LockExit/LR/LRSuccessfull", 1, TR::DebugCounter::Undetermined);
      }
   else
      {
      generateRRInstruction(cg, loadRegOp, node, tempReg, monitorReg);
      generateRILInstruction(cg, andImmOp, node, tempReg, LOCK_RES_PRIMITIVE_EXIT_MASK);
      instr = generateS390CompareAndBranchInstruction(cg, compareImmOp, node, tempReg, LOCK_RESERVATION_BIT,
         TR::InstOpCode::COND_BNE, resLabel, false);
      }

   if (!comp->getOption(TR_DisableOOL))
      {
      helperReturnOOLLabel = generateLabelSymbol(cg);
      doneOOLLabel = generateLabelSymbol(cg);
      if (debugObj)
         debugObj->addInstructionComment(instr, "Branch to OOL reservation exit sequence");
      outlinedSlowPath = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(resLabel, doneOOLLabel, cg);
      cg->getS390OutOfLineCodeSectionList().push_front(outlinedSlowPath);
      }
   else
      TR_ASSERT(0, "Not implemented: Lock reservation with Disable OOL.");

   if (!isPrimitive)
      {
      generateRIInstruction  (cg, use64b? TR::InstOpCode::AGHI : TR::InstOpCode::AHI, node, tempReg, -LOCK_INC_DEC_VALUE);
      generateRXInstruction(cg, use64b? TR::InstOpCode::STG : TR::InstOpCode::ST,
         node, tempReg, generateS390MemoryReference(objReg, lwOffset, cg));
      }

   if (outlinedSlowPath) // Means we have OOL
      {
      outlinedSlowPath->swapInstructionListsWithCompilation(); // Toggle instruction list
      TR::Instruction *temp = generateS390LabelInstruction(cg,TR::InstOpCode::LABEL,node,resLabel);
      if (debugObj)
         {
         if (isPrimitive)
            debugObj->addInstructionComment(temp, "Denotes start of OOL primitive reservation exit sequence");
         else
            debugObj->addInstructionComment(temp, "Denotes start of OOL non-primitive reservation exit sequence");
         }
      // XXX: Temporary fix, OOL instruction stream does not pick up live locals or monitors correctly.
      TR_ASSERT(!temp->getLiveLocals() && !temp->getLiveMonitors(), "Expecting first OOL instruction to not have live locals/monitors info");
      temp->setLiveLocals(instr->getLiveLocals());
      temp->setLiveMonitors(instr->getLiveMonitors());

      // Non-PRIMITIVE reservationLock exit sequence              PRIMITIVE reservationLock exit sequence
      // LGFI  tempReg, LOCK_RES_OWNING                           TODO - PRIMITIVE reservationLock exit sequence
      // NR    tempReg, monitorReg
      // LR    valReg, metaReg
      // AHI   valReg, LR-Bit
      // CRJ   tempReg, valReg, BNE, callHelper
      // LR    tempReg, monitorReg
      // NILF  tempReg, LOCK_RES_NON_PRIMITIVE_EXIT_MASK
      // BRC   BERC, callHelper
      // AHI   monitorReg, -INC_DEC_VALUE
      // ST    monitorReg, #lwOffset(objectReg)
      // BRC   returnLabel
      // callHelper:
      // BRASL R14, jitMonitorExit
      // returnLabel:

      generateRIInstruction(cg, loadImmOp, node, tempReg, ~(LOCK_RES_OWNING_COMPLEMENT));
      generateRRInstruction(cg, andOp, node, tempReg, monitorReg);
      generateRRInstruction(cg, loadRegOp, node, valReg, metaReg);
      generateRIInstruction  (cg, addImmOp, node, valReg, (uintptrj_t) LOCK_RESERVATION_BIT);

      instr = generateS390CompareAndBranchInstruction(cg, compareOp, node, tempReg, valReg,
         TR::InstOpCode::COND_BNE, callLabel, false, false);
      instr->setStartInternalControlFlow();

      generateRRInstruction(cg, loadRegOp, node, tempReg, monitorReg);
      generateRILInstruction(cg, andImmOp, node, tempReg,
         isPrimitive ? OBJECT_HEADER_LOCK_RECURSION_MASK : LOCK_RES_NON_PRIMITIVE_EXIT_MASK);

      if (isPrimitive)
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, helperReturnOOLLabel);
      else
         {
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, callLabel/*,conditions*/);
         }
      cg->generateDebugCounter("LockExit/LR/Recursive", 1, TR::DebugCounter::Undetermined);
      generateRIInstruction  (cg, addImmOp, node, monitorReg,
         (uintptrj_t) (isPrimitive ? LOCK_INC_DEC_VALUE : -LOCK_INC_DEC_VALUE) & 0x0000FFFF);
      generateRXInstruction(cg, storeOp, node, monitorReg, generateS390MemoryReference(objReg, lwOffset, cg));

      if (!isPrimitive)
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, helperReturnOOLLabel);
      // call to jithelper
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, callLabel);
      cg->generateDebugCounter("LockExit/LR/VMHelper", 1, TR::DebugCounter::Undetermined);
      uintptrj_t returnAddress = (uintptrj_t) (node->getSymbolReference()->getMethodAddress());
      TR::RegisterDependencyConditions *deps = NULL;
      helperLink->buildDirectDispatch(node, &deps);
      TR::RegisterDependencyConditions *mergeConditions = mergeConditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(ICFConditions, deps, cg);
      instr = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, helperReturnOOLLabel, mergeConditions);
      // OOL return label
      instr->setEndInternalControlFlow();
      if (debugObj)
         {
         debugObj->addInstructionComment(instr, "OOL reservation exit VMHelper return label");
         }
      instr = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, doneOOLLabel);
      if (debugObj)
         {
         if (isPrimitive)
            debugObj->addInstructionComment(instr, "Denotes end of OOL primitive reversation exit sequence: return to mainline");
         else
            debugObj->addInstructionComment(instr, "Denotes end of OOL non-primitive reversation exit sequence: return to mainline");
         }
      outlinedSlowPath->swapInstructionListsWithCompilation(); // Toggle instruction list
      instr = generateS390LabelInstruction(cg,TR::InstOpCode::LABEL,node,doneOOLLabel);
      if (debugObj)
         debugObj->addInstructionComment(instr, "OOL reservation exit return label");

      generateS390LabelInstruction(cg,TR::InstOpCode::LABEL,node, doneLabel);
      }
   else
      {
      TR_ASSERT(0, "Not implemented: Lock reservation with Disable OOL.");
      }

   if (monitorReg)
      cg->stopUsingRegister(monitorReg);
   if (valReg)
      cg->stopUsingRegister(valReg);
   if (tempReg)
      cg->stopUsingRegister(tempReg);

   cg->decReferenceCount(node->getFirstChild());
   return NULL;
   }

// the following routine is a bit grotty - it has to determine if there are any GRA
// assigned real registers that will conflict with real registers required by
// instance-of generation.
// it also has to verify that instance-of won't require more registers than are
// available.
static bool graDepsConflictWithInstanceOfDeps(TR::Node * depNode, TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * castClassNode = node->getSecondChild();
   TR::SymbolReference * castClassSymRef = castClassNode->getSymbolReference();
   TR::Compilation *comp = cg->comp();

   bool testCastClassIsSuper  = TR::TreeEvaluator::instanceOfOrCheckCastNeedSuperTest(node, cg);
   bool isFinalClass          = (castClassSymRef == NULL) ? false : castClassSymRef->isNonArrayFinal(comp);
   bool needsHelperCall       = needHelperCall(node, testCastClassIsSuper, isFinalClass);

   if (maxInstanceOfPostDependencies() + depNode->getNumChildren() > cg->getMaximumNumberOfAssignableGPRs())
      {
      return true;
      }
   if (!needsHelperCall)
      {
      return false;
      }

   for (int i=0; i<depNode->getNumChildren(); i++)
      {
      TR::Node * child = depNode->getChild(i);
      if ((child->getOpCodeValue() == TR::lRegLoad || child->getOpCodeValue() == TR::PassThrough)
          && TR::Compiler->target.is32Bit())
         {
         int32_t regIndex = child->getHighGlobalRegisterNumber();
         if (killedByInstanceOfHelper(regIndex, node, cg))
            {
            return true;
            }

         regIndex = child->getLowGlobalRegisterNumber();
         if (killedByInstanceOfHelper(regIndex, node, cg))
            {
            return true;
            }
         }
      else
         {
         int32_t regIndex = child->getGlobalRegisterNumber();
         if (killedByInstanceOfHelper(regIndex, node, cg))
            {
            return true;
            }
         }
      }
   return false;
   }



/**   \brief Generates ArrayOfJavaLangObjectTest (object class is reference array) for instanceOf or checkCast node
 *    \details
 *    scratchReg1 = load (objectClassReg+offset_romClass)
 *    scratchReg1 = load (ROMClass+J9ROMClass+modifiers)
 *    andImmediate with J9AccClassArray(0x10000)
 *    If not Array -> Branch to Fail Label
 *    testerReg = load (objectClassReg + leafcomponent_offset)
 *    testerReg = load (objectClassReg + offset_romClass)
 *    testerReg = load (objectClassReg + offset_modifiers)
 *    andImmediate with J9AccClassInternalPrimitiveType(0x20000)
 *    if not arrays of primitive set condition code to Zero indicating true result
 */
static
void genInstanceOfOrCheckcastArrayOfJavaLangObjectTest(TR::Node *node, TR::CodeGenerator *cg, TR::Register *objectClassReg, TR::LabelSymbol *failLabel, TR_S390ScratchRegisterManager *srm)
   {
   TR::Compilation *comp = cg->comp();
   TR_Debug *debugObj = cg->getDebug();
   TR::Instruction *cursor = NULL;
   TR::Register *scratchReg1 = srm->findOrCreateScratchRegister();
   generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, scratchReg1, generateS390MemoryReference(objectClassReg, offsetof(J9Class,romClass), cg));
   generateRXInstruction(cg, TR::InstOpCode::L, node, scratchReg1, generateS390MemoryReference(scratchReg1, offsetof(J9ROMClass, modifiers), cg));
   generateRILInstruction(cg, TR::InstOpCode::NILF, node, scratchReg1, J9AccClassArray);
   cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, failLabel);
   if (debugObj)
      debugObj->addInstructionComment(cursor,"Fail instanceOf/checkCast if Not Array");
   generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, scratchReg1, generateS390MemoryReference(objectClassReg, offsetof(J9ArrayClass,componentType), cg));
   generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, scratchReg1, generateS390MemoryReference(scratchReg1, offsetof(J9Class,romClass), cg));
   generateRXInstruction(cg, TR::InstOpCode::L, node, scratchReg1, generateS390MemoryReference(scratchReg1, offsetof(J9ROMClass, modifiers), cg));
   generateRILInstruction(cg, TR::InstOpCode::NILF, node, scratchReg1, J9AccClassInternalPrimitiveType);
   srm->reclaimScratchRegister(scratchReg1);
   }


/**   \brief Generates Superclass Test for both checkcast and instanceof nodes.
 *    \details
 *    It will generate pseudocode as follows.
 *    if (objectClassDepth <= castClassDepth) call Helper
 *    else
 *    load superClassArrReg,superClassOfObjectClass
 *    cmp superClassArrReg[castClassDepth], castClass
 *    Here It sets up the condition code for callee to react on.
 */
static
bool genInstanceOfOrCheckcastSuperClassTest(TR::Node *node, TR::CodeGenerator *cg, TR::Register *objClassReg, TR::Register *castClassReg, int32_t castClassDepth,
   TR::LabelSymbol *falseLabel, TR::LabelSymbol *callHelperLabel, TR_S390ScratchRegisterManager *srm)
   {
   TR::Compilation *comp = cg->comp();
   int32_t superClassDepth = castClassDepth * TR::Compiler->om.sizeofReferenceAddress();
   TR::Register *castClassDepthReg = NULL;
   TR::InstOpCode::Mnemonic loadOp;
   int32_t byteOffset;
   TR::Instruction *cursor = NULL;
   if (TR::Compiler->target.is64Bit())
      {
      loadOp = TR::InstOpCode::LLGH;
      byteOffset = 6;
      }
   else
      {
      loadOp = TR::InstOpCode::LLH;
      byteOffset = 2;
      }
   //Following Changes are for dynamicCastClass only
   bool dynamicCastClass = castClassDepth == -1;
   bool eliminateSuperClassArraySizeCheck = (!dynamicCastClass && (castClassDepth < cg->comp()->getOptions()->_minimumSuperclassArraySize));
   // In case of dynamic Cast Class, We do not know the depth of the cast Class at compile time. So following routine compares depth at run time.
   if ( dynamicCastClass )
      {
      TR::Register *scratchRegister1 = srm->findOrCreateScratchRegister();
      //TR::Register *scratchRegister1 = scratch1Reg;
      TR_ASSERT((node->getOpCodeValue() == TR::instanceof &&
            node->getSecondChild()->getOpCodeValue() != TR::loadaddr), "genTestIsSuper: castClassDepth == -1 is only supported for transformed isInstance calls.");
      cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, scratchRegister1,
            generateS390MemoryReference(castClassReg, offsetof(J9Class, romClass), cg), cursor);
      cursor = generateRXInstruction(cg, TR::InstOpCode::L, node, scratchRegister1,
            generateS390MemoryReference(scratchRegister1, offsetof(J9ROMClass, modifiers), cg), cursor);
      TR_ASSERT(((J9AccInterface | J9AccClassArray) < UINT_MAX && (J9AccInterface | J9AccClassArray) > 0),
            "genTestIsSuper::(J9AccInterface | J9AccClassArray) is not a 32-bit number\n");
      cursor = generateRILInstruction(cg, TR::InstOpCode::NILF, node, scratchRegister1, (int32_t) (J9AccInterface | J9AccClassArray), cursor);
      cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, callHelperLabel, cursor);
      castClassDepthReg = srm->findOrCreateScratchRegister();
      cursor = generateRXInstruction(cg, loadOp, node, castClassDepthReg,
            generateS390MemoryReference(castClassReg, offsetof(J9Class, classDepthAndFlags) + byteOffset, cg), cursor);

      srm->reclaimScratchRegister(scratchRegister1);
      TR_ASSERT(sizeof(((J9Class*)0)->classDepthAndFlags) == sizeof(uintptr_t),
            "genTestIsSuper::J9Class->classDepthAndFlags is wrong size\n");
      }


   //objectClassDepthReg <- objectClassDepth
   if (!eliminateSuperClassArraySizeCheck)
      {
      TR::Register *objectClassDepthReg = srm->findOrCreateScratchRegister();
      cursor = generateRXInstruction(cg, loadOp, node, objectClassDepthReg,
         generateS390MemoryReference(objClassReg, offsetof(J9Class, classDepthAndFlags) + byteOffset, cg) , NULL);

      //Compare objectClassDepth and castClassDepth
      if (dynamicCastClass)
         cursor = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, objectClassDepthReg, castClassDepthReg, TR::InstOpCode::COND_BNH, falseLabel, false, false);
      else
         cursor = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, objectClassDepthReg, castClassDepth, TR::InstOpCode::COND_BNH, falseLabel, true, false, cursor);
      srm->reclaimScratchRegister(objectClassDepthReg);
      }

   //superClassArrReg <- objectClass->superClasses
   TR::Register *superClassArrReg = srm->findOrCreateScratchRegister();
   cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, superClassArrReg,
      generateS390MemoryReference(objClassReg, offsetof(J9Class, superclasses), cg), cursor);
   if (dynamicCastClass)
      {
      if (TR::Compiler->target.is64Bit())
         {
         cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, castClassDepthReg, castClassDepthReg, 3, cursor);
         }
      else
         {
         cursor = generateRSInstruction(cg, TR::InstOpCode::SLL, node, castClassDepthReg, 2, cursor);
         }
         cursor = generateRXInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, castClassReg,
            generateS390MemoryReference(superClassArrReg, castClassDepthReg, 0, cg), cursor);
         srm->reclaimScratchRegister(castClassDepthReg);
      }
   else
      {
      //CG superClassArrReg[castClassDepth],castClassReg
      cursor = generateRXInstruction (cg, TR::InstOpCode::getCmpOpCode(), node, castClassReg,
         generateS390MemoryReference(superClassArrReg, superClassDepth, cg), cursor);
      }
   srm->reclaimScratchRegister(superClassArrReg);
   return dynamicCastClass;
   //We expect Result of the test reflects in Condition Code. Callee shoud react on this.
   }

/** \brief
 *     Generates null test of \p objectReg for instanceof or checkcast \p node.
 *
 *  \param node
 *     The instanceof, checkcast, or checkcastAndNULLCHK node.
 *
 *  \param cg
 *     The code generator used to generate the instructions.
 *
 *  \param objectReg
 *     The object which to null test.
 *
 *  \return
 *     <c>true</c> if the null test will implicitly raise an exception; false otherwise.
 *
 *  \details
 *     Note that if this function returns <c>false</c> the appropriate null test condition code will be set and the
 *     callee is responsible for generating the branh instruction to act on the condition code.
 */
static
bool genInstanceOfOrCheckCastNullTest(TR::Node* node, TR::CodeGenerator* cg, TR::Register* objectReg)
   {
   const bool isNullTestImplicit = node->getOpCodeValue() == TR::checkcastAndNULLCHK && cg->getHasResumableTrapHandler();

   if (isNullTestImplicit)
      {
      TR::Instruction* compareAndTrapInsturction = generateRIEInstruction(cg, TR::InstOpCode::getCmpImmTrapOpCode(), node, objectReg, 0, TR::InstOpCode::COND_BE);
      compareAndTrapInsturction->setExceptBranchOp();
      compareAndTrapInsturction->setNeedsGCMap(0x0000FFFF);
      }
   else
      {
      genNullTest(cg, node, objectReg, objectReg, NULL);
      }

      return isNullTestImplicit;
   }


/** \brief
 *     Generates a dynamicCache test with helper call for instanceOf/ifInstanceOf node
 *
 *  \details
 *     This funcition generates a sequence to check per site cache for object class and cast class before calling out to jitInstanceOf helper
 */
static
void genInstanceOfDynamicCacheAndHelperCall(TR::Node *node, TR::CodeGenerator *cg, TR::Register *castClassReg, TR::Register *objClassReg, TR::Register *resultReg, TR_S390ScratchRegisterManager *srm, TR::LabelSymbol *doneLabel, TR::LabelSymbol *helperCallLabel, TR::LabelSymbol *dynamicCacheTestLabel, TR::LabelSymbol *branchLabel, TR::LabelSymbol *trueLabel, TR::LabelSymbol *falseLabel, bool dynamicCastClass, bool generateDynamicCache, bool cacheCastClass, bool ifInstanceOf, bool trueFallThrough )
   {
   TR::Compilation                *comp = cg->comp();
   bool needResult = resultReg != NULL;
   if (!castClassReg)
      castClassReg = cg->evaluate(node->getSecondChild());
   int32_t maxOnsiteCacheSlots = comp->getOptions()->getMaxOnsiteCacheSlotForInstanceOf();
   TR::Register *dynamicCacheReg = NULL;
   int32_t addressSize = TR::Compiler->om.sizeofReferenceAddress();
   /* Layout of the writable data snippet
    * Case - 1 : Cast class is runtime variable
    * [UpdateIndex][ObjClassSlot-0][CastClassSlot-0]...[ObjClassSlot-N][CastClassSlot-N]
    * Case - 2 : Cast Class is interface / unresolved
    * [UpdateIndex][ObjClassSlot-0]...[ObjClassSlot-N]
    * If there is only one cache slot, we will not have header.
    * Last bit of cached objectClass will set to 1 indicating false cast
    */
   int32_t snippetSizeInBytes = ((cacheCastClass ? 2 : 1) * maxOnsiteCacheSlots * addressSize) + (addressSize * (maxOnsiteCacheSlots != 1));
   if (generateDynamicCache)
      {
      TR::S390WritableDataSnippet *dynamicCacheSnippet = NULL;
      /* We can only request the snippet size of power 2, following table summarizes bytes needed for corresponding number of cache slots
       * Case 1 : Cast class is runtime variable
       * Case 2 : Cast class is interface / unresolved
       * Number Of Slots |  Bytes needed for Case 1 | Bytes needed for Case 2
       *        1        |              16          |           8
       *        2        |              64          |           32
       *        3        |              64          |           32
       *        4        |              128         |           64
       *        5        |              128         |           64
       *        6        |              128         |           64
       */
      int32_t requestedBytes = 1 << (int) (log2(snippetSizeInBytes-1)+1);
      traceMsg(comp, "Requested Bytes = %d\n",requestedBytes);
      // NOTE: For single slot cache, we initialize snippet with addressSize (4/8) assuming which can not be objectClass
      // In all cases, we use first addressSize bytes to store offset of the circular buffer and rest of buffer will be initialized with 0xf.
      TR_ASSERT_FATAL(maxOnsiteCacheSlots <= 7, "Maximum 7 slots per site allowed because we use a fixed stack allocated buffer to construct the snippet\n");
      UDATA initialSnippet[16] = { static_cast<UDATA>(addressSize) };
      dynamicCacheSnippet = (TR::S390WritableDataSnippet*)cg->CreateConstant(node, initialSnippet, requestedBytes, true);
      
      int32_t currentIndex = maxOnsiteCacheSlots > 1 ? addressSize : 0;
      dynamicCacheReg = srm->findOrCreateScratchRegister();
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, dynamicCacheTestLabel);
      generateRILInstruction(cg, TR::InstOpCode::LARL, node, dynamicCacheReg, dynamicCacheSnippet, 0);
      TR::Register *cachedObjectClass = srm->findOrCreateScratchRegister();
      TR::LabelSymbol *gotoNextTest = NULL;
      /* Dynamic Cache Test
       * LARL dynamicCacheReg, dynamicCacheSnippet
       * if (cacheCastClass)
       *    CG castClassReg, @(dynamicCacheSnippet+currentIndex+addressSize)
       *    BRC NE,isLastCacheSlot ? helperCall:checkNextSlot
       * LG cachedOjectClass,@(dynamicCacheSnippet+currentIndex)
       * XR cachedObjectClass,objClassReg
       * if (isLastCacheSlot && trueFallThrough)
       *    CGIJ cachedObjectClass, 1, Equal, falseLabel
       *    BRC NotZero, helperCallLabel
       * else if (isLastCacheSlot)
       *    BRC Zero, trueLabel
       *    CGIJ cachedObjectClass, 1, NotEqual, helperCallLabel
       * else
       *    BRC Zero ,trueLabel
       *    CGIJ cachedObjectClass,1,Equal,falseLabel
       * if (isLastCacheSlot)
       *    fallThroughLabel:
       * else
       *    checkNextSlot:
       */
      for (auto i=0; i<maxOnsiteCacheSlots; i++)
         {
         if (cacheCastClass)
            {
            gotoNextTest = (i+1 == maxOnsiteCacheSlots) ? helperCallLabel : generateLabelSymbol(cg);
            generateRXInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, castClassReg, generateS390MemoryReference(dynamicCacheReg,currentIndex+addressSize,cg));
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, gotoNextTest);
            }
         generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, cachedObjectClass, generateS390MemoryReference(dynamicCacheReg,currentIndex,cg));
         generateRRInstruction(cg, TR::InstOpCode::getXORRegOpCode(), node,cachedObjectClass, objClassReg);
         if (i+1 == maxOnsiteCacheSlots)
            {
            if (trueFallThrough)
               {
               generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, cachedObjectClass, 1, TR::InstOpCode::COND_BE, falseLabel, false, false);
               generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, helperCallLabel);
               }
            else
               {
               generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, trueLabel);
               generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, cachedObjectClass, 1, TR::InstOpCode::COND_BNE, helperCallLabel, false, false);
               }
            }
         else
            {  
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, trueLabel);
            generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, cachedObjectClass, 1, TR::InstOpCode::COND_BE, falseLabel, false, false);
            }
         
         if (gotoNextTest && gotoNextTest != helperCallLabel)
            generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, gotoNextTest);
         currentIndex += (cacheCastClass? 2: 1)*addressSize;
         }
      srm->reclaimScratchRegister(cachedObjectClass);
      }
   else if (!dynamicCastClass)
      {
      // If dynamic Cache Test is not generated and it is not dynamicCastClass, we need to generate following branch
      // In cases of dynamic cache test / dynamic Cast Class, we would have a branch to helper call at appropriate location.
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, helperCallLabel);
      }

      /* helperCallLabel : jitInstanceOfCall prologue
       *                   BRASL jitInstanceOf
       *                   jitInstanceOfCall epilogue
       *                   CGIJ helperReturnReg,1,skipSettingBitForFalseResult <- Start of Internal Control Flow
       *                   OILL objClassReg,1
       * skipSettingBitForFalseResult:
       *               Case - 1 : maxOnsiteCacheSlots = 1
       *                   STG objClassReg, @(dynamicCacheReg)    
       *                   if (cacheCastClass)
       *                      STG castClassReg, @(dynamicCacheReg,addressSize)
       *               Case - 2 : maxOnsiteCacheSlots > 1
       *                   LG offsetRegister,@(dynamicCacheReg)
       *                   STG objClassReg,@(dynamicCacheReg,offsetRegister)
       *                   if (cacheCastClass)
       *                      STG castClassReg, @(dynamicCacheReg,offsetRegister,addressSize)
       *                   AGHI offsetReg,addressSize
       *                   CIJ offsetReg,snippetSizeInBytes,NotEqual,skipResetOffset
       *                   LGHI offsetReg,addressSize
       * skipResetOffset:
       *                   STG offsetReg,@(dynamicCacheReg) -> End of Internal Control Flow
       *                   LT resultReg,helperReturnReg
       */  
   TR_S390OutOfLineCodeSection *outlinedSlowPath = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(helperCallLabel, doneLabel, cg);
   cg->getS390OutOfLineCodeSectionList().push_front(outlinedSlowPath);
      outlinedSlowPath->swapInstructionListsWithCompilation();
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, helperCallLabel);
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOf/(%s)/Helper", comp->signature()),1,TR::DebugCounter::Undetermined);
   TR::S390CHelperLinkage *helperLink =  static_cast<TR::S390CHelperLinkage*>(cg->getLinkage(TR_CHelper));
   resultReg = helperLink->buildDirectDispatch(node, resultReg);
   if (generateDynamicCache)
      {
      TR::LabelSymbol *skipSettingBitForFalseResult = generateLabelSymbol(cg);
      TR::Instruction *cursor = generateRIEInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::CGIJ : TR::InstOpCode::CIJ, node, resultReg, (uint8_t) 1, skipSettingBitForFalseResult, TR::InstOpCode::COND_BE);
      // We will set the last bit of objectClassRegister to 1 if helper returns false.
      generateRIInstruction(cg, TR::InstOpCode::OILL, node, objClassReg, 0x1);
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, skipSettingBitForFalseResult);
      // Update cache sequence
      if (maxOnsiteCacheSlots == 1)
         {
         generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, objClassReg, generateS390MemoryReference(dynamicCacheReg,0,cg));
         if (cacheCastClass)
            generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, castClassReg, generateS390MemoryReference(dynamicCacheReg,addressSize,cg));
         }
      else
         {
         TR::Register *offsetRegister = srm->findOrCreateScratchRegister();
         // NOTE: In OOL helper call is not within ICF hence we can avoid passing dependency to helper call dispatch function and stretching it to merge label.
         // Although internal control flow starts after returning from helper we need to define starting point and ending point of internal control flow.
         cursor->setStartInternalControlFlow();
         generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, offsetRegister, generateS390MemoryReference(dynamicCacheReg,0,cg));    
         generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, objClassReg, generateS390MemoryReference(dynamicCacheReg,offsetRegister,0,cg));
         if (cacheCastClass)
            generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, castClassReg, generateS390MemoryReference(dynamicCacheReg,offsetRegister,addressSize,cg));
         TR::LabelSymbol *skipResetOffsetLabel = generateLabelSymbol(cg);
         generateRIInstruction(cg,TR::InstOpCode::getAddHalfWordImmOpCode(),node,offsetRegister,static_cast<int32_t>(cacheCastClass?addressSize*2:addressSize));
         generateRIEInstruction(cg, TR::InstOpCode::CIJ, node, offsetRegister, snippetSizeInBytes, skipResetOffsetLabel, TR::InstOpCode::COND_BNE);
         generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode() , node, offsetRegister, addressSize);
         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, skipResetOffsetLabel);
         cursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, offsetRegister, generateS390MemoryReference(dynamicCacheReg,0,cg));
         TR::RegisterDependencyConditions * OOLconditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 5, cg);
         OOLconditions->addPostCondition(objClassReg, TR::RealRegister::AssignAny);
         OOLconditions->addPostCondition(resultReg, TR::RealRegister::AssignAny);
         OOLconditions->addPostCondition(dynamicCacheReg, TR::RealRegister::AssignAny);
         OOLconditions->addPostCondition(offsetRegister, TR::RealRegister::AssignAny);
         if (cacheCastClass)
            OOLconditions->addPostCondition(castClassReg, TR::RealRegister::AssignAny);
         cursor->setEndInternalControlFlow();
         cursor->setDependencyConditions(OOLconditions);
         srm->reclaimScratchRegister(offsetRegister);
         }
      srm->reclaimScratchRegister(dynamicCacheReg);
      }

   // WARNING: It is not recommended to have two exit point in OOL section
   // In this case we need it in case of ifInstanceOf to save additional complex logic in mainline section
   // In case if there is GLRegDeps attached to ifIntsanceOf node, it will be evaluated and attached as post dependency conditions
   // at the end of node
   // We can take a risk of having two exit points in OOL here as there is no other register instruction between them
   if (ifInstanceOf)
      {
      generateRRInstruction(cg, TR::InstOpCode::getLoadTestRegOpCode(), node, resultReg, resultReg);
      if (trueFallThrough)
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, branchLabel);
      else
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, branchLabel);
      }
   
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, doneLabel);
   outlinedSlowPath->swapInstructionListsWithCompilation();
   if (!needResult)
      cg->stopUsingRegister(resultReg);
   }

/**   \brief Generates inlined sequence of tests for instanceOf/ifInstanceOf node.
 *    \details
 *    It calls common function to generate list of inlined tests and generates instructions handling both instanceOf and ifInstanceOf case.
 */
TR::Register *
J9::Z::TreeEvaluator::VMgenCoreInstanceofEvaluator2(TR::Node * node, TR::CodeGenerator * cg, TR::LabelSymbol *trueLabel, TR::LabelSymbol *falseLabel,
   bool initialResult, bool needResult, TR::RegisterDependencyConditions *graDeps, bool ifInstanceOf)
   {
   TR::Compilation                *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *) (comp->fe());
   TR_OpaqueClassBlock           *compileTimeGuessClass;
   int32_t maxProfiledClasses = comp->getOptions()->getCheckcastMaxProfiledClassTests();
   traceMsg(comp, "%s:Maximum Profiled Classes = %d\n", node->getOpCode().getName(),maxProfiledClasses);
   InstanceOfOrCheckCastProfiledClasses profiledClassesList[maxProfiledClasses];

   TR::Node                      *objectNode = node->getFirstChild();
   TR::Node                      *castClassNode = node->getSecondChild();

   TR::Register                  *objectReg = cg->evaluate(objectNode);
   TR::Register                  *objClassReg = NULL;
   TR::Register                  *resultReg = NULL;
   TR::Register                  *castClassReg = NULL;

   // In the evaluator, We need at maximum two scratch registers, so creating a pool of scratch registers with 2 size.
   TR_S390ScratchRegisterManager *srm = cg->generateScratchRegisterManager(2);
   bool topClassWasCastClass=false;
   float topClassProbability=0.0;
   InstanceOfOrCheckCastSequences sequences[InstanceOfOrCheckCastMaxSequences];
   uint32_t numberOfProfiledClass;
   uint32_t                       numSequencesRemaining = calculateInstanceOfOrCheckCastSequences(node, sequences, &compileTimeGuessClass, cg, profiledClassesList, &numberOfProfiledClass, maxProfiledClasses, &topClassProbability, &topClassWasCastClass);
   bool outLinedSuperClass = false;
   TR::Instruction *cursor = NULL;
   TR::Instruction *gcPoint = NULL;

   // We load resultReg with the parameter initialResult when we need result as outcome for routine
   if (needResult)
      {
      resultReg = cg->allocateRegister();
      cursor = generateRIInstruction(cg,TR::InstOpCode::getLoadHalfWordImmOpCode(),node,resultReg,static_cast<int32_t>(initialResult));
      }

   TR_S390OutOfLineCodeSection *outlinedSlowPath = NULL;

   TR::LabelSymbol *doneOOLLabel = NULL;
   TR::LabelSymbol *doneLabel = generateLabelSymbol(cg);
   TR::LabelSymbol *callLabel = generateLabelSymbol(cg);
   TR::LabelSymbol *doneTestCacheLabel = NULL;
   TR::LabelSymbol *oppositeResultLabel = generateLabelSymbol(cg);
   TR::LabelSymbol *helperTrueLabel = NULL;
   TR::LabelSymbol *helperFalseLabel = NULL;
   TR::LabelSymbol *helperReturnLabel = NULL;
   TR::LabelSymbol *dynamicCacheTestLabel = NULL;
   TR::LabelSymbol *branchLabel = NULL;
   TR::LabelSymbol *jmpLabel = NULL;

   TR::InstOpCode::S390BranchCondition branchCond;
   TR_Debug *debugObj = cg->getDebug();
   bool trueFallThrough;
   bool dynamicCastClass = false;
   bool generateGoToFalseBRC = true;

   if (ifInstanceOf)
      {
      if (trueLabel)
         {
         traceMsg(comp,"IfInstanceOf Node : Branch True\n");
         falseLabel = (needResult) ? oppositeResultLabel : doneLabel;
         branchLabel = trueLabel;
         branchCond = TR::InstOpCode::COND_BE;
         jmpLabel = falseLabel;
         trueFallThrough = false;
         }
      else
         {
         traceMsg(comp,"IfInstanceOf Node : Branch False\n");
         trueLabel = (needResult)? oppositeResultLabel : doneLabel;
         branchLabel = falseLabel;
         branchCond = TR::InstOpCode::COND_BNE;
         jmpLabel = trueLabel;
         trueFallThrough = true;
         }
      }
   else
      {
      if (initialResult)
         {
         trueLabel = doneLabel;
         falseLabel = oppositeResultLabel;
         branchCond = TR::InstOpCode::COND_BE;
         trueFallThrough = false;
         }
      else
         {
         trueLabel = oppositeResultLabel;
         falseLabel = doneLabel;
         branchCond = TR::InstOpCode::COND_BNE;
         trueFallThrough = true;
         }
      branchLabel = doneLabel;
      jmpLabel = oppositeResultLabel;
      }

   bool generateDynamicCache = false;
   bool cacheCastClass = false;
   InstanceOfOrCheckCastSequences *iter = &sequences[0];
   while (numSequencesRemaining >   1 || (numSequencesRemaining==1 && *iter!=HelperCall))
      {
      switch (*iter)
         {
         case EvaluateCastClass:
            TR_ASSERT(!castClassReg, "Cast class already evaluated");
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp, "%s: Class Not Evaluated. Evaluating it\n", node->getOpCode().getName());
            castClassReg = cg->evaluate(castClassNode);
            break;
         case LoadObjectClass:
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp, "%s: Loading Object Class\n",node->getOpCode().getName());
            objClassReg = cg->allocateRegister();
            TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node, objClassReg, generateS390MemoryReference(objectReg, static_cast<int32_t>(TR::Compiler->om.offsetOfObjectVftField()), cg), NULL);
            break;
         case GoToTrue:
            traceMsg(comp, "%s: Emitting GoToTrue\n", node->getOpCode().getName());
            // If fall through in True (Initial Result False)
            //if (trueLabel != oppositeResultLabel)
            if (trueLabel != oppositeResultLabel  || (ifInstanceOf && !trueFallThrough))
               generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BC, node, trueLabel);
            break;
         case GoToFalse:
            traceMsg(comp, "%s: Emitting GoToFalse\n", node->getOpCode().getName());
            // There is only one case when we generate a GoToFalse branch here, when we have a primitive Cast Class other wise all tests take care of generating terminating sequence
            if (generateGoToFalseBRC)
               generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BC, node, falseLabel);
            break;
         case NullTest:
            {
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp, "%s: Emitting NullTest\n", node->getOpCode().getName());
            TR_ASSERT(!objectNode->isNonNull(), "Object is known to be non-null, no need for a null test");
            bool isNullTestImplicit = genInstanceOfOrCheckCastNullTest(node, cg, objectReg);
            if (!isNullTestImplicit)
               {
               //If object is Null, and initialResult is true, go to oppositeResultLabel else goto done Label
               generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, falseLabel);
               }
            }
            break;
         case ClassEqualityTest:
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp, "%s: Emitting Class Equality Test\n", node->getOpCode().getName());
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/Equality", comp->signature()),1,TR::DebugCounter::Undetermined);
             /*   #IF NextTest = GoToFalse
              *      branchCond = ifInstanceOf ? (!trueFallThrough ? COND_BE : COND_BNE ) : (init=true ? COND_BE : COND_BNE )
              *      brnachLabel = ifInstanceOf ? (!trueFallThrough ? trueLabel : falseLabel ) : doneLabel
              *      CGRJ castClassReg, objClassReg, branchCond, branchLabel
              *   #ELSE
              *      CGRJ castClassReg, objClassReg, COND_BE, trueLabel
              */
            if ( *(iter+1) == GoToFalse )
               {
               cursor = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, castClassReg, objClassReg, branchCond, branchLabel, false, false);
               generateGoToFalseBRC = false;
               }
            else
               {
               cursor = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, castClassReg, objClassReg, TR::InstOpCode::COND_BE, trueLabel, false, false);
               generateGoToFalseBRC = true;
               }
            if (debugObj)
               debugObj->addInstructionComment(cursor, "ClassEqualityTest");
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/EqualityFail", comp->signature()),1,TR::DebugCounter::Undetermined);
            break;
         case SuperClassTest:
            {
            /*** genInstanceOfOrCheckcastSuperClassTest generates sequences for Super Class Test handling all cases when we have a normal static class or dynamic class
               * Mostly this will be last test except in case of dynamic cast class.
               * case-1 instanceof , initial Result = false: BRC 0x8, doneLabel
               * case-2 instanceof , initial Result = true: BRC 0x6, doneLabel
               * case-3 ifInstanceOf , trueLabel == branchLabel : BRC 0x8, branchLabel
               * case-4 ifInstanceOf , falseLabel == branchLabel : BRC 0x6, branchLabel
               */
            int32_t castClassDepth = castClassNode->getSymbolReference()->classDepth(comp);
            dynamicCacheTestLabel = generateLabelSymbol(cg);
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp, "%s: Emitting Super Class Test, Cast Class Depth = %d\n", node->getOpCode().getName(),castClassDepth);
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/SuperClassTest", comp->signature()),1,TR::DebugCounter::Undetermined);
            // For dynamic cast class genInstanceOfOrCheckcastSuperClassTest will generate branch to either helper call or dynamicCacheTest depending on the next generated test.
            dynamicCastClass = genInstanceOfOrCheckcastSuperClassTest(node, cg, objClassReg, castClassReg, castClassDepth, falseLabel, *(iter+1) == DynamicCacheDynamicCastClassTest ? dynamicCacheTestLabel : callLabel, srm);
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, branchCond, node, branchLabel);
            // If next test is dynamicCacheTest then generate a Branch to Skip it.
            if (*(iter+1) == DynamicCacheDynamicCastClassTest)
               generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BC, node, jmpLabel);
            generateGoToFalseBRC=false;
            break;
            }
         /**   Following switch case generates sequence of instructions for profiled class test for instanceOf node
          *    arbitraryClassReg1 <= profiledClass
          *    if (arbitraryClassReg1 == objClassReg)
          *       profiledClassIsInstanceOfCastClass ? return true : return false
          *    else
          *       continue to NextTest
          */
         case ProfiledClassTest:
            {
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp, "%s: Emitting ProfiledClass Test\n", node->getOpCode().getName());
            TR::Register *arbitraryClassReg1 = srm->findOrCreateScratchRegister();
            uint8_t numPICs = 0;
            TR::Instruction *temp= NULL;
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/Profile", comp->signature()),1,TR::DebugCounter::Undetermined);
            while (numPICs < numberOfProfiledClass)
               {
               if (cg->needClassAndMethodPointerRelocations())
                  temp = generateRegLitRefInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, arbitraryClassReg1, (uintptrj_t) profiledClassesList[numPICs].profiledClass, TR_ClassPointer, NULL, NULL, NULL);
               else
                  temp = generateRILInstruction(cg, TR::InstOpCode::LARL, node, arbitraryClassReg1, (uintptrj_t)profiledClassesList[numPICs].profiledClass);

               // Adding profiled class to the static PIC slots.  
               if (fej9->isUnloadAssumptionRequired((TR_OpaqueClassBlock *)(profiledClassesList[numPICs].profiledClass), comp->getCurrentMethod()))
                  comp->getStaticPICSites()->push_front(temp);
               // Adding profiled class to static HCR PIC sites.               
               if (cg->wantToPatchClassPointer(profiledClassesList[numPICs].profiledClass, node))
                  comp->getStaticHCRPICSites()->push_front(temp);
               
               if (profiledClassesList[numPICs].isProfiledClassInstanceOfCastClass)
                  generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, arbitraryClassReg1, objClassReg, TR::InstOpCode::COND_BE, trueLabel, false, false);
               else
                  generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, arbitraryClassReg1, objClassReg, TR::InstOpCode::COND_BE, falseLabel, false, false);
               numPICs++;
               }
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/ProfileFail", comp->signature()),1,TR::DebugCounter::Undetermined);
            srm->reclaimScratchRegister(arbitraryClassReg1);
            break;
            }
         /**   In case of Single Implementer of the Interface,
          *    arbitraryClassReg1 <= compileTimeGuessClass
          *    CGRJ arbitraryClassReg,objClassReg,0x8,trueLabel
          */
         case CompileTimeGuessClassTest:
            {
            TR::Register *arbitraryClassReg2 = srm->findOrCreateScratchRegister();
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/compTimeGuess", comp->signature()),1,TR::DebugCounter::Undetermined);
            genLoadAddressConstant(cg, node, (uintptrj_t)compileTimeGuessClass, arbitraryClassReg2);
            generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, arbitraryClassReg2, objClassReg, TR::InstOpCode::COND_BE, trueLabel, false, false);
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/compTimeGuessFail", comp->signature()),1,TR::DebugCounter::Undetermined);
            srm->reclaimScratchRegister(arbitraryClassReg2);
            break;
            }
         case ArrayOfJavaLangObjectTest:
            {
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp,"Emitting ArrayOfJavaLangObjectTest\n",node->getOpCode().getName());
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "instanceOfStats/(%s)/ArrayTest", comp->signature()),1,TR::DebugCounter::Undetermined);
            genInstanceOfOrCheckcastArrayOfJavaLangObjectTest(node, cg, objClassReg, falseLabel, srm) ;
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, branchCond, node, branchLabel);
            generateGoToFalseBRC = false;
            break;
            }
         /**   Following switch case generates sequence of instructions for cast class cache test
          *    Load castClassCacheReg, offsetOf(J9Class,castClassCache)
          *    castClassCacheReg <= castClassCacheReg XOR castClassReg
          *    if castClassCacheReg == 0 (Success)
          *       return true
          *    else if castClassCacheReg == 1 (Failed instanceOf)
          *       return false
          *    else
          *       continue
          */
         case CastClassCacheTest:
            {
            doneTestCacheLabel =  generateLabelSymbol(cg);
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp,"Emitting CastClassCacheTest\n",node->getOpCode().getName());
            TR::Register *castClassCacheReg = srm->findOrCreateScratchRegister();
            generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, castClassCacheReg,
               generateS390MemoryReference(objClassReg, offsetof(J9Class, castClassCache), cg));
            generateRRInstruction(cg, TR::InstOpCode::getXORRegOpCode(), node, castClassCacheReg, castClassReg);
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, trueLabel);
            generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, castClassCacheReg, 1, TR::InstOpCode::COND_BE, falseLabel, false, false);
            srm->reclaimScratchRegister(castClassCacheReg);
            break;
            }
         case DynamicCacheObjectClassTest:
            {
            generateDynamicCache = true;
            dynamicCacheTestLabel = generateLabelSymbol(cg);
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp,"Emitting Dynamic Cache for ObjectClass only\n",node->getOpCode().getName());
            break;
            }
         case DynamicCacheDynamicCastClassTest:
            {
            generateDynamicCache = true;
            cacheCastClass = true;
            TR_ASSERT(dynamicCacheTestLabel!=NULL, "DynamicCacheDynamicCastClassTest: dynamicCacheTestLabel should be generated by SuperClassTest before reaching this point");
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp,"Emitting Dynamic Cache for CastClass and ObjectClass\n",node->getOpCode().getName());
            break;
            }
         case HelperCall:
            TR_ASSERT(false, "Doesn't make sense, HelperCall should be the terminal sequence");
            break;
         default:
            break;
         }
      --numSequencesRemaining;
      ++iter;
      }

   if (numSequencesRemaining > 0 && *iter == HelperCall)
      genInstanceOfDynamicCacheAndHelperCall(node, cg, castClassReg, objClassReg, resultReg, srm, doneLabel, callLabel, dynamicCacheTestLabel, branchLabel, trueLabel, falseLabel, dynamicCastClass, generateDynamicCache, cacheCastClass, ifInstanceOf, trueFallThrough);

   if (needResult)
      {
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, oppositeResultLabel);
      generateRIInstruction(cg,TR::InstOpCode::getLoadHalfWordImmOpCode(),node,resultReg,static_cast<int32_t>(!initialResult));
      }
   
   TR::RegisterDependencyConditions *conditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(graDeps, 0, 4+srm->numAvailableRegisters(), cg);
   if (objClassReg)
      conditions->addPostCondition(objClassReg, TR::RealRegister::AssignAny);
   if (needResult)
      conditions->addPostCondition(resultReg, TR::RealRegister::AssignAny);
   conditions->addPostConditionIfNotAlreadyInserted(objectReg, TR::RealRegister::AssignAny);
   if (castClassReg)
      conditions->addPostConditionIfNotAlreadyInserted(castClassReg, TR::RealRegister::AssignAny);
   srm->addScratchRegistersToDependencyList(conditions);
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, conditions);
   if (objClassReg)
      cg->stopUsingRegister(objClassReg);
   if (castClassReg)
      cg->stopUsingRegister(castClassReg);
   srm->stopUsingRegisters();
   cg->decReferenceCount(objectNode);
   cg->decReferenceCount(castClassNode);
   if (needResult)
      node->setRegister(resultReg);
   return resultReg;
   }

/**   \brief Sets up parameters for VMgenCoreInstanceOfEvaluator2 when we have a ifInstanceOf node
 *    \details
 *    For ifInstanceOf node, it checks if the node has GRA dependency node as third child and if it has, calls normal instanceOf
 *    Otherwise calls VMgenCoreInstanceOfEvaluator2with parameters to generate instructions for ifInstanceOf.
 */
TR::Register *
J9::Z::TreeEvaluator::VMifInstanceOfEvaluator2(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR::Node * graDepNode = NULL;
   TR::ILOpCodes opCode = node->getOpCodeValue();
   TR::Node * instanceOfNode = node->getFirstChild();
   TR::Node * valueNode     = node->getSecondChild();
   int32_t value = valueNode->getInt();
   TR::LabelSymbol * branchLabel = node->getBranchDestination()->getNode()->getLabel();
   TR::RegisterDependencyConditions * graDeps = NULL;

   TR::LabelSymbol * falseLabel = NULL;
   TR::LabelSymbol * trueLabel = NULL;

   if (node->getNumChildren() == 3)
      {
      graDepNode = node->getChild(2);
      }

   if (graDepNode && graDepsConflictWithInstanceOfDeps(graDepNode, instanceOfNode, cg))
      {
      return (TR::Register*) 1;
      }

   bool needResult = (instanceOfNode->getReferenceCount() > 1);

   if ((opCode == TR::ificmpeq && value == 1) || (opCode != TR::ificmpeq && value == 0))
      trueLabel       = branchLabel;
   else
      falseLabel      = branchLabel;

   if (graDepNode)
      {
      cg->evaluate(graDepNode);
      graDeps = generateRegisterDependencyConditions(cg, graDepNode, 0);
      }
   bool initialResult = trueLabel != NULL;

   VMgenCoreInstanceofEvaluator2(instanceOfNode, cg, trueLabel, falseLabel, initialResult, needResult, graDeps, true);

   cg->decReferenceCount(instanceOfNode);
   node->setRegister(NULL);

   return NULL;
   }


TR::Register *
J9::Z::TreeEvaluator::VMifInstanceOfEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Compilation         *comp = cg->comp();
   static bool newIfInstanceOf = (feGetEnv("TR_oldInstanceOf")) == NULL;
   // We have support for new C helper functions with new instanceOf evaluator so bydefault we are calling it.
   if (true)
      return VMifInstanceOfEvaluator2(node,cg);

   TR::Node * graDepNode = NULL;

   TR::ILOpCodes opCode = node->getOpCodeValue();
   TR::Node * instanceOfNode = node->getFirstChild();
   TR::Node * castClassNode = instanceOfNode->getSecondChild();
   TR::Node * objectNode    = instanceOfNode->getFirstChild();
   TR::Node * valueNode     = node->getSecondChild();
   int32_t value = valueNode->getInt();
   TR::LabelSymbol * branchLabel = node->getBranchDestination()->getNode()->getLabel();
   TR::RegisterDependencyConditions * graDeps = NULL;

   TR::LabelSymbol * falseLabel;
   TR::LabelSymbol * trueLabel;
   bool trueFallThrough;

   // GRA
   // If the result itself is assigned to a global register, we still have to do
   // something special ......
   if (node->getNumChildren() == 3)
      {
      graDepNode = node->getChild(2);
      }

   // Fast path failure check
   //  TODO: For now we cannot handle Global regs in this path
   //        due to possible colision with call out deps.
   if (graDepNode && graDepsConflictWithInstanceOfDeps(graDepNode, instanceOfNode, cg))
      {
      return (TR::Register*) 1;
      }

   // If the result itself is assigned to a global register, we still have to
   // evaluate it
   int32_t needResult = (instanceOfNode->getReferenceCount() > 1);

   if ((opCode == TR::ificmpeq && value == 1) || (opCode != TR::ificmpeq && value == 0))
      {
      falseLabel      = NULL;
      trueLabel       = branchLabel;
      trueFallThrough = false;
      }
   else
      {
      trueLabel       = NULL;
      falseLabel      = branchLabel;
      trueFallThrough = true;
      }

   TR::Register * objectReg    = cg->evaluate(objectNode);
   TR::Register * castClassReg = cg->evaluate(castClassNode);

   // GRA
   if (graDepNode)
      {
      cg->evaluate(graDepNode);
      graDeps = generateRegisterDependencyConditions(cg, graDepNode, 0);
      }

   TR::TreeEvaluator::VMgenCoreInstanceofEvaluator(instanceOfNode, cg, falseLabel, trueLabel, needResult, trueFallThrough, graDeps, true);

   cg->decReferenceCount(instanceOfNode);
   node->setRegister(NULL);

   return NULL;
   }

/**   \brief Sets up parameters for VMgenCoreInstanceOfEvaluator2 when we have a instanceOf node
 */

TR::Register *
J9::Z::TreeEvaluator::VMinstanceOfEvaluator2(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR::Compilation            *comp = cg->comp();
   static bool initialResult = feGetEnv("TR_instanceOfInitialValue") != NULL;
   traceMsg(comp,"Initial result = %d\n",initialResult);
   // Complementing Initial Result to True if the floag is not passed.
   return VMgenCoreInstanceofEvaluator2(node,cg,NULL,NULL,!initialResult,1,NULL,false);
   }

TR::Register *
J9::Z::TreeEvaluator::VMinstanceOfEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Compilation *comp = cg->comp();
   static bool newinstanceOf = (feGetEnv("TR_oldInstanceOf")) == NULL;
   // We have support for new C helper functions with new instanceOf evaluator so by default we are calling it.
   if (true)
      return VMinstanceOfEvaluator2(node,cg);
   TR::Node * objectNode       = node->getFirstChild();
   TR::Node * castClassNode    = node->getSecondChild();
   TR::Register * objectReg    = cg->evaluate(objectNode);
   TR::Register * castClassReg = cg->evaluate(castClassNode);

   return TR::TreeEvaluator::VMgenCoreInstanceofEvaluator(node, cg, NULL, NULL, true, true, NULL);
   }

/**   \brief Generates Sequence of inline tests for checkcast node.
 *    \details
 *    We call common function that generates an array of inline tests we need to generate for this node
 */
TR::Register *
J9::Z::TreeEvaluator::VMcheckcastEvaluator2(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Compilation                *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *) (comp->fe());
   TR_OpaqueClassBlock           *profiledClass, *compileTimeGuessClass;

   int32_t maxProfiledClasses = comp->getOptions()->getCheckcastMaxProfiledClassTests();
   traceMsg(comp, "%s:Maximum Profiled Classes = %d\n", node->getOpCode().getName(),maxProfiledClasses);
   InstanceOfOrCheckCastProfiledClasses profiledClassesList[maxProfiledClasses];
   InstanceOfOrCheckCastSequences sequences[InstanceOfOrCheckCastMaxSequences];

   // We use this information to decide if we want to do SuperClassTest inline or not
   bool topClassWasCastClass=false;
   float topClassProbability=0.0;
   bool dynamicCastClass = false;
   uint32_t numberOfProfiledClass;
   uint32_t                       numSequencesRemaining = calculateInstanceOfOrCheckCastSequences(node, sequences, &compileTimeGuessClass, cg, profiledClassesList, &numberOfProfiledClass, maxProfiledClasses, &topClassProbability, &topClassWasCastClass);

   TR::Node                      *objectNode = node->getFirstChild();
   TR::Node                      *castClassNode = node->getSecondChild();
   TR::Register                  *objectReg = NULL;
   TR::Register                  *castClassReg = NULL;
   TR::Register                  *objClassReg = NULL;
   TR::Register                  *objectCopyReg = NULL;
   TR::Register                  *castClassCopyReg = NULL;
   TR::Register                  *resultReg = NULL;

   // We need here at maximum two scratch registers so forcing scratchRegisterManager to create pool of two registers only.
   TR_S390ScratchRegisterManager *srm = cg->generateScratchRegisterManager(2);

   TR::Instruction *gcPoint = NULL;
   TR::Instruction *cursor = NULL;
   TR_S390OutOfLineCodeSection *outlinedSlowPath = NULL;
   TR::LabelSymbol *doneOOLLabel = NULL;
   TR::LabelSymbol *startOOLLabel = NULL;
   TR::LabelSymbol *helperReturnOOLLabel = NULL;
   TR::LabelSymbol *doneLabel = generateLabelSymbol(cg);
   TR::LabelSymbol *callLabel = generateLabelSymbol(cg);
   TR::LabelSymbol *resultLabel = doneLabel;

   TR_Debug * debugObj = cg->getDebug();
   objectReg = cg->evaluate(objectNode);

   // When we topProfiledClass in the profiled information is cast class with frequency greater than 0.5, we expect class equality to succeed so we put rest of the test outlined.
   bool outLinedTest = numSequencesRemaining >= 2 && sequences[numSequencesRemaining-2] == SuperClassTest && topClassProbability >= 0.5 && topClassWasCastClass;
   traceMsg(comp, "Outline Super Class Test: %d\n", outLinedTest);
   InstanceOfOrCheckCastSequences *iter = &sequences[0];

   while (numSequencesRemaining > 1)
      {
      switch(*iter)
         {
         case EvaluateCastClass:
            TR_ASSERT(!castClassReg, "Cast class already evaluated");
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp, "%s: Class Not Evaluated. Evaluating it\n", node->getOpCode().getName());
            castClassReg = cg->evaluate(castClassNode);
            break;
         case LoadObjectClass:
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp, "%s: Loading Object Class\n",node->getOpCode().getName());
            objClassReg = cg->allocateRegister();
            TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node, objClassReg, generateS390MemoryReference(objectReg, static_cast<int32_t>(TR::Compiler->om.offsetOfObjectVftField()), cg), NULL);
            break;
         case GoToTrue:
            TR_ASSERT(false, "Doesn't Make sense, GoToTrue should not be part of multiple sequences");
            break;
         case GoToFalse:
            TR_ASSERT(false, "Doesn't make sense, GoToFalse should be the terminal sequence");
            break;
         case NullTest:
            {
            //If Object is Null, no need to carry out rest of test and jump to Done Label
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp, "%s: Emitting NullTest\n", node->getOpCode().getName());
            TR_ASSERT(!objectNode->isNonNull(), "Object is known to be non-null, no need for a null test");
            bool isNullTestImplicit = genInstanceOfOrCheckCastNullTest(node, cg, objectReg);
            if (!isNullTestImplicit)
               {
               generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, doneLabel);
               }
            }
            break;
         case ClassEqualityTest:
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp, "%s: Emitting Class Equality Test\n", node->getOpCode().getName());
            if (outLinedTest && !comp->getOption(TR_DisableOOL))
               {
               // This is the case when we are going to have an Internal Control Flow in the OOL
               startOOLLabel = generateLabelSymbol(cg);
               doneOOLLabel = doneLabel;
               helperReturnOOLLabel = generateLabelSymbol(cg);
               cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/EqualOOL", comp->signature()),1,TR::DebugCounter::Undetermined);
               generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, castClassReg, objClassReg, TR::InstOpCode::COND_BNE, startOOLLabel, false, false);
               cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/EqualOOLPass", comp->signature()),1,TR::DebugCounter::Undetermined);
               outlinedSlowPath = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(startOOLLabel,doneOOLLabel,cg);
               cg->getS390OutOfLineCodeSectionList().push_front(outlinedSlowPath);
               outlinedSlowPath->swapInstructionListsWithCompilation();
               generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, startOOLLabel);
               resultLabel = helperReturnOOLLabel;
               }
            else
               {
               cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/Equal", comp->signature()),1,TR::DebugCounter::Undetermined);
               generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, castClassReg, objClassReg, TR::InstOpCode::COND_BE, doneLabel, false, false);
               cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/EqualFail", comp->signature()),1,TR::DebugCounter::Undetermined);
               }
            break;
         case SuperClassTest:
            {
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/SuperClass", comp->signature()),1,TR::DebugCounter::Undetermined);
            int32_t castClassDepth = castClassNode->getSymbolReference()->classDepth(comp);
            TR_ASSERT(numSequencesRemaining == 2, "SuperClassTest should always be followed by a GoToFalse and must always be the second last test generated");
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp, "%s: Emitting Super Class Test, Cast Class Depth=%d\n", node->getOpCode().getName(),castClassDepth);
            dynamicCastClass = genInstanceOfOrCheckcastSuperClassTest(node, cg, objClassReg, castClassReg, castClassDepth, callLabel, NULL, srm);
            /* outlinedSlowPath will be non-NULL if we have a higher probability of ClassEqualityTest succeeding.
             * In such cases we will do rest of the tests in OOL section, and as such we need to skip the helper call
             * if the result of SuperClassTest is true and branch to resultLabel which will branch back to the doneLabel from OOL code. 
             * In normal cases SuperClassTest will be inlined with doneLabel as fallThroughLabel so we need to branch to callLabel to generate CastClassException
             * through helper call if result of SuperClassTest turned out to be false. 
             */ 
            cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, outlinedSlowPath != NULL ? TR::InstOpCode::COND_BE : TR::InstOpCode::COND_BNE, node, outlinedSlowPath ? resultLabel : callLabel);
            break;
            }
         /**   Following switch case generates sequence of instructions for profiled class test for this checkCast node
          *    arbitraryClassReg1 <= profiledClass
          *    if (arbitraryClassReg1 == objClassReg)
          *       JMP DoneLabel
          *    else
          *       continue to NextTest
          */
         case ProfiledClassTest:
            {
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp, "%s: Emitting Profiled Class Test\n", node->getOpCode().getName());
            TR::Register *arbitraryClassReg1 = srm->findOrCreateScratchRegister();
            uint8_t numPICs = 0;
            TR::Instruction *temp= NULL;
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/Profiled", comp->signature()),1,TR::DebugCounter::Undetermined);
            while (numPICs < numberOfProfiledClass)
               {
               if (cg->needClassAndMethodPointerRelocations())
                  temp = generateRegLitRefInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, arbitraryClassReg1, (uintptrj_t) profiledClassesList[numPICs].profiledClass, TR_ClassPointer, NULL, NULL, NULL);
               else
                  temp = generateRILInstruction(cg, TR::InstOpCode::LARL, node, arbitraryClassReg1, (uintptrj_t)profiledClassesList[numPICs].profiledClass);

               // Adding profiled classes to static PIC sites
               if (fej9->isUnloadAssumptionRequired((TR_OpaqueClassBlock *)(profiledClassesList[numPICs].profiledClass), comp->getCurrentMethod()))
                  comp->getStaticPICSites()->push_front(temp);
               // Adding profiled classes to HCR PIC sites
               if (cg->wantToPatchClassPointer(profiledClassesList[numPICs].profiledClass, node))
                  comp->getStaticHCRPICSites()->push_front(temp);
               
               temp = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, arbitraryClassReg1, objClassReg, TR::InstOpCode::COND_BE, resultLabel, false, false);
               numPICs++;
               }
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/ProfiledFail", comp->signature()),1,TR::DebugCounter::Undetermined);
            srm->reclaimScratchRegister(arbitraryClassReg1);
            break;
            }
         case CompileTimeGuessClassTest:
            {
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp, "%s: Emitting Compile Time Guess Class Test\n", node->getOpCode().getName());
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/CompTimeGuess", comp->signature()),1,TR::DebugCounter::Undetermined);
            TR::Register *arbitraryClassReg2 = srm->findOrCreateScratchRegister();
            genLoadAddressConstant(cg, node, (uintptrj_t)compileTimeGuessClass, arbitraryClassReg2);
            cursor = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, arbitraryClassReg2, objClassReg, TR::InstOpCode::COND_BE, resultLabel , false, false);
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/CompTimeFail", comp->signature()),1,TR::DebugCounter::Undetermined);
            srm->reclaimScratchRegister(arbitraryClassReg2);
            break;
            }
         case ArrayOfJavaLangObjectTest:
            {
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/ArrayTest", comp->signature()),1,TR::DebugCounter::Undetermined);
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp,"%s: Emitting ArrayOfJavaLangObjectTest\n",node->getOpCode().getName());
            genInstanceOfOrCheckcastArrayOfJavaLangObjectTest(node, cg, objClassReg, callLabel, srm) ;
            cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, doneLabel);
            break;
            }
         /**   Following switch case generates sequence of instructions for cast class cache test for this checkCast node
          *    Load castClassCacheReg, offsetOf(J9Class,castClassCache)
          *    if castClassCacheReg == castClassReg
          *       JMP DoneLabel
          *    else
          *       continue to NextTest
          */
         case CastClassCacheTest:
            {
            if (comp->getOption(TR_TraceCG))
               traceMsg(comp,"%s: Emitting CastClassCacheTest\n",node->getOpCode().getName());
            TR::Register *castClassCacheReg = srm->findOrCreateScratchRegister();
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/Cache", comp->signature()),1,TR::DebugCounter::Undetermined);
            generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, castClassCacheReg,
               generateS390MemoryReference(objClassReg, offsetof(J9Class, castClassCache), cg));
            cursor = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, castClassCacheReg, castClassReg, TR::InstOpCode::COND_BE, resultLabel , false, false);
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/CacheFail", comp->signature()),1,TR::DebugCounter::Undetermined);
            srm->reclaimScratchRegister(castClassCacheReg);
            break;
            }
         case HelperCall:
            TR_ASSERT(false, "Doesn't make sense, HelperCall should be the terminal sequence");
            break;
         default:
            break;
         }
      --numSequencesRemaining;
      ++iter;
      }

   TR::RegisterDependencyConditions *conditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 7+srm->numAvailableRegisters(), cg);
   TR::RegisterDependencyConditions *outlinedConditions = NULL;

   // In case of Higher probability of quality test to pass, we put rest of the test outlined
   if (!outlinedSlowPath)
      outlinedConditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 4, cg);
   else
      outlinedConditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 4+srm->numAvailableRegisters(), cg);

   conditions->addPostCondition(objectReg, TR::RealRegister::AssignAny);
   if (objClassReg)
      conditions->addPostCondition(objClassReg, TR::RealRegister::AssignAny);


   srm->addScratchRegistersToDependencyList(conditions);
   TR::S390CHelperLinkage *helperLink =  static_cast<TR::S390CHelperLinkage*>(cg->getLinkage(TR_CHelper));
   // We will be generating sequence to call Helper if we have either GoToFalse or HelperCall Test
   if (numSequencesRemaining > 0 && *iter != GoToTrue)
      {

      TR_ASSERT(*iter == HelperCall || *iter == GoToFalse, "Expecting helper call or fail here");
      bool helperCallForFailure = *iter != HelperCall;
      if (comp->getOption(TR_TraceCG))
         traceMsg(comp, "%s: Emitting helper call%s\n", node->getOpCode().getName(),helperCallForFailure?" for failure":"");
      //Follwing code is needed to put the Helper Call Outlined.
      if (!comp->getOption(TR_DisableOOL) && !outlinedSlowPath)
         {
         // As SuperClassTest is the costliest test and is guaranteed to give results for checkCast node. Hence it will always be second last test 
         // in iter array followed by GoToFalse as last test for checkCastNode
         if ( *(iter-1) != SuperClassTest)
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, callLabel);
         doneOOLLabel = doneLabel;
         helperReturnOOLLabel = generateLabelSymbol(cg);
         outlinedSlowPath = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(callLabel,doneOOLLabel,cg);
         cg->getS390OutOfLineCodeSectionList().push_front(outlinedSlowPath);
         outlinedSlowPath->swapInstructionListsWithCompilation();
         }


      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, callLabel);
      outlinedConditions->addPostCondition(objectReg, TR::RealRegister::AssignAny);
      if (outLinedTest)
         {
         outlinedConditions->addPostCondition(objClassReg, TR::RealRegister::AssignAny);
         srm->addScratchRegistersToDependencyList(outlinedConditions);
         }

      if(!castClassReg)
         castClassReg = cg->evaluate(castClassNode);
      conditions->addPostCondition(castClassReg, TR::RealRegister::AssignAny);
      outlinedConditions->addPostCondition(castClassReg, TR::RealRegister::AssignAny);
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCast/(%s)/Helper", comp->signature()),1,TR::DebugCounter::Undetermined);
      TR::RegisterDependencyConditions *deps = NULL;
      resultReg = startOOLLabel ? helperLink->buildDirectDispatch(node, &deps) : helperLink->buildDirectDispatch(node);
      if (resultReg)
         outlinedConditions->addPostCondition(resultReg, TR::RealRegister::AssignAny);

      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/HelperCall", comp->signature()),1,TR::DebugCounter::Undetermined);
      if(outlinedSlowPath)
         {
         TR::RegisterDependencyConditions *mergeConditions = NULL;
         if (startOOLLabel)
            mergeConditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(outlinedConditions, deps, cg);
         else
            mergeConditions = outlinedConditions;
         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, helperReturnOOLLabel, mergeConditions);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, doneOOLLabel);
         outlinedSlowPath->swapInstructionListsWithCompilation();
         }
      }
   if (resultReg)
      cg->stopUsingRegister(resultReg);
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, conditions);
   cg->stopUsingRegister(castClassReg);
   if (objClassReg)
      cg->stopUsingRegister(objClassReg);
   srm->stopUsingRegisters();
   cg->decReferenceCount(objectNode);
   cg->decReferenceCount(castClassNode);
   return NULL;
   }

TR::Register *
J9::Z::TreeEvaluator::VMcheckcastEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Compilation *comp = cg->comp();
   static bool newCheckCast = (feGetEnv("TR_oldCheckCast") == NULL);
   // We have support for new C helper functions with new checkCast evaluator so bydefault we are calling it.
   if (true)
      return VMcheckcastEvaluator2(node, cg);
   TR::Register * objReg, * castClassReg, * objClassReg, * scratch1Reg, * scratch2Reg;
   TR::LabelSymbol * doneLabel, * callLabel, * startOOLLabel, * doneOOLLabel, *helperReturnOOLLabel, *resultLabel, *continueLabel;
   TR::Node * objNode, * castClassNode;
   TR::RegisterDependencyConditions * conditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(6, 7, cg);
   TR::Instruction * gcPoint;
   TR::Register * litPoolBaseReg=NULL;
   bool objRegMustBeKilled = false;
   TR::Register * compareReg = NULL;
   objNode = node->getFirstChild();
   castClassNode = node->getSecondChild();
   TR::SymbolReference * castClassSymRef = castClassNode->getSymbolReference();
   TR_Debug * debugObj = cg->getDebug();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());

   bool testEqualClass        = instanceOfOrCheckCastNeedEqualityTest(node, cg);
   bool testCastClassIsSuper  = instanceOfOrCheckCastNeedSuperTest(node, cg);
   bool isFinalClass          = (castClassSymRef == NULL) ? false : castClassSymRef->isNonArrayFinal(comp);
   bool needsHelperCall       = needHelperCall(node, testCastClassIsSuper, isFinalClass);
   bool testCache             = needTestCache(true, needsHelperCall, testCastClassIsSuper);
   bool needsNullTest         = !objNode->isNonNull() && !node->chkIsReferenceNonNull();
   bool nullCCSet             = false;

   bool isCheckcastAndNullChk = (node->getOpCodeValue() == TR::checkcastAndNULLCHK);

   castClassReg = cg->gprClobberEvaluate(castClassNode);

   objClassReg = cg->allocateRegister();
   scratch1Reg = cg->allocateRegister();

   // Find instances where L/LTR could be replaced by an ICM instruction
   if (needsNullTest)
      {
      nullCCSet = true;
      if(cg->getHasResumableTrapHandler() && isCheckcastAndNullChk)
         {
         compareReg = objReg = cg->evaluate(objNode);
         TR::S390RIEInstruction* cursor =
            new (cg->trHeapMemory()) TR::S390RIEInstruction(TR::InstOpCode::getCmpImmTrapOpCode(), node, objReg, (int16_t)0, TR::InstOpCode::COND_BE, cg);
         cursor->setExceptBranchOp();
         cursor->setNeedsGCMap(0x0000FFFF);
         }
      else if (needsNullTest &&
          !objNode->getRegister() &&
          !objNode->getOpCode().isLoadConst() &&
           (objNode->getOpCode().isLoad() || objNode->getOpCode().isLoadIndirect()) &&
          !(objNode->getSymbolReference()->isLiteralPoolAddress()))
         {
         TR::MemoryReference * tempMR;
         TR::Symbol * sym = objNode->getSymbolReference()->getSymbol();

         if ((objNode->getOpCode().isLoadIndirect() || objNode->getOpCodeValue() == TR::aload) && !sym->isInternalPointer())
            {
            compareReg = objReg = cg->allocateCollectedReferenceRegister();
            }
         else
            {
            compareReg = objReg = cg->allocateRegister();
            objReg->setContainsInternalPointer();
            objReg->setPinningArrayPointer(sym->castToInternalPointerAutoSymbol()->getPinningArrayPointer());
            }

         tempMR = generateS390MemoryReference(objNode, cg);

         generateRXYInstruction(cg, TR::InstOpCode::getLoadTestOpCode(), objNode, objReg, tempMR);

         objNode->setRegister(objReg);
         nullCCSet = true;
         tempMR->stopUsingMemRefRegister(cg);
         }
      else
         {
         objReg = cg->allocateRegister();
         TR::Register * origReg = cg->evaluate(objNode);
         genNullTest(cg, node, objReg, origReg, NULL);
         compareReg = origReg;  // Get's rid of a couple AGIs

         objRegMustBeKilled = true;
         }
      }
   else
      {
      compareReg = objReg = cg->evaluate(objNode);
      }

   if (needsNullTest && isCheckcastAndNullChk && !cg->getHasResumableTrapHandler())
      {
      // find the bytecodeInfo
      // of the compacted NULLCHK
      TR::Node *nullChkInfo = comp->findNullChkInfo(node);
      generateNullChkSnippet(nullChkInfo, cg);
      }

   conditions->addPostCondition(objReg, TR::RealRegister::GPR2);
   conditions->addPostCondition(castClassReg, TR::RealRegister::GPR1);
   conditions->addPostCondition(scratch1Reg, cg->getReturnAddressRegister());
   conditions->addPostCondition(objClassReg, cg->getEntryPointRegister());
   cg->addVMThreadPostCondition(conditions, NULL);

   // Add in compareRef if is happens to not already be inserted
   //
   conditions->addPostConditionIfNotAlreadyInserted(compareReg, TR::RealRegister::AssignAny);

   if (!testCache && !testEqualClass && !testCastClassIsSuper)
      {
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/Helper", comp->signature()),1,TR::DebugCounter::Undetermined);
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCast/(%s)/Helper", comp->signature()),1,TR::DebugCounter::Undetermined);
      gcPoint = generateDirectCall(cg, node, false, node->getSymbolReference(), conditions);
      gcPoint->setDependencyConditions(conditions);
      gcPoint->setNeedsGCMap(0x0000FFFF);

      cg->stopUsingRegister(castClassReg);
      cg->stopUsingRegister(scratch1Reg);
      cg->stopUsingRegister(objClassReg);
      if (objRegMustBeKilled)
         cg->stopUsingRegister(objReg);

      cg->decReferenceCount(objNode);
      cg->decReferenceCount(castClassNode);

      return NULL;
      }

   doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   callLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   startOOLLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   doneOOLLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   helperReturnOOLLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   continueLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   resultLabel = doneLabel;

   if (needsNullTest && !isCheckcastAndNullChk)
      {
      if (!nullCCSet)
         {
         genNullTest(cg, node, objReg, objReg, NULL);
         }
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, doneLabel);
      }

   TR_S390OutOfLineCodeSection *outlinedSlowPath = NULL;

   if (testEqualClass)
      {
      TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node, objClassReg, generateS390MemoryReference(compareReg, (int32_t) TR::Compiler->om.offsetOfObjectVftField(), cg), NULL);


      if (testCastClassIsSuper)
         {
         // we should enable OOL only if the above compare has a high chance of passing
         // the profiler tells us the probability of a suceessful check cast
         TR_OpaqueClassBlock * castClassAddr = TR::TreeEvaluator::getCastClassAddress(castClassNode);
         TR_OpaqueClassBlock * topGuessClassAddr = TR::TreeEvaluator::interpreterProfilingInstanceOfOrCheckCastInfo(cg, node);
         float topProb = TR::TreeEvaluator::interpreterProfilingInstanceOfOrCheckCastTopProb(cg, node);
         // experimental : set the probability threashold = 50% to enable OOL
         if (!comp->getOption(TR_DisableOOL) && castClassAddr == topGuessClassAddr && topProb >= 0.5)
            {
            // OOL: Fall through if test passes, else call OOL sequence
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/EqualOOL", comp->signature()),1,TR::DebugCounter::Undetermined);
            TR::Instruction * temp = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, castClassReg, objClassReg, TR::InstOpCode::COND_BNE, startOOLLabel, false, false);
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/EqualOOLPass", comp->signature()),1,TR::DebugCounter::Undetermined);
            if (debugObj)
               debugObj->addInstructionComment(temp, "Branch to OOL checkCast sequence");

            if (comp->getOption(TR_TraceCG))
               traceMsg (comp, "OOL enabled: successful checkCast probability = (%.2f)%%\n", topProb * 100);

            //Using OOL but generating code manually
            outlinedSlowPath =
               new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(startOOLLabel,doneOOLLabel,cg);
            cg->getS390OutOfLineCodeSectionList().push_front(outlinedSlowPath);
            outlinedSlowPath->swapInstructionListsWithCompilation();
            temp = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, startOOLLabel);
            resultLabel = helperReturnOOLLabel;
            if (debugObj)
               debugObj->addInstructionComment(temp, "Denotes start of OOL checkCast sequence");
            }
         else
            {
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/Equal", comp->signature()),1,TR::DebugCounter::Undetermined);
            gcPoint = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, castClassReg, objClassReg, TR::InstOpCode::COND_BE, doneLabel, false, false);
            cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/EqualFail", comp->signature()),1,TR::DebugCounter::Undetermined);
            }
         }
      else
         {
         cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/Equal", comp->signature()),1,TR::DebugCounter::Undetermined);
         gcPoint = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, castClassReg, objClassReg, TR::InstOpCode::COND_BNE, callLabel, false, false);
         cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/EqualPass", comp->signature()),1,TR::DebugCounter::Undetermined);
         }
      }

   // the VM Helper should return to OOL sequence if it's enabled.
   TR::Snippet * snippet = new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, callLabel, node->getSymbolReference(), resultLabel);
   cg->addSnippet(snippet);

   if ((testCache || testCastClassIsSuper) && !testEqualClass)
      {
      TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node, objClassReg, generateS390MemoryReference(compareReg, (int32_t) TR::Compiler->om.offsetOfObjectVftField(), cg), NULL);
      }

   if (testCache)
      {
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/Profiled", comp->signature()),1,TR::DebugCounter::Undetermined);
      generateInlineTest(cg, node, castClassNode, objClassReg, NULL, scratch1Reg, litPoolBaseReg, false, resultLabel, resultLabel, resultLabel, true);
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/ProfiledFail", comp->signature()),1,TR::DebugCounter::Undetermined);
      // The cached value could have been from a previously successful checkcast or instanceof.
      // An answer of 0 in the low order bit indicates 'success' (the cast or instanceof was successful).
      // An answer of 1 in the lower order bit indicates 'failure' (the cast would have thrown an exception, instanceof would have been unsuccessful)
      // Because of this, we can just do a simple load and compare of the 2 class pointers. If it succeeds, the low order bit
      // must be off (success) from a previous checkcast or instanceof. If the low order bit is on, it is guaranteed not to
      // compare and we will take the slow path.


#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
      // for the following two instructions we may need to convert the
      // class offset from scratch1Reg into a J9Class pointer and
      // offset from castClassReg into a J9Pointer. Then we can compare
      // J9Class pointers
#endif
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/Cache", comp->signature()),1,TR::DebugCounter::Undetermined);
      TR::MemoryReference * cacheMR = generateS390MemoryReference(objClassReg, offsetof(J9Class, castClassCache), cg);
      generateRXInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, castClassReg, cacheMR);

      if (testCastClassIsSuper)
         {
         gcPoint = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, resultLabel);
         cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/CacheFail", comp->signature()),1,TR::DebugCounter::Undetermined);
         }
      else
         {
         gcPoint = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, callLabel);
         cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/CacheSuccess", comp->signature()),1,TR::DebugCounter::Undetermined);
         }
      }

   if (testCastClassIsSuper)
      {
      //see if we can use the cached value from interpreterProfilingInstanceOfOrCheckCastInfo
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/Profiled", comp->signature()),1,TR::DebugCounter::Undetermined);
      generateInlineTest(cg, node, castClassNode, objClassReg, NULL, scratch1Reg, litPoolBaseReg, false, continueLabel, resultLabel, resultLabel, true, 1);
      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/ProfiledFail", comp->signature()),1,TR::DebugCounter::Undetermined);
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, continueLabel);
      int32_t castClassDepth = castClassSymRef->classDepth(comp);

      scratch2Reg = cg->allocateRegister();
      // Should let the assigner decide (no interface to do it yet)
      conditions->addPostCondition(scratch2Reg, TR::RealRegister::GPR3);

      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "checkCastStats/(%s)/SuperClass", comp->signature()),1,TR::DebugCounter::Undetermined);
      genTestIsSuper(cg, node, objClassReg, castClassReg, scratch1Reg, scratch2Reg, NULL, litPoolBaseReg, castClassDepth, callLabel, NULL, NULL, conditions, NULL, false, NULL, NULL);
      gcPoint = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, callLabel);

      cg->stopUsingRegister(scratch2Reg);
      }

   if (outlinedSlowPath)
      {
      // Return label from VM Helper call back to OOL sequence
      // We can not branch directly back from VM Helper to main line because
      // there might be reg spills in the rest of the OOL sequence, these code need to be executed.
      TR::Instruction * temp = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, helperReturnOOLLabel);
      if (debugObj)
         {
         debugObj->addInstructionComment(temp, "OOL checkCast VMHelper return label");
         //printf ("OOL checkCast %s\n",cg->comp()->signature());
         //fflush (stdout);
         }
      temp = generateS390BranchInstruction(cg,TR::InstOpCode::BRC,TR::InstOpCode::COND_BRC,node,doneOOLLabel);
      if (debugObj)
         debugObj->addInstructionComment(temp, "Denotes end of OOL checkCast sequence: return to mainline");

      // Done using OOL with manual code generation
      outlinedSlowPath->swapInstructionListsWithCompilation();
      temp = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneOOLLabel);
      if (debugObj)
         debugObj->addInstructionComment(temp, "OOL checkCast return label");
      }

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, conditions);


   // We need the last real instruction to be the GC point
   gcPoint->setNeedsGCMap(0x0000FFFF);

   cg->stopUsingRegister(castClassReg);
   cg->stopUsingRegister(scratch1Reg);
   cg->stopUsingRegister(objClassReg);
   if (objRegMustBeKilled)
      cg->stopUsingRegister(objReg);

   cg->decReferenceCount(objNode);
   cg->decReferenceCount(castClassNode);

   return NULL;
   }

TR::Register *
J9::Z::TreeEvaluator::VMmonentEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   int32_t lwOffset = fej9->getByteOffsetToLockword((TR_OpaqueClassBlock *) cg->getMonClass(node));
   TR::S390CHelperLinkage *helperLink =  static_cast<TR::S390CHelperLinkage*>(cg->getLinkage(TR_CHelper));

   if (comp->getOption(TR_OptimizeForSpace) ||
       (comp->getOption(TR_FullSpeedDebug) && node->isSyncMethodMonitor()) ||
       comp->getOption(TR_DisableInlineMonEnt) ||
       comp->getOption(TR_FullSpeedDebug))  // Required for Live Monitor Meta Data in FSD.
      {
      TR::ILOpCodes opCode = node->getOpCodeValue();
      TR::Node::recreate(node, TR::call);
      TR::Register *targetRegister = helperLink->buildDirectDispatch(node);
      cg->decReferenceCount(node->getFirstChild());
      TR::Node::recreate(node, opCode);
      return targetRegister;
      }


   TR_S390ScratchRegisterManager *srm = cg->generateScratchRegisterManager();

   TR::Node                *objNode                   = node->getFirstChild();
   TR::Register            *objReg                    = cg->evaluate(objNode);
   TR::Register            *baseReg                   = objReg;
   TR::Register            *monitorReg                = cg->allocateRegister();
   TR::Register            *objectClassReg            = NULL;
   TR::Register            *lookupOffsetReg           = NULL;
   TR::Register            *tempRegister              = NULL;
   TR::Register            *metaReg                   = NULL;
   TR::Register            *wasteReg                  = NULL;
   TR::Register            *lockPreservingReg         = NULL;
   TR::Register            *dummyResultReg               = NULL;


   TR::LabelSymbol         *doneLabel                 = generateLabelSymbol(cg);
   TR::LabelSymbol         *callLabel                 = generateLabelSymbol(cg);
   TR::LabelSymbol         *monitorLookupCacheLabel   = generateLabelSymbol(cg);
   TR::Instruction         *gcPoint                   = NULL;
   TR::Instruction         *startICF                  = NULL;
   static char * disableInlineRecursiveMonitor = feGetEnv("TR_DisableInlineRecursiveMonitor");

   bool inlineRecursive = true;
   if (disableInlineRecursiveMonitor)
     inlineRecursive = false;

   int32_t numDeps = 4;

#if defined (J9VM_THR_LOCK_NURSERY)
   if (lwOffset <=0)
      {
      numDeps +=2;
      if (comp->getOption(TR_EnableMonitorCacheLookup))
         {
         numDeps +=2; // extra one for lit pool reg in disablez9 mode
         }
      }
#endif

   if (comp->getOptions()->enableDebugCounters())
      numDeps += 5;
   bool simpleLocking = false;
   bool reserveLocking = false, normalLockWithReservationPreserving = false;


   bool disableOOL = comp->getOption(TR_DisableOOL);
   if (disableOOL)
      inlineRecursive = false;

   TR::RegisterDependencyConditions * conditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, numDeps, cg);

   bool isAOT = comp->getOption(TR_AOT);
   TR_Debug * debugObj = cg->getDebug();

   if (!comp->getOption(TR_Enable390FreeVMThreadReg))
      metaReg = cg->getMethodMetaDataRealRegister();
   else
      metaReg = cg->getVMThreadRegister();

   conditions->addPostCondition(objReg, TR::RealRegister::AssignAny);
   conditions->addPostCondition(monitorReg, TR::RealRegister::AssignAny);
   cg->addVMThreadPostCondition(conditions, NULL);

   static const char * peekFirst = feGetEnv("TR_PeekingMonEnter");
   // This debug option is for printing the locking mechanism.
   static int printMethodSignature = feGetEnv("PrintMethodSignatureForLockResEnt")? 1 : 0;
#if defined (J9VM_THR_LOCK_NURSERY)
   if (lwOffset <= 0)
      {
      inlineRecursive = false;
      // should not happen often, only on a subset of objects that don't have a lockword
      // set with option -Xlockword

      TR::LabelSymbol               *helperCallLabel = generateLabelSymbol(cg);
      TR::LabelSymbol               *helperReturnOOLLabel = generateLabelSymbol(cg);
      TR::MemoryReference * tempMR = generateS390MemoryReference(objReg, TR::Compiler->om.offsetOfObjectVftField(), cg);
      // TODO We don't need objectClassReg except in this ifCase. We can use scratchRegisterManager to allocate one here.
      objectClassReg = cg->allocateRegister();
      conditions->addPostCondition(objectClassReg, TR::RealRegister::AssignAny);
      TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node, objectClassReg, tempMR, NULL);
      int32_t offsetOfLockOffset = offsetof(J9Class, lockOffset);
      tempMR = generateS390MemoryReference(objectClassReg, offsetOfLockOffset, cg);

      tempRegister = cg->allocateRegister();
      TR::LabelSymbol *targetLabel = callLabel;
      if (comp->getOption(TR_EnableMonitorCacheLookup))
         targetLabel = monitorLookupCacheLabel;

      generateRXYInstruction(cg, TR::InstOpCode::getLoadTestOpCode(), node, tempRegister, tempMR);

      TR::Instruction *cmpInstr = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, targetLabel);

      if (disableOOL)
         cmpInstr->setStartInternalControlFlow();

      if(TR::Compiler->target.is64Bit())
         generateRXInstruction(cg, TR::InstOpCode::LA, node, tempRegister, generateS390MemoryReference(objReg, tempRegister, 0, cg));
      else
         generateRRInstruction(cg, TR::InstOpCode::getAddRegOpCode(), node, tempRegister, objReg);

      if (comp->getOption(TR_EnableMonitorCacheLookup))
         {
         TR::RegisterDependencyConditions * OOLConditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 5, cg);
         OOLConditions->addPostCondition(objReg, TR::RealRegister::AssignAny);
         OOLConditions->addPostCondition(monitorReg, TR::RealRegister::AssignAny);
         OOLConditions->addPostCondition(tempRegister, TR::RealRegister::AssignAny);
         // pulling this chunk of code into OOL sequence for better Register allocation and avoid branches
         TR_S390OutOfLineCodeSection *monitorCacheLookupOOL;
         monitorCacheLookupOOL = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(monitorLookupCacheLabel,doneLabel,cg);
         cg->getS390OutOfLineCodeSectionList().push_front(monitorCacheLookupOOL);
         monitorCacheLookupOOL->swapInstructionListsWithCompilation();

         TR::Instruction *cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, monitorLookupCacheLabel);

         if (!disableOOL)
            {
            if (debugObj)
               {
               debugObj->addInstructionComment(cmpInstr, "Branch to OOL monent monitorLookupCache");
               debugObj->addInstructionComment(cursor, "Denotes start of OOL monent monitorLookupCache");
               }
            }

         lookupOffsetReg = cg->allocateRegister();
         OOLConditions->addPostCondition(lookupOffsetReg, TR::RealRegister::AssignAny);

         int32_t offsetOfMonitorLookupCache = offsetof(J9VMThread, objectMonitorLookupCache);
         int32_t t = trailingZeroes(fej9->getObjectAlignmentInBytes());
         int32_t shiftAmount = trailingZeroes((int32_t) TR::Compiler->om.sizeofReferenceField()) - t;
         int32_t end = 63 - trailingZeroes((int32_t) TR::Compiler->om.sizeofReferenceField());
         int32_t start = end - trailingZeroes(J9VMTHREAD_OBJECT_MONITOR_CACHE_SIZE) + 1;

         if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_zEC12) && TR::Compiler->target.is64Bit())
            generateRIEInstruction(cg, TR::InstOpCode::RISBGN, node, lookupOffsetReg, objReg, start, end+0x80, shiftAmount);
         else if(cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10) && TR::Compiler->target.is64Bit())
            generateRIEInstruction(cg, TR::InstOpCode::RISBG, node, lookupOffsetReg, objReg, start, end+0x80, shiftAmount);
         else
            {
            generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, lookupOffsetReg, objReg);

            if (TR::Compiler->target.is64Bit())
               generateRSInstruction(cg, TR::InstOpCode::SRAG, node, lookupOffsetReg, lookupOffsetReg, t);
            else
               generateRSInstruction(cg, TR::InstOpCode::SRA, node, lookupOffsetReg, t);

            J9JavaVM * jvm = fej9->getJ9JITConfig()->javaVM;

            if (TR::Compiler->target.is32Bit())
               generateS390ImmOp(cg, TR::InstOpCode::getAndOpCode(), node, lookupOffsetReg, lookupOffsetReg, (int32_t) J9VMTHREAD_OBJECT_MONITOR_CACHE_SIZE - 1, OOLConditions, 0);
            else
               generateS390ImmOp(cg, TR::InstOpCode::getAndOpCode(), node, lookupOffsetReg, lookupOffsetReg, (int64_t) J9VMTHREAD_OBJECT_MONITOR_CACHE_SIZE - 1, OOLConditions, 0);

            if (TR::Compiler->target.is64Bit())
               generateRSInstruction(cg, TR::InstOpCode::SLLG, node, lookupOffsetReg, lookupOffsetReg, trailingZeroes((int32_t) TR::Compiler->om.sizeofReferenceField()));
            else
               generateRSInstruction(cg, TR::InstOpCode::SLL, node, lookupOffsetReg, trailingZeroes((int32_t) TR::Compiler->om.sizeofReferenceField()));
            }

         TR::MemoryReference * temp2MR = generateS390MemoryReference(cg->getMethodMetaDataRealRegister(), lookupOffsetReg, offsetOfMonitorLookupCache, cg);

#if defined(J9VM_INTERP_COMPRESSED_OBJECT_HEADER)
         generateRXInstruction(cg, TR::InstOpCode::LLGF, node, tempRegister, temp2MR, NULL);
         startICF = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, tempRegister, NULLVALUE, TR::InstOpCode::COND_BE, helperCallLabel, false, true);
#else
         generateRXYInstruction(cg, TR::InstOpCode::getLoadTestOpCode(), node, tempRegister, temp2MR);

         startICF = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, helperCallLabel);
#endif

         int32_t offsetOfMonitor = offsetof(J9ObjectMonitor, monitor);
         temp2MR = generateS390MemoryReference(tempRegister, offsetOfMonitor, cg);
         generateRXInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, objReg, temp2MR);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, helperCallLabel);

         int32_t offsetOfAlternateLockWord = offsetof(J9ObjectMonitor, alternateLockword);

         baseReg = tempRegister;
         lwOffset = 0 + offsetOfAlternateLockWord;

         if (TR::Compiler->target.is64Bit() && fej9->generateCompressedLockWord())
            generateRRInstruction(cg, TR::InstOpCode::XR, node, monitorReg, monitorReg);
         else
            generateRRInstruction(cg, TR::InstOpCode::getXORRegOpCode(), node, monitorReg, monitorReg);

         if (peekFirst)
            {
            generateRXInstruction(cg, TR::InstOpCode::C, node, monitorReg, generateS390MemoryReference(baseReg, lwOffset, cg));
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, helperCallLabel);
            }

         if (TR::Compiler->target.is64Bit() && fej9->generateCompressedLockWord())
            generateRSInstruction(cg, TR::InstOpCode::CS, node, monitorReg, metaReg,
                                  generateS390MemoryReference(baseReg, lwOffset, cg));
         else
            generateRSInstruction(cg, TR::InstOpCode::getCmpAndSwapOpCode(), node, monitorReg, metaReg,
                                  generateS390MemoryReference(baseReg, lwOffset, cg));

         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, helperReturnOOLLabel);
         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, helperCallLabel );
         TR::RegisterDependencyConditions *deps = NULL;
         dummyResultReg = helperLink->buildDirectDispatch(node, &deps);
         TR::RegisterDependencyConditions *mergeConditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(OOLConditions, deps, cg);
         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, helperReturnOOLLabel , mergeConditions);
         if (!disableOOL)
            {
            cursor = generateS390BranchInstruction(cg,TR::InstOpCode::BRC,TR::InstOpCode::COND_BRC,node,doneLabel);
            if (debugObj)
               debugObj->addInstructionComment(cursor, "Denotes end of OOL monent monitorCacheLookup: return to mainline");

            // Done using OOL with manual code generation
            monitorCacheLookupOOL->swapInstructionListsWithCompilation();
            }
      }

      simpleLocking = true;
      lwOffset = 0;
      baseReg = tempRegister;
   }
#endif

   // Lock Reservation happens only for objects with lockword.
   // evaluateLockForReservation may output three different results:
   // 1- Lock Reservation: (reserveLocking = true)
   // 2- ReservationPreserving: (normalLockWithReservationPreserving = true)
   // 3- Normal lock: otherwise
   if (!simpleLocking && comp->getOption(TR_ReservingLocks))
      TR::TreeEvaluator::evaluateLockForReservation(node, &reserveLocking, &normalLockWithReservationPreserving, cg);

   if (printMethodSignature)
      printf("%s:\t%s\t%s\n",simpleLocking ? "lwOffset <= 0" : reserveLocking ? "Lock Reservation" :
             normalLockWithReservationPreserving ? "Reservation Preserving" : "Normal Lock",
             comp->signature(),comp->getHotnessName(comp->getMethodHotness()));

   if (reserveLocking)
      {

      // TODO - ScratchRegisterManager Should Manage these temporary Registers.
      if (wasteReg)
         cg->stopUsingRegister(wasteReg);
      cg->stopUsingRegister(monitorReg);
      // TODO : objectClassReg contains the J9Class for object which is set in lwOffset <= 0 case. Usually that is NULL in the following function call
      return reservationLockEnter(node, lwOffset, objectClassReg, cg, helperLink);
      }

   if (normalLockWithReservationPreserving)
      {
      lockPreservingReg = cg->allocateRegister();
      conditions->addPostCondition(lockPreservingReg, TR::RealRegister::AssignAny);
      }
   const char* debugCounterNamePrefix = normalLockWithReservationPreserving? "LockEnt/Preserving": "LockEnt/Normal";
   // Opcodes:
   bool use64b = true;
   if (TR::Compiler->target.is64Bit() && fej9->generateCompressedLockWord())
      use64b = false;
   else if (!TR::Compiler->target.is64Bit())
      use64b = false;
   TR::InstOpCode::Mnemonic loadOp = use64b ? TR::InstOpCode::LG : TR::InstOpCode::L;
   TR::InstOpCode::Mnemonic loadRegOp = use64b ? TR::InstOpCode::LGR : TR::InstOpCode::LR;
   TR::InstOpCode::Mnemonic orImmOp = TR::InstOpCode::OILF;
   TR::InstOpCode::Mnemonic compareOp = use64b ? TR::InstOpCode::CGR : TR::InstOpCode::CR;
   TR::InstOpCode::Mnemonic addImmOp = use64b ? TR::InstOpCode::AGHI : TR::InstOpCode::AHI;
   TR::InstOpCode::Mnemonic storeOp = use64b ? TR::InstOpCode::STG : TR::InstOpCode::ST;
   TR::InstOpCode::Mnemonic xorOp = use64b ? TR::InstOpCode::XGR : TR::InstOpCode::XR;
   TR::InstOpCode::Mnemonic casOp = use64b ? TR::InstOpCode::CSG : TR::InstOpCode::CS;
   TR::InstOpCode::Mnemonic andOp = use64b ? TR::InstOpCode::NGR : TR::InstOpCode::NR;
   TR::InstOpCode::Mnemonic loadHalfWordImmOp = use64b ? TR::InstOpCode::LGHI : TR::InstOpCode::LHI;

   // MonitorReg = 0
   generateRRInstruction(cg, xorOp, node, monitorReg, monitorReg);

   // PeekFirst option read the lock value first and then issue CAS only the lock value is zero.
   // This causes an extra load operation when the lock is free, but it leads to avoidance of unnecessary CAS operations.
   if (peekFirst)
      {
      generateRXInstruction(cg, TR::InstOpCode::C, node, monitorReg, generateS390MemoryReference(baseReg, lwOffset, cg));
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, callLabel);
      }
   // Main path instruction sequence.
   // This sequence is the same for both normal locks and lock preservation.
   //    XR      monitorReg,monitorReg
   //    CS      monitorReg,GPR13,#lwOffset(objectReg)
   //    BRC     BLRC(0x4), callLabel (OOL path)

   //Compare and Swap the lock value with R13 if the lock value is 0.
   generateRSInstruction(cg, casOp, node, monitorReg, metaReg, generateS390MemoryReference(baseReg, lwOffset, cg));

   // Jump to OOL branch in case that the CAS is unsuccessful (Lockword had contained a non-zero value before CAS)
   // Both TR::InstOpCode::MASK6 and TR::InstOpCode::MASK4 are ok here. TR::InstOpCode::MASK4 is directly testing failure condition.
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BL, node, callLabel);
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "%s/CSSuccessfull", debugCounterNamePrefix), 1, TR::DebugCounter::Undetermined);
   TR_S390OutOfLineCodeSection *outlinedHelperCall = NULL;
   TR::Instruction *cursor;
   TR::LabelSymbol *returnLabel = generateLabelSymbol(cg);
   if (!disableOOL)
      {
      outlinedHelperCall = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(callLabel, doneLabel, cg);
      cg->getS390OutOfLineCodeSectionList().push_front(outlinedHelperCall);
      outlinedHelperCall->swapInstructionListsWithCompilation();
      cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, callLabel);
      if (debugObj)
         debugObj->addInstructionComment(cursor, "Denotes start of OOL monent sequence");
      }

   if (inlineRecursive)
      {
      TR::LabelSymbol * callHelper = generateLabelSymbol(cg);

      //Using OOL but generating code manually
      //Tasuki lock, inlined nested monitor handling
      //(on entry objectReg has been set up)

      //   Normal Lock                                        Lock reservation preserving
      // L     monitorReg, #lwOffset(objectReg)             L     monitorReg, #lwOffset(objectReg)
      // LHI   wasteReg, NON_INC_DEC_MASK           DIFF    LHI   wasteReg, LOCK_RES_PRESERVE_ENTER
      // AHI   monitorReg, INC_DEC_VALUE            DIFF
      // NR    wasteReg, monitorReg                         NR    wasteReg, monitorReg
      //                                            DIFF    LR    lockPreservingReg, metaReg
      //                                            DIFF    OILF  lockPreservingReg, LR-BIT
      // CRJ   wasteReg, metaReg, MASK6, callHelper DIFF    CRJ   wasteReg, lockPreservingReg, MASK6, callHelper
      //                                            DIFF    AHI   monitorReg,INC_DEC_VALUE
      // ST    monitorReg, #lwOffset(objectReg)             ST    monitorReg, #lwOffset(objectReg)
      // BRC   returnLabel                                  BRC   returnLabel
      // callHelper:                                        callHelper:
      // BRASL R14, jitMonitorEnter                         BRASL   R14, jitMonitorEnter
      // returnLabel:                                       returnLabel:

      TR::MemoryReference * tempMR = generateS390MemoryReference(baseReg, lwOffset, cg);
      TR::MemoryReference * tempMR1 = generateS390MemoryReference(baseReg, lwOffset, cg);
      wasteReg = cg->allocateRegister();
      conditions->addPostCondition(wasteReg, TR::RealRegister::AssignAny);
      // Loading Lock value into monitorReg
      generateRXInstruction(cg, loadOp, node, monitorReg, tempMR);
      generateRIInstruction(cg, loadHalfWordImmOp, node, wasteReg,
            normalLockWithReservationPreserving ? ~LOCK_RES_PRESERVE_ENTER_COMPLEMENT : ~OBJECT_HEADER_LOCK_RECURSION_MASK);

      // In normal lock, we first increment the counter and then do the mask and comparison.
      // However, in lock preserving first we do mask and compare and then we increment the counter
      // We can do the same technique for both. The reason for current implementation is to expose less differences between
      // this implementation and other architecture implementations.
      if (!normalLockWithReservationPreserving)
         generateRIInstruction(cg, addImmOp, node, monitorReg, OBJECT_HEADER_LOCK_FIRST_RECURSION_BIT);
      // Mask out the counter value from lockword.
      generateRRInstruction(cg, andOp, node, wasteReg, monitorReg);
      if (normalLockWithReservationPreserving)
         {
         generateRRInstruction(cg,loadRegOp, node, lockPreservingReg, metaReg);
         generateRILInstruction(cg, orImmOp, node, lockPreservingReg, LOCK_RESERVATION_BIT);
         }

      // The lock value (after masking out the counter) is being compared with R13 (or R13|LRbit for reservation preserving case)
      // to check whether the same thread has acquired the lock before.
      // if comparison fails (masked lock value != R13) that means another thread owns the lock.
      // In this case we call helper function and let the VM handle the situation.
      startICF = generateS390CompareAndBranchInstruction(cg, compareOp, node, wasteReg, normalLockWithReservationPreserving ? lockPreservingReg : metaReg, TR::InstOpCode::COND_BNE, callHelper, false, false);

      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "%s/Recursive", debugCounterNamePrefix), 1, TR::DebugCounter::Undetermined);
      // In case of recursive lock, the counter should be incremented.
      if (normalLockWithReservationPreserving)
         generateRIInstruction(cg, addImmOp, node, monitorReg, OBJECT_HEADER_LOCK_FIRST_RECURSION_BIT);
      generateRXInstruction(cg, storeOp, node, monitorReg, tempMR1);

      generateS390BranchInstruction(cg,TR::InstOpCode::BRC,TR::InstOpCode::COND_BRC,node,returnLabel);

      tempMR->stopUsingMemRefRegister(cg);
      tempMR1->stopUsingMemRefRegister(cg);

      // Helper Call
      cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, callHelper);
      }

      cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "%s/VMHelper", debugCounterNamePrefix), 1, TR::DebugCounter::Undetermined);
      TR::RegisterDependencyConditions *deps = NULL;
      dummyResultReg = inlineRecursive ? helperLink->buildDirectDispatch(node, &deps) : helperLink->buildDirectDispatch(node);
      TR::RegisterDependencyConditions *mergeConditions = NULL;
      if (inlineRecursive)
         mergeConditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(conditions, deps, cg);
      else
         mergeConditions = conditions;
      generateS390LabelInstruction(cg,TR::InstOpCode::LABEL,node,returnLabel,mergeConditions);

      if (!disableOOL)
         {
         // End of OOl path.
         cursor = generateS390BranchInstruction(cg,TR::InstOpCode::BRC,TR::InstOpCode::COND_BRC,node,doneLabel);
         if (debugObj)
            {
            debugObj->addInstructionComment(cursor, "Denotes end of OOL monent: return to mainline");
            }

         // Done using OOL with manual code generation
         outlinedHelperCall->swapInstructionListsWithCompilation();
         }

   bool needDeps = false;
#if defined (J9VM_THR_LOCK_NURSERY)
   if (lwOffset <= 0 && disableOOL)
      needDeps = true;
#endif

   TR::Instruction *doneInstr = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, conditions);

#if defined (J9VM_THR_LOCK_NURSERY)
   if (lwOffset <= 0 && disableOOL)
      doneInstr->setEndInternalControlFlow();
#endif
   cg->stopUsingRegister(monitorReg);
   if (wasteReg)
      cg->stopUsingRegister(wasteReg);
   if (objectClassReg)
      cg->stopUsingRegister(objectClassReg);
   if (lookupOffsetReg)
      cg->stopUsingRegister(lookupOffsetReg);
   if (tempRegister && (tempRegister != objectClassReg))
      cg->stopUsingRegister(tempRegister);
   if (lockPreservingReg)
      cg->stopUsingRegister(lockPreservingReg);
   cg->decReferenceCount(objNode);
   return NULL;
   }

TR::Register *
J9::Z::TreeEvaluator::VMmonexitEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   int32_t lwOffset = fej9->getByteOffsetToLockword((TR_OpaqueClassBlock *) cg->getMonClass(node));
   TR::S390CHelperLinkage *helperLink =  static_cast<TR::S390CHelperLinkage*>(cg->getLinkage(TR_CHelper));
   if (comp->getOption(TR_OptimizeForSpace) ||
       comp->getOption(TR_DisableInlineMonExit) ||
       comp->getOption(TR_FullSpeedDebug))  // Required for Live Monitor Meta Data in FSD.
      {
      TR::ILOpCodes opCode = node->getOpCodeValue();
      TR::Node::recreate(node, TR::call);
      TR::Register * targetRegister = helperLink->buildDirectDispatch(node);
      cg->decReferenceCount(node->getFirstChild());
      TR::Node::recreate(node, opCode);
      return targetRegister;
      }

   TR::Node          *objNode             = node->getFirstChild();


   //TODO Use scratchRegisterManager here to avoid allocating un-necessary registers
   TR::Register      *dummyResultRegister = NULL;
   TR::Register      *objReg              = cg->evaluate(objNode);
   TR::Register      *baseReg             = objReg;
   TR::Register      *objectClassReg      = NULL;
   TR::Register      *lookupOffsetReg     = NULL;
   TR::Register      *tempRegister        = NULL;
   TR::Register      *monitorReg          = cg->allocateRegister();
   TR::Register      *metaReg             = NULL;
   TR::Register      *scratchRegister     = NULL;
   TR::Instruction         *startICF                  = NULL;
   bool disableOOL  = comp->getOption(TR_DisableOOL);
   static char * disableInlineRecursiveMonitor = feGetEnv("TR_DisableInlineRecursiveMonitor");
   bool inlineRecursive = true;
   if (disableInlineRecursiveMonitor || disableOOL)
     inlineRecursive = false;

   TR::LabelSymbol *callLabel                      = generateLabelSymbol(cg);
   TR::LabelSymbol *monitorLookupCacheLabel        = generateLabelSymbol(cg);
   TR::LabelSymbol *doneLabel                      = generateLabelSymbol(cg);
   TR::LabelSymbol *callHelper                     = generateLabelSymbol(cg);
   TR::LabelSymbol *returnLabel                    = generateLabelSymbol(cg);

   int32_t numDeps = 4;
#if defined (J9VM_THR_LOCK_NURSERY)
   if (lwOffset <=0)
      {
      numDeps +=2;
      if (comp->getOption(TR_EnableMonitorCacheLookup))
         {
         numDeps +=2; // extra one for lit pool reg in disablez9 mode
         }
      }
#endif

   if (comp->getOptions()->enableDebugCounters())
         numDeps += 4;

   TR::RegisterDependencyConditions * conditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, numDeps, cg);


   TR::Instruction * gcPoint;
   bool isAOT = comp->getOption(TR_AOT);
   TR_Debug * debugObj = cg->getDebug();

   bool reserveLocking                          = false;
   bool normalLockWithReservationPreserving     = false;
   bool simpleLocking                           = false;

   if (!comp->getOption(TR_Enable390FreeVMThreadReg))
      metaReg = cg->getMethodMetaDataRealRegister();
   else
      metaReg = cg->getVMThreadRegister();



   conditions->addPostCondition(objReg, TR::RealRegister::AssignAny);
   conditions->addPostCondition(monitorReg, TR::RealRegister::AssignAny);
   cg->addVMThreadPostCondition(conditions, NULL);


#if defined (J9VM_THR_LOCK_NURSERY)
   if (lwOffset <= 0)
      {
      inlineRecursive = false; // should not happen often, only on a subset of objects that don't have a lockword, set with option -Xlockword

      TR::LabelSymbol *helperCallLabel          = generateLabelSymbol(cg);
      TR::LabelSymbol *helperReturnOOLLabel     = generateLabelSymbol(cg);

      objectClassReg = cg->allocateRegister();
      TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node, objectClassReg, generateS390MemoryReference(objReg, TR::Compiler->om.offsetOfObjectVftField(), cg), NULL);

      int32_t offsetOfLockOffset = offsetof(J9Class, lockOffset);
      TR::MemoryReference* tempMR = generateS390MemoryReference(objectClassReg, offsetOfLockOffset, cg);
      tempRegister = cg->allocateRegister();

      TR::LabelSymbol *targetLabel = callLabel;
      if (comp->getOption(TR_EnableMonitorCacheLookup))
         targetLabel = monitorLookupCacheLabel;

      generateRXYInstruction(cg, TR::InstOpCode::getLoadTestOpCode(), node, tempRegister, tempMR);

      TR::Instruction *cmpInstr = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, targetLabel);

      if (disableOOL)
         cmpInstr->setStartInternalControlFlow();

      if(TR::Compiler->target.is64Bit())
         generateRXInstruction(cg, TR::InstOpCode::LA, node, tempRegister, generateS390MemoryReference(objReg, tempRegister, 0, cg));
      else
         generateRRInstruction(cg, TR::InstOpCode::getAddRegOpCode(), node, tempRegister, objReg);

      if (comp->getOption(TR_EnableMonitorCacheLookup))
         {
         lookupOffsetReg = cg->allocateRegister();
         TR::RegisterDependencyConditions * OOLConditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 5, cg);
         OOLConditions->addPostCondition(objReg, TR::RealRegister::AssignAny);
         OOLConditions->addPostCondition(monitorReg, TR::RealRegister::AssignAny);
         // TODO Should be using SRM for tempRegister
         OOLConditions->addPostCondition(tempRegister, TR::RealRegister::AssignAny);
         OOLConditions->addPostCondition(lookupOffsetReg, TR::RealRegister::AssignAny);


         // pulling this chunk of code into OOL sequence for better Register allocation and avoid branches
         TR_S390OutOfLineCodeSection *monitorCacheLookupOOL = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(monitorLookupCacheLabel,doneLabel,cg);
         cg->getS390OutOfLineCodeSectionList().push_front(monitorCacheLookupOOL);
         monitorCacheLookupOOL->swapInstructionListsWithCompilation();

         TR::Instruction *cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, monitorLookupCacheLabel);

         if (!disableOOL)
            {
            if (debugObj)
               {
               debugObj->addInstructionComment(cmpInstr, "Branch to OOL monexit monitorLookupCache");
               debugObj->addInstructionComment(cursor, "Denotes start of OOL monexit monitorLookupCache");
               }
            }


         int32_t offsetOfMonitorLookupCache = offsetof(J9VMThread, objectMonitorLookupCache);
         int32_t t = trailingZeroes(fej9->getObjectAlignmentInBytes());
         int32_t shiftAmount = trailingZeroes((int32_t) TR::Compiler->om.sizeofReferenceField()) - t;
         int32_t end = 63 - trailingZeroes((int32_t) TR::Compiler->om.sizeofReferenceField());
         int32_t start = end - trailingZeroes(J9VMTHREAD_OBJECT_MONITOR_CACHE_SIZE) + 1;

         if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_zEC12) && TR::Compiler->target.is64Bit())
            generateRIEInstruction(cg, TR::InstOpCode::RISBGN, node, lookupOffsetReg, objReg, start, end+0x80, shiftAmount);
         else if(cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10) && TR::Compiler->target.is64Bit())
            generateRIEInstruction(cg, TR::InstOpCode::RISBG, node, lookupOffsetReg, objReg, start, end+0x80, shiftAmount);
         else
            {
            generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, lookupOffsetReg, objReg);

            if (TR::Compiler->target.is64Bit())
               generateRSInstruction(cg, TR::InstOpCode::SRAG, node, lookupOffsetReg, lookupOffsetReg, t);
            else
               generateRSInstruction(cg, TR::InstOpCode::SRA, node, lookupOffsetReg, t);

            J9JavaVM * jvm = fej9->getJ9JITConfig()->javaVM;

            if (TR::Compiler->target.is32Bit())
               generateS390ImmOp(cg, TR::InstOpCode::getAndOpCode(), node, lookupOffsetReg, lookupOffsetReg, (int32_t) J9VMTHREAD_OBJECT_MONITOR_CACHE_SIZE - 1, OOLConditions, 0);
            else
               generateS390ImmOp(cg, TR::InstOpCode::getAndOpCode(), node, lookupOffsetReg, lookupOffsetReg, (int64_t) J9VMTHREAD_OBJECT_MONITOR_CACHE_SIZE - 1, OOLConditions, 0);

            if (TR::Compiler->target.is64Bit())
               generateRSInstruction(cg, TR::InstOpCode::SLLG, node, lookupOffsetReg, lookupOffsetReg, trailingZeroes((int32_t) TR::Compiler->om.sizeofReferenceField()));
            else
               generateRSInstruction(cg, TR::InstOpCode::SLL, node, lookupOffsetReg, trailingZeroes((int32_t) TR::Compiler->om.sizeofReferenceField()));
            }

         // TODO No Need to use Memory Reference Here. Combine it with generateRXInstruction
         TR::MemoryReference * temp2MR = generateS390MemoryReference(cg->getMethodMetaDataRealRegister(), lookupOffsetReg, offsetOfMonitorLookupCache, cg);

#if defined(J9VM_INTERP_COMPRESSED_OBJECT_HEADER)
         generateRXInstruction(cg, TR::InstOpCode::LLGF, node, tempRegister, temp2MR, NULL);
         startICF = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, tempRegister, NULLVALUE, TR::InstOpCode::COND_BE, helperCallLabel, false, true);
#else
         generateRXYInstruction(cg, TR::InstOpCode::getLoadTestOpCode(), node, tempRegister, temp2MR);
         startICF = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, helperCallLabel);
#endif

         int32_t offsetOfMonitor = offsetof(J9ObjectMonitor, monitor);
         // TODO No Need to use Memory Reference Here. Combine it with generateRXInstruction
         temp2MR = generateS390MemoryReference(tempRegister, offsetOfMonitor, cg);
         generateRXInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, objReg, temp2MR);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, helperCallLabel);

         int32_t offsetOfAlternateLockWord = offsetof(J9ObjectMonitor, alternateLockword);

         baseReg = tempRegister;
         lwOffset = 0 + offsetOfAlternateLockWord;

         // Check if the lockWord in the object contains our VMThread
         if (TR::Compiler->target.is64Bit() && fej9->generateCompressedLockWord())
            generateRXInstruction(cg, TR::InstOpCode::C, node, metaReg, generateS390MemoryReference(baseReg, lwOffset, cg));
         else
            generateRXInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, metaReg, generateS390MemoryReference(baseReg, lwOffset, cg));

         // If VMThread does not match, call helper.
         TR::Instruction* helperBranch = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, helperCallLabel);

         // If VMThread matches, we can safely perform the monitor exit by zero'ing
         // out the lockWord on the object
         if (!cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10))
            {
            if (TR::Compiler->target.is64Bit() && fej9->generateCompressedLockWord())
               {
               generateRRInstruction(cg, TR::InstOpCode::XR, node, monitorReg, monitorReg);
               gcPoint = generateRXInstruction(cg, TR::InstOpCode::ST, node, monitorReg, generateS390MemoryReference(baseReg, lwOffset, cg));
               }
            else
               {
               generateRRInstruction(cg, TR::InstOpCode::getXORRegOpCode(), node, monitorReg, monitorReg);
               gcPoint = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, monitorReg, generateS390MemoryReference(baseReg, lwOffset, cg));
               }
            }
         else
            {
            if (TR::Compiler->target.is64Bit() && fej9->generateCompressedLockWord())
               gcPoint = generateSILInstruction(cg, TR::InstOpCode::MVHI, node, generateS390MemoryReference(baseReg, lwOffset, cg), 0);
            else
               gcPoint = generateSILInstruction(cg, TR::InstOpCode::getMoveHalfWordImmOpCode(), node, generateS390MemoryReference(baseReg, lwOffset, cg), 0);
            }

         generateS390BranchInstruction(cg,TR::InstOpCode::BRC,TR::InstOpCode::COND_BRC,node,helperReturnOOLLabel);

         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL , node, helperCallLabel );
         TR::RegisterDependencyConditions *deps = NULL;
         helperLink->buildDirectDispatch(node, &deps);
         TR::RegisterDependencyConditions *mergeConditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(OOLConditions, deps, cg);
         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, helperReturnOOLLabel , mergeConditions);

         if (!disableOOL)
            {
            cursor = generateS390BranchInstruction(cg,TR::InstOpCode::BRC,TR::InstOpCode::COND_BRC,node,doneLabel);
            if (debugObj)
               debugObj->addInstructionComment(cursor, "Denotes end of OOL monexit monitorCacheLookup: return to mainline");

            // Done using OOL with manual code generation
            monitorCacheLookupOOL->swapInstructionListsWithCompilation();
            }
         }

      lwOffset = 0;
      baseReg = tempRegister;
      simpleLocking = true;
      }
#endif

   // Lock Reservation happens only for objects with lockword.
   if (!simpleLocking && comp->getOption(TR_ReservingLocks))
      TR::TreeEvaluator::evaluateLockForReservation(node, &reserveLocking, &normalLockWithReservationPreserving, cg);
   if (reserveLocking)
      {
      // TODO - It would be much better to find a way not allocating these registers at the first place.
      cg->stopUsingRegister(monitorReg);
      return reservationLockExit(node, lwOffset, objectClassReg, cg, helperLink);
      }
   ////////////
   // Opcodes:
   bool use64b = true;
   if (TR::Compiler->target.is64Bit() && fej9->generateCompressedLockWord())
      use64b = false;
   else if (!TR::Compiler->target.is64Bit())
      use64b = false;
   TR::InstOpCode::Mnemonic loadOp = use64b ? TR::InstOpCode::LG : TR::InstOpCode::L;
   TR::InstOpCode::Mnemonic loadRegOp = use64b ? TR::InstOpCode::LGR : TR::InstOpCode::LR;
   TR::InstOpCode::Mnemonic orImmOp = TR::InstOpCode::OILF;
   TR::InstOpCode::Mnemonic compareOp = use64b ? TR::InstOpCode::CGR : TR::InstOpCode::CR;
   TR::InstOpCode::Mnemonic compareImmOp = use64b ? TR::InstOpCode::CG : TR::InstOpCode::C;
   TR::InstOpCode::Mnemonic addImmOp = use64b ? TR::InstOpCode::AGHI : TR::InstOpCode::AHI;
   TR::InstOpCode::Mnemonic storeOp = use64b ? TR::InstOpCode::STG : TR::InstOpCode::ST;
   TR::InstOpCode::Mnemonic xorOp = use64b ? TR::InstOpCode::XGR : TR::InstOpCode::XR;
   TR::InstOpCode::Mnemonic casOp = use64b ? TR::InstOpCode::CSG : TR::InstOpCode::CS;
   TR::InstOpCode::Mnemonic loadImmOp = TR::InstOpCode::LGFI;
   TR::InstOpCode::Mnemonic andOp = use64b ? TR::InstOpCode::NGR : TR::InstOpCode::NR;
   TR::InstOpCode::Mnemonic andImmOp = TR::InstOpCode::NILF;
   TR::InstOpCode::Mnemonic moveImmOp = use64b ? TR::InstOpCode::MVGHI : TR::InstOpCode::MVHI;
   TR::InstOpCode::Mnemonic loadHalfWordImmOp = use64b ? TR::InstOpCode::LGHI : TR::InstOpCode::LHI;

   // Main path instruction sequence.
   // This sequence is the same for both normal locks and lock preservation.
   //    C       metaReg, #lwOffset(objectReg)
   //    BRC     MASK6, callLabel
   //    MVHI    #lwOffset(objectReg), 0

   //TODO - use compareAndBranch instruction
   // Check if the lockWord in the object contains our VMThread
   generateRXInstruction(cg, compareImmOp, node, metaReg, generateS390MemoryReference(baseReg, lwOffset, cg));
   // If VMThread does not match, call helper.
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, callLabel);
   if (normalLockWithReservationPreserving)
      cg->generateDebugCounter("LockExit/Preserving/MVHISuccessfull", 1, TR::DebugCounter::Undetermined);
   else
      cg->generateDebugCounter("LockExit/Normal/MVHISuccessfull", 1, TR::DebugCounter::Undetermined);
   // If VMThread matches, we can safely perform the monitor exit by zero'ing
   // out the lockWord on the object
   if (!cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10))
      {
      generateRRInstruction(cg, xorOp, node, monitorReg, monitorReg);
      generateRXInstruction(cg, storeOp, node, monitorReg, generateS390MemoryReference(baseReg, lwOffset, cg));
      }
   else
      {
      generateSILInstruction(cg, moveImmOp, node, generateS390MemoryReference(baseReg, lwOffset, cg), 0);
      }

   TR_S390OutOfLineCodeSection *outlinedHelperCall = NULL;
   if (!disableOOL)
     {
     outlinedHelperCall = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(callLabel,doneLabel,cg);
     cg->getS390OutOfLineCodeSectionList().push_front(outlinedHelperCall);
     outlinedHelperCall->swapInstructionListsWithCompilation();
     }
   TR::Instruction *cursor = generateS390LabelInstruction(cg,TR::InstOpCode::LABEL,node,callLabel);

   if (inlineRecursive)
      {
      // inlineRecursive is only enabled when OOL is enabled
      if (debugObj)
         {
         debugObj->addInstructionComment(cursor, "Denotes start of OOL monexit sequence");
         }

      // (on entry objectReg has been set up)

      //   Normal Lock                                           Lock reservation preserving
      // L     monitorReg, #lwOffset(objectReg)                L     monitorReg, #lwOffset(objectReg)
      // LHI   wasteReg, ~LOCK_RECURSION_MASK                  LHI   wasteReg, LOCK_OWNING_NON_INFLATED
      // AHI   monitorReg, -INC_DEC_VALUE
      // NR    wasteReg, monitorReg                            NR    wasteReg, monitorReg
      // CRJ   wasteReg, metaReg, MASK6, callHelper            CRJ   wasteReg, metaReg, MASK6, callHelper
      //                                                       LHI   wasteReg, LOCK_RECURSION_MASK
      //                                                       NR    wasteReg, monitorReg
      //                                                       BRC   BERC,     callHelper
      //                                                       LHI   wasteReg, LOCK_OWNING_NON_INFLATED
      //                                                       NR    wasteReg, monitorReg
      //                                                       CIJ   wasteReg, callHelper, BERC, LOCK_RES_CONTENDED_VALUE
      //                                                       AHI   monitorReg, -INC_DEC_VALUE
      // ST    monitorReg, #lwOffset(objectReg)                ST    monitorReg, #lwOffset(objectReg)
      // BRC   returnLabel                                     BRC   returnLabel
      // callHelper:                                           callHelper:
      // BRASL R14,jitMonitorExit                              BRASL R14, jitMonitorExit
      // returnLabel:                                          returnLabel:
      scratchRegister = cg->allocateRegister();
      conditions->addPostCondition(scratchRegister, TR::RealRegister::AssignAny);

      TR::MemoryReference * tempMR = generateS390MemoryReference(baseReg, lwOffset, cg);
      TR::MemoryReference * tempMR1 = generateS390MemoryReference(baseReg, lwOffset, cg);
      if(!normalLockWithReservationPreserving)
         {
         generateRXInstruction(cg, loadOp, node, monitorReg, tempMR);
         generateRIInstruction(cg, loadHalfWordImmOp, node, scratchRegister, ~OBJECT_HEADER_LOCK_RECURSION_MASK);
         generateRIInstruction(cg, addImmOp, node, monitorReg, -OBJECT_HEADER_LOCK_FIRST_RECURSION_BIT);
         generateRRInstruction(cg, andOp, node, scratchRegister, monitorReg);
         startICF = generateS390CompareAndBranchInstruction(cg, compareOp, node, scratchRegister, metaReg, TR::InstOpCode::COND_BNE, callHelper, false, false);
         cg->generateDebugCounter("LockExit/Normal/Recursive", 1, TR::DebugCounter::Undetermined);
         generateRXInstruction(cg, storeOp, node, monitorReg, tempMR1);
         }
      else
         {
         generateRXInstruction(cg, loadOp, node, monitorReg, tempMR);
         generateRIInstruction(cg, loadHalfWordImmOp, node, scratchRegister, ~LOCK_OWNING_NON_INFLATED_COMPLEMENT);
         generateRRInstruction(cg, andOp, node, scratchRegister, monitorReg);
         startICF = generateS390CompareAndBranchInstruction(cg, compareOp, node, scratchRegister, metaReg, TR::InstOpCode::COND_BNE, callHelper, false, false);
         generateRIInstruction(cg, loadHalfWordImmOp, node, scratchRegister, OBJECT_HEADER_LOCK_RECURSION_MASK);
         generateRRInstruction(cg, andOp, node, scratchRegister, monitorReg);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, callHelper);
         generateRIInstruction(cg, loadHalfWordImmOp, node, scratchRegister, LOCK_OWNING_NON_INFLATED_COMPLEMENT);
         generateRRInstruction(cg, andOp, node, scratchRegister, monitorReg);
         generateS390CompareAndBranchInstruction(cg, compareImmOp, node, scratchRegister, LOCK_RES_CONTENDED_VALUE, TR::InstOpCode::COND_BE, callHelper, false, false);
         cg->generateDebugCounter("LockExit/Preserving/Recursive", 1, TR::DebugCounter::Undetermined);
         generateRIInstruction(cg, addImmOp, node, monitorReg, -OBJECT_HEADER_LOCK_FIRST_RECURSION_BIT);
         generateRXInstruction(cg, storeOp, node, monitorReg, tempMR1);
         }
      generateS390BranchInstruction(cg,TR::InstOpCode::BRC,TR::InstOpCode::COND_BRC,node,returnLabel);
      tempMR->stopUsingMemRefRegister(cg);
      tempMR1->stopUsingMemRefRegister(cg);

      cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, callHelper);
      if (normalLockWithReservationPreserving)
         cg->generateDebugCounter("LockExit/Preserving/VMHelper", 1, TR::DebugCounter::Undetermined);
      else
         cg->generateDebugCounter("LockExit/Normal/VMHelper", 1, TR::DebugCounter::Undetermined);
      }
   TR::RegisterDependencyConditions *deps = NULL;
   TR::Register *dummyResultReg = inlineRecursive ? helperLink->buildDirectDispatch(node, &deps) : helperLink->buildDirectDispatch(node);
   TR::RegisterDependencyConditions *mergeConditions = NULL;
   if (inlineRecursive)
      mergeConditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(conditions, deps, cg);
   else
      mergeConditions = conditions;

   generateS390LabelInstruction(cg,TR::InstOpCode::LABEL,node,returnLabel,mergeConditions);

   if (!disableOOL)
      {
      cursor = generateS390BranchInstruction(cg,TR::InstOpCode::BRC,TR::InstOpCode::COND_BRC,node,doneLabel);
      if (debugObj)
         {
         debugObj->addInstructionComment(cursor, "Denotes end of OOL monexit: return to mainline");
         }
      // Done using OOL with manual code generation
      outlinedHelperCall->swapInstructionListsWithCompilation();
      }
   bool needDeps = false;
#if defined (J9VM_THR_LOCK_NURSERY)
   if (lwOffset <= 0 && disableOOL)
      needDeps = true;
#endif

   TR::Instruction *doneInstr;
   doneInstr = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, conditions);

#if defined (J9VM_THR_LOCK_NURSERY)
   if (lwOffset <= 0 && disableOOL)
      doneInstr->setEndInternalControlFlow();
#endif


   cg->stopUsingRegister(monitorReg);
   if (objectClassReg)
      cg->stopUsingRegister(objectClassReg);
   if (lookupOffsetReg)
      cg->stopUsingRegister(lookupOffsetReg);
   if (tempRegister && (tempRegister != objectClassReg))
      cg->stopUsingRegister(tempRegister);
   if (scratchRegister)
      cg->stopUsingRegister(scratchRegister);
   cg->decReferenceCount(objNode);

   return NULL;
   }

static void
roundArrayLengthToObjectAlignment(TR::CodeGenerator* cg, TR::Node* node, TR::Instruction*& iCursor, TR::Register* dataSizeReg,
      TR::RegisterDependencyConditions* conditions, TR::Register *litPoolBaseReg, int32_t allocSize, int32_t elementSize, TR::Register* sizeReg, TR::LabelSymbol * exitOOLLabel = NULL)
   {
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(cg->fe());
   int32_t alignmentConstant = fej9->getObjectAlignmentInBytes();
   if (exitOOLLabel)
      {
      TR_Debug * debugObj = cg->getDebug();
      iCursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, exitOOLLabel);
      //TODO if not outline stuff?
      if (debugObj)
         debugObj->addInstructionComment(iCursor, "Exit OOL, going back to main line");
      }

   // Size of array is headerSize + dataSize. If either aren't
   // multiples of alignment then their sum likely won't be
   bool needsAlignment = ( ((allocSize % alignmentConstant) != 0) ||
                           ((elementSize % alignmentConstant) != 0) );

   bool canCombineAGRs = ( ((allocSize % alignmentConstant) == 0) &&
                            (elementSize < alignmentConstant));

   if(!canCombineAGRs)
      iCursor = generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, sizeReg, dataSizeReg, iCursor);

   if(needsAlignment)
      {
      iCursor = generateRIInstruction(cg, TR::InstOpCode::getAddHalfWordImmOpCode(), node, sizeReg, alignmentConstant - 1 + allocSize, iCursor);
      if (TR::Compiler->target.is64Bit())
         iCursor = generateS390ImmOp(cg, TR::InstOpCode::getAndOpCode(), node, sizeReg, sizeReg, -((int64_t) (alignmentConstant)), conditions, litPoolBaseReg);
      else
         iCursor = generateS390ImmOp(cg, TR::InstOpCode::getAndOpCode(), node, sizeReg, sizeReg, -((int32_t) (alignmentConstant)), conditions, litPoolBaseReg);
      }
   else
      {
      iCursor = generateRIInstruction(cg, TR::InstOpCode::getAddHalfWordImmOpCode(), node, sizeReg, allocSize, iCursor);
      }
   }


static void
genHeapAlloc(TR::Node * node, TR::Instruction *& iCursor, bool isVariableLen, TR::Register * enumReg, TR::Register * resReg,
   TR::Register * zeroReg, TR::Register * dataSizeReg, TR::Register * sizeReg, TR::LabelSymbol * callLabel, int32_t allocSize,
   int32_t elementSize, TR::CodeGenerator * cg, TR::Register * litPoolBaseReg, TR::RegisterDependencyConditions * conditions,
   TR::Instruction *& firstBRCToOOL, TR::Instruction *& secondBRCToOOL, TR::LabelSymbol * exitOOLLabel = NULL)
   {
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   if (!TR::Options::getCmdLineOptions()->realTimeGC())
      {
      TR::Register *metaReg;
      if (!comp->getOption(TR_Enable390FreeVMThreadReg))
         metaReg = cg->getMethodMetaDataRealRegister();
      else
         metaReg = cg->getVMThreadRegister();

      // bool sizeInReg = (isVariableLen || (allocSize > MAX_IMMEDIATE_VAL));

      int alignmentConstant = fej9->getObjectAlignmentInBytes();

      if (isVariableLen)
         {
         if (exitOOLLabel)
            {
            TR_Debug * debugObj = cg->getDebug();
            iCursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, exitOOLLabel);
            if (debugObj)
               debugObj->addInstructionComment(iCursor, "Exit OOL, going back to main line");
            }
         // Detect large or negative number of elements, and call the helper in that case.
         // This 1MB limit comes from the cg.

         TR::Register * tmp = sizeReg;
         if (allocSize % alignmentConstant == 0 && elementSize < alignmentConstant)
            {
            tmp = dataSizeReg;
            }

         if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z196))
            {
            iCursor = generateRSInstruction(cg, TR::InstOpCode::SRAK, node, tmp, enumReg, 16, iCursor);
            }
         else
            {
            iCursor = generateRRInstruction(cg, TR::InstOpCode::LR, node, tmp, enumReg, iCursor);
            iCursor = generateRSInstruction(cg, TR::InstOpCode::SRA, node, tmp, 16, iCursor);
            }

         iCursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, callLabel, iCursor);
         if(!firstBRCToOOL)
            {
            firstBRCToOOL = iCursor;
            }
         else
            {
            secondBRCToOOL = iCursor;
            }
         }

      // We are loading up a partially constructed object. Don't let GC interfere with us
      // at this moment
      if (isVariableLen)
         {
         //Call helper to turn array length into size in bytes and do object alignment if necessary
         roundArrayLengthToObjectAlignment(cg, node, iCursor, dataSizeReg, conditions, litPoolBaseReg, allocSize, elementSize, sizeReg);

   #if defined(J9VM_INTERP_FLAGS_IN_CLASS_SLOT)
         // All arrays in combo builds will always be at least 12 bytes in size in all specs:
         //
         // 1)  class pointer + contig length + one or more elements
         // 2)  class pointer + 0 + 0 (for zero length arrays)
         //
         //Since objects are aligned to 8 bytes then the minimum size for an array must be 16 after rounding

         static_assert(J9_GC_MINIMUM_OBJECT_SIZE >= 8, "Expecting a minimum object size >= 8");
   #endif
         }

      // Calculate the after-allocation heapAlloc: if the size is huge,
      //   we need to check address wrap-around also. This is unsigned
      //   integer arithmetic, checking carry bit is enough to detect it.
      //   For variable length array, we did an up-front check already.

      static char * disableInitClear = feGetEnv("TR_disableInitClear");
      static char * disableBatchClear = feGetEnv("TR_DisableBatchClear");

      static char * useDualTLH = feGetEnv("TR_USEDUALTLH");

      TR::Register * addressReg = NULL, * lengthReg = NULL, * shiftReg = NULL;
      if (disableBatchClear && disableInitClear==NULL)
         {
         addressReg = cg->allocateRegister();
         lengthReg = cg->allocateRegister();
         shiftReg = cg->allocateRegister();

         if (conditions != NULL)
            {
            conditions->resetIsUsed();
            conditions->addPostCondition(addressReg, TR::RealRegister::AssignAny);
            conditions->addPostCondition(shiftReg, TR::RealRegister::AssignAny);
            conditions->addPostCondition(lengthReg, TR::RealRegister::AssignAny);
            }
         }

      if (isVariableLen)
         {
         if (disableBatchClear && disableInitClear==NULL)
            iCursor = generateRRInstruction(cg, TR::InstOpCode::LGR, node, lengthReg, sizeReg, iCursor);
         if (!comp->getOption(TR_DisableDualTLH) && useDualTLH && node->canSkipZeroInitialization())
            {
            iCursor = generateRXInstruction(cg, TR::InstOpCode::getAddOpCode(), node, sizeReg,
                  generateS390MemoryReference(metaReg, offsetof(J9VMThread, nonZeroHeapAlloc), cg), iCursor);
            }
         else
            {
            iCursor = generateRXInstruction(cg, TR::InstOpCode::getAddOpCode(), node, sizeReg,
                  generateS390MemoryReference(metaReg, offsetof(J9VMThread, heapAlloc), cg), iCursor);
            }
         }
      else
         {
         if (TR::Compiler->target.is64Bit())
            iCursor = genLoadLongConstant(cg, node, allocSize, sizeReg, iCursor, conditions);
         else
            iCursor = generateLoad32BitConstant(cg, node, allocSize, sizeReg, true, iCursor, conditions);

         if (disableBatchClear && disableInitClear==NULL)
            iCursor = generateRRInstruction(cg, TR::InstOpCode::LGR, node, lengthReg, sizeReg, iCursor);

         if (!comp->getOption(TR_DisableDualTLH) && useDualTLH && node->canSkipZeroInitialization())
            {
            iCursor = generateRXInstruction(cg, TR::InstOpCode::getAddOpCode(), node, sizeReg,
                  generateS390MemoryReference(metaReg, offsetof(J9VMThread, nonZeroHeapAlloc), cg), iCursor);
            }
         else
            {
            iCursor = generateRXInstruction(cg, TR::InstOpCode::getAddOpCode(), node, sizeReg,
                  generateS390MemoryReference(metaReg, offsetof(J9VMThread, heapAlloc), cg), iCursor);
            }

         }

      if (allocSize > cg->getMaxObjectSizeGuaranteedNotToOverflow())
         {
         iCursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BO, node, callLabel, iCursor);
         if(!firstBRCToOOL)
            {
            firstBRCToOOL = iCursor;
            }
         else
            {
            secondBRCToOOL = iCursor;
            }
         }

      if (!comp->getOption(TR_DisableDualTLH) && useDualTLH && node->canSkipZeroInitialization())
         {
               iCursor = generateRXInstruction(cg, TR::InstOpCode::getCmpLogicalOpCode(), node, sizeReg,
                            generateS390MemoryReference(metaReg, offsetof(J9VMThread, nonZeroHeapTop), cg), iCursor);

            // Moving the BRC before load so that the return object can be dead right after BRASL when heap alloc OOL opt is enabled
         iCursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BH, node, callLabel, iCursor);
         if(!firstBRCToOOL)
            {
            firstBRCToOOL = iCursor;
            }
         else
            {
            secondBRCToOOL = iCursor;
            }


         iCursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, resReg,
               generateS390MemoryReference(metaReg, offsetof(J9VMThread, nonZeroHeapAlloc), cg), iCursor);
         }
      else
         {
         iCursor = generateRXInstruction(cg, TR::InstOpCode::getCmpLogicalOpCode(), node, sizeReg,
                      generateS390MemoryReference(metaReg, offsetof(J9VMThread, heapTop), cg), iCursor);

            // Moving the BRC before load so that the return object can be dead right after BRASL when heap alloc OOL opt is enabled
         iCursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BH, node, callLabel, iCursor);
         if(!firstBRCToOOL)
            {
            firstBRCToOOL = iCursor;
            }
         else
            {
            secondBRCToOOL = iCursor;
            }


         iCursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, resReg,
                                   generateS390MemoryReference(metaReg, offsetof(J9VMThread, heapAlloc), cg), iCursor);
         }


      if (!comp->getOption(TR_DisableDualTLH) && useDualTLH && node->canSkipZeroInitialization())
         iCursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, sizeReg,
                      generateS390MemoryReference(metaReg, offsetof(J9VMThread, nonZeroHeapAlloc), cg), iCursor);
      else
         iCursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, sizeReg,
                      generateS390MemoryReference(metaReg, offsetof(J9VMThread, heapAlloc), cg), iCursor);
      TR::LabelSymbol * fillerRemLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol * doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

      TR::LabelSymbol * fillerLoopLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

      // do this clear, if disableBatchClear is on
      if (disableBatchClear && disableInitClear==NULL) //&& (node->getOpCodeValue() == TR::anewarray) && (node->getFirstChild()->getInt()>0) && (node->getFirstChild()->getInt()<6) )
         {
         iCursor = generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, addressReg, resReg, iCursor);
         // Dont overwrite the class
         //
         iCursor = generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, shiftReg, lengthReg, iCursor);
         iCursor = generateRSInstruction(cg, TR::InstOpCode::SRA, node, shiftReg, 8);

         iCursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BZ, node, fillerRemLabel, iCursor);
         iCursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, fillerLoopLabel);
         iCursor = generateSS1Instruction(cg, TR::InstOpCode::XC, node, 255, generateS390MemoryReference(addressReg, 0, cg), generateS390MemoryReference(addressReg, 0, cg), iCursor);

         iCursor = generateRXInstruction(cg, TR::InstOpCode::LA, node, addressReg, generateS390MemoryReference(addressReg, 256, cg), iCursor);

         iCursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRCT, node, shiftReg, fillerLoopLabel);
         iCursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, fillerRemLabel);

         // and to only get the right 8 bits (remainder)
         iCursor = generateRIInstruction(cg, TR::InstOpCode::NILL, node, lengthReg, 0x00FF);
         iCursor = generateRIInstruction(cg, TR::InstOpCode::AHI, node, lengthReg, -1);
         // branch to done if length < 0

         iCursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BL, node, doneLabel, iCursor);

         iCursor = generateSS1Instruction(cg, TR::InstOpCode::XC, node, 0, generateS390MemoryReference(addressReg, 0, cg), generateS390MemoryReference(addressReg, 0, cg), iCursor);

         // minus 1 from lengthreg since xc auto adds 1 to it

         iCursor = generateEXDispatch(node, cg, lengthReg, shiftReg, iCursor);
         iCursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel);
         }
      cg->stopUsingRegister(addressReg);
      cg->stopUsingRegister(shiftReg);
      cg->stopUsingRegister(lengthReg);

      if (zeroReg != NULL)
         {
         iCursor = generateRRInstruction(cg, TR::InstOpCode::getXORRegOpCode(), node, zeroReg, zeroReg, iCursor);
         }
      }
   else
      {
      TR_ASSERT(0, "genHeapAlloc() not supported for RT");
      }
   }



static void
genInitObjectHeader(TR::Node * node, TR::Instruction *& iCursor, TR_OpaqueClassBlock * classAddress, TR::Register * classReg, TR::Register * resReg,
      TR::Register * zeroReg, TR::Register * temp1Reg, TR::Register * litPoolBaseReg,
      TR::RegisterDependencyConditions * conditions,
      TR::CodeGenerator * cg, TR::Register * enumReg = NULL, bool canUseIIHF = false)
   {
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   TR_J9VM *fej9vm = (TR_J9VM *)(comp->fe());
   if (!TR::Options::getCmdLineOptions()->realTimeGC())
      {
      J9ROMClass *romClass = 0;
      int32_t staticFlag = 0;
      uint32_t orFlag = 0;
      TR::Register *metaReg;
      TR_ASSERT(classAddress, "Cannot have a null OpaqueClassBlock\n");
      romClass = TR::Compiler->cls.romClassOf(classAddress);
      staticFlag = romClass->instanceShape;

      if (!comp->getOption(TR_Enable390FreeVMThreadReg))
         metaReg = cg->getMethodMetaDataRealRegister();
      else
         metaReg = cg->getVMThreadRegister();

      // a pointer to the virtual register that will actually hold the class pointer.
      TR::Register * clzReg = classReg;

      if (comp->compileRelocatableCode())
         {
         if (node->getOpCodeValue() == TR::newarray)
            {
            iCursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, temp1Reg,
                  generateS390MemoryReference(metaReg, offsetof(J9VMThread, javaVM), cg), iCursor);
            iCursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, temp1Reg,
                  generateS390MemoryReference(temp1Reg,
                        fej9vm->getPrimitiveArrayOffsetInJavaVM(node->getSecondChild()->getInt()), cg),
                        iCursor);
            clzReg = temp1Reg;
            }
         else if (node->getOpCodeValue() == TR::anewarray)
            {
            TR_ASSERT(classReg, "must have a classReg for TR::anewarray in AOT mode");
            iCursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, temp1Reg,
                  generateS390MemoryReference(classReg, offsetof(J9Class, arrayClass), cg), iCursor);
            clzReg = temp1Reg;
            //clzReg = classReg;
            }
         else
            {
            TR_ASSERT(node->getOpCodeValue() == TR::New && classReg,
                      "must have a classReg for TR::New in AOT mode");
            clzReg = classReg;
            }
         }

      // Store the class
      if (clzReg == NULL)
         {
         if (cg->wantToPatchClassPointer(classAddress, node))
            {
            iCursor = genLoadAddressConstantInSnippet(cg, node, (intptr_t) classAddress | (intptrj_t)orFlag, temp1Reg, iCursor, conditions, litPoolBaseReg, true);
            if (orFlag != 0)
               {
#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
               iCursor = generateS390ImmOp(cg, TR::InstOpCode::O, node, temp1Reg, temp1Reg, (int32_t)orFlag, conditions, litPoolBaseReg);
#else
               if (TR::Compiler->target.is64Bit())
                  iCursor = generateS390ImmOp(cg, TR::InstOpCode::OG, node, temp1Reg, temp1Reg, (int64_t)orFlag, conditions, litPoolBaseReg);
               else
                  iCursor = generateS390ImmOp(cg, TR::InstOpCode::O, node, temp1Reg, temp1Reg, (int32_t)orFlag, conditions, litPoolBaseReg);
#endif
               }
            }
         else
            {
            //case for arraynew and anewarray for compressedrefs and 31 bit on 64 bit registers use64BitRegsOn32Bit
            /*
             * node->getOpCodeValue() == TR::newarray
             [0x484DF88C20]   LGFI    GPR15,674009856
             [0x484DF88DD8]   ST      GPR15,#613 0(GPR3)
             [0x484DF88F60]   ST      GPR2,#614 4(GPR3)

            to
            IIHF
            STG      GPR2,#614 0(GPR3)

             */

            if (!canUseIIHF)
               iCursor = genLoadAddressConstant(cg, node, (intptr_t) classAddress | (intptrj_t)orFlag, temp1Reg, iCursor, conditions, litPoolBaseReg);
            }
         if (canUseIIHF)
            {
            iCursor = generateRILInstruction(cg, TR::InstOpCode::IIHF, node, enumReg, (intptr_t) classAddress | (intptrj_t)orFlag, iCursor);
            }
         else
            {
#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
            // must store just 32 bits (class offset)

            iCursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, temp1Reg,
                  generateS390MemoryReference(resReg, (int32_t) TR::Compiler->om.offsetOfObjectVftField(), cg), iCursor);
#else
            iCursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, temp1Reg,
                  generateS390MemoryReference(resReg, (int32_t) TR::Compiler->om.offsetOfObjectVftField(), cg), iCursor);
#endif
            }
         }
      else
         {
#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
         // must store just 32 bits (class offset)
         iCursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, clzReg,
               generateS390MemoryReference(resReg, (int32_t) TR::Compiler->om.offsetOfObjectVftField(), cg), iCursor);
#else
         iCursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, clzReg,
               generateS390MemoryReference(resReg, (int32_t) TR::Compiler->om.offsetOfObjectVftField(), cg), iCursor);
#endif
         }

#ifndef J9VM_INTERP_FLAGS_IN_CLASS_SLOT
#if defined(J9VM_OPT_NEW_OBJECT_HASH)

      TR_J9VMBase *fej9 = (TR_J9VMBase *)(cg->fe());
      bool isStaticFlag = fej9->isStaticObjectFlags();

      // If the object flags cannot be determined at compile time, we have to add a load
      // for it. And then, OR it with temp1Reg.
      if (isStaticFlag)
         {
         // The object flags can be determined at compile time.
         staticFlag |= fej9->getStaticObjectFlags();
         if (staticFlag != 0)
            {
            if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10) && staticFlag >= MIN_IMMEDIATE_VAL && staticFlag <= MAX_IMMEDIATE_VAL)
               {
               iCursor = generateSILInstruction(cg, TR::InstOpCode::MVHI, node, generateS390MemoryReference(resReg, TMP_OFFSETOF_J9OBJECT_FLAGS, cg), staticFlag, iCursor);
               }
            else
               {
               iCursor = generateLoad32BitConstant(cg, node, staticFlag, temp1Reg, true, iCursor, conditions, litPoolBaseReg);
               // Store the flags
               iCursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, temp1Reg,
                     generateS390MemoryReference(resReg, TMP_OFFSETOF_J9OBJECT_FLAGS, cg), iCursor);
               }
            }
         }
      else
         {
         // If the object flags cannot be determined at compile time, we add a load for it.
         if(!comp->getOption(TR_DisableDualTLH) && useDualTLH && node->canSkipZeroInitialization())
            iCursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, temp1Reg,
                  generateS390MemoryReference(metaReg, offsetof(J9VMThread, nonZeroAllocateThreadLocalHeap.objectFlags), cg), iCursor);
         else
            iCursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, temp1Reg,
                  generateS390MemoryReference(metaReg, offsetof(J9VMThread, allocateThreadLocalHeap.objectFlags), cg), iCursor);

         // OR staticFlag with temp1Reg
         if (staticFlag)
            iCursor = generateS390ImmOp(cg, TR::InstOpCode::O, node, temp1Reg, temp1Reg, staticFlag, conditions, litPoolBaseReg);
         // Store the flags
         iCursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, temp1Reg,
               generateS390MemoryReference(resReg, TMP_OFFSETOF_J9OBJECT_FLAGS, cg), iCursor);
         //iCursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, temp1Reg,
         //           generateS390MemoryReference(resReg, TMP_OFFSETOF_J9OBJECT_FLAGS, cg), iCursor);
         }
#endif /* J9VM_OPT_NEW_OBJECT_HASH */
#endif /* FLAGS_IN_CLASS_SLOT */


#if !defined(J9VM_THR_LOCK_NURSERY)
      // Init monitor
      if (zeroReg != NULL)
         {

         if (TR::Compiler->target.is64Bit() && fej9->generateCompressedLockWord())
            iCursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, zeroReg,
                  generateS390MemoryReference(resReg, TMP_OFFSETOF_J9OBJECT_MONITOR, cg), iCursor);
         else
            iCursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, zeroReg,
                  generateS390MemoryReference(resReg, TMP_OFFSETOF_J9OBJECT_MONITOR, cg), iCursor);
         }
#endif
#if defined(J9VM_THR_LOCK_NURSERY) && defined(J9VM_THR_LOCK_NURSERY_FAT_ARRAYS)
      // Initialize monitor slots
      // for arrays that have a lock
      // word
      int32_t lwOffset = fej9->getByteOffsetToLockword(classAddress);
      if ((zeroReg != NULL) &&
            (node->getOpCodeValue() != TR::New) &&
            (lwOffset > 0))
         {
         if (TR::Compiler->target.is64Bit() && fej9->generateCompressedLockWord())
            iCursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, zeroReg,
                  generateS390MemoryReference(resReg, TMP_OFFSETOF_J9INDEXABLEOBJECT_MONITOR, cg), iCursor);
         else
            iCursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, zeroReg,
                  generateS390MemoryReference(resReg, TMP_OFFSETOF_J9INDEXABLEOBJECT_MONITOR, cg), iCursor);
         }
#endif
      }
   else
      {
      TR_ASSERT(0, "genInitObjecHeader not supported for RT");
      }

   }


static void
genAlignDoubleArray(TR::Node * node, TR::Instruction *& iCursor, bool isVariableLen, TR::Register * resReg, int32_t objectSize,
   int32_t dataBegin, TR::Register * dataSizeReg, TR::Register * temp1Reg, TR::Register * temp2Reg, TR::Register * litPoolBaseReg,
   TR::RegisterDependencyConditions * conditions, TR::CodeGenerator * cg)
   {
   TR::LabelSymbol * slotAtStart = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * doneAlign = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   iCursor = generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, temp1Reg, resReg, iCursor);
   iCursor = generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, temp2Reg, 3, iCursor);
   iCursor = generateS390ImmOp(cg, TR::InstOpCode::N, node, temp1Reg, temp1Reg, 7, conditions, litPoolBaseReg);
   iCursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNZ, node, slotAtStart, iCursor);

   // The slop bytes are at the end of the allocated object.
   if (isVariableLen)
      {
      if (TR::Compiler->target.is64Bit())
         {
         iCursor = generateRRInstruction(cg, TR::InstOpCode::LGFR, node, dataSizeReg, dataSizeReg, iCursor);
         }

      iCursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, temp2Reg,
            generateS390MemoryReference(resReg, dataSizeReg, dataBegin, cg), iCursor);
      }
   else if (objectSize >= MAXDISP)
      {
      iCursor = genLoadAddressConstant(cg, node, (intptrj_t) objectSize, temp1Reg, iCursor, conditions);
      iCursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, temp2Reg,
                   generateS390MemoryReference(resReg, temp1Reg, 0, cg), iCursor);
      }
   else
      {
      iCursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, temp2Reg,
                   generateS390MemoryReference(resReg, objectSize, cg), iCursor);
      }
   iCursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, doneAlign, iCursor);

   // the slop bytes are at the start of the allocation
   iCursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, slotAtStart, iCursor);
   iCursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, temp2Reg,
                generateS390MemoryReference(resReg, (int32_t) 0, cg), iCursor);
   iCursor = generateRIInstruction(cg, TR::InstOpCode::getAddHalfWordImmOpCode(), node, resReg, 4, iCursor);
   iCursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneAlign, iCursor);
   }


static void
genInitArrayHeader(TR::Node * node, TR::Instruction *& iCursor, bool isVariableLen, TR_OpaqueClassBlock * classAddress, TR::Register * classReg,
   TR::Register * resReg, TR::Register * zeroReg, TR::Register * eNumReg, TR::Register * dataSizeReg, TR::Register * temp1Reg,
   TR::Register * litPoolBaseReg, TR::RegisterDependencyConditions * conditions, TR::CodeGenerator * cg)
   {
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   bool canUseIIHF= false;
   if (!comp->compileRelocatableCode() && (node->getOpCodeValue() == TR::newarray || node->getOpCodeValue() == TR::anewarray)
#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
         && (TR::Compiler->target.is64Bit() || cg->use64BitRegsOn32Bit())
#else
         && (TR::Compiler->target.is32Bit() && cg->use64BitRegsOn32Bit())
#endif
#ifndef J9VM_INTERP_FLAGS_IN_CLASS_SLOT
#if defined(J9VM_OPT_NEW_OBJECT_HASH)
         && false
#endif /* J9VM_OPT_NEW_OBJECT_HASH */
#endif /* FLAGS_IN_CLASS_SLOT */
      )
      {
      canUseIIHF = true;
      }
   genInitObjectHeader(node, iCursor, classAddress, classReg, resReg, zeroReg, temp1Reg, litPoolBaseReg, conditions, cg, eNumReg, canUseIIHF);

   // Store the array size
   if (canUseIIHF)
      {
      iCursor = generateRXInstruction(cg, TR::InstOpCode::STG, node, eNumReg,
                      generateS390MemoryReference(resReg, TR::Compiler->om.offsetOfObjectVftField(), cg), iCursor);
      }
   else
      iCursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, eNumReg,
                generateS390MemoryReference(resReg, fej9->getOffsetOfContiguousArraySizeField(), cg), iCursor);

   static char * allocZeroArrayWithVM = feGetEnv("TR_VMALLOCZEROARRAY");
   static char * useDualTLH = feGetEnv("TR_USEDUALTLH");
   //write 0
   if(!comp->getOption(TR_DisableDualTLH) && useDualTLH && node->canSkipZeroInitialization() && allocZeroArrayWithVM == NULL)
      iCursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, eNumReg,
                      generateS390MemoryReference(resReg, fej9->getOffsetOfDiscontiguousArraySizeField(), cg), iCursor);
   }

TR::Register *
J9::Z::TreeEvaluator::VMnewEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   int32_t allocateSize, objectSize, dataBegin;
   TR::ILOpCodes opCode;
   TR_OpaqueClassBlock * classAddress = 0;
   TR::Register *classReg              = NULL;
   TR::Register *resReg                = NULL;
   TR::Register *zeroReg               = NULL;
   TR::Register *litPoolBaseReg        = NULL;
   TR::Register *enumReg               = NULL;
   TR::Register *copyReg               = NULL;
   TR::Register *classRegAOT           = NULL;
   TR::Register *temp1Reg              = NULL;
   TR::Register *callResult            = NULL;
   TR::Register *dataSizeReg           = NULL;
   TR::Node     *litPoolBaseChild      = NULL;
   TR::Register *copyClassReg          = NULL;

   TR_S390ScratchRegisterManager *srm = cg->generateScratchRegisterManager();

   TR::LabelSymbol * callLabel, * doneLabel;
   TR_S390OutOfLineCodeSection* outlinedSlowPath = NULL;
   TR::RegisterDependencyConditions * conditions;
   TR::Instruction * iCursor = NULL;
   bool isArray = false, isDoubleArray = false;
   bool isVariableLen;
   int32_t litPoolRegTotalUse, temp2RegTotalUse;
   int32_t elementSize;
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());


   /* New Evaluator Optimization: Using OOL instead of snippet for heap alloc
    * The purpose of moving to an OOL from a snippet is that we don't need to
    * hard code dependencies at the merge label, hence it could possibly reduce
    * spills. When we have a snippet, then all registers used in between the
    * branch to the snippet and the merge label need to be assigned to specific
    * registers and added to the dependencies at the merge label.
    * Option to disable it: disableHeapAllocOOL */

   /* Variables needed for Heap alloc OOL Opt */
   TR::Register * tempResReg;//Temporary register used to get the result from the BRASL call in heap alloc OOL
   TR::RegisterDependencyConditions * heapAllocDeps1;//Depenedencies needed for BRASL call in heap alloc OOL
   TR::Instruction *firstBRCToOOL = NULL;
   TR::Instruction *secondBRCToOOL = NULL;

   bool outlineNew = false;
   bool disableOutlinedNew = comp->getOption(TR_DisableOutlinedNew);

   //Disabling outline new for now
   //TODO: enable later
   static bool enableOutline = (feGetEnv("TR_OutlineNew")!=NULL);
   disableOutlinedNew = !enableOutline;

   bool generateArraylets = comp->generateArraylets();

   // in time, the tlh will probably always be batch cleared, and therefore it will not be
   // necessary for the JIT-generated inline code to do the clearing of fields. But, 2 things
   // have to happen first:
   // 1.The JVM has to change it's code so that it has batch clearing on for 390 (it is currently only
   //   on if turned on as a runtime option)
   // 2.The JVM has to support the call - on z/OS, Modron GC is not enabled yet and so batch tlh clearing
   //   can not be enabled yet.
   static bool needZeroReg = !fej9->tlhHasBeenCleared();

   opCode = node->getOpCodeValue();

   // Since calls to canInlineAllocate could result in different results during the same compilation,
   // We must be conservative and only do inline allocation if the first call (in LocalOpts.cpp) has succeeded and we have the litPoolBaseChild added.
   // Refer to defects 161084 and 87089
   bool doInline = cg->doInlineAllocate(node);

   static int count = 0;
   doInline = doInline &&
   performTransformation(comp, "O^O <%3d> Inlining Allocation of %s [0x%p].\n", count++, node->getOpCode().getName(), node);

   if (doInline)
      {

      static char *maxNumOfOOLOptStr = feGetEnv("TR_MaxNumOfOOLOpt");
      if (maxNumOfOOLOptStr)
         {
         int maxNumOfOOLOpt = atoi(maxNumOfOOLOptStr);
         traceMsg(cg->comp(),"TR_MaxNumOfOOLOpt: count=%d, maxNumOfOOLOpt=%d %d\n", count, maxNumOfOOLOpt, __LINE__);
         if(maxNumOfOOLOpt < count)
            {
            traceMsg(cg->comp(),"TR_MaxNumOfOOLOpt: maxNumOfOOLOpt < count, Setting TR_DisableHeapAllocOOL %d\n", __LINE__);
            comp->setOption(TR_DisableHeapAllocOOL);
            }
         }

      objectSize = comp->canAllocateInline(node, classAddress);
      isVariableLen = (objectSize == 0);
      allocateSize = objectSize;
      callLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      conditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(10, 13, cg);
      if (!comp->getOption(TR_DisableHeapAllocOOL))
         {
         heapAllocDeps1 = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(2, 4, cg);
         }
      TR::Node * firstChild = node->getFirstChild();
      TR::Node * secondChild = NULL;

      // load literal pool register
      if (((node->getNumChildren()==3) && ((node->getOpCodeValue()==TR::anewarray)
                        || (node->getOpCodeValue()==TR::newarray))) ||
            ((node->getNumChildren()==2) && (node->getOpCodeValue()==TR::New)))
         {
         litPoolBaseChild=node->getLastChild();
         TR_ASSERT((litPoolBaseChild->getOpCodeValue()==TR::aload) || (litPoolBaseChild->getOpCodeValue()==TR::aRegLoad),
               "Literal pool base child expected\n");
         litPoolBaseReg=cg->evaluate(litPoolBaseChild);
         litPoolRegTotalUse = litPoolBaseReg->getTotalUseCount();
         }

      //////////////////////////////////////////////////////////////////////////////////////////////////////
      ///============================ STAGE 1: Evaluate Children ========================================///
      //////////////////////////////////////////////////////////////////////////////////////////////////////
      if (opCode == TR::New)
         {
         classReg = cg->evaluate(firstChild);
         dataBegin = sizeof(J9Object);
         }
      else
         {
         isArray = true;
         TR_J9VMBase *fej9 = (TR_J9VMBase *)(cg->fe());
         if (generateArraylets || TR::Compiler->om.useHybridArraylets())
            {
            if (node->getOpCodeValue() == TR::newarray)
            elementSize = TR::Compiler->om.getSizeOfArrayElement(node);
            else if (comp->useCompressedPointers())
            elementSize = TR::Compiler->om.sizeofReferenceField();
            else
            elementSize = TR::Compiler->om.sizeofReferenceAddress();

            if (generateArraylets)
            dataBegin = fej9->getArrayletFirstElementOffset(elementSize, comp);
            else
            dataBegin = TR::Compiler->om.contiguousArrayHeaderSizeInBytes();
            }
         else
            {
            dataBegin = TR::Compiler->om.contiguousArrayHeaderSizeInBytes();
            elementSize = TR::Compiler->om.getSizeOfArrayElement(node);
            }
         secondChild = node->getSecondChild();
         // For TR::newarray, classReg is not the real class actually.
         if (!comp->getOption(TR_DisableHeapAllocOOL))
            {
            /* Evaluate the second child node with info about the type of object in the mainline only
             * when it's an evaluation for anewarray or packed anewarray or if the second child's opcode
             * is not a load const. Otherwise, we evaluate the second child manually in OOL since it's
             * not used anywhere in the mainline, hence keeping a register unnecessarily live for a very
             * long time before it is killed. */

            if (!secondChild->getOpCode().isLoadConst() || node->getOpCodeValue() == TR::anewarray)
               {
               classReg = cg->evaluate(secondChild);
               }
            }
         else
            {
            classReg = cg->evaluate(secondChild);
            }

         // Potential helper call requires us to evaluate the arguments always.
         enumReg = cg->evaluate(firstChild);
         if (!cg->canClobberNodesRegister(firstChild))
            {
            copyReg = cg->allocateRegister();
            TR::InstOpCode::Mnemonic loadOpCode = (firstChild->getType().isInt64()) ? TR::InstOpCode::LGR : TR::InstOpCode::LR;
            iCursor = generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, copyReg, enumReg, iCursor);
            enumReg = copyReg;
            }
         }

      //////////////////////////////////////////////////////////////////////////////////////////////////////
      ///============================ STAGE 1.1: Use OutlinedNew? =========================================///
      //////////////////////////////////////////////////////////////////////////////////////////////////////
      if (opCode != TR::anewarray && opCode != TR::New && opCode != TR::newarray)
         {
         //for now only enabling for TR::New
         disableOutlinedNew = true;
         }
      else if (generateArraylets)
         {
         if (comp->getOption(TR_TraceCG))
         traceMsg(comp, "OUTLINED NEW: Disable for %s %p because outlined allocation can't deal with arraylets\n", node->getOpCode().getName(), node);
         disableOutlinedNew = true;
         cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "cg.new/refusedToOutline/arraylets/%s", node->getOpCode().getName()), 1, TR::DebugCounter::Undetermined);
         }
      else if (comp->getMethodHotness() > warm)
         {
         if (comp->getOption(TR_TraceCG))
         traceMsg(comp, "OUTLINED NEW: Disable for %p because opt level is %s\n", node, comp->getHotnessName());
         disableOutlinedNew = true;
         cg->generateDebugCounter(TR::DebugCounter::debugCounterName(comp, "cg.new/refusedToOutline/optlevel/%s", comp->getHotnessName()), 1, TR::DebugCounter::Undetermined);
         }
      else if (needZeroReg)
         {
         if (comp->getOption(TR_TraceCG))
         traceMsg(comp, "OUTLINED NEW: Disable for %p due to tlhNotCleared\n", node);
         disableOutlinedNew = true;
         cg->generateDebugCounter("cg.new/refusedToOutline/tlhNotCleared", 1, TR::DebugCounter::Undetermined);
         }
      else if (allocateSize > cg->getMaxObjectSizeGuaranteedNotToOverflow())
         {
         if (comp->getOption(TR_TraceCG))
         traceMsg(comp, "OUTLINED NEW: Disable for %p due to allocate large object size\n", node);
         disableOutlinedNew = true;
         cg->generateDebugCounter("cg.new/refusedToOutline/largeObjectSize", 1, TR::DebugCounter::Undetermined);
         }

      if (!disableOutlinedNew && performTransformation(comp, "O^O OUTLINED NEW: outlining %s %p, size %d\n", node->getOpCode().getName(), node, allocateSize))
      outlineNew = true;

      //////////////////////////////////////////////////////////////////////////////////////////////////////
      ///============================ STAGE 2: Setup Register Dependencies===============================///
      //////////////////////////////////////////////////////////////////////////////////////////////////////

      temp1Reg = srm->findOrCreateScratchRegister();
      resReg = cg->allocateCollectedReferenceRegister();

      if (needZeroReg)
         zeroReg = srm->findOrCreateScratchRegister();
      conditions->addPostCondition(classReg, TR::RealRegister::AssignAny);
      if (enumReg)
         {
         conditions->addPostCondition(enumReg, TR::RealRegister::AssignAny);
         traceMsg(comp,"enumReg = %s\n", enumReg->getRegisterName(comp));
         }
      conditions->addPostCondition(resReg, TR::RealRegister::AssignAny);
      traceMsg(comp, "classReg = %s , resReg = %s \n", classReg->getRegisterName(comp), resReg->getRegisterName(comp));
      /* VM helper function for heap alloc expects these parameters to have these values:
       * GPR1 -> Type of Object
       * GPR2 -> Size/Number of objects (if applicable) */
      // We don't need these many registers dependencies as Outlined path will only contain helper call
      TR::Register *copyEnumReg = enumReg;
      TR::Register *copyClassReg = classReg;

      //////////////////////////////////////////////////////////////////////////////////////////////////////
      ///============================ STAGE 3: Calculate Allocation Size ================================///
      //////////////////////////////////////////////////////////////////////////////////////////////////////
      // Three possible outputs:
      // if variable-length array   - dataSizeReg will contain the (calculated) size
      // if outlined                - tmpReg will contain the value of
      // otherwise                  - size is in (int) allocateSize
      int alignmentConstant = fej9->getObjectAlignmentInBytes();

      if (isVariableLen)
         allocateSize += dataBegin;
      else
         allocateSize = (allocateSize + alignmentConstant - 1) & (-alignmentConstant);

      TR::LabelSymbol * exitOOLLabel = NULL;


      if (isVariableLen)
         {

         //want to fold some of the
         /*
          * figure out packed arrays
          * LTGFR   GPR14,GPR2
          * SLLG    GPR14,GPR14,1
          BRC     BE(0x8), Snippet Label [0x484BD04470] <------combine LTGFR + SLLG to RSIBG

          LR      GPR15,GPR2
          SRA     GPR15,16
          BRC     MASK6(0x6), Snippet Label [0x484BD04470]      # (Start of internal control flow)
          LG      GPR3,#511 96(GPR13)
          1     AGHI    GPR14,7  <---can combine 1 & 3 when allocateSize (8) is multiple of alignmentConstant (8), but need
          to re-arrange some of the registers, result is expected in GPR15
          2     NILF    GPR14,-8
          3     LGHI    GPR15,8
          4     AGR     GPR15,GPR14
          5     AGR     GPR15,GPR3
          CLG     GPR15,#513 104(GPR13)

          final:

          *
          */
         TR::Register * tmp = NULL;
         dataSizeReg = srm->findOrCreateScratchRegister();
         if (allocateSize % alignmentConstant == 0 && elementSize < alignmentConstant)
            {
            if (outlineNew)
               tmp = resReg;
            else
               tmp = temp1Reg;
            }
         else
            {
            tmp = dataSizeReg;
            }

         /*     if (elementSize >= 2)
          {
          if (TR::Compiler->target.is64Bit())
          iCursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, dataSizeReg, dataSizeReg, trailingZeroes(elementSize), iCursor);
          else
          iCursor = generateRSInstruction(cg, TR::InstOpCode::SLL, node, dataSizeReg, trailingZeroes(elementSize), iCursor);
          } */
         if (callLabel != NULL && (node->getOpCodeValue() == TR::anewarray ||
                     node->getOpCodeValue() == TR::newarray))
            {
            TR_Debug * debugObj = cg->getDebug();
            TR::LabelSymbol * startOOLLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
            exitOOLLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
            TR_S390OutOfLineCodeSection *zeroSizeArrayChckOOL;
            if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10) && TR::Compiler->target.is64Bit())
               {
               //need 31 bit as well, combining lgfr + sllg into rsibg
               int32_t shift_amount = trailingZeroes(elementSize);
               iCursor = generateRIEInstruction(cg, TR::InstOpCode::RISBG, node, tmp, enumReg, (int8_t) (32 - shift_amount),
                     (int8_t)((63 - shift_amount) |0x80), (int8_t) shift_amount);
               }
            else
               {
               iCursor = generateRRInstruction(cg, TR::InstOpCode::getLoadTestRegWidenOpCode(), node, tmp, enumReg, iCursor);
               if (elementSize >= 2)
                  {
                  if (TR::Compiler->target.is64Bit())
                  iCursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, tmp, tmp, trailingZeroes(elementSize), iCursor);
                  else
                  iCursor = generateRSInstruction(cg, TR::InstOpCode::SLL, node, tmp, trailingZeroes(elementSize), iCursor);
                  }
               }

            static char * allocZeroArrayWithVM = feGetEnv("TR_VMALLOCZEROARRAY");
            // DualTLH: Remove when performance confirmed
            static char * useDualTLH = feGetEnv("TR_USEDUALTLH");
            // OOL
            if (!comp->getOption(TR_DisableOOL))
               {
               if (comp->getOption(TR_DisableDualTLH) && useDualTLH || allocZeroArrayWithVM == NULL)
                  {
                  iCursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, startOOLLabel, iCursor);
                  TR_Debug * debugObj = cg->getDebug();
                  zeroSizeArrayChckOOL = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(startOOLLabel,exitOOLLabel,cg);
                  cg->getS390OutOfLineCodeSectionList().push_front(zeroSizeArrayChckOOL);
                  zeroSizeArrayChckOOL->swapInstructionListsWithCompilation();
                  // Check to see if array-type is a super-class of the src object
                  //
                  TR::Instruction * cursor;
                  cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, startOOLLabel);
                  if (debugObj)
                  debugObj->addInstructionComment(cursor, "Denotes start of OOL for allocating zero size arrays");

                  /* using TR::Compiler->om.discontiguousArrayHeaderSizeInBytes() - TR::Compiler->om.contiguousArrayHeaderSizeInBytes()
                   * for byte size for discontinous 0 size arrays becasue later instructions do ( + 15 & -8) to round it to object size header and adding a j9 class header
                   *
                   *
                   ----------- OOL: Beginning of out-of-line code section ---------------
                   Label [0x484BE2AC80]:    ; Denotes start of OOL for allocating zero size arrays
                   AGHI    GPR_0x484BE2A900,16
                   BRC     J(0xf), Label [0x484BE2ACE0]
                   --------------- OOL: End of out-of-line code section ------------------

                   Label [0x484BE2ACE0]:    ; Exit OOL, going back to main line
                   LR      GPR_0x484BE2AAE0,GPR_0x484BE2A7A0
                   SRA     GPR_0x484BE2AAE0,16
                   BRC     MASK6(0x6), Snippet Label [0x484BE2A530]      # (Start of internal control flow)
                   AGHI    GPR_0x484BE2A900,15 <----add 7 + 8
                   NILF    GPR_0x484BE2A900,-8 <---round to object size
                   AG      GPR_0x484BE2A900,#490 96(GPR13)

                   */
                  cursor = generateRIInstruction(cg, TR::InstOpCode::getAddHalfWordImmOpCode(), node, tmp,
                        TR::Compiler->om.discontiguousArrayHeaderSizeInBytes() - TR::Compiler->om.contiguousArrayHeaderSizeInBytes(), cursor);

                  generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, exitOOLLabel,cursor);
                  zeroSizeArrayChckOOL->swapInstructionListsWithCompilation();
                  }
               else
                  {
                  iCursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, callLabel, iCursor);
                  if(!firstBRCToOOL)
                     {
                     firstBRCToOOL = iCursor;
                     }
                  else
                     {
                     secondBRCToOOL = iCursor;
                     }
                  }
               }
            else
               {
               iCursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, exitOOLLabel, iCursor);
               iCursor = generateRIInstruction(cg, TR::InstOpCode::getAddHalfWordImmOpCode(), node, tmp,
                     TR::Compiler->om.discontiguousArrayHeaderSizeInBytes() - TR::Compiler->om.contiguousArrayHeaderSizeInBytes(), iCursor);
               }

            }
         else
            {
            iCursor = generateRRInstruction(cg, TR::InstOpCode::getLoadRegWidenOpCode(), node, tmp, enumReg, iCursor);

            if (elementSize >= 2)
               {
               if (TR::Compiler->target.is64Bit())
               iCursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, tmp, tmp, trailingZeroes(elementSize), iCursor);
               else
               iCursor = generateRSInstruction(cg, TR::InstOpCode::SLL, node, tmp, trailingZeroes(elementSize), iCursor);
               }
            }

         }

      if (outlineNew && !isVariableLen)
         {
         TR::Register * tmpReg = NULL;
         if (opCode == TR::New)
            tmpReg = enumReg;
         else
            tmpReg = resReg;

         if (TR::Compiler->target.is64Bit())
            iCursor = genLoadLongConstant(cg, node, allocateSize, tmpReg, iCursor, conditions);
         else
            iCursor = generateLoad32BitConstant(cg, node, allocateSize, tmpReg, true, iCursor, conditions);
         }

      //////////////////////////////////////////////////////////////////////////////////////////////////////
      ///============================ STAGE 4: Generate HeapTop Test=====================================///
      //////////////////////////////////////////////////////////////////////////////////////////////////////
      TR::Instruction *current;
      TR::Instruction *firstInstruction;
      srm->addScratchRegistersToDependencyList(conditions);

      current = cg->getAppendInstruction();

      TR_ASSERT(current != NULL, "Could not get current instruction");

      if (comp->compileRelocatableCode() && (opCode == TR::New || opCode == TR::anewarray))
         {
         iCursor = firstInstruction = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_VGNOP, node, callLabel, current);
         if(!firstBRCToOOL)
            {
            firstBRCToOOL = iCursor;
            }
         else
            {
            secondBRCToOOL = iCursor;
            }
         }

      if (outlineNew)
         {
         if (isVariableLen)
            roundArrayLengthToObjectAlignment(cg, node, iCursor, dataSizeReg, conditions, litPoolBaseReg, allocateSize, elementSize, resReg, exitOOLLabel );

         TR_RuntimeHelper helper;
         if (opCode == TR::New)
            helper = TR_S390OutlinedNew;
         else
            helper = TR_S390OutlinedNewArray;

#if !defined(PUBLIC_BUILD)
         static bool bppoutline = (feGetEnv("TR_BPRP_Outline")!=NULL);
         if (bppoutline)
            {
            TR::LabelSymbol * callLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
            TR::Instruction * instr = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, callLabel);

            if (helper == TR_S390OutlinedNew && cg->_outlineCall._frequency == -1)
               {
               cg->_outlineCall._frequency = 1;
               cg->_outlineCall._callSymRef = cg->symRefTab()->findOrCreateRuntimeHelper(helper, false, false, false);
               cg->_outlineCall._callLabel = callLabel;
               }
            else if (helper == TR_S390OutlinedNewArray && cg->_outlineArrayCall._frequency == -1)
               {
               cg->_outlineArrayCall._frequency = 1;
               cg->_outlineArrayCall._callSymRef = cg->symRefTab()->findOrCreateRuntimeHelper(helper, false, false, false);
               cg->_outlineArrayCall._callLabel = callLabel;
               }
            }
#endif
         // outlineNew is disabled, so We don't use the hardcoded dependency for that
         // TODO When we decide to enable outlinedNew we need to make sure we have class and size in right register as per expectation
         iCursor = generateDirectCall(cg, node, false, cg->symRefTab()->findOrCreateRuntimeHelper(helper, false, false, false), conditions);
         //check why it fails when TR::InstOpCode::BRCL instead of TR::InstOpCode::BRC is used
         iCursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BH, node, callLabel, iCursor);
         if(!firstBRCToOOL)
            {
            firstBRCToOOL = iCursor;
            }
         else
            {
            secondBRCToOOL = iCursor;
            }

         }
      else
         {
         static char * useDualTLH = feGetEnv("TR_USEDUALTLH");
         //Here we set up backout paths if we overflow nonZeroTLH in genHeapAlloc.
         //If we overflow the nonZeroTLH, set the destination to the right VM runtime helper (eg jitNewObjectNoZeroInit, etc...)
         //The zeroed-TLH versions have their correct destinations already setup in TR_ByteCodeIlGenerator::genNew, TR_ByteCodeIlGenerator::genNewArray, TR_ByteCodeIlGenerator::genANewArray
         //TR::PPCHeapAllocSnippet retrieves this destination via node->getSymbolReference() below after genHeapAlloc.
         if(!comp->getOption(TR_DisableDualTLH) && useDualTLH && node->canSkipZeroInitialization())
            {
            if (node->getOpCodeValue() == TR::New)
            node->setSymbolReference(comp->getSymRefTab()->findOrCreateNewObjectNoZeroInitSymbolRef(comp->getMethodSymbol()));
            else if (node->getOpCodeValue() == TR::newarray)
            node->setSymbolReference(comp->getSymRefTab()->findOrCreateNewArrayNoZeroInitSymbolRef(comp->getMethodSymbol()));
            else if (node->getOpCodeValue() == TR::anewarray)
            node->setSymbolReference(comp->getSymRefTab()->findOrCreateANewArrayNoZeroInitSymbolRef(comp->getMethodSymbol()));
            }

         if (enumReg == NULL && opCode != TR::New)
            {
            enumReg = cg->allocateRegister();
            conditions->addPostCondition(enumReg, TR::RealRegister::AssignAny);
            traceMsg(comp,"enumReg = %s\n", enumReg->getRegisterName(comp));
            }
         // classReg and enumReg have to be intact still, in case we have to call the helper.
         // On return, zeroReg is set to 0, and dataSizeReg is set to the size of data area if
         // isVariableLen is true.
         genHeapAlloc(node, iCursor, isVariableLen, enumReg, resReg, zeroReg, dataSizeReg, temp1Reg, callLabel, allocateSize, elementSize, cg,
               litPoolBaseReg, conditions, firstBRCToOOL, secondBRCToOOL, exitOOLLabel);
         }

      //////////////////////////////////////////////////////////////////////////////////////////////////////
      ///============================ STAGE 5: Generate Fall-back Path ==================================///
      //////////////////////////////////////////////////////////////////////////////////////////////////////
         /* New Evaluator Optimization: Using OOL instead of snippet for heap alloc */

         /* Example of the OOL for newarray
          * Outlined Label L0048:    ; Denotes start of OOL for heap alloc
          * LHI     GPR_0120,0x5
          * ASSOCREGS
          * PRE:
          * {GPR2:GPR_0112:R} {GPR1:GPR_0120:R}
          * BRASL   GPR_0117,0x00000000
          * POST:
          * {GPR1:D_GPR_0116:R}* {GPR14:GPR_0117:R} {GPR2:&GPR_0118:R}
          * LR      &GPR_0115,&GPR_0118
          * BRC     J(0xf), Label L0049*/

      TR_Debug * debugObj = cg->getDebug();
      TR_S390OutOfLineCodeSection *heapAllocOOL = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(callLabel, doneLabel, cg);
      cg->getS390OutOfLineCodeSectionList().push_front(heapAllocOOL);
      heapAllocOOL->swapInstructionListsWithCompilation();
      TR::Instruction * cursorHeapAlloc;
      // Generating OOL label: Outlined Label L00XX
      cursorHeapAlloc = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, callLabel);
      if (debugObj)
         debugObj->addInstructionComment(cursorHeapAlloc, "Denotes start of OOL for heap alloc");
      generateHelperCallForVMNewEvaluators(node, cg, true, resReg);
      /* Copying the return value from the temporary register to the actual register that is returned */
      /* Generating the branch to jump back to the merge label:
       * BRCL    J(0xf), Label L00YZ, labelTargetAddr=0xZZZZZZZZ*/
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, doneLabel);
      heapAllocOOL->swapInstructionListsWithCompilation();
      //////////////////////////////////////////////////////////////////////////////////////////////////////
      ///============================ STAGE 6: Initilize the new object header ==========================///
      //////////////////////////////////////////////////////////////////////////////////////////////////////
      if (isArray)
         {
         if ( comp->compileRelocatableCode() && opCode == TR::anewarray)
         genInitArrayHeader(node, iCursor, isVariableLen, classAddress, classReg, resReg, zeroReg,
               enumReg, dataSizeReg, temp1Reg, litPoolBaseReg, conditions, cg);
         else
         genInitArrayHeader(node, iCursor, isVariableLen, classAddress, NULL, resReg, zeroReg,
               enumReg, dataSizeReg, temp1Reg, litPoolBaseReg, conditions, cg);

         // Write Arraylet Pointer
         if (generateArraylets)
            {
            iCursor = generateS390ImmOp(cg, TR::InstOpCode::getAddOpCode(), node, temp1Reg, resReg, dataBegin, conditions, litPoolBaseReg);
            if(TR::Compiler->vm.heapBaseAddress() == 0)
            iCursor = generateS390ImmOp(cg, TR::InstOpCode::getAddOpCode(), node, temp1Reg, temp1Reg, -((int64_t)(TR::Compiler->vm.heapBaseAddress())), conditions, litPoolBaseReg);
            if(TR::Compiler->om.compressedReferenceShiftOffset() > 0)
            iCursor = generateRSInstruction(cg, TR::InstOpCode::SRL, node, temp1Reg, TR::Compiler->om.compressedReferenceShiftOffset(), iCursor);

            iCursor = generateRXInstruction(cg, (TR::Compiler->target.is64Bit()&& !comp->useCompressedPointers()) ? TR::InstOpCode::STG : TR::InstOpCode::ST, node, temp1Reg,
                  generateS390MemoryReference(resReg, fej9->getOffsetOfContiguousArraySizeField(), cg), iCursor);

            }
         }
      else
         {
         genInitObjectHeader(node, iCursor, classAddress, classReg , resReg, zeroReg, temp1Reg, litPoolBaseReg, conditions, cg);
         }

      TR_ASSERT((fej9->tlhHasBeenCleared() || J9JIT_TESTMODE || J9JIT_TOSS_CODE), "");

      //////////////////////////////////////////////////////////////////////////////////////////////////////
      ///============================ STAGE 6b: Prefetch after stores ===================================///
      //////////////////////////////////////////////////////////////////////////////////////////////////////
      if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10) && cg->enableTLHPrefetching())
         {
         iCursor = generateS390MemInstruction(cg, TR::InstOpCode::PFD, node, 2, generateS390MemoryReference(resReg, 0x100, cg), iCursor);
         }

      //////////////////////////////////////////////////////////////////////////////////////////////////////
      ///============================ STAGE 7: AOT Relocation Records ===================================///
      //////////////////////////////////////////////////////////////////////////////////////////////////////
      if (comp->compileRelocatableCode() && (opCode == TR::New || opCode == TR::anewarray) )
         {
         TR_RelocationRecordInformation *recordInfo =
         (TR_RelocationRecordInformation *) comp->trMemory()->allocateMemory(sizeof(TR_RelocationRecordInformation), heapAlloc);
         recordInfo->data1 = allocateSize;
         recordInfo->data2 = node->getInlinedSiteIndex();
         recordInfo->data3 = (uintptr_t) callLabel;
         recordInfo->data4 = (uintptr_t) firstInstruction;
         TR::SymbolReference * classSymRef;
         TR_ExternalRelocationTargetKind reloKind;

         if (opCode == TR::New)
            {
            classSymRef = node->getFirstChild()->getSymbolReference();
            reloKind = TR_VerifyClassObjectForAlloc;
            }
         else
            {
            classSymRef = node->getSecondChild()->getSymbolReference();
            reloKind = TR_VerifyRefArrayForAlloc;
            }

         cg->addAOTRelocation(new (cg->trHeapMemory()) TR::BeforeBinaryEncodingExternalRelocation(firstInstruction,
                     (uint8_t *) classSymRef,
                     (uint8_t *) recordInfo,
                     reloKind, cg),
               __FILE__, __LINE__, node);

         }

      //////////////////////////////////////////////////////////////////////////////////////////////////////
      ///============================ STAGE 8: Done. Housekeeping items =================================///
      //////////////////////////////////////////////////////////////////////////////////////////////////////

      // Add these registers to the dep list if they are actually used in the evaluator body
      // We detect use by observing if the totalUseCounts on the registers increased since their first
      // instance at the top of the evaluator.
      //
      if (litPoolBaseReg!=NULL && litPoolBaseReg->getTotalUseCount()>litPoolRegTotalUse)
         {
         // reset the isUSed bit on the condition, this prevents the assertion
         // "ERROR: cannot add conditions to an used dependency, create a copy first" from firing up.
         conditions->resetIsUsed();
         if (comp->getOption(TR_DisableHeapAllocOOL))
            conditions->addPostCondition(litPoolBaseReg, TR::RealRegister::AssignAny);
         }

      if (!comp->getOption(TR_DisableHeapAllocOOL))
         {
         if (secondBRCToOOL)
            {
            firstBRCToOOL->setStartInternalControlFlow();
            secondBRCToOOL->setEndInternalControlFlow();
            secondBRCToOOL->setDependencyConditions(conditions);
            }
         iCursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel);
         }
      else
         {
         // determine where internal control flow begins by looking for the first branch
         // instruction after where the label instruction would have been inserted

         TR::Instruction *next = current->getNext();
         while(next != NULL && !next->isBranchOp())
         next = next->getNext();
         TR_ASSERT(next != NULL, "Could not find branch instruction where internal control flow begins");
         next->setStartInternalControlFlow();
         iCursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, conditions);
         doneLabel->setEndInternalControlFlow();
         }

      cg->decReferenceCount(firstChild);
      if (secondChild)
         {
         cg->decReferenceCount(secondChild);
         }
      if (litPoolBaseChild!=NULL)
         {
         cg->decReferenceCount(litPoolBaseChild);
         }

      if (classReg)
         cg->stopUsingRegister(classReg);
      if (copyClassReg)
         cg->stopUsingRegister(copyClassReg);
      if (copyEnumReg != enumReg)
         cg->stopUsingRegister(copyEnumReg);
      if (enumReg)
         cg->stopUsingRegister(enumReg);
      if (copyReg)
         cg->stopUsingRegister(copyReg);
      srm->stopUsingRegisters();
      node->setRegister(resReg);
      return resReg;
      }
   else
      {
      // The call to doInlineAllocate may return true during LocalOpts, but subsequent optimizations may prove
      // that the anewarray cannot be allocated inline (i.e. it will end up going to helper).  An example is
      // when arraysize is proven to be 0, which is considered a discontiguous array size in balanced mode GC.
      // In such cases, we need to remove the last litpool child before calling directCallEvaluator.
      if (((node->getNumChildren()==3) && ((node->getOpCodeValue()==TR::anewarray) || (node->getOpCodeValue()==TR::newarray))) ||
            ((node->getNumChildren()==2) && (node->getOpCodeValue()==TR::New)))
         {
         // Remove the last literal pool child.
         node->removeLastChild();
         }
      return generateHelperCallForVMNewEvaluators(node, cg);
      }
   }

TR::Register *
J9::Z::TreeEvaluator::VMarrayCheckEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(cg->fe());
   TR::Node     *object1    = node->getFirstChild();
   TR::Node     *object2    = node->getSecondChild();
   TR::Register *object1Reg = cg->evaluate(object1);
   TR::Register *object2Reg = cg->evaluate(object2);

   TR::LabelSymbol *fallThrough  = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::Instruction *instr;
   TR::LabelSymbol *snippetLabel = NULL;
   TR::Snippet     *snippet      = NULL;
   TR::Register    *tempReg      = cg->allocateRegister();
   TR::Register    *tempClassReg = cg->allocateRegister();
   TR::InstOpCode::Mnemonic loadOpcode;
   TR::RegisterDependencyConditions *deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 7, cg);

   fallThrough->setEndInternalControlFlow();

   // If the objects are the same and one of them is known to be an array, they
   // are compatible.
   //
   if (node->isArrayChkPrimitiveArray1() ||
       node->isArrayChkReferenceArray1() ||
       node->isArrayChkPrimitiveArray2() ||
       node->isArrayChkReferenceArray2())
      {
      instr = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::getCmpRegOpCode(), node, object1Reg, object2Reg, TR::InstOpCode::COND_BE, fallThrough, false, false);
      instr->setStartInternalControlFlow();
      }

   else
      {
      // Neither object is known to be an array
      // Check that object 1 is an array. If not, throw exception.
      //
      TR::Register * class1Reg = cg->allocateRegister();
      TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node, class1Reg, generateS390MemoryReference(object1Reg, TR::Compiler->om.offsetOfObjectVftField(), cg), NULL);

      // TODO: Can we check the value of J9_JAVA_CLASS_RAM_ARRAY and use NILF here?
#ifdef TR_HOST_64BIT
      genLoadLongConstant(cg, node, J9_JAVA_CLASS_RAM_ARRAY, tempReg, NULL, deps, NULL);
      generateRXInstruction(cg, TR::InstOpCode::NG, node, tempReg,
      new (cg->trHeapMemory()) TR::MemoryReference(class1Reg, offsetof(J9Class, classDepthAndFlags), cg));
#else
      generateLoad32BitConstant(cg, node, J9_JAVA_CLASS_RAM_ARRAY, tempReg, true, NULL, deps, NULL);
      generateRXInstruction(cg, TR::InstOpCode::N, node, tempReg,
      new (cg->trHeapMemory()) TR::MemoryReference(class1Reg, offsetof(J9Class, classDepthAndFlags), cg));
#endif
      cg->stopUsingRegister(class1Reg);

      if (!snippetLabel)
         {
         snippetLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
         instr        = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BZ,   node, snippetLabel);
         instr->setStartInternalControlFlow();

         snippet      = new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, snippetLabel, node->getSymbolReference());
         cg->addSnippet(snippet);
         }
      else
         {
         instr        = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BZ,   node, snippetLabel);
         instr->setStartInternalControlFlow();
         }
      }

   // Test equality of the object classes.
   //
   TR::TreeEvaluator::genLoadForObjectHeaders(cg, node, tempReg, generateS390MemoryReference(object1Reg, TR::Compiler->om.offsetOfObjectVftField(), cg), NULL);

#ifdef J9VM_INTERP_COMPRESSED_OBJECT_HEADER
   generateRXInstruction(cg, TR::InstOpCode::X, node, tempReg, generateS390MemoryReference(object2Reg, TR::Compiler->om.offsetOfObjectVftField(), cg));
#else
   generateRXInstruction(cg, TR::InstOpCode::getXOROpCode(), node, tempReg, generateS390MemoryReference(object2Reg, TR::Compiler->om.offsetOfObjectVftField(), cg));
#endif

   TR::TreeEvaluator::generateVFTMaskInstruction(node, tempReg, cg);

   // XOR doesn't set the proper condition codes, so test explicitly
   generateRIInstruction(cg, TR::InstOpCode::getCmpHalfWordImmOpCode(), node, tempReg, 0);

   // If either object is known to be a primitive array, we are done. Either
   // the equality test fails and we throw the exception or it succeeds and
   // we finish.
   //
   if (node->isArrayChkPrimitiveArray1() || node->isArrayChkPrimitiveArray2())
      {
      if (!snippetLabel)
         {
         snippetLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
         instr        = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, snippetLabel);

         snippet      = new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, snippetLabel, node->getSymbolReference());
         cg->addSnippet(snippet);
         }
      else
         {
         instr        = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, snippetLabel);
         }
      }

   // Otherwise, there is more testing to do. If the classes are equal we
   // are done, and branch to the fallThrough label.
   //
   else
      {
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, fallThrough);

      // If either object is not known to be a reference array type, check it
      // We already know that object1 is an array type but we may have to now
      // check object2.
      //
      if (!node->isArrayChkReferenceArray1())
         {
         TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node, tempClassReg, generateS390MemoryReference(object1Reg, TR::Compiler->om.offsetOfObjectVftField(), cg), NULL);

         // ramclass->classDepth&flags
         generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, tempReg,
         new (cg->trHeapMemory()) TR::MemoryReference(tempClassReg, offsetof(J9Class, classDepthAndFlags), cg));

         // X = (ramclass->ClassDepthAndFlags)>>J9_JAVA_CLASS_RAM_SHAPE_SHIFT
         generateRSInstruction(cg, TR::InstOpCode::SRL, node, tempReg, J9_JAVA_CLASS_RAM_SHAPE_SHIFT);

         // X & OBJECT_HEADER_SHAPE_MASK
         generateRRInstruction(cg, TR::InstOpCode::getXORRegOpCode(), node, tempClassReg, tempClassReg);
         generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, tempClassReg, OBJECT_HEADER_SHAPE_MASK);
         generateRRInstruction(cg, TR::InstOpCode::NR, node, tempClassReg, tempReg);

         generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, tempReg, OBJECT_HEADER_SHAPE_POINTERS);

        if (!snippetLabel)
            {
            snippetLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
            instr = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::CR, node, tempReg, tempClassReg, TR::InstOpCode::COND_BNZ, snippetLabel, false, false);

            snippet      = new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, snippetLabel, node->getSymbolReference());
            cg->addSnippet(snippet);
            }
         else
            {
            instr = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::CR, node, tempReg, tempClassReg, TR::InstOpCode::COND_BNZ, snippetLabel, false, false);
            }
         }
      if (!node->isArrayChkReferenceArray2())
         {
         // Check that object 2 is an array. If not, throw exception.
         TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node, tempClassReg, generateS390MemoryReference(object2Reg, TR::Compiler->om.offsetOfObjectVftField(), cg), NULL);

         // TODO: Can we check the value of J9_JAVA_CLASS_RAM_ARRAY and use NILF here?
#ifdef TR_HOST_64BIT
         {
         genLoadLongConstant(cg, node, J9_JAVA_CLASS_RAM_ARRAY, tempReg, NULL, deps, NULL);
         generateRXInstruction(cg, TR::InstOpCode::NG, node, tempReg,
         new (cg->trHeapMemory()) TR::MemoryReference(tempClassReg, offsetof(J9Class, classDepthAndFlags), cg));
         }
#else
         {
         generateLoad32BitConstant(cg, node, J9_JAVA_CLASS_RAM_ARRAY, tempReg, true, NULL, deps, NULL);
         generateRXInstruction(cg, TR::InstOpCode::N, node, tempReg,
         new (cg->trHeapMemory()) TR::MemoryReference(tempClassReg, offsetof(J9Class, classDepthAndFlags), cg));
         }
#endif
         if (!snippetLabel)
            {
            snippetLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
            instr        = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BZ,   node, snippetLabel);

            snippet      = new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, snippetLabel, node->getSymbolReference());
            cg->addSnippet(snippet);
            }
         else
            {
            instr        = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BZ,   node, snippetLabel);
            }

         //* Test object2 is reference array
         TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node, tempClassReg, generateS390MemoryReference(object2Reg, TR::Compiler->om.offsetOfObjectVftField(), cg), NULL);

         // ramclass->classDepth&flags
         generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, tempReg,
         new (cg->trHeapMemory()) TR::MemoryReference(tempClassReg, offsetof(J9Class, classDepthAndFlags), cg));

         // X = (ramclass->ClassDepthAndFlags)>>J9_JAVA_CLASS_RAM_SHAPE_SHIFT
         generateRSInstruction(cg, TR::InstOpCode::SRL, node, tempReg, J9_JAVA_CLASS_RAM_SHAPE_SHIFT);

         // X & OBJECT_HEADER_SHAPE_MASK
         generateRRInstruction(cg, TR::InstOpCode::getXORRegOpCode(), node, tempClassReg, tempClassReg);
         generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, tempClassReg,OBJECT_HEADER_SHAPE_MASK);
         generateRRInstruction(cg, TR::InstOpCode::NR, node, tempClassReg, tempReg);

         generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, tempReg, OBJECT_HEADER_SHAPE_POINTERS);

         instr = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::CR, node, tempReg, tempClassReg, TR::InstOpCode::COND_BNZ, snippetLabel, false, false);
         }

      // Now both objects are known to be reference arrays, so they are
      // compatible for arraycopy.
      }

   // Now generate the fall-through label
   //
   deps->addPostCondition(object1Reg, TR::RealRegister::AssignAny);
   deps->addPostConditionIfNotAlreadyInserted(object2Reg, TR::RealRegister::AssignAny);  // 1st and 2nd object may be the same.
   deps->addPostCondition(tempReg, TR::RealRegister::AssignAny);
   deps->addPostCondition(tempClassReg, TR::RealRegister::AssignAny);
   cg->addVMThreadPostCondition(deps, NULL);
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, fallThrough, deps);

   cg->stopUsingRegister(tempClassReg);
   cg->stopUsingRegister(tempReg);
   cg->decReferenceCount(object1);
   cg->decReferenceCount(object2);

   return 0;
   }



/////////////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////////////
static bool
inlineMathSQRT(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * targetRegister = NULL;
   static char * nosupportSQRT = feGetEnv("TR_NOINLINESQRT");

   if (NULL != nosupportSQRT)
      {
      return false;
      }


   // Calculate it for ourselves
   if (firstChild->getOpCode().isLoadConst())
      {
      union { double valD; int64_t valI; } result;
      targetRegister = cg->allocateRegister(TR_FPR);
      result.valD = sqrt(firstChild->getDouble());
      TR::S390ConstantDataSnippet * cds = cg->findOrCreate8ByteConstant(node, result.valI);
      generateRXInstruction(cg, TR::InstOpCode::LD, node, targetRegister, generateS390MemoryReference(cds, cg, 0, node));
      }
   else
      {
      TR::Register * opRegister = NULL;

      //See whether to use SQDB or SQDBR depending on how many times it is referenced
      if (firstChild->isSingleRefUnevaluated() && firstChild->getOpCodeValue() == TR::dloadi)
         {
         targetRegister = cg->allocateRegister(TR_FPR);
         generateRXInstruction(cg, TR::InstOpCode::SQDB, node, targetRegister, generateS390MemoryReference(firstChild, cg));
         }
      else
         {
         opRegister = cg->evaluate(firstChild);

         if (cg->canClobberNodesRegister(firstChild))
            {
            targetRegister = opRegister;
            }
         else
            {
            targetRegister = cg->allocateRegister(TR_FPR);
            }
         generateRRInstruction(cg, TR::InstOpCode::SQDBR, node, targetRegister, opRegister);
         }
      }

   node->setRegister(targetRegister);
   cg->decReferenceCount(firstChild);
   return true;
   }

static bool inlineIsAssignableFrom(TR::Node *node, TR::CodeGenerator *cg)
   {
   static char *disable = feGetEnv("TR_disableInlineIsAssignableFrom");
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());

   if (disable)
      return false;

   TR::Node *thisClass = node->getFirstChild();
   if (thisClass->getOpCodeValue() == TR::aloadi &&
         thisClass->getFirstChild()->getOpCodeValue() == TR::loadaddr)
      {
      TR::SymbolReference *thisClassSymRef = thisClass->getFirstChild()->getSymbolReference();

      if (thisClassSymRef->isClassInterface(comp) || thisClassSymRef->isClassAbstract(comp))
         {
         return false;
         }
      }

   int32_t classDepth = -1;
   TR::Node     *javaLangClassFrom = node->getFirstChild();
   if((javaLangClassFrom->getOpCodeValue() == TR::aloadi
         && javaLangClassFrom->getSymbolReference() == comp->getSymRefTab()->findJavaLangClassFromClassSymbolRef()
         && javaLangClassFrom->getFirstChild()->getOpCodeValue() == TR::loadaddr))
      {
      TR::Node   *castClassRef =javaLangClassFrom->getFirstChild();

      TR::SymbolReference *castClassSymRef = NULL;
      if(castClassRef->getOpCode().hasSymbolReference())
         castClassSymRef= castClassRef->getSymbolReference();

      TR::StaticSymbol    *castClassSym = NULL;
      if (castClassSymRef && !castClassSymRef->isUnresolved())
         castClassSym= castClassSymRef ? castClassSymRef->getSymbol()->getStaticSymbol() : NULL;

      TR_OpaqueClassBlock * clazz = NULL;
      if (castClassSym)
         clazz = (TR_OpaqueClassBlock *) castClassSym->getStaticAddress();

      if(clazz)
         classDepth = (int32_t)TR::Compiler->cls.classDepthOf(clazz);
      }

   TR::Register        *returnRegister = NULL;
   TR::SymbolReference *symRef     = node->getSymbolReference();
   TR::MethodSymbol    *callSymbol = symRef->getSymbol()->castToMethodSymbol();

   TR::LabelSymbol *startLabel = generateLabelSymbol(cg);
//   startLabel->setStartInternalControlFlow();
   TR::LabelSymbol *doneLabel = generateLabelSymbol(cg);
   TR::LabelSymbol *failLabel = generateLabelSymbol(cg);
   TR::LabelSymbol *outlinedCallLabel = generateLabelSymbol(cg);
 //  doneLabel->setEndInternalControlFlow();

   TR::Register *thisClassReg = cg->evaluate(node->getFirstChild());
   TR::Register *checkClassReg = cg->evaluate(node->getSecondChild());

   TR::RegisterDependencyConditions * deps = NULL;


   TR::Register *tempReg = cg->allocateRegister();
   TR::Register *objClassReg, *castClassReg, *scratch1Reg,*scratch2Reg;
   int8_t numOfPostDepConditions = (thisClassReg == checkClassReg)? 2 : 3;


   if (classDepth != -1)
      {
      deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, numOfPostDepConditions+4, cg);
      objClassReg = cg->allocateRegister();
      castClassReg = cg->allocateRegister();
      scratch1Reg = cg->allocateRegister();
      scratch2Reg = cg->allocateRegister();
      deps->addPostCondition(scratch1Reg, TR::RealRegister::AssignAny);
      deps->addPostCondition(scratch2Reg, TR::RealRegister::AssignAny);
      deps->addPostCondition(castClassReg, TR::RealRegister::AssignAny);
      deps->addPostCondition(objClassReg, TR::RealRegister::AssignAny);

      }
   else
      {
      deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, numOfPostDepConditions, cg);
      objClassReg = tempReg;
      }

   deps->addPostCondition(thisClassReg, TR::RealRegister::AssignAny);
   if (thisClassReg != checkClassReg)
     {
     deps->addPostCondition(checkClassReg, TR::RealRegister::AssignAny);
     }
   deps->addPostCondition(tempReg, TR::RealRegister::AssignAny);

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, startLabel);

   genNullTest(cg, node, thisClassReg, thisClassReg, NULL);
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, outlinedCallLabel);
   genNullTest(cg, node, checkClassReg, checkClassReg, NULL);
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, outlinedCallLabel);

   generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, objClassReg,
                generateS390MemoryReference(checkClassReg, fej9->getOffsetOfClassFromJavaLangClassField(), cg));

   generateRXInstruction(cg, TR::InstOpCode::getCmpLogicalOpCode(), node, objClassReg,
         generateS390MemoryReference(thisClassReg, fej9->getOffsetOfClassFromJavaLangClassField(), cg));

   generateRIInstruction(cg, TR::InstOpCode::LHI, node, tempReg, 1);

   TR_Debug * debugObj = cg->getDebug();
   if (classDepth != -1)
      {
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, doneLabel);
      generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, castClassReg,
                                                generateS390MemoryReference(thisClassReg, fej9->getOffsetOfClassFromJavaLangClassField(), cg));

      genTestIsSuper(cg, node, objClassReg, castClassReg, scratch1Reg, scratch2Reg, tempReg, NULL, classDepth, failLabel, doneLabel, NULL, deps, NULL, false, NULL, NULL);

      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, doneLabel);
      }
   else
      {
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, outlinedCallLabel);
      }


   TR_S390OutOfLineCodeSection *outlinedHelperCall = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(node, TR::icall, tempReg, outlinedCallLabel, doneLabel, cg);
   cg->getS390OutOfLineCodeSectionList().push_front(outlinedHelperCall);
   outlinedHelperCall->generateS390OutOfLineCodeSectionDispatch();


   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());

   node->setRegister(tempReg);

   if (classDepth != -1)
      {
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, failLabel, deps);
      generateRIInstruction(cg, TR::InstOpCode::LHI, node, tempReg, 0);

      cg->stopUsingRegister(objClassReg);
      cg->stopUsingRegister(castClassReg);
      cg->stopUsingRegister(scratch1Reg);
      cg->stopUsingRegister(scratch2Reg);
      }
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, deps);

   return true;
   }


bool
J9::Z::TreeEvaluator::VMinlineCallEvaluator(TR::Node * node, bool indirect, TR::CodeGenerator * cg)
   {
   TR::ResolvedMethodSymbol * methodSymbol = node->getSymbol()->getResolvedMethodSymbol();

   if (!methodSymbol)
      {
      return false;
      }


   bool callWasInlined = false;
   if (methodSymbol)
      {
      switch (methodSymbol->getRecognizedMethod())
         {
         case TR::java_lang_StrictMath_sqrt:
         case TR::java_lang_Math_sqrt:
            {
            callWasInlined = inlineMathSQRT(node, cg);
            break;
            }
         case TR::java_lang_Class_isAssignableFrom:
            {
            callWasInlined = inlineIsAssignableFrom(node, cg);
            break;
            }
         }
      }

   return callWasInlined;
   }


void
J9::Z::TreeEvaluator::genArrayCopyWithArrayStoreCHK(TR::Node* node, TR::Register *srcObjReg, TR::Register *dstObjReg, TR::Register *srcAddrReg, TR::Register *dstAddrReg, TR::Register *lengthReg, TR::CodeGenerator *cg)
   {
   TR::Instruction *iCursor;
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(cg->fe());
   intptrj_t *funcdescrptr = (intptrj_t*) fej9->getReferenceArrayCopyHelperAddress();

   TR::RegisterDependencyConditions * deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(9, 9, cg);
   TR::LabelSymbol * doneLabel, * callLabel, * OKLabel;
   doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   callLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   OKLabel   = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::Snippet * snippet;
   TR::Linkage * linkage = cg->getLinkage(node->getSymbol()->castToMethodSymbol()->getLinkageConvention());
   TR::SystemLinkage *sysLink = (TR::SystemLinkage *) cg->getLinkage(TR_System);

   TR::RealRegister *sspRegReal = sysLink->getStackPointerRealRegister();
   TR::Register *sspReg;

   TR::Compilation *comp = cg->comp();

   if (sspRegReal->getState() == TR::RealRegister::Locked)
      {
      sspReg = sspRegReal;
      }
   else
      {
      sspReg = cg->allocateRegister();
      }

   TR::Register *helperReg = cg->allocateRegister();
   TR::Register         *thdReg = cg->getVMThreadRegister();
   int32_t  offset  = sysLink->getOffsetToFirstParm();
   int32_t  ptrSize = (int32_t)TR::Compiler->om.sizeofReferenceAddress();

   // Set the following parms in C parm area
   // 1) VM Thread
   // 2) srcObj
   // 3) dstObj
   // 4) srcAddr
   // 5) dstAddr
   // 6) num of slots
   // 7) VM referenceArrayCopy func desc
   TR::Register *metaReg;
   if (!comp->getOption(TR_Enable390FreeVMThreadReg))
      metaReg  = cg->getMethodMetaDataRealRegister();
   else
      {
      metaReg = cg->getVMThreadRegister();
      }
   if (sspRegReal->getState() != TR::RealRegister::Locked)
      {
       deps->addPreCondition(sspReg, TR::RealRegister::GPR4);
       deps->addPostCondition(sspReg, TR::RealRegister::GPR4);
      }
   if (cg->supportsJITFreeSystemStackPointer())
      {
      generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, sspReg,
         generateS390MemoryReference(metaReg, (int32_t)(fej9->thisThreadGetSystemSPOffset()), cg));
      generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, helperReg, 0);
      generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, helperReg,
         generateS390MemoryReference(metaReg, (int32_t)(fej9->thisThreadGetSystemSPOffset()), cg));
      }

   TR::Instruction *inst = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, metaReg,
         generateS390MemoryReference(sspReg, offset+0*ptrSize, cg));
   if (comp->getOption(TR_Enable390FreeVMThreadReg))
      {
      TR::RegisterDependencyConditions *vmThreadConds = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(1,0, cg);
      cg->addVMThreadPreCondition(vmThreadConds, NULL);
      inst->setDependencyConditions(vmThreadConds);
      }
   generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, srcObjReg,
         generateS390MemoryReference(sspReg, offset+1*ptrSize, cg));
   generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, dstObjReg,
         generateS390MemoryReference(sspReg, offset+2*ptrSize, cg));
   generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, srcAddrReg,
         generateS390MemoryReference(sspReg, offset+3*ptrSize, cg));
   generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, dstAddrReg,
         generateS390MemoryReference(sspReg, offset+4*ptrSize, cg));

   TR::Register *countReg  = cg->allocateRegister();
   generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, countReg, lengthReg  );
   int32_t shiftAmount = comp->useCompressedPointers() ? (int32_t)TR::Compiler->om.sizeofReferenceField()
                                                             : (int32_t)TR::Compiler->om.sizeofReferenceAddress();
   generateRSInstruction(cg, TR::InstOpCode::SRL, node,  countReg, trailingZeroes(shiftAmount));
   generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, countReg,
         generateS390MemoryReference(sspReg, offset+5*ptrSize, cg));
   cg->stopUsingRegister(countReg);

   if (comp->compileRelocatableCode())
      generateRegLitRefInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, helperReg, (intptrj_t)funcdescrptr, TR_ArrayCopyHelper, NULL, NULL, NULL);
   else
      genLoadAddressConstant(cg, node, (long) funcdescrptr, helperReg);
   generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, helperReg,
         generateS390MemoryReference(sspReg, offset+6*ptrSize, cg));
   cg->stopUsingRegister(helperReg);

   TR::Register *rcReg     = cg->allocateRegister();
   TR::Register *raReg     = cg->allocateRegister();
   TR::Register *tmpReg    = cg->allocateRegister();
   TR::Register *R2SaveReg = cg->allocateRegister();

   snippet = new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, callLabel, cg->symRefTab()->findOrCreateRuntimeHelper(TR_S390referenceArrayCopyHelper, false, false, false), doneLabel);
   cg->addSnippet(snippet);
   void*     destAddr = cg->symRefTab()->findOrCreateRuntimeHelper(TR_S390referenceArrayCopyHelper, false, false, false)->getMethodAddress();

// The snippet kill r14 and may kill r15, the rc is in r2
   deps->addPostCondition(rcReg,  linkage->getIntegerReturnRegister());
   deps->addPostCondition(raReg,  linkage->getReturnAddressRegister());
   deps->addPostCondition(tmpReg, linkage->getEntryPointRegister());
   cg->addVMThreadPostCondition(deps, NULL);

   TR::Instruction *gcPoint =
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, callLabel);
   gcPoint->setNeedsGCMap(0xFFFFFFFF);

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel);

   if (cg->supportsJITFreeSystemStackPointer())
      {
      generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, sspReg,
      generateS390MemoryReference(metaReg, (int32_t)(fej9->thisThreadGetSystemSPOffset()), cg));
      }

   if (sspRegReal->getState() != TR::RealRegister::Locked)
      {
      cg->stopUsingRegister(sspReg);
      }

   generateRIInstruction(cg, TR::InstOpCode::getCmpHalfWordImmOpCode(), node, rcReg, 65535);

   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, OKLabel);

   // raise exceptions
   TR::SymbolReference *throwSymRef = comp->getSymRefTab()->findOrCreateArrayStoreExceptionSymbolRef(comp->getJittedMethodSymbol());
   TR::LabelSymbol *exceptionSnippetLabel = cg->lookUpSnippet(TR::Snippet::IsHelperCall, throwSymRef);
   if (exceptionSnippetLabel == NULL)
      {
      exceptionSnippetLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      cg->addSnippet(new (cg->trHeapMemory()) TR::S390HelperCallSnippet(cg, node, exceptionSnippetLabel, throwSymRef));
      }

   gcPoint = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, exceptionSnippetLabel);
   gcPoint->setNeedsGCMap(0xFFFFFFFF);

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, OKLabel, deps);

   cg->stopUsingRegister(raReg);
   cg->stopUsingRegister(tmpReg);
   cg->stopUsingRegister(rcReg);
   cg->stopUsingRegister(R2SaveReg);

   return;
   }

void
J9::Z::TreeEvaluator::restoreGPR7(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR::MemoryReference * tempMR = generateS390MemoryReference(cg->getMethodMetaDataRealRegister(), offsetof(J9VMThread, tempSlot), cg);
   TR::Register * tempReg = cg->allocateRegister();
   generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node,   cg->machine()->getS390RealRegister(TR::RealRegister::GPR7), tempMR);
   }

void J9::Z::TreeEvaluator::genWrtbarForArrayCopy(TR::Node *node, TR::Register *srcReg, TR::Register *dstReg, bool srcNonNull, TR::CodeGenerator *cg)
   {
   TR::Instruction * cursor;
   TR::RegisterDependencyConditions * conditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 4, cg);
   TR::Compilation * comp = cg->comp();

   TR_WriteBarrierKind gcMode = comp->getOptions()->getGcMode();
   bool doWrtBar = (gcMode == TR_WrtbarOldCheck || gcMode == TR_WrtbarCardMarkAndOldCheck || gcMode == TR_WrtbarAlways);
   // Do not do card marking when gcMode is TR_WrtbarCardMarkAndOldCheck - we go through helper, which performs CM, so it is redundant.
   bool doCrdMrk = (gcMode == TR_WrtbarCardMark || gcMode == TR_WrtbarCardMarkIncremental);
   TR::LabelSymbol * doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   if (doWrtBar)
      {
      TR::Register * tempReg = cg->allocateRegister();
      TR::Register * tempReg2 = cg->allocateRegister();
      TR::SymbolReference * wbref = comp->getSymRefTab()->findOrCreateWriteBarrierBatchStoreSymbolRef(comp->getMethodSymbol());

      TR::Register * srcObjReg = srcReg;
      TR::Register * dstObjReg;
      // It's possible to have srcReg and dstReg point to same array
      // If so, we need to copy before calling helper
      if (srcReg == dstReg){
         dstObjReg = cg->allocateRegister();
         generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, dstObjReg, dstReg);
      }
      else
         dstObjReg = dstReg;

      conditions->addPostCondition(tempReg, cg->getReturnAddressRegister());
      conditions->addPostCondition(tempReg2, cg->getEntryPointRegister());
      conditions->addPostCondition(dstObjReg, TR::RealRegister::GPR1);

      /*** Start of VMnonNullSrcWrtBarEvaluator ***********************/
      // 83613: If this condition changes, please verify that the inline CM
      // conditions are still correct.  Currently, we don't perform inline CM
      // for old&CM objects, since this wrtbarEvaluator will call the helper,which
      // also performs CM.

      // check for old space or color black (fej9->getWriteBarrierGCFlagMaskAsByte())
      //
      //  object layout
      //   -------------
      //  |class_pointer|
      //   -------------
      //  |*****    flag|
      //   -------------
      //   .....
      //
      // flag is in the lower 2 bytes in a 8 byte slot on 64 bit obj.(4 byte slot in 32bit obj)
      // so the offset should be ...

      if (gcMode != TR_WrtbarAlways)
         {
         bool is64Bit = TR::Compiler->target.is64Bit();
         bool isConstantHeapBase = !comp->getOptions()->isVariableHeapBaseForBarrierRange0();
         bool isConstantHeapSize = !comp->getOptions()->isVariableHeapSizeForBarrierRange0();
         TR::Register * temp1Reg = cg->allocateRegister();

         conditions->addPostCondition(temp1Reg, TR::RealRegister::AssignAny);

         TR::MemoryReference * offset = generateS390MemoryReference(cg->getMethodMetaDataRealRegister(), offsetof(J9VMThread, heapBaseForBarrierRange0), cg);
         TR::MemoryReference * size = generateS390MemoryReference(cg->getMethodMetaDataRealRegister(), offsetof(J9VMThread, heapSizeForBarrierRange0), cg);
         generateRRInstruction(cg, is64Bit ? TR::InstOpCode::LGR : TR::InstOpCode::LR, node, temp1Reg, dstObjReg);
         generateRXInstruction(cg, is64Bit ? TR::InstOpCode::SG : TR::InstOpCode::S, node, temp1Reg, offset);
         generateRXInstruction(cg, is64Bit ? TR::InstOpCode::CLG : TR::InstOpCode::CL, node, temp1Reg, size);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BH, node, doneLabel);
         cg->stopUsingRegister(temp1Reg);
         // if not match, callout to the helper
         }

      generateDirectCall(cg, node, false, wbref, conditions);
      /*** End Of *****************************************************/
      cg->stopUsingRegister(tempReg);
      cg->stopUsingRegister(tempReg2);
      if (srcReg == dstReg)
         cg->stopUsingRegister(dstObjReg);
      }

   else if (doCrdMrk)
      {
      if (!TR::Options::getCmdLineOptions()->realTimeGC())
         {
         TR::Register * temp1Reg = cg->allocateRegister();
         conditions->addPostCondition(temp1Reg, TR::RealRegister::AssignAny);
         conditions->addPostCondition(dstReg, TR::RealRegister::AssignAny);
         VMCardCheckEvaluator(node, dstReg, temp1Reg, conditions, cg, false, doneLabel);
         cg->stopUsingRegister(temp1Reg);
         }
      else
         TR_ASSERT(0, "genWrtbarForArrayCopy card marking not supported for RT");
      }
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, conditions);
   }

static TR::Register *VMinlineCompareAndSwap(
      TR::Node *node,
      TR::CodeGenerator *cg,
      TR::InstOpCode::Mnemonic casOp,
      bool isObj)
   {
   TR::Register *scratchReg = NULL;
   TR::Register *objReg, *oldVReg, *newVReg;
   TR::Register *resultReg = cg->allocateRegister();
   TR::LabelSymbol *doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::MemoryReference* casMemRef = NULL;

   TR::Compilation * comp = cg->comp();

   TR::Node* thisNode   = node->getChild(0);
   TR::Node* objNode    = node->getChild(1);
   TR::Node* offsetNode = node->getChild(2);
   TR::Node* oldVNode   = node->getChild(3);
   TR::Node* newVNode   = node->getChild(4);

   bool usingCompressedPointers = false;
   TR::Node *translatedNode = newVNode;
   if (isObj && comp->useCompressedPointers() &&
         translatedNode->getOpCodeValue() == TR::l2i)
      {
      // pattern match the sequence
      //  icall                         <- node
      //     thisNode
      //     objNode
      //     offsetNode
      //     l2i                        <- oldVNode
      //        lushr
      //           a2l
      //              oldValue
      //           iconst shftKonst
      //     l2i                        <- newVNode
      //        lushr
      //           a2l
      //              newValue
      //           iconst shftKonst
      //
      ////usingCompressedPointers = true;

      if (translatedNode->getOpCode().isConversion())
         translatedNode = translatedNode->getFirstChild();
      if (translatedNode->getOpCode().isRightShift()) // optional
         translatedNode = translatedNode->getFirstChild();

      bool usingLowMemHeap = false;
      if (TR::Compiler->vm.heapBaseAddress() == 0 ||
             newVNode->isNull())
         usingLowMemHeap = true;

      if (translatedNode->getOpCode().isSub() || usingLowMemHeap)
         usingCompressedPointers = true;

      if (usingCompressedPointers)
         {
         while ((translatedNode->getNumChildren() > 0) && (translatedNode->getOpCodeValue() != TR::a2l))
            translatedNode = translatedNode->getFirstChild();
         if (translatedNode->getOpCodeValue() == TR::a2l)
            translatedNode = translatedNode->getFirstChild();
         // artificially bump up the refCount on the value so
         // that different registers are allocated for the actual
         // and compressed values. this is done so that the VMwrtbarEvaluator
         // uses the uncompressed value
         //
         translatedNode->incReferenceCount();
         }
      }

   // Eval old and new vals
   //
   objReg  = cg->evaluate(objNode);
   oldVReg = cg->gprClobberEvaluate(oldVNode);  //  CS oldReg, newReg, OFF(objReg)
   newVReg = cg->evaluate(newVNode);                    //    oldReg is clobbered

   TR::Register * compressedRegister = newVReg;
   if (usingCompressedPointers)
      compressedRegister = cg->evaluate(translatedNode);

   bool needsDup = false;

   if (objReg == newVReg)
      {
      // Make a copy of the register - reg deps later on expect them in different registers.
      newVReg = cg->allocateCollectedReferenceRegister();
      generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, newVReg, objReg);
      if (!usingCompressedPointers)
         compressedRegister = newVReg;

      needsDup = true;
      }

   generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, resultReg, 0x0);

   //  We can run into trouble when the offset value gets too big, or it may
   //  simply not nbe known at compile time.
   //
   if (offsetNode->getOpCode().isLoadConst() && offsetNode->getRegister()==NULL)
      {
      // We know at compile time
      intptr_t offsetValue = offsetNode->getLongInt();
      if (offsetValue>=0 && offsetValue<MAXDISP)
         {
         casMemRef = generateS390MemoryReference(objReg, offsetValue, cg);
         }
         //  ADD Golden Eagle support here if we ever see this path take (unlikely)
      }

   //  We couldn't figure out how to get the offset into the DISP field of the CAS inst
   //  So use an explicit local ADD
   //
   if (casMemRef == NULL)  // Not setup, hence we need a reg
      {
      scratchReg = cg->gprClobberEvaluate(offsetNode);

      // On 31bit we only care about the low word
      //
      if (TR::Compiler->target.is32Bit() && !cg->use64BitRegsOn32Bit())
         {
         generateRRInstruction(cg, TR::InstOpCode::getAddRegOpCode(), node, scratchReg->getLowOrder(),objReg);
         casMemRef = generateS390MemoryReference(scratchReg->getLowOrder(), 0, cg);
         }
      else
         {
         generateRRInstruction(cg, TR::InstOpCode::getAddRegOpCode(), node, scratchReg,objReg);
         casMemRef = generateS390MemoryReference(scratchReg, 0, cg);
         }
      }

   // Compare and swap
   //
   generateRSInstruction(cg, casOp, node, oldVReg, newVReg, casMemRef);

   //  Setup return
   //
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, doneLabel);

   generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, resultReg, 0x1);

   TR::RegisterDependencyConditions* cond = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 1, cg);
   cond->addPostCondition(resultReg, TR::RealRegister::AssignAny);

   cg->addVMThreadPostCondition(cond, NULL);
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, cond);

   // Do wrtbar for Objects
   //
   TR_WriteBarrierKind gcMode = comp->getOptions()->getGcMode();
   bool doWrtBar = (gcMode == TR_WrtbarOldCheck || gcMode == TR_WrtbarCardMarkAndOldCheck ||
                    gcMode == TR_WrtbarAlways);
   bool doCrdMrk = (gcMode == TR_WrtbarCardMark || gcMode == TR_WrtbarCardMarkAndOldCheck ||
                    gcMode == TR_WrtbarCardMarkIncremental);

   if (isObj && (doWrtBar || doCrdMrk))
      {
      TR::LabelSymbol *doneLabelWrtBar = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::Register *epReg = cg->allocateRegister();
      TR::Register *raReg = cg->allocateRegister();
      TR::RegisterDependencyConditions* condWrtBar = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 5, cg);
      condWrtBar->addPostCondition(objReg, TR::RealRegister::GPR1);
      if (compressedRegister != newVReg)
         condWrtBar->addPostCondition(newVReg, TR::RealRegister::AssignAny); //defect 92001
      if (compressedRegister != objReg)  // add this because I got conflicting dependencies on GPR1 and GPR2!
         condWrtBar->addPostCondition(compressedRegister, TR::RealRegister::GPR2); //defect 92001
      condWrtBar->addPostCondition(epReg, cg->getEntryPointRegister());
      condWrtBar->addPostCondition(raReg, cg->getReturnAddressRegister());
      // Cardmarking is not inlined for gencon. Consider doing so when perf issue arises.
      if (doWrtBar)
         {
         TR::SymbolReference *wbRef;
         TR_WriteBarrierKind gcMode = comp->getOptions()->getGcMode();

         if (gcMode == TR_WrtbarCardMarkAndOldCheck || gcMode == TR_WrtbarOldCheck)
            wbRef = comp->getSymRefTab()->findOrCreateWriteBarrierStoreGenerationalSymbolRef(comp->getMethodSymbol());
         else
            wbRef = comp->getSymRefTab()->findOrCreateWriteBarrierStoreSymbolRef(comp->getMethodSymbol());
         VMnonNullSrcWrtBarCardCheckEvaluator(node, objReg, compressedRegister, epReg, raReg, doneLabelWrtBar, wbRef, condWrtBar, cg, false);
         }

      else if (doCrdMrk)
         {
         VMCardCheckEvaluator(node, objReg, epReg, condWrtBar, cg, false, doneLabelWrtBar, false);
                                                                           // true #1 -> copy of objReg just happened, it's safe to clobber tempReg
                                                                           // false #2 -> Don't do compile time check for heap obj
         }

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabelWrtBar, condWrtBar);

      cg->stopUsingRegister(epReg);
      cg->stopUsingRegister(raReg);
      }

   // Value is not used, and not eval'd to avoid the extra reg
   //  So recursively decrement to compensate
   //
   cg->recursivelyDecReferenceCount(thisNode);

   cg->decReferenceCount(objNode);
   cg->decReferenceCount(offsetNode);
   cg->decReferenceCount(oldVNode);
   cg->decReferenceCount(newVNode);

   cg->stopUsingRegister(oldVReg);

   if (needsDup)
      {
      cg->stopUsingRegister(newVReg);
      }
   if (scratchReg)
      {
      cg->stopUsingRegister(scratchReg);
      }

   if (usingCompressedPointers)
      cg->decReferenceCount(translatedNode);

   node->setRegister(resultReg);
   return resultReg;
   }


/////////////////////////////////////////////////////////////////////////////////
//  getTOCOffset()
//     return codertTOC offset from vmThread (R13)
////////////////////////////////////////////////////////////////////////////////
int
getTOCOffset()
   {
   return (offsetof(J9VMThread, codertTOC));
   }

TR::Instruction *
J9::Z::TreeEvaluator::generateVFTMaskInstruction(TR::Node *node, TR::Register *reg, TR::CodeGenerator *cg, TR::Instruction *preced)
   {
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(cg->fe());
   TR::Instruction *result = preced;
   uintptrj_t mask = TR::Compiler->om.maskOfObjectVftField();
   if (~mask == 0)
      {
      // no mask instruction required
      }
   else if (~mask <= 0xffff)
      {
      result = generateRIInstruction(cg, TR::InstOpCode::NILL, node, reg, mask, preced);
      }
   else
      {
      TR_ASSERT(0, "Can't mask out flag bits beyond the low 16 from the VFT pointer");
      }
   return result;
   }

// This routine generates RION and RIOFF guarded by VMThread->jitCurrentRIFlags
// based on test for bit: J9_JIT_TOGGLE_RI_IN_COMPILED_CODE
TR::Instruction *
J9::Z::TreeEvaluator::generateRuntimeInstrumentationOnOffSequence(TR::CodeGenerator *cg, TR::InstOpCode::Mnemonic op, TR::Node *node, TR::Instruction *preced, bool postRA)
   {
   TR::Compilation *comp = cg->comp();
   TR_ASSERT(op == TR::InstOpCode::RION || op == TR::InstOpCode::RIOFF, "Unexpected Runtime Instrumentation OpCode");

#ifdef TR_HOST_S390
   TR::LabelSymbol * OOLStartLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * OOLReturnLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR_Debug * debugObj = cg->getDebug();

   // Test the last byte of vmThread->jitCurrentRIFlags
   TR_ASSERT(0 != (J9_JIT_TOGGLE_RI_IN_COMPILED_CODE & 0xFF), "Cannot use TM to test for J9_JIT_TOGGLE_RI_IN_COMPILED_CODE");
   TR::MemoryReference *vmThreadMemRef = generateS390MemoryReference(cg->getMethodMetaDataRealRegister(), offsetof(J9VMThread, jitCurrentRIFlags) + sizeof(((J9VMThread *)0)->jitCurrentRIFlags) - 1, cg);
   preced = generateSIInstruction(cg, TR::InstOpCode::TM, node, vmThreadMemRef, J9_JIT_TOGGLE_RI_IN_COMPILED_CODE, preced);
   preced = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK7, node, OOLStartLabel, preced);

   if (debugObj)
      if (op == TR::InstOpCode::RION)
         debugObj->addInstructionComment(preced, "-->OOL RION");
      else
         debugObj->addInstructionComment(preced, "-->OOL RIOFF");


   TR_S390OutOfLineCodeSection *RIOnOffOOL = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(OOLStartLabel, OOLReturnLabel, cg);
   cg->getS390OutOfLineCodeSectionList().push_front(RIOnOffOOL);
   RIOnOffOOL->swapInstructionListsWithCompilation();

   TR::Instruction * cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, OOLStartLabel);
   if (debugObj)
      debugObj->addInstructionComment(cursor, "OOL RION/OFF seq");

   // Generate the RION/RIOFF instruction.
   cursor = generateRuntimeInstrumentationInstruction(cg, op, node, NULL, cursor);

   cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, OOLReturnLabel, cursor);

   RIOnOffOOL->swapInstructionListsWithCompilation();

   preced = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, OOLReturnLabel, preced);

   // OOL's are appended to the instruction stream during RA.  If this is
   // emitted postRA, we have to attach it ourselves.
   if (postRA)
      {
      TR::Instruction *appendInstruction = cg->getAppendInstruction();
      appendInstruction->setNext(RIOnOffOOL->getFirstInstruction());
      RIOnOffOOL->getFirstInstruction()->setPrev(appendInstruction);
      cg->setAppendInstruction(RIOnOffOOL->getAppendInstruction());
      }
#endif /* TR_HOST_S390 */
   return preced;
   }


#if defined(TR_HOST_S390) && defined(J9ZOS390)
// psuedo-call to asm function
extern "C" void _getSTCKLSOOffset(int32_t* offsetArray);  /* 390 asm stub */
#endif

/**
 * generate a single precision sqrt instruction
 */
static TR::Register * inlineSinglePrecisionSQRT(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * targetRegister = NULL;
   TR::Register * opRegister = cg->evaluate(firstChild);

   if (cg->canClobberNodesRegister(firstChild))
      {
      targetRegister = opRegister;
      }
   else
      {
      targetRegister = cg->allocateRegister(TR_FPR);
      }
   generateRRInstruction(cg, TR::InstOpCode::SQEBR, node, targetRegister, opRegister);
   node->setRegister(targetRegister);
   cg->decReferenceCount(firstChild);
   return node->getRegister();
   }

/** \brief
 *     Evaluates a sequence of instructions which generate the current time in terms of 1/2048 of micro-seconds.
 *
 *  \param cg
 *     The code generator used to generate the instructions.
 *
 *  \param node
 *     The node with which to associate the generated instructions with.
 *
 *  \return
 *     A register (or register pair for 31-bit) containing the current time in terms of 1/2048 of micro-seconds.
 */
static TR::Register* inlineCurrentTimeMaxPrecision(TR::CodeGenerator* cg, TR::Node* node)
   {
   // STCKF is an S instruction and requires a 64-bit memory reference
   TR::SymbolReference* reusableTempSlot = cg->allocateReusableTempSlot();

   generateSInstruction(cg, TR::InstOpCode::STCKF, node, generateS390MemoryReference(node, reusableTempSlot, cg));

   // Dynamic literal pool could have assigned us a literal base register
   TR::Register* literalBaseRegister = (node->getNumChildren() == 1) ? cg->evaluate(node->getFirstChild()) : NULL;

   TR::Register* targetRegister;

   if (TR::Compiler->target.is64Bit() || cg->use64BitRegsOn32Bit())
      {
      targetRegister = cg->allocate64bitRegister();

#if defined(TR_HOST_S390) && defined(J9ZOS390)
      int32_t offsets[3];
      _getSTCKLSOOffset(offsets);

      TR::Register* tempRegister = cg->allocate64bitRegister();

      // z/OS requires time correction to account for leap seconds. The number of leap seconds is stored in the LSO
      // field of the MVS data area.
      if (TR::Compiler->target.isZOS())
         {
         // Load FFCVT(R0)
         generateRXYInstruction(cg, TR::InstOpCode::LLGT, node, tempRegister, generateS390MemoryReference(offsets[0], cg));

         // Load CVTEXT2 - CVT
         generateRXYInstruction(cg, TR::InstOpCode::LLGT, node, tempRegister, generateS390MemoryReference(tempRegister, offsets[1], cg));
         }
#endif

      generateRXInstruction(cg, TR::InstOpCode::LG, node, targetRegister, generateS390MemoryReference(node, reusableTempSlot, cg));

      int64_t todJanuary1970 = 0x7D91048BCA000000LL;
      generateRegLitRefInstruction(cg, TR::InstOpCode::SLG, node, targetRegister, todJanuary1970, NULL, NULL, literalBaseRegister);

#if defined(TR_HOST_S390) && defined(J9ZOS390)
      if (TR::Compiler->target.isZOS())
         {
         // Subtract the LSO offset
         generateRXYInstruction(cg, TR::InstOpCode::SLG, node, targetRegister, generateS390MemoryReference(tempRegister, offsets[2],cg));
         }

      cg->stopUsingRegister(tempRegister);
#endif

      // Get current time in terms of 1/2048 of micro-seconds
      generateRSInstruction(cg, TR::InstOpCode::SRLG, node, targetRegister, targetRegister, 1);
      }
   else
      {
      targetRegister = cg->allocateConsecutiveRegisterPair();

      TR::Register* tempRegister1 = cg->allocateRegister();
      TR::Register* tempRegister2 = cg->allocateRegister();

#if defined(TR_HOST_S390) && defined(J9ZOS390)
      int32_t offsets[3];
      _getSTCKLSOOffset(offsets);

      // z/OS requires time correction to account for leap seconds. The number of leap seconds is stored in the LSO
      // field of the MVS data area.
      if (TR::Compiler->target.isZOS())
         {
         // Load FFCVT(r0)
         generateRXYInstruction(cg, TR::InstOpCode::L, node, tempRegister1, generateS390MemoryReference(offsets[0], cg));

         // Load CVTEXT2 - CVT
         generateRXYInstruction(cg, TR::InstOpCode::L, node, tempRegister1, generateS390MemoryReference(tempRegister1, offsets[1],cg));
         }
#endif

      generateRSInstruction(cg, TR::InstOpCode::LM, node, targetRegister, generateS390MemoryReference(node, reusableTempSlot, cg));

      int32_t todJanuary1970High = 0x7D91048B;
      int32_t todJanuary1970Low = 0xCA000000;

      // tempRegister2 is not actually used
      generateS390ImmOp(cg, TR::InstOpCode::SL, node, tempRegister2, targetRegister->getLowOrder(), todJanuary1970Low, NULL, literalBaseRegister);
      generateS390ImmOp(cg, TR::InstOpCode::SLB, node, tempRegister2, targetRegister->getHighOrder(), todJanuary1970High, NULL, literalBaseRegister);

#if defined(TR_HOST_S390) && defined(J9ZOS390)
      if (TR::Compiler->target.isZOS())
         {
         // Subtract the LSO offset
         generateRXYInstruction(cg, TR::InstOpCode::SL, node, targetRegister->getLowOrder(), generateS390MemoryReference(tempRegister1, offsets[2] + 4, cg));
         generateRXYInstruction(cg, TR::InstOpCode::SLB, node, targetRegister->getHighOrder(), generateS390MemoryReference(tempRegister1, offsets[2], cg));
         }
#endif

      // Get current time in terms of 1/2048 of micro-seconds
      generateRSInstruction(cg, TR::InstOpCode::SRDL, node, targetRegister, 1);

      cg->stopUsingRegister(tempRegister1);
      cg->stopUsingRegister(tempRegister2);
      }

   cg->freeReusableTempSlot();

   if (literalBaseRegister != NULL)
      {
      cg->decReferenceCount(node->getFirstChild());
      }

   node->setRegister(targetRegister);

   return targetRegister;
   }

static bool
isKnownMethod(TR::MethodSymbol * methodSymbol)
   {
   return methodSymbol &&
          (methodSymbol->getRecognizedMethod() == TR::java_lang_Math_sqrt ||
           methodSymbol->getRecognizedMethod() == TR::java_lang_StrictMath_sqrt ||
           methodSymbol->getRecognizedMethod() == TR::java_lang_Class_isAssignableFrom);
   }

static TR::Register *inlineAtomicOps(
      TR::Node *node,
      TR::CodeGenerator *cg,
      int8_t size,
      TR::MethodSymbol *method,
      bool isArray = false)
   {
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   TR::Node *valueChild = node->getFirstChild();
   TR::Node *deltaChild = NULL;
   TR::Register *valueReg = cg->evaluate(valueChild);
   TR::Register *deltaReg = NULL;
   TR::Register *resultReg = NULL;

   int32_t delta = 0;
   int32_t numDeps = 4;

   bool isAddOp = true;
   bool isGetAndOp = true;
   bool isLong = false;
   bool isArgConstant = false;

   TR::RecognizedMethod currentMethod = method->getRecognizedMethod();

   // Gather information about the method
   //
   switch (currentMethod)
      {
      case TR::java_util_concurrent_atomic_AtomicBoolean_getAndSet:
      case TR::java_util_concurrent_atomic_AtomicInteger_getAndSet:
      case TR::java_util_concurrent_atomic_AtomicLong_getAndSet:
      case TR::java_util_concurrent_atomic_AtomicReference_getAndSet:
      case TR::java_util_concurrent_atomic_AtomicIntegerArray_getAndSet:
      case TR::java_util_concurrent_atomic_AtomicLongArray_getAndSet:
      case TR::java_util_concurrent_atomic_AtomicReferenceArray_getAndSet:
         {
         isAddOp = false;
         break;
         }
      case TR::java_util_concurrent_atomic_AtomicInteger_addAndGet:
      case TR::java_util_concurrent_atomic_AtomicIntegerArray_addAndGet:
         {
         isGetAndOp = false;
         }
      case TR::java_util_concurrent_atomic_AtomicInteger_getAndAdd:
      case TR::java_util_concurrent_atomic_AtomicIntegerArray_getAndAdd:
         {
         break;
         }
      case TR::java_util_concurrent_atomic_AtomicInteger_incrementAndGet:
      case TR::java_util_concurrent_atomic_AtomicIntegerArray_incrementAndGet:
         {
         isGetAndOp = false;
         }
      case TR::java_util_concurrent_atomic_AtomicInteger_getAndIncrement:
      case TR::java_util_concurrent_atomic_AtomicIntegerArray_getAndIncrement:
         {
         delta = (int32_t)1;
         isArgConstant = true;
         resultReg = cg->allocateRegister();
         break;
         }
      case TR::java_util_concurrent_atomic_AtomicInteger_decrementAndGet:
      case TR::java_util_concurrent_atomic_AtomicIntegerArray_decrementAndGet:
         {
         isGetAndOp = false;
         }
      case TR::java_util_concurrent_atomic_AtomicInteger_getAndDecrement:
      case TR::java_util_concurrent_atomic_AtomicIntegerArray_getAndDecrement:
         {
         delta = (int32_t)-1;
         isArgConstant = true;
         resultReg = cg->allocateRegister();
         break;
         }
      case TR::java_util_concurrent_atomic_AtomicLong_addAndGet:
      case TR::java_util_concurrent_atomic_AtomicLongArray_addAndGet:
         {
         isGetAndOp = false;
         }
      case TR::java_util_concurrent_atomic_AtomicLong_getAndAdd:
      case TR::java_util_concurrent_atomic_AtomicLongArray_getAndAdd:
         {
         isLong = true;
         break;
         }
      case TR::java_util_concurrent_atomic_AtomicLong_incrementAndGet:
      case TR::java_util_concurrent_atomic_AtomicLongArray_incrementAndGet:
         {
         isGetAndOp = false;
         }
      case TR::java_util_concurrent_atomic_AtomicLong_getAndIncrement:
      case TR::java_util_concurrent_atomic_AtomicLongArray_getAndIncrement:
         {
         isLong = true;
         delta = (int64_t)1;
         break;
         }
      case TR::java_util_concurrent_atomic_AtomicLong_decrementAndGet:
      case TR::java_util_concurrent_atomic_AtomicLongArray_decrementAndGet:
         {
         isGetAndOp = false;
         }
      case TR::java_util_concurrent_atomic_AtomicLong_getAndDecrement:
      case TR::java_util_concurrent_atomic_AtomicLongArray_getAndDecrement:
         {
         isLong = true;
         delta = (int64_t)-1;
         break;
         }
      }

   //Determine the offset of the value field
   //
   int32_t shiftAmount = 0;
   TR::Node *indexChild = NULL;
   TR::Register *indexRegister = NULL;
   TR::Register *fieldOffsetReg = NULL;
   int32_t fieldOffset;

   if (!isArray)
      {
      TR_OpaqueClassBlock * bdClass;
      char *className, *fieldSig;
      int32_t classNameLen, fieldSigLen;

      fieldSigLen = 1;

      switch (currentMethod)
         {
         case TR::java_util_concurrent_atomic_AtomicBoolean_getAndSet:
            className = "Ljava/util/concurrent/atomic/AtomicBoolean;";
            classNameLen = 43;
            fieldSig = "I";  // not a typo, the field is int
            break;
         case TR::java_util_concurrent_atomic_AtomicInteger_getAndSet:
         case TR::java_util_concurrent_atomic_AtomicInteger_addAndGet:
         case TR::java_util_concurrent_atomic_AtomicInteger_getAndAdd:
         case TR::java_util_concurrent_atomic_AtomicInteger_incrementAndGet:
         case TR::java_util_concurrent_atomic_AtomicInteger_getAndIncrement:
         case TR::java_util_concurrent_atomic_AtomicInteger_decrementAndGet:
         case TR::java_util_concurrent_atomic_AtomicInteger_getAndDecrement:
            className = "Ljava/util/concurrent/atomic/AtomicInteger;";
            classNameLen = 43;
            fieldSig = "I";
            break;
         case TR::java_util_concurrent_atomic_AtomicLong_getAndSet:
         case TR::java_util_concurrent_atomic_AtomicLong_addAndGet:
         case TR::java_util_concurrent_atomic_AtomicLong_getAndAdd:
         case TR::java_util_concurrent_atomic_AtomicLong_incrementAndGet:
         case TR::java_util_concurrent_atomic_AtomicLong_getAndIncrement:
         case TR::java_util_concurrent_atomic_AtomicLong_decrementAndGet:
         case TR::java_util_concurrent_atomic_AtomicLong_getAndDecrement:
            className = "Ljava/util/concurrent/atomic/AtomicLong;";
            classNameLen = 40;
            fieldSig = "J";
            break;
         case TR::java_util_concurrent_atomic_AtomicReference_getAndSet:
            className = "Ljava/util/concurrent/atomic/AtomicReference;";
            classNameLen = 45;
            fieldSig = "Ljava/lang/Object;";
         fieldSigLen = 18;
         break;
         default:
            TR_ASSERT( 0, "Unknown atomic operation method\n");
            return NULL;
         }

      TR_ResolvedMethod *owningMethod = node->getSymbolReference()->getOwningMethod(comp);
      TR_OpaqueClassBlock *containingClass = fej9->getClassFromSignature(className, classNameLen, owningMethod, true);
      fieldOffset = fej9->getInstanceFieldOffset(containingClass, "value", 5, fieldSig, fieldSigLen)
                    + fej9->getObjectHeaderSizeInBytes();  // size of a J9 object header
      }
   else
      {
      if (isArray)
         {
         indexChild = node->getChild(1);
         indexRegister = cg->evaluate(indexChild);
         fieldOffset = TR::Compiler->om.contiguousArrayHeaderSizeInBytes();
         if (size == 4)
            shiftAmount = 2;
         else if (size == 8)
            shiftAmount = 3;

         fieldOffsetReg = cg->allocateRegister();
         generateRSInstruction(cg, TR::InstOpCode::SLL, node, fieldOffsetReg, indexRegister, shiftAmount);
         }
      }

   // Exploit z196 interlocked-update instructions
   if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z196))
      {
      if (isAddOp) //getAndAdd or andAndGet
         {
         if (node->getNumChildren() > 1)
            {
            // 2nd operant needs to be in a register
            deltaChild = node->getSecondChild();

            if (isLong && TR::Compiler->target.is32Bit()) // deal with reg pairs on 31bit platform
               {
               deltaReg = cg->allocateRegister();
               if (deltaChild->getOpCode().isLoadConst() && !deltaChild->getRegister())
                  {
                  // load the immediate into one 64bit reg
                  int64_t value= deltaChild->getLongInt();
                  generateRILInstruction(cg, TR::InstOpCode::LGFI, node, deltaReg, (int32_t)(value));
                  if (value < MIN_IMMEDIATE_VAL || value > MAX_IMMEDIATE_VAL)
                     generateRILInstruction(cg, TR::InstOpCode::IIHF, node, deltaReg, (int32_t)(value >> 32));
                  }
               else
                  {
                  // evaluate 2nd child will return a reg pair, shift them into a 64-bit reg
                  TR::Register * deltaRegPair = cg->evaluate(deltaChild);
                  generateRSInstruction(cg, TR::InstOpCode::SLLG, node, deltaReg, deltaRegPair->getHighOrder(), 32);
                  generateRRInstruction(cg, TR::InstOpCode::LR, node, deltaReg, deltaRegPair->getLowOrder());
                  cg->stopUsingRegister(deltaRegPair);
                  }
               }
            else  // 64bit platform and AtomicInteger require no register pair
               {
               deltaReg = cg->evaluate(deltaChild);
               }
            cg->decReferenceCount(deltaChild);
            }
         else
            {
            // no 2nd child = Atomic.increment or decrement, delta should be +/- 1
            deltaReg = cg->allocateRegister();
            if (!isLong)
               {
               generateRIInstruction(cg, TR::InstOpCode::LHI, node, deltaReg, delta);
               }
            else
               {
               generateRIInstruction(cg, TR::InstOpCode::LGHI, node, deltaReg, delta);
               }
            }

         // Load And Add: LAA R1,R2,Mem
         // R1 = Mem; Mem = Mem + R2;
         // IMPORTANT: LAAG throws hardware exception if Mem is not double word aligned
         //            Class AtomicLong currently has its value field d.word aligned
         if (!resultReg)
            resultReg = cg->allocateRegister();

         if (!isLong)
            {
            if (fieldOffsetReg)
               generateRSInstruction(cg, TR::InstOpCode::LAA, node, resultReg, deltaReg, new (cg->trHeapMemory()) TR::MemoryReference(valueReg, fieldOffsetReg, fieldOffset, cg));
            else
               generateRSInstruction(cg, TR::InstOpCode::LAA, node, resultReg, deltaReg, new (cg->trHeapMemory()) TR::MemoryReference(valueReg, fieldOffset, cg));
            }
         else
            {
            if (fieldOffsetReg)
               generateRSInstruction(cg, TR::InstOpCode::LAAG, node, resultReg, deltaReg, new (cg->trHeapMemory()) TR::MemoryReference(valueReg, fieldOffsetReg, fieldOffset, cg));
            else
               generateRSInstruction(cg, TR::InstOpCode::LAAG, node, resultReg, deltaReg, new (cg->trHeapMemory()) TR::MemoryReference(valueReg, fieldOffset, cg));
            }
         if (!isGetAndOp)
            {
            // for addAndGet, the result needs to be recomputed. LAA loaded the original value into resultReg.
            if (!isLong)
               generateRRInstruction(cg, TR::InstOpCode::AR, node, resultReg, deltaReg);
            else
               generateRRInstruction(cg, TR::InstOpCode::AGR, node, resultReg, deltaReg);
            }

         cg->stopUsingRegister(deltaReg);
         cg->decReferenceCount(valueChild);
         cg->stopUsingRegister(valueReg);

         TR::Register *resultPairReg;
         if (isLong && TR::Compiler->target.is32Bit()) // on 31-bit platoform, restore the result back into a register pair
            {
            TR::Register * resultRegLow = cg->allocateRegister();
            resultPairReg = cg->allocateConsecutiveRegisterPair(resultRegLow, resultReg);

            generateRRInstruction(cg, TR::InstOpCode::LR, node, resultRegLow, resultReg);
            generateRSInstruction(cg, TR::InstOpCode::SRLG, node, resultReg, resultReg, 32);

            node->setRegister(resultPairReg);
            return resultPairReg;
            }

         node->setRegister(resultReg);
         return resultReg;
         }
      }

   if (node->getNumChildren() > 1)
      {
      deltaChild = node->getSecondChild();

      //Determine if the delta is a constant.
      //
      if (deltaChild->getOpCode().isLoadConst() && !deltaChild->getRegister())
         {
         delta = (int32_t)(deltaChild->getInt());
         isArgConstant = true;
         resultReg = cg->allocateRegister();
         }
      else if (isAddOp)
         {
         deltaReg = cg->evaluate(deltaChild);
         resultReg = cg->allocateRegister();
         }
      else
         {
         resultReg = cg->evaluate(deltaChild);
         }
      }

   TR::RegisterDependencyConditions * dependencies = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, numDeps, cg);
   TR::LabelSymbol *doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol *loopLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   loopLabel->setStartInternalControlFlow();

   // If this is a getAndSet of a constant, load the constant outside the loop.
   //
   if (!isAddOp && isArgConstant)
      generateLoad32BitConstant(cg, node, delta, resultReg, true);

   // Get the existing value
   //
   TR::Register *tempReg = cg->allocateRegister();
   if (fieldOffsetReg)
      generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, tempReg, new (cg->trHeapMemory()) TR::MemoryReference(valueReg, fieldOffsetReg, fieldOffset, cg));
   else
      generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, tempReg, new (cg->trHeapMemory()) TR::MemoryReference(valueReg, fieldOffset, cg));

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, loopLabel);

   // Perform the addition operation, if necessary
   //
   if (isAddOp)
      {
      generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(),node, resultReg, tempReg);
      if(isArgConstant)
         {
         generateS390ImmOp(cg, TR::InstOpCode::getAddOpCode(), node, resultReg, resultReg, (int32_t) delta, dependencies, NULL);
         }
      else
         {
         generateRRInstruction(cg, TR::InstOpCode::getAddRegOpCode(), node, resultReg ,deltaReg);
         }
      }

   // Compare and swap!
   //
   if (fieldOffsetReg)
      generateRSInstruction(cg, TR::InstOpCode::CS, node, tempReg, resultReg, new (cg->trHeapMemory()) TR::MemoryReference(valueReg, fieldOffsetReg, fieldOffset, cg));
   else
      generateRSInstruction(cg, TR::InstOpCode::CS, node, tempReg, resultReg, new (cg->trHeapMemory()) TR::MemoryReference(valueReg, fieldOffset, cg));

   // Branch if the compare and swap failed and try again.
   //
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC,TR::InstOpCode::COND_BL, node, loopLabel);

   dependencies->addPostCondition(valueReg, TR::RealRegister::AssignAny);
   dependencies->addPostCondition(tempReg, TR::RealRegister::AssignAny);

   if (resultReg)
      dependencies->addPostCondition(resultReg, TR::RealRegister::AssignAny);
   if (deltaReg)
      dependencies->addPostCondition(deltaReg, TR::RealRegister::AssignAny);

   doneLabel->setEndInternalControlFlow();
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, dependencies);

   if (deltaChild != NULL)
      cg->decReferenceCount(deltaChild);
   if (deltaReg)
      cg->stopUsingRegister(deltaReg);

   cg->decReferenceCount(valueChild);
   cg->stopUsingRegister(valueReg);

   if (isGetAndOp)
      {
      // For Get And Op, the return value be stored in the temp register
      //
      if(resultReg)
         cg->stopUsingRegister(resultReg);
      node->setRegister(tempReg);
      return tempReg;
      }
   else
      {
      // For Op And Get,  the return  value will be stored in the result register
      //
      cg->stopUsingRegister(tempReg);
      node->setRegister(resultReg);
      return resultReg;
      }
   }

static void
checkFieldOrderForDCASOrSet(
      TR::CodeGenerator *cg,
      bool isAMR,
      bool *isRefFirst,
      int32_t *firstFieldOffset)
   {
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   TR_OpaqueClassBlock * classBlock = NULL;
   char *fieldName;
   int32_t fieldNameLen;
   char *fieldSig;
   int32_t fieldSigLen;
   int32_t intOrBoolOffset;

   int32_t booleanOffset = 0;
   int32_t integerOffset = 0;

   if (isAMR)
      {
      classBlock = fej9->getClassFromSignature("Ljava/util/concurrent/atomic/AtomicMarkableReference$ReferenceBooleanPair;", 74, comp->getCurrentMethod(), true);
      fieldName = "bit";
      fieldNameLen = 3;
      fieldSig = "Z";
      fieldSigLen = 1;

      intOrBoolOffset = fej9->getInstanceFieldOffset(classBlock, fieldName, fieldNameLen, fieldSig, fieldSigLen);
      booleanOffset = intOrBoolOffset;
      }
   else
      {
      classBlock = fej9->getClassFromSignature("Ljava/util/concurrent/atomic/AtomicStampedReference$ReferenceIntegerPair;", 73, comp->getCurrentMethod(), true);
      fieldName = "integer";
      fieldNameLen = 7;
      fieldSig = "I";
      fieldSigLen = 1;

      intOrBoolOffset = fej9->getInstanceFieldOffset(classBlock, fieldName, fieldNameLen, fieldSig, fieldSigLen);
      integerOffset = intOrBoolOffset;
      }

   fieldName = "reference";
   fieldNameLen = 9;
   fieldSig = "Ljava/lang/Object;";
   fieldSigLen = 18;

   int32_t referenceOffset = fej9->getInstanceFieldOffset(classBlock, fieldName, fieldNameLen, fieldSig, fieldSigLen);

   if (isAMR)
      {
      *firstFieldOffset = (referenceOffset < booleanOffset) ? referenceOffset : booleanOffset;
      }
   else
      {
      *firstFieldOffset = (referenceOffset < integerOffset) ? referenceOffset : integerOffset;
      }

   if (isAMR)
      {
      *isRefFirst = referenceOffset < booleanOffset;
      }
   else
      {
      *isRefFirst = referenceOffset < integerOffset;
      }

   traceMsg(
         comp,
         "KKK: class %p, reference offset %d, bit offset %d, isRefFirst %d\n",
         classBlock, referenceOffset, intOrBoolOffset, *isRefFirst);
   }

static TR::Register *
inlineDoubleWordCASOrSetSupported(
      TR::Node *node,
      TR::CodeGenerator *cg,
      bool isAMR)
   {
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(cg->fe());
   TR::Node *currentPairNode = node->getChild(0);
   TR::Register *currentPairRegister = cg->evaluate(currentPairNode);
   TR::Register *resultRegister= cg->allocateRegister();
   TR::LabelSymbol *doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::MemoryReference * currentMR = NULL;

   int32_t firstFieldOffset;
   int32_t returnValWhenTrue=0; // when the LTGR matches true, will branch, and will return this value
   int32_t returnValWhenFalse=1; // when the LTGR matches false, won't branch, and will return this value

   bool isRefFirst;

   checkFieldOrderForDCASOrSet(cg, isAMR, &isRefFirst, &firstFieldOffset);

   if (TR::Compiler->target.is64Bit() && !TR::Compiler->om.generateCompressedObjectHeaders())
      {
      if ((firstFieldOffset + fej9->getObjectHeaderSizeInBytes()) % 16 == 0)
         {
            returnValWhenTrue = 1;
            returnValWhenFalse = 0;
         }
      generateRSInstruction(cg, TR::InstOpCode::SLLG, node, resultRegister, currentPairRegister, 60);
      generateRRInstruction(cg, TR::InstOpCode::LTGR, node, resultRegister, resultRegister);
      generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, resultRegister, returnValWhenTrue);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, doneLabel);
      generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, resultRegister, returnValWhenFalse);
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel);

      }
   else
      {
      TR_ASSERT(false, "doubleWordCASOrSetSupported should only be called on 64bit uncompressed \n");
      }

   cg->decReferenceCount(node->getChild(0));
   node->setRegister(resultRegister);
   return resultRegister;
   }

static TR::Register *
evaluateTwo32BitLoadsInA64BitRegister(
      TR::Node *node,
      TR::CodeGenerator *cg,
      TR::Node * highNode,
      TR::Node *lowNode)
   {
   TR::Register * targetRegister = cg->gprClobberEvaluate(highNode);
   TR::Instruction * cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, targetRegister, targetRegister, 32);

   generateRRInstruction(cg, TR::InstOpCode::LR, node, targetRegister, cg->evaluate(lowNode));
   return targetRegister;
   }

//TODO: CS clobbers first arg, and padLow ,refFirst
static TR::RegisterPair *
evaluateTwo32BitLoadsInAConsecutiveEvenOddPair(
      TR::Node *node,
      TR::CodeGenerator *cg,
      TR::Node * highNode,
      TR::Node *lowNode,
      TR::RegisterDependencyConditions * dependencies,
      bool isRefFirst,
      bool isClobberEval)
   {
   TR::Register * evenReg = (isClobberEval || (!isRefFirst))? cg->gprClobberEvaluate(highNode) : cg->evaluate(highNode);
   TR::Register * oddReg  = (isClobberEval || (isRefFirst))? cg->gprClobberEvaluate(lowNode) : cg->evaluate(lowNode);
   TR::Register *  padReg = isRefFirst ? oddReg : evenReg;
   generateRSInstruction(cg, TR::InstOpCode::SLLG, node, padReg, padReg, 32);

   TR::RegisterPair * newRegisterPair  =  cg->allocateConsecutiveRegisterPair(oddReg, evenReg);
   dependencies->addPostCondition(evenReg, TR::RealRegister::LegalEvenOfPair);
   dependencies->addPostCondition(oddReg, TR::RealRegister::LegalOddOfPair);
   dependencies->addPostCondition(newRegisterPair, TR::RealRegister::EvenOddPair);
   TR_ASSERT( newRegisterPair->getHighOrder() == evenReg, "evenReg is not high order\n");
   return newRegisterPair;
   }

static TR::Register *
inlineDoubleWordCAS(
      TR::Node *node,
      TR::CodeGenerator *cg,
      bool isAMR)
   {
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(cg->fe());
   TR::Node *currentPairNode = node->getChild(1);
   TR::Node *newReferenceNode = node->getChild(2);
   TR::Node *expectedReferenceNode = node->getChild(3);
   TR::Node *newMarkNode = node->getChild(4);
   TR::Node *expectedMarkNode = node->getChild(5);

   TR::Register *currentPairRegister = cg->evaluate(currentPairNode);
   TR::RegisterDependencyConditions * dependencies = NULL;

   TR::Register *expectedPairRegister = NULL;
   TR::Register *newPairRegister = NULL;
   TR::Register *resultRegister= cg->allocateRegister();

   TR::LabelSymbol *doCSLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol *doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   TR::Compilation *comp = cg->comp();

   TR::MemoryReference * currentMR = NULL;
   bool isRefFirst = false;
   int32_t firstOffset;
   checkFieldOrderForDCASOrSet(cg, isAMR, &isRefFirst, &firstOffset);

   int offsetOfFirstField = firstOffset + fej9->getObjectHeaderSizeInBytes();
   TR::InstOpCode::Mnemonic csOp = TR::InstOpCode::CDSG;
   if ((TR::Compiler->target.is32Bit() || TR::Compiler->om.generateCompressedObjectHeaders()))
      {
      csOp = TR::InstOpCode::CSG;
      }

   generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, resultRegister, 0);

   if (TR::Compiler->target.is32Bit() || TR::Compiler->om.generateCompressedObjectHeaders())
      {
      if (isRefFirst)
         {
         expectedPairRegister = evaluateTwo32BitLoadsInA64BitRegister(node, cg, expectedReferenceNode, expectedMarkNode);
         newPairRegister      = evaluateTwo32BitLoadsInA64BitRegister(node, cg, newReferenceNode, newMarkNode);
         }
      else
         {
         expectedPairRegister = evaluateTwo32BitLoadsInA64BitRegister(node, cg, expectedMarkNode, expectedReferenceNode);
         newPairRegister      = evaluateTwo32BitLoadsInA64BitRegister(node, cg, newMarkNode, newReferenceNode);
         }
      }
   else
      {
      dependencies = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 8, cg);
      if (isRefFirst)
         {
         expectedPairRegister = evaluateTwo32BitLoadsInAConsecutiveEvenOddPair(node, cg, expectedReferenceNode, expectedMarkNode, dependencies, isRefFirst, true);
         newPairRegister      = evaluateTwo32BitLoadsInAConsecutiveEvenOddPair(node, cg, newReferenceNode, newMarkNode, dependencies, isRefFirst, false);
         }
      else
         {
         expectedPairRegister = evaluateTwo32BitLoadsInAConsecutiveEvenOddPair(node, cg, expectedMarkNode, expectedReferenceNode, dependencies, isRefFirst, true);
         newPairRegister      = evaluateTwo32BitLoadsInAConsecutiveEvenOddPair(node, cg, newMarkNode, newReferenceNode, dependencies, isRefFirst, false);
         }
      dependencies->addPostCondition(currentPairRegister, TR::RealRegister::AssignAny);
      dependencies->addPostCondition(resultRegister, TR::RealRegister::AssignAny);

      // before doing CDSG on 64-bit default mode, we need to make sure that the last 4 bytes of the object is zero since we removed the int padding field in classlib
      // resultReg has 0 currently
      generateRXInstruction(cg, TR::InstOpCode::ST, node, resultRegister, generateS390MemoryReference(currentPairRegister, offsetOfFirstField + 8 + 4, cg));
      }

   TR::Instruction *cursor = generateRSInstruction(cg, csOp, node, expectedPairRegister, newPairRegister, generateS390MemoryReference(currentPairRegister, offsetOfFirstField, cg));

   if (TR::Compiler->target.is32Bit() && (!cg->supportsHighWordFacility() || comp->getOption(TR_DisableHighWordRA)))
      {
      dependencies = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 2, cg);
      dependencies->addPostCondition(expectedPairRegister, TR::RealRegister::AssignAny);
      dependencies->addPostCondition(newPairRegister, TR::RealRegister::AssignAny);
      }

   //Branch if the compare and swap failed
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BL, node, doneLabel);
   generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, resultRegister, 1);
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, dependencies);

   // Do wrtbar for Objects
   //
   TR_WriteBarrierKind gcMode = comp->getOptions()->getGcMode();
   bool doWrtBar = (gcMode == TR_WrtbarOldCheck ||
         gcMode == TR_WrtbarCardMarkAndOldCheck ||
         gcMode == TR_WrtbarAlways);
   bool doCrdMrk = (gcMode == TR_WrtbarCardMark || gcMode == TR_WrtbarCardMarkAndOldCheck || gcMode == TR_WrtbarCardMarkIncremental);
   TR::Register * objReg, * srcReg;
   srcReg = resultRegister;
   objReg = currentPairRegister;

   if (doWrtBar || doCrdMrk)
      {
      TR::LabelSymbol *doneLabelWrtBar = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::Register *epReg = cg->allocateRegister();
      TR::Register *raReg = cg->allocateRegister();

      TR::RegisterDependencyConditions* condWrtBar = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 4, cg);

      condWrtBar->addPostCondition(objReg, TR::RealRegister::GPR1);
      condWrtBar->addPostCondition(resultRegister, TR::RealRegister::GPR2);
      condWrtBar->addPostCondition(epReg, cg->getEntryPointRegister());
      condWrtBar->addPostCondition(raReg, cg->getReturnAddressRegister());

      if (doWrtBar)
         {
         TR::SymbolReference *wbRef;

         if (gcMode == TR_WrtbarCardMarkAndOldCheck || gcMode == TR_WrtbarOldCheck)
            wbRef = comp->getSymRefTab()->findOrCreateWriteBarrierStoreGenerationalSymbolRef(comp->getMethodSymbol());
         else
            wbRef = comp->getSymRefTab()->findOrCreateWriteBarrierStoreSymbolRef(comp->getMethodSymbol());

         VMnonNullSrcWrtBarCardCheckEvaluator(node, objReg, srcReg, epReg, raReg, doneLabelWrtBar, wbRef, condWrtBar, cg, false);
         }
      else if (doCrdMrk)
         {
         VMCardCheckEvaluator(node, objReg, raReg, condWrtBar, cg, false, doneLabelWrtBar, false);
                                                                           // true #1 -> copy of objReg just happened, it's safe to clobber tempReg
                                                                           // false #2 -> Don't do compile time check for heap obj
         }

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabelWrtBar, condWrtBar);

      cg->stopUsingRegister(epReg);
      cg->stopUsingRegister(raReg);
      }

   if (TR::Compiler->target.is64Bit() && !TR::Compiler->om.generateCompressedObjectHeaders())
      {
      cg->stopUsingRegister(expectedPairRegister->getHighOrder());
      cg->stopUsingRegister(expectedPairRegister->getLowOrder());
      if (!isRefFirst) cg->stopUsingRegister(newPairRegister->getHighOrder());
      if (isRefFirst) cg->stopUsingRegister(newPairRegister->getLowOrder());
      }

   cg->stopUsingRegister(newPairRegister);
   cg->stopUsingRegister(expectedPairRegister);

   cg->decReferenceCount(node->getChild(0));
   cg->decReferenceCount(node->getChild(1));
   cg->decReferenceCount(node->getChild(2));
   cg->decReferenceCount(node->getChild(3));
   cg->decReferenceCount(node->getChild(4));
   cg->decReferenceCount(node->getChild(5));
   node->setRegister(resultRegister);

   return resultRegister;
   }

static TR::Register *
inlineDoubleWordSet(
      TR::Node *node,
      TR::CodeGenerator *cg,
      bool isAMR)
   {
   TR::Node *currentPairNode = node->getChild(1);
   TR::Node *newReferenceNode = node->getChild(2);
   TR::Node *newMarkNode = node->getChild(3);
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());

   TR::Register *currentPairRegister = cg->evaluate(currentPairNode);
   TR::RegisterPair *newPairRegister = NULL;

   TR::RegisterDependencyConditions * dependencies =  new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 4, cg);
   TR::MemoryReference * currentMR = NULL;
   bool isRefFirst = false;
   int32_t firstOffset;
   checkFieldOrderForDCASOrSet(cg, isAMR, &isRefFirst, &firstOffset);
   int offsetOfFirstField = firstOffset + fej9->getObjectHeaderSizeInBytes();
   TR::Instruction * cursor = NULL;

   if (isRefFirst) newPairRegister = evaluateTwo32BitLoadsInAConsecutiveEvenOddPair(node, cg, newReferenceNode, newMarkNode, dependencies, isRefFirst, false);
   else newPairRegister = evaluateTwo32BitLoadsInAConsecutiveEvenOddPair(node, cg, newMarkNode, newReferenceNode, dependencies, isRefFirst, false);

   if ((TR::Compiler->target.is32Bit() || TR::Compiler->om.generateCompressedObjectHeaders()))
      {
      cursor = generateRSInstruction(cg, TR::InstOpCode::STM, node, newPairRegister, generateS390MemoryReference(currentPairRegister, offsetOfFirstField, cg));
      }
   else
      cursor = generateRXInstruction(cg, TR::InstOpCode::STPQ, node, newPairRegister, generateS390MemoryReference(currentPairRegister, offsetOfFirstField, cg));

   cursor->setDependencyConditions(dependencies);

   // need proper write barrier
   TR_WriteBarrierKind gcMode = comp->getOptions()->getGcMode();
   bool doWrtBar = (gcMode == TR_WrtbarOldCheck ||
         gcMode== TR_WrtbarCardMarkAndOldCheck ||
         gcMode == TR_WrtbarAlways);
   bool doCrdMrk = (gcMode == TR_WrtbarCardMark || gcMode== TR_WrtbarCardMarkAndOldCheck || gcMode == TR_WrtbarCardMarkIncremental);
   TR::Register * objReg;
   TR::Register * srcReg;
   srcReg = newPairRegister;
   objReg = currentPairRegister;

   if (doWrtBar || doCrdMrk)
      {
      TR::LabelSymbol *doneLabelWrtBar = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::Register *epReg = cg->allocateRegister();
      TR::Register *raReg = cg->allocateRegister();

      TR::RegisterDependencyConditions* condWrtBar = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 4, cg);

      condWrtBar->addPostCondition(objReg, TR::RealRegister::GPR1);
      condWrtBar->addPostCondition(srcReg, TR::RealRegister::GPR2);
      condWrtBar->addPostCondition(epReg, cg->getEntryPointRegister());
      condWrtBar->addPostCondition(raReg, cg->getReturnAddressRegister());
      // Cardmarking is not inlined for gencon. Consider doing so when perf issue arises.
      if (doWrtBar)
         {
         TR::SymbolReference *wbRef;

         if (gcMode == TR_WrtbarCardMarkAndOldCheck || gcMode == TR_WrtbarOldCheck)
            wbRef = comp->getSymRefTab()->findOrCreateWriteBarrierStoreGenerationalSymbolRef(comp->getMethodSymbol());
         else
            wbRef = comp->getSymRefTab()->findOrCreateWriteBarrierStoreSymbolRef(comp->getMethodSymbol());

         VMnonNullSrcWrtBarCardCheckEvaluator(node, objReg, srcReg, epReg, raReg, doneLabelWrtBar, wbRef, condWrtBar, cg, false);
         }
      else if (doCrdMrk)
         {
         VMCardCheckEvaluator(node, objReg, epReg, condWrtBar, cg, false, doneLabelWrtBar, false);
                                                                           // true #1 -> copy of objReg just happened, it's safe to clobber tempReg
                                                                           // false #2 -> Don't do compile time check for heap obj
         }
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabelWrtBar, condWrtBar);

      cg->stopUsingRegister(epReg);
      cg->stopUsingRegister(raReg);
      }

   if (!isRefFirst) cg->stopUsingRegister(newPairRegister->getHighOrder());
   if (isRefFirst) cg->stopUsingRegister(newPairRegister->getLowOrder());

   cg->stopUsingRegister(newPairRegister);
   cg->decReferenceCount(node->getChild(0));
   cg->decReferenceCount(node->getChild(1));
   cg->decReferenceCount(node->getChild(2));
   cg->decReferenceCount(node->getChild(3));

   node->setRegister(NULL);

   return NULL;
   }

static TR::Register *
inlineAtomicFieldUpdater(
      TR::Node *node,
      TR::CodeGenerator *cg,
      TR::MethodSymbol *method)
   {
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   TR::Register * resultReg;
   TR::RecognizedMethod currentMethod = method->getRecognizedMethod();

   //Gather information about the method
   bool isAddOp = true;
   bool isGetAndOp = true;
   bool isArgConstant = false;
   int32_t delta = 1;
   char* className = "java/util/concurrent/atomic/AtomicIntegerFieldUpdater$AtomicIntegerFieldUpdaterImpl";
   int32_t classNameLen = 83;

   switch (currentMethod)
      {
      case TR::java_util_concurrent_atomic_AtomicIntegerFieldUpdater_getAndDecrement:
         delta = -1;
      case TR::java_util_concurrent_atomic_AtomicIntegerFieldUpdater_getAndIncrement:
         isArgConstant = true;
      case TR::java_util_concurrent_atomic_AtomicIntegerFieldUpdater_getAndAdd:
         break;
      case TR::java_util_concurrent_atomic_AtomicIntegerFieldUpdater_decrementAndGet:
         delta = -1;
      case TR::java_util_concurrent_atomic_AtomicIntegerFieldUpdater_incrementAndGet:
         isArgConstant = true;
      case TR::java_util_concurrent_atomic_AtomicIntegerFieldUpdater_addAndGet:
         isGetAndOp = false;
         break;
      }

   // getting the offsets to various fields: tclass, class, offset
   TR_ResolvedMethod *owningMethod = node->getSymbolReference()->getOwningMethod(comp);
   TR_OpaqueClassBlock *containingClass = fej9->getClassFromSignature(className, classNameLen, owningMethod, true);
   int32_t offset = fej9->getInstanceFieldOffset(containingClass, "offset", 6, "J", 1)
      + fej9->getObjectHeaderSizeInBytes();  // size of a J9 object header
   int32_t cclass = fej9->getInstanceFieldOffset(containingClass, "cclass", 6, "Ljava/lang/Class;", 17)
      + fej9->getObjectHeaderSizeInBytes();  // size of a J9 object header
   int32_t tclass = fej9->getInstanceFieldOffset(containingClass, "tclass", 6, "Ljava/lang/Class;", 17)
      + fej9->getObjectHeaderSizeInBytes();  // size of a J9 object header

   TR::Register * thisReg = cg->evaluate(node->getFirstChild());
   TR::Register * objReg = cg->evaluate(node->getSecondChild());
   TR::Register * tempReg = cg->allocateRegister();
   TR::Register * trueReg = cg->machine()->getS390RealRegister(TR::RealRegister::GPR5);
   TR::Register * deltaReg;
   TR::Register * offsetReg = cg->allocateRegister();
   TR::Register * tClassReg = cg->allocateRegister();
   TR::Register * objClassReg = cg->allocateRegister();

   TR::LabelSymbol *doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol *callLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   // evaluate the delta node if it exists
   if (isArgConstant)
      {
      deltaReg = cg->allocateRegister();
      generateRIInstruction(cg, TR::InstOpCode::LHI, node, deltaReg, delta);
      }
   else
      {
      deltaReg = cg->evaluate(node->getChild(2));
      }

   bool is64Bit = TR::Compiler->target.is64Bit() && !comp->useCompressedPointers();

   // cclass == null?
   generateRRInstruction(cg, is64Bit ? TR::InstOpCode::XGR : TR::InstOpCode::XR, node, tempReg, tempReg);
   generateRXInstruction(cg, is64Bit ? TR::InstOpCode::CG : TR::InstOpCode::C, node, tempReg, generateS390MemoryReference(thisReg, cclass, cg));
   generateRRFInstruction(cg, TR::InstOpCode::LOCR, node, tempReg, trueReg, getMaskForBranchCondition(TR::InstOpCode::COND_BNER), true);

   // obj == null?
   generateRRInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::LTGR : TR::InstOpCode::LTR, node, objReg, objReg);
   generateRRFInstruction(cg, TR::InstOpCode::LOCR, node, tempReg, trueReg, getMaskForBranchCondition(TR::InstOpCode::COND_BER), true);

   TR::TreeEvaluator::genLoadForObjectHeadersMasked(cg, node, objClassReg, generateS390MemoryReference(objReg, TR::Compiler->om.offsetOfObjectVftField(), cg), NULL);

   // obj.getClass() == tclass?
   if (comp->useCompressedPointers())
      {
      // inline the getClass() method = grab it from j9class
      generateRXInstruction(cg, TR::InstOpCode::LG, node, objClassReg, generateS390MemoryReference(objClassReg, fej9->getOffsetOfJavaLangClassFromClassField(), cg));

      // get tclass
      generateRXInstruction(cg, TR::InstOpCode::LLGF, node, tClassReg, generateS390MemoryReference(thisReg, tclass, cg));
      int32_t shiftAmount = TR::Compiler->om.compressedReferenceShift();
      if (shiftAmount != 0)
         {
         generateRSInstruction(cg, TR::InstOpCode::SLLG, node, tClassReg, tClassReg, shiftAmount);
         }
      }
   else
      {
      // inline the getClass() method = grab it from j9class
      generateRXInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::LG : TR::InstOpCode::L, node, objClassReg, generateS390MemoryReference(objClassReg, fej9->getOffsetOfJavaLangClassFromClassField(), cg));

      // get tclass
      generateRXInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::LG : TR::InstOpCode::L, node, tClassReg, generateS390MemoryReference(thisReg, tclass, cg));
      }
   generateRRInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::CGR : TR::InstOpCode::CR, node, objClassReg, tClassReg);
   generateRRFInstruction(cg, TR::InstOpCode::LOCR, node, tempReg, trueReg, getMaskForBranchCondition(TR::InstOpCode::COND_BNER), true);

   // if any of the above has set the flag, we need to revert back to call the original method via OOL
   generateRRInstruction(cg, TR::InstOpCode::LTR, node, tempReg, tempReg);
   generateS390BranchInstruction (cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, callLabel);

   // start OOL
   TR_S390OutOfLineCodeSection *outlinedCall = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(callLabel, doneLabel, cg);
   cg->getS390OutOfLineCodeSectionList().push_front(outlinedCall);
   outlinedCall->swapInstructionListsWithCompilation();
   TR::Instruction * cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, callLabel);

   if (cg->getDebug())
      cg->getDebug()->addInstructionComment(cursor, "Denotes start of OOL AtomicFieldUpdater");

   // original call, this decrements node counts
   resultReg = TR::TreeEvaluator::performCall(node, false, cg);

   cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, doneLabel);
   if (cg->getDebug())
      cg->getDebug()->addInstructionComment(cursor, "Denotes end of OOL AtomicFieldUpdater");

   outlinedCall->swapInstructionListsWithCompilation();

   // inline fast path: use Load-and-add. Get the offset of the value from the reflection object
   generateRXInstruction(cg, TR::InstOpCode::LG, node, offsetReg, generateS390MemoryReference(thisReg, offset, cg));
   generateRSInstruction(cg, TR::InstOpCode::LAA, node, resultReg, deltaReg, new (cg->trHeapMemory()) TR::MemoryReference(objReg, offsetReg, 0, cg));

   // for addAndGet we need to recompute the resultReg
   if (!isGetAndOp)
      {
      generateRRInstruction(cg, TR::InstOpCode::AR, node, resultReg, deltaReg);
      }

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel);

   cg->stopUsingRegister(tempReg);
   cg->stopUsingRegister(deltaReg);
   cg->stopUsingRegister(offsetReg);
   cg->stopUsingRegister(tClassReg);
   cg->stopUsingRegister(objClassReg);

   return resultReg;
   }

static TR::Register *
inlineKeepAlive(
      TR::Node *node,
      TR::CodeGenerator *cg)
   {
   TR::Node *paramNode = node->getFirstChild();
   TR::Register *paramReg = cg->evaluate(paramNode);
   TR::RegisterDependencyConditions *conditions = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(1, 1, cg);
   conditions->addPreCondition(paramReg, TR::RealRegister::AssignAny);
   conditions->addPostCondition(paramReg, TR::RealRegister::AssignAny);
   TR::LabelSymbol *label = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, label, conditions);
   cg->decReferenceCount(paramNode);
   return NULL;
   }

/**
 * Helper routine to generate a write barrier sequence for the Transactional Memory inlined sequences.
 */
static void
genWrtBarForTM(
      TR::Node *node,
      TR::CodeGenerator *cg,
      TR::Register * objReg,
      TR::Register * srcReg,
      TR::Register * resultReg,
      bool checkResultRegForTMSuccess)
   {
   TR::Compilation *comp = cg->comp();
   TR_WriteBarrierKind gcMode = comp->getOptions()->getGcMode();
   bool doWrtBar = (gcMode == TR_WrtbarOldCheck ||
         gcMode == TR_WrtbarCardMarkAndOldCheck ||
         gcMode == TR_WrtbarAlways);
   bool doCrdMrk = (gcMode == TR_WrtbarCardMark || gcMode == TR_WrtbarCardMarkAndOldCheck || gcMode == TR_WrtbarCardMarkIncremental);

   if (doWrtBar || doCrdMrk)
      {
      TR::LabelSymbol *doneLabelWrtBar = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::Register *epReg = cg->allocateRegister();
      TR::Register *raReg = cg->allocateRegister();

      TR::RegisterDependencyConditions* condWrtBar = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 5, cg);

      condWrtBar->addPostCondition(objReg, TR::RealRegister::GPR1);
      condWrtBar->addPostCondition(srcReg, TR::RealRegister::GPR2);
      condWrtBar->addPostCondition(epReg, cg->getEntryPointRegister());
      condWrtBar->addPostCondition(raReg, cg->getReturnAddressRegister());

      // tmOffer returns 0 if transaction succeeds, tmPoll returns a non-Null object pointer if the transaction succeeds
      // we skip the wrtbar if TM failed
      if (checkResultRegForTMSuccess)
         {
         // the resultReg is not in the reg deps for tmOffer, add it for internal control flow
         condWrtBar->addPostCondition(resultReg, TR::RealRegister::AssignAny);
         generateRRInstruction(cg, TR::InstOpCode::LTR, node, resultReg, resultReg);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, doneLabelWrtBar);
         }
      else
         {
         generateRRInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::LTGR : TR::InstOpCode::LTR, node, resultReg, resultReg);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, doneLabelWrtBar);
         }

      if (doWrtBar)
         {
         TR::SymbolReference *wbRef;

         if (gcMode == TR_WrtbarCardMarkAndOldCheck || gcMode == TR_WrtbarOldCheck)
            wbRef = comp->getSymRefTab()->findOrCreateWriteBarrierStoreGenerationalSymbolRef(comp->getMethodSymbol());
         else
            wbRef = comp->getSymRefTab()->findOrCreateWriteBarrierStoreSymbolRef(comp->getMethodSymbol());

         VMnonNullSrcWrtBarCardCheckEvaluator(node, objReg, srcReg, epReg, raReg, doneLabelWrtBar,
                                                                    wbRef, condWrtBar, cg, false);
         }
      else if (doCrdMrk)
         {
         VMCardCheckEvaluator(node, objReg, epReg, condWrtBar, cg, false, doneLabelWrtBar, false);
         // true #1 -> copy of objReg just happened, it's safe to clobber tempReg
         // false #2 -> Don't do compile time check for heap obj
         }

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabelWrtBar, condWrtBar);

      cg->stopUsingRegister(epReg);
      cg->stopUsingRegister(raReg);
      }
   }

static TR::Register *
inlineConcurrentHashMapTmPut(
      TR::Node *node,
      TR::CodeGenerator * cg)
   {
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
#ifndef PUBLIC_BUILD
   int32_t offsetSyncObj = 0, offsetState = 0, offsetTable = 0, offsetThreshold = 0, offsetNext = 0, offsetCount = 0, offsetModCount = 0;
   TR_OpaqueClassBlock * classBlock1 = NULL;
   TR_OpaqueClassBlock * classBlock2 = NULL;
   TR_OpaqueClassBlock * classBlock3 = NULL;

   classBlock1 = fej9->getClassFromSignature("Ljava/util/concurrent/ConcurrentHashMap$Segment;", 48, comp->getCurrentMethod(), true);
   classBlock2 = fej9->getClassFromSignature("java/util/concurrent/locks/AbstractQueuedSynchronizer", 53, comp->getCurrentMethod(), true);
   classBlock3 = fej9->getClassFromSignature("Ljava/util/concurrent/ConcurrentHashMap$HashEntry;", 50, comp->getCurrentMethod(), true);


   static char * disableTMPutenv = feGetEnv("TR_DisableTMPut");
   bool disableTMPut = (disableTMPutenv != NULL);
   if (classBlock1 && classBlock2 && classBlock3)
      {
      offsetSyncObj = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock1, "sync", 4, "Ljava/util/concurrent/locks/ReentrantLock$Sync;", 47);
      offsetTable = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock1, "table", 5, "[Ljava/util/concurrent/ConcurrentHashMap$HashEntry;", 51);
      offsetThreshold = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock1, "threshold", 9, "I", 1);
      offsetCount = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock1, "count", 5, "I", 1);
      offsetModCount = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock1, "modCount", 8, "I", 1);

      offsetState = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock2, "state", 5, "I", 1);
      offsetNext = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock3, "next", 4, "Ljava/util/concurrent/ConcurrentHashMap$HashEntry;", 50);
      }
   else
      disableTMPut = true;

   TR::Register * rReturn = cg->allocateRegister();
   TR::Register * rThis = cg->evaluate(node->getFirstChild());
   TR::Register * rHash = cg->evaluate(node->getSecondChild());
   TR::Register * rNode = cg->evaluate(node->getChild(2));
   TR::Register * rTmpObj = cg->allocateCollectedReferenceRegister();
   TR::Register * rTmp = cg->allocateRegister();
   TR::Register * rIndex = cg->allocateRegister();
   TR::Register * rRetryCount = cg->allocateRegister();

   TR::LabelSymbol * tstartLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * endLabel =  TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * failureLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * returnLabel =  TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   TR::RegisterDependencyConditions *deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 8, cg);

   deps->addPostCondition(rReturn, TR::RealRegister::AssignAny);
   deps->addPostCondition(rThis, TR::RealRegister::AssignAny);
   deps->addPostCondition(rHash, TR::RealRegister::AssignAny);
   deps->addPostCondition(rNode, TR::RealRegister::AssignAny);
   deps->addPostCondition(rTmpObj, TR::RealRegister::AssignAny);
   deps->addPostCondition(rTmp, TR::RealRegister::AssignAny);
   deps->addPostCondition(rIndex, TR::RealRegister::AssignAny);
   deps->addPostCondition(rRetryCount, TR::RealRegister::AssignAny);

   bool usesCompressedrefs = comp->useCompressedPointers();
   int32_t shiftAmount = TR::Compiler->om.compressedReferenceShift();
   int32_t indexScale = TR::Compiler->target.is64Bit()? 3:2;
   if (usesCompressedrefs)
      {
      indexScale=2;
      }

   TR::Instruction * cursor = NULL;

   static char * debugTM= feGetEnv("TR_DebugTM");
   static char * enableNIAI = feGetEnv("TR_TMUseNIAI");
   // In theory, we only need to use OI to fetch exclusive the cache lines we are storing to.
   // This option enables an experimental mode where we use OI to fetch all cache lines as exclusive
   // in case there are some cache line aliasing issues.
   static char * useOIForAllCacheLinesAccessed = feGetEnv("TR_TMOIAll");

   if (disableTMPut)
      {
      generateRIInstruction(cg, TR::InstOpCode::LHI, node, rReturn, 3);   // tmPut() is disabled.
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, returnLabel);
      }
   else if (debugTM)
      {
      printf ("\nTM: use TM CHM.put in %s (%s)", comp->signature(), comp->getHotnessName(comp->getMethodHotness()));
      fflush(stdout);
      }

   generateRIInstruction(cg, TR::InstOpCode::LHI, node, rReturn, 1);

   static const char *s = feGetEnv("TR_TMPutRetry");
   static uint32_t TMPutRetry = s ? atoi(s) : 5;
   generateRIInstruction(cg, TR::InstOpCode::LHI, node, rRetryCount, TMPutRetry);

   // Label used by the retry loop to retry transaction.
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, tstartLabel);
   /// immediate field described in TR::TreeEvaluator::tstartEvaluator(TR_Node * node, TR_CodeGenerator * cg)
   cursor = generateSILInstruction(cg, TR::InstOpCode::TBEGIN, node, generateS390MemoryReference(cg->machine()->getS390RealRegister(TR::RealRegister::GPR0),0,cg), 0xFF02);

   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK7, node, failureLabel);

   if (!enableNIAI)
      {
      // For zEC12, a transaction will abort if a cache line is loaded within the transaction as read-only, only to have an XI induced
      // by a promote-to-exclusive on the store.  Use OI instead of NIAI, as the NIAI will not cause an immediate fetch exclusive if the
      // cache line is already loaded read-only.
      generateSIInstruction(cg, TR::InstOpCode::OI, node, generateS390MemoryReference(rThis, offsetCount, cg), 0x0);
      }
   else
      {
      generateS390IEInstruction(cg, TR::InstOpCode::NIAI, 1, 0, node);
      }

   // Load this.syncObj (which if of type ReentrantLock)
   if (usesCompressedrefs)
      {
      generateRXInstruction(cg, TR::InstOpCode::LLGF, node, rTmpObj, generateS390MemoryReference(rThis, offsetSyncObj, cg));
      if (shiftAmount != 0 )
         generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rTmpObj, rTmpObj, shiftAmount);
      }
   else
      {
      generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, rTmpObj, generateS390MemoryReference(rThis, offsetSyncObj, cg));
      }

   if (useOIForAllCacheLinesAccessed)
      generateSIInstruction(cg, TR::InstOpCode::OI, node, generateS390MemoryReference(rTmpObj, offsetState - 4, cg), 0x0);  // offsetState - 4 to avoid OSC penalties.

   // Check if syncObj.state == 0.
   generateRXInstruction(cg, TR::InstOpCode::LT, node, rTmp, generateS390MemoryReference(rTmpObj, offsetState, cg));
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, endLabel);

   // Load this.table
   if (usesCompressedrefs)
      {
      generateRXInstruction(cg, TR::InstOpCode::LLGF, node, rTmpObj, generateS390MemoryReference(rThis, offsetTable, cg));
      if (shiftAmount != 0 )
         generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rTmpObj, rTmpObj, shiftAmount);
      }
   else
      {
      generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, rTmpObj, generateS390MemoryReference(rThis, offsetTable, cg));
      }

   // Ensure that the table cache line is loaded as exclusive.  Depending on the index we later calculate, we might
   // be writing to the same cache line as the array header.
   if (!enableNIAI)
      generateSIInstruction(cg, TR::InstOpCode::OI, node, generateS390MemoryReference(rTmpObj, 0, cg), 0x0);
   else
      generateS390IEInstruction(cg, TR::InstOpCode::NIAI, 1, 0, node);

   generateRSInstruction(cg, TR::InstOpCode::ICM, node, rIndex, (uint32_t) 0xF, generateS390MemoryReference(rTmpObj, fej9->getOffsetOfContiguousArraySizeField(), cg));

   // Cond Load from discontiguousArraySize if contiguousArraySize is zero.
   generateRSInstruction(cg, TR::InstOpCode::LOC, node, rIndex, 0x8, generateS390MemoryReference(rTmpObj, fej9->getOffsetOfDiscontiguousArraySizeField(), cg));

   generateRIInstruction(cg, TR::InstOpCode::AHI, node, rIndex, -1);
   generateRRInstruction(cg, TR::InstOpCode::NR, node, rIndex, rHash);

   if (TR::Compiler->target.is64Bit())
      {
      // Zero extend rIndex and shift it left by indexScale.
      //     Effectively, shift first, and write result into bits 32-indexScale to 63 - indexScale.
      generateRIEInstruction(cg, TR::InstOpCode::RISBG, node, rIndex, rIndex, 32 - indexScale, 63 - indexScale + 0x80, indexScale);
      }
   else
      {
      generateRSInstruction(cg, TR::InstOpCode::SLL, node, rIndex, indexScale);
      }

   if (!enableNIAI)
      {
      // For zEC12, a transaction will abort if a cache line is loaded within the transaction as read-only, only to have an XI induced
      // by a promote-to-exclusive on the store.  Use OI instead of NIAI, as the NIAI will not cause an immediate fetch exclusive if the
      // cache line is already loaded read-only.
      generateRXInstruction(cg, TR::InstOpCode::LA, node, rTmp, generateS390MemoryReference(rTmpObj, rIndex, TR::Compiler->om.contiguousArrayHeaderSizeInBytes(), cg));
      generateSIInstruction(cg, TR::InstOpCode::OI, node, generateS390MemoryReference(rTmp, 0, cg), 0x0);

      // We have to use rTmp in LT as well, otherwise, LT will get scheduled ahead of the OI.
      generateRXInstruction(cg, (usesCompressedrefs)?TR::InstOpCode::LT:TR::InstOpCode::getLoadTestOpCode(), node, rTmp, generateS390MemoryReference(rTmp, 0, cg));
      }
   else
      {
      generateS390IEInstruction(cg, TR::InstOpCode::NIAI, 1, 0, node);
      generateRXInstruction(cg, (usesCompressedrefs)?TR::InstOpCode::LT:TR::InstOpCode::getLoadTestOpCode(), node, rTmp, generateS390MemoryReference(rTmpObj, rIndex, TR::Compiler->om.contiguousArrayHeaderSizeInBytes(), cg));
      }

   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, endLabel);

   if (usesCompressedrefs)
      {
      if (shiftAmount != 0 )
         {
         generateRSInstruction(cg, TR::InstOpCode::SRLG, node, rTmp, rNode, shiftAmount);
         generateRXInstruction(cg, TR::InstOpCode::ST, node, rTmp, generateS390MemoryReference(rTmpObj, rIndex, TR::Compiler->om.contiguousArrayHeaderSizeInBytes(), cg));
         }
      else
         {
         generateRXInstruction(cg, TR::InstOpCode::ST, node, rNode, generateS390MemoryReference(rTmpObj, rIndex, TR::Compiler->om.contiguousArrayHeaderSizeInBytes(), cg));
         }
      }
   else
      {
      // need wrtbar for this store
      generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, rNode, generateS390MemoryReference(rTmpObj, rIndex, TR::Compiler->om.contiguousArrayHeaderSizeInBytes(), cg));
      }

   generateSIYInstruction(cg, TR::InstOpCode::ASI, node, generateS390MemoryReference(rThis, offsetCount, cg), 1);
   generateSIYInstruction(cg, TR::InstOpCode::ASI, node, generateS390MemoryReference(rThis, offsetModCount, cg), 1);

   // Success.  Set return value to zero.
   generateRIInstruction(cg, TR::InstOpCode::LHI, node, rReturn, 0);

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, endLabel);

   cursor = generateSInstruction(cg, TR::InstOpCode::TEND, node, generateS390MemoryReference(cg->machine()->getS390RealRegister(TR::RealRegister::GPR0),0,cg));

   // Jump to return label to exit.
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, returnLabel);

   // ----------------------------------------------------------------------------------------------------
   // The transaction aborted - Sequence to decrement retry count and loop back to transaction for retry.
   // ----------------------------------------------------------------------------------------------------
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, failureLabel);
   // Branch on Count - Decrements retryCount and jumps to transaction again if retryCount is still positive.
   generateS390BranchInstruction(cg, TR::InstOpCode::BRCT, node, rRetryCount, tstartLabel);

   // Too many aborts and failed retries.  Set return value to 2.
   generateRIInstruction(cg, TR::InstOpCode::LHI, node, rReturn, 2);

   // ------------------------------------------------------------------------------------------------------
   // Return point of inlined tmPut() code.  We'll add write barrier as well, which only exercises if
   // rReturn is zero (Success).
   // ------------------------------------------------------------------------------------------------------
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, returnLabel, deps);

   genWrtBarForTM(node, cg, rTmpObj, rNode, rReturn, true);

   cg->stopUsingRegister(rTmp);
   cg->stopUsingRegister(rTmpObj);
   cg->stopUsingRegister(rIndex);
   cg->stopUsingRegister(rRetryCount);
   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());
   cg->decReferenceCount(node->getChild(2));

   node->setRegister(rReturn);
   return rReturn;
#endif
   return NULL;
   }

static TR::Register *
inlineConcurrentHashMapTmRemove(
      TR::Node *node,
      TR::CodeGenerator * cg)
   {
#ifndef PUBLIC_BUILD
   int32_t offsetSyncObj = 0, offsetState = 0, offsetTable = 0, offsetThreshold = 0, offsetNext = 0, offsetCount = 0, offsetModCount = 0, offsetHash = 0, offsetKey = 0, offsetValue = 0;
   TR_OpaqueClassBlock * classBlock1 = NULL;
   TR_OpaqueClassBlock * classBlock2 = NULL;
   TR_OpaqueClassBlock * classBlock3 = NULL;

   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());

   classBlock1 = fej9->getClassFromSignature("Ljava/util/concurrent/ConcurrentHashMap$Segment;", 48, comp->getCurrentMethod(), true);
   classBlock2 = fej9->getClassFromSignature("java/util/concurrent/locks/AbstractQueuedSynchronizer", 53, comp->getCurrentMethod(), true);
   classBlock3 = fej9->getClassFromSignature("Ljava/util/concurrent/ConcurrentHashMap$HashEntry;", 50, comp->getCurrentMethod(), true);


   static char * disableTMRemoveenv = feGetEnv("TR_DisableTMRemove");
   bool disableTMRemove = (disableTMRemoveenv != NULL);

   if (classBlock1 && classBlock2 && classBlock3)
      {
      offsetSyncObj = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock1, "sync", 4, "Ljava/util/concurrent/locks/ReentrantLock$Sync;", 47);
      offsetTable = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock1, "table", 5, "[Ljava/util/concurrent/ConcurrentHashMap$HashEntry;", 51);
      offsetThreshold = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock1, "threshold", 9, "I", 1);
      offsetCount = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock1, "count", 5, "I", 1);
      offsetModCount = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock1, "modCount", 8, "I", 1);

      offsetState = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock2, "state", 5, "I", 1);

      offsetNext = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock3, "next", 4, "Ljava/util/concurrent/ConcurrentHashMap$HashEntry;", 50);
      offsetHash = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock3, "hash", 4, "I", 1);
      offsetKey = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock3, "key", 3, "Ljava/lang/Object;", 18);
      offsetValue = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock3, "value", 5, "Ljava/lang/Object;", 18);
      }
   else
      disableTMRemove = true;

   TR::Register * rReturn = cg->allocateCollectedReferenceRegister();
   TR::Register * rThis = cg->evaluate(node->getFirstChild());
   TR::Register * rKey = cg->evaluate(node->getSecondChild());
   TR::Register * rHash = cg->evaluate(node->getChild(2));
   TR::Register * rValue = cg->evaluate(node->getChild(3));
   TR::Register * rTmpObj = cg->allocateCollectedReferenceRegister();
   TR::Register * rTmp = cg->allocateCollectedReferenceRegister();
   TR::Register * rIndex = cg->allocateRegister();
   TR::Register * rRetryCount = cg->allocateRegister();

   TR::LabelSymbol * tstartLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * endLabel =  TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * failureLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * removeLabel =  TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * returnLabel =  TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   TR::RegisterDependencyConditions *deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 9, cg);

   deps->addPostCondition(rReturn, TR::RealRegister::AssignAny);
   deps->addPostCondition(rThis, TR::RealRegister::AssignAny);
   deps->addPostCondition(rHash, TR::RealRegister::AssignAny);
   deps->addPostCondition(rKey, TR::RealRegister::AssignAny);
   deps->addPostCondition(rValue, TR::RealRegister::AssignAny);
   deps->addPostCondition(rTmpObj, TR::RealRegister::AssignAny);
   deps->addPostCondition(rTmp, TR::RealRegister::AssignAny);
   deps->addPostCondition(rIndex, TR::RealRegister::AssignAny);
   deps->addPostCondition(rRetryCount, TR::RealRegister::AssignAny);

   bool usesCompressedrefs = comp->useCompressedPointers();
   int32_t shiftAmount = TR::Compiler->om.compressedReferenceShift();
   int32_t indexScale = TR::Compiler->target.is64Bit()? 3:2;
   if (usesCompressedrefs)
      {
      indexScale=2;
      }

   TR::Instruction * cursor = NULL;

   static char * debugTM= feGetEnv("TR_DebugTM");
   static char * enableNIAI = feGetEnv("TR_TMUseNIAI");
   // In theory, we only need to use OI to fetch exclusive the cache lines we are storing to.
   // This option enables an experimental mode where we use OI to fetch all cache lines as exclusive
   // in case there are some cache line aliasing issues.
   static char * useOIForAllCacheLinesAccessed = feGetEnv("TR_TMOIAll");

   // Retry counter.
   static const char *s = feGetEnv("TR_TMRemoveRetry");
   static uint32_t TMRemoveRetry = s ? atoi(s) : 5;
   generateRIInstruction(cg, TR::InstOpCode::LHI, node, rRetryCount, TMRemoveRetry);

   // Return value of CHM.remove is the value being removed, if successful.  NULL otherwise.
   generateRRInstruction(cg, TR::InstOpCode::getXORRegOpCode(), node, rReturn, rReturn);

   if (disableTMRemove)
      {
      cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, returnLabel);
      }
   else if (debugTM)
      {
      printf ("\nTM: use TM CHM.remove in %s (%s)", comp->signature(), comp->getHotnessName(comp->getMethodHotness()));
      fflush(stdout);
      }

   // Label used by the retry loop to retry transaction.
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, tstartLabel);
   /// immediate field described in TR::TreeEvaluator::tstartEvaluator(TR_Node * node, TR_CodeGenerator * cg)
   cursor = generateSILInstruction(cg, TR::InstOpCode::TBEGIN, node, generateS390MemoryReference(cg->machine()->getS390RealRegister(TR::RealRegister::GPR0),0,cg), 0xFF02);

   cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK7, node, failureLabel);

   if (!enableNIAI)
      {
      // For zEC12, a transaction will abort if a cache line is loaded within the transaction as read-only, only to have an XI induced
      // by a promote-to-exclusive on the store.  Use OI instead of NIAI, as the NIAI will not cause an immediate fetch exclusive if the
      // cache line is already loaded read-only.
      cursor = generateSIInstruction(cg, TR::InstOpCode::OI, node, generateS390MemoryReference(rThis, offsetCount, cg), 0x0);
      }
   else
      {
      cursor = generateS390IEInstruction(cg, TR::InstOpCode::NIAI, 1, 0, node);
      }

   // Load this.syncObj (is of type Reentrant Lock).
   if (usesCompressedrefs)
      {
      cursor = generateRXInstruction(cg, TR::InstOpCode::LLGF, node, rTmpObj, generateS390MemoryReference(rThis, offsetSyncObj, cg));
      if (shiftAmount != 0 )
         cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rTmpObj, rTmpObj, shiftAmount);
      }
   else
      {
      cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, rTmpObj, generateS390MemoryReference(rThis, offsetSyncObj, cg));
      }

   if (useOIForAllCacheLinesAccessed)
      cursor = generateSIInstruction(cg, TR::InstOpCode::OI, node, generateS390MemoryReference(rTmpObj, offsetState - 4, cg), 0x0);  // offsetState - 4 to avoid OSC penalties.

   // Check if syncObj.state == 0.
   cursor = generateRXInstruction(cg, TR::InstOpCode::LT, node, rTmp, generateS390MemoryReference(rTmpObj, offsetState, cg));
   cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, endLabel);

   if (usesCompressedrefs)
      {
      cursor = generateRXInstruction(cg, TR::InstOpCode::LLGF, node, rTmpObj, generateS390MemoryReference(rThis, offsetTable, cg));
      if (shiftAmount != 0 )
         cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rTmpObj, rTmpObj, shiftAmount);
      }
   else
      {
      cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, rTmpObj, generateS390MemoryReference(rThis, offsetTable, cg));
      }

   // Ensure that the table cache line is loaded as exclusive.  Depending on the index we later calculate, we might
   // be writing to the same cache line as the array header.
   if (!enableNIAI)
      cursor = generateSIInstruction(cg, TR::InstOpCode::OI, node, generateS390MemoryReference(rTmpObj, 0, cg), 0x0);
   else
      cursor = generateS390IEInstruction(cg, TR::InstOpCode::NIAI, 1, 0, node);

   cursor = generateRSInstruction(cg, TR::InstOpCode::ICM, node, rIndex, (uint32_t) 0xF, generateS390MemoryReference(rTmpObj, fej9->getOffsetOfContiguousArraySizeField(), cg));

   // Cond Load from discontiguousArraySize if contiguousArraySize is zero.
   cursor = generateRSInstruction(cg, TR::InstOpCode::LOC, node, rIndex, 0x8, generateS390MemoryReference(rTmpObj, fej9->getOffsetOfDiscontiguousArraySizeField(), cg));

   cursor = generateRIInstruction(cg, TR::InstOpCode::AHI, node, rIndex, -1);
   cursor = generateRRInstruction(cg, TR::InstOpCode::NR, node, rIndex, rHash);

   if (TR::Compiler->target.is64Bit())
      {
      // Zero extend rIndex and shift it left by indexScale.
      //     Effectively, shift first, and write result into bits 32-indexScale to 63 - indexScale.
      cursor = generateRIEInstruction(cg, TR::InstOpCode::RISBG, node, rIndex, rIndex, 32 - indexScale, 63 - indexScale + 0x80, indexScale);
      }
   else
      {
      cursor = generateRSInstruction(cg, TR::InstOpCode::SLL, node, rIndex, indexScale);
      }

   if (!enableNIAI)
      {
      // For zEC12, a transaction will abort if a cache line is loaded within the transaction as read-only, only to have an XI induced
      // by a promote-to-exclusive on the store.  Use OI instead of NIAI, as the NIAI will not cause an immediate fetch exclusive if the
      // cache line is already loaded read-only.
      cursor = generateRXInstruction(cg, TR::InstOpCode::LA, node, rTmp, generateS390MemoryReference(rTmpObj, rIndex, TR::Compiler->om.contiguousArrayHeaderSizeInBytes(), cg));
      cursor = generateSIInstruction(cg, TR::InstOpCode::OI, node, generateS390MemoryReference(rTmp, 0, cg), 0x0);

      // We have to use rTmp in LT as well, otherwise, LT will get scheduled ahead of the OI.
      cursor = generateRXInstruction(cg, (usesCompressedrefs)?TR::InstOpCode::LT:TR::InstOpCode::getLoadTestOpCode(), node, rTmp, generateS390MemoryReference(rTmp, 0, cg));
      }
   else
      {
      cursor = generateS390IEInstruction(cg, TR::InstOpCode::NIAI, 1, 0, node);
      cursor = generateRXInstruction(cg, (usesCompressedrefs)?TR::InstOpCode::LT:TR::InstOpCode::getLoadTestOpCode(), node, rTmp, generateS390MemoryReference(rTmpObj, rIndex, TR::Compiler->om.contiguousArrayHeaderSizeInBytes(), cg));
      }

   cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, endLabel);

   if (usesCompressedrefs)
       {
       cursor = generateRRInstruction(cg, TR::InstOpCode::LLGFR, node, rTmp, rTmp);
       if (shiftAmount != 0)
          {
          cursor = generateRSInstruction(cg, TR::InstOpCode::SRLG, node, rKey, rKey, shiftAmount);
          cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rTmp, rTmp, shiftAmount);
          }

       if (useOIForAllCacheLinesAccessed)
          cursor = generateSIInstruction(cg, TR::InstOpCode::OI, node, generateS390MemoryReference(rTmp, 0, cg), 0x0);

       // Compare Key with object in table.
       cursor = generateRXInstruction(cg, TR::InstOpCode::C, node, rKey, generateS390MemoryReference(rTmp, offsetKey, cg));
       if (shiftAmount != 0)
          cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rKey, rKey, shiftAmount);
       cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, endLabel);
       cursor = generateRRInstruction(cg, TR::InstOpCode::LTGR, node, rValue, rValue);
       cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, removeLabel);
       if (shiftAmount != 0)
          cursor = generateRSInstruction(cg, TR::InstOpCode::SRLG, node, rValue, rValue, shiftAmount);

       // Compare Value with object in table.
       cursor = generateRXInstruction(cg, TR::InstOpCode::C, node, rValue, generateS390MemoryReference(rTmp, offsetValue, cg));
       if (shiftAmount != 0)
          cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rValue, rValue, shiftAmount);
       }
    else
       {
       if (useOIForAllCacheLinesAccessed)
          cursor = generateSIInstruction(cg, TR::InstOpCode::OI, node, generateS390MemoryReference(rTmp, 0, cg), 0x0);

       cursor = generateRXInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, rKey, generateS390MemoryReference(rTmp, offsetKey, cg));
       cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, endLabel);
       cursor = generateRRInstruction(cg, TR::InstOpCode::getLoadTestRegOpCode(), node, rValue, rValue);
       cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, removeLabel);
       cursor = generateRXInstruction(cg, TR::InstOpCode::getCmpOpCode(), node, rValue, generateS390MemoryReference(rTmp, offsetValue, cg));
       }
    cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, endLabel);

    cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, removeLabel);

    if (usesCompressedrefs)
       {
       cursor = generateRXInstruction(cg, TR::InstOpCode::LLGF, node, rReturn, generateS390MemoryReference(rTmp, offsetValue, cg));
       cursor = generateRXInstruction(cg, TR::InstOpCode::L, node, rTmp, generateS390MemoryReference(rTmp, offsetNext, cg));
       cursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, rTmp, generateS390MemoryReference(rTmpObj, rIndex, TR::Compiler->om.contiguousArrayHeaderSizeInBytes(), cg));
       }
    else
       {
       cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, rReturn, generateS390MemoryReference(rTmp, offsetValue, cg));
       cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, rTmp, generateS390MemoryReference(rTmp, offsetNext, cg));
       cursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, rTmp, generateS390MemoryReference(rTmpObj, rIndex, TR::Compiler->om.contiguousArrayHeaderSizeInBytes(), cg));
       }

   cursor = generateSIYInstruction(cg, TR::InstOpCode::ASI, node, generateS390MemoryReference(rThis, offsetCount, cg), -1);
   cursor = generateSIYInstruction(cg, TR::InstOpCode::ASI, node, generateS390MemoryReference(rThis, offsetModCount, cg), 1);

   cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, endLabel);

   cursor = generateSInstruction(cg, TR::InstOpCode::TEND, node, generateS390MemoryReference(cg->machine()->getS390RealRegister(TR::RealRegister::GPR0),0,cg));

   if (usesCompressedrefs)
      {
      cursor = generateRRInstruction(cg, TR::InstOpCode::LLGFR, node, rTmp, rTmp);
      if (shiftAmount != 0)
        {
        cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rTmp, rTmp, shiftAmount);
        cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rReturn, rReturn, shiftAmount);
        }
      }

   // Jump to return label to exit.
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, returnLabel);

   // ----------------------------------------------------------------------------------------------------
   // The transaction aborted - Sequence to decrement retry count and loop back to transaction for retry.
   // ----------------------------------------------------------------------------------------------------
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, failureLabel);
   // Branch on Count - Decrements retryCount and jumps to transaction again if retryCount is still positive.
   generateS390BranchInstruction(cg, TR::InstOpCode::BRCT, node, rRetryCount, tstartLabel);

   // ----------------------------------------------------------------------------------------------------
   // Merge point for the inlined sequences.
   // ----------------------------------------------------------------------------------------------------
   cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, returnLabel, deps);

   genWrtBarForTM(node, cg, rTmpObj, rTmp, rReturn, false);

   cg->stopUsingRegister(rTmp);
   cg->stopUsingRegister(rTmpObj);
   cg->stopUsingRegister(rIndex);
   cg->stopUsingRegister(rRetryCount);
   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());
   cg->decReferenceCount(node->getChild(2));
   cg->decReferenceCount(node->getChild(3));

   node->setRegister(rReturn);
   return rReturn;
#endif
   return NULL;
   }

static TR::Register *
inlineConcurrentLinkedQueueTMOffer(
      TR::Node *node,
      TR::CodeGenerator *cg)
   {
   int32_t offsetTail = 0;
   int32_t offsetNext = 0;
   TR_OpaqueClassBlock * classBlock1 = NULL;
   TR_OpaqueClassBlock * classBlock2 = NULL;
   TR::Register * rReturn = cg->allocateRegister();
   TR::Register * rThis = cg->evaluate(node->getFirstChild());
   TR::Register * rP = cg->allocateCollectedReferenceRegister();
   TR::Register * rQ = cg->allocateCollectedReferenceRegister();
   TR::Register * rN = cg->evaluate(node->getSecondChild());
   TR::Instruction * cursor = NULL;
   TR::LabelSymbol * insertLabel =  TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * doneLabel =  TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * failLabel =  TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());

   TR::RegisterDependencyConditions *deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 5, cg);

   deps->addPostCondition(rReturn, TR::RealRegister::AssignAny);
   deps->addPostCondition(rThis, TR::RealRegister::AssignAny);
   deps->addPostCondition(rP, TR::RealRegister::AssignAny);
   deps->addPostCondition(rQ, TR::RealRegister::AssignAny);
   deps->addPostCondition(rN, TR::RealRegister::AssignAny);

   bool usesCompressedrefs = comp->useCompressedPointers();
   int32_t shiftAmount = TR::Compiler->om.compressedReferenceShift();
   static char * disableTMOfferenv = feGetEnv("TR_DisableTMOffer");
   bool disableTMOffer = (disableTMOfferenv != NULL);

   classBlock1 = fej9->getClassFromSignature("Ljava/util/concurrent/ConcurrentLinkedQueue$Node;", 49, comp->getCurrentMethod(), true);
   classBlock2 = fej9->getClassFromSignature("Ljava/util/concurrent/ConcurrentLinkedQueue;", 44, comp->getCurrentMethod(), true);


   if (classBlock1 && classBlock2)
      {
      offsetNext = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock1, "next", 4, "Ljava/util/concurrent/ConcurrentLinkedQueue$Node;", 49);
      offsetTail = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock2, "tail", 4, "Ljava/util/concurrent/ConcurrentLinkedQueue$Node;", 49);
      }
   else
      disableTMOffer = true;

   cursor = generateRIInstruction(cg, TR::InstOpCode::LHI, node, rReturn, 1);

   static char * debugTM= feGetEnv("TR_DebugTM");

   if (debugTM)
      {
      if (disableTMOffer)
         {
         printf ("\nTM: disabling TM CLQ.Offer in %s (%s)", comp->signature(), comp->getHotnessName(comp->getMethodHotness()));
         fflush(stdout);
         }
      else
         {
         printf ("\nTM: use TM CLQ.Offer in %s (%s)", comp->signature(), comp->getHotnessName(comp->getMethodHotness()));
         fflush(stdout);
         }
      }

   static char * useNonConstrainedTM = feGetEnv("TR_UseNonConstrainedTM");
   static char * disableNIAI = feGetEnv("TR_DisableNIAI");

   if (!disableTMOffer)
      {
      if (useNonConstrainedTM)
         {
         /// immediate field described in TR::TreeEvaluator::tstartEvaluator(TR_Node * node, TR_CodeGenerator * cg)
         cursor = generateSILInstruction(cg, TR::InstOpCode::TBEGIN, node, generateS390MemoryReference(cg->machine()->getS390RealRegister(TR::RealRegister::GPR0),0,cg), 0xFF02);

         cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK7, node, failLabel);
         }
      else
         {
         cursor = generateSILInstruction(cg, TR::InstOpCode::TBEGINC, node, generateS390MemoryReference(cg->machine()->getS390RealRegister(TR::RealRegister::GPR0),0,cg), 0xFF00);  //GPRMask
         }

      if (!disableNIAI)
         cursor = generateS390IEInstruction(cg, TR::InstOpCode::NIAI, 1, 0, node);

      // We must make sure the hard-coded reference loads are guarded
      auto guardedLoadMnemonic = usesCompressedrefs ? TR::InstOpCode::LLGFSG : TR::InstOpCode::LGG;

      if (TR::Compiler->om.shouldGenerateReadBarriersForFieldLoads())
         {
         cursor = generateRXYInstruction(cg, guardedLoadMnemonic, node, rP, generateS390MemoryReference(rThis, offsetTail, cg));
         }
      else
         {
         if (usesCompressedrefs)
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::LLGF, node, rP, generateS390MemoryReference(rThis, offsetTail, cg));

            if (shiftAmount != 0)
               {
               cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rP, rP, shiftAmount);
               }
            }
         else
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, rP, generateS390MemoryReference(rThis, offsetTail, cg));
            }
         }

      if (!disableNIAI)
         cursor = generateS390IEInstruction(cg, TR::InstOpCode::NIAI, 1, 0, node);

      if (TR::Compiler->om.shouldGenerateReadBarriersForFieldLoads())
         {
         cursor = generateRXYInstruction(cg, guardedLoadMnemonic, node, rQ, generateS390MemoryReference(rP, offsetNext, cg));

         cursor = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::CLG, node, rQ, 0, TR::InstOpCode::COND_CC0, insertLabel, false, false);
         }
      else
         {
         if (usesCompressedrefs)
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::LT, node, rQ, generateS390MemoryReference(rP, offsetNext, cg));
            cursor = generateRRInstruction(cg, TR::InstOpCode::LLGFR, node, rQ, rQ);

            if (shiftAmount != 0)
               {
               cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rQ, rQ, shiftAmount);
               }
            }
         else
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadTestOpCode(), node, rQ, generateS390MemoryReference(rP, offsetNext, cg));
            }

         cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, insertLabel);
         }

      cursor = generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, rP, rQ);

      if (!disableNIAI)
         cursor = generateS390IEInstruction(cg, TR::InstOpCode::NIAI, 1, 0, node);

      if (TR::Compiler->om.shouldGenerateReadBarriersForFieldLoads())
         {
         cursor = generateRXYInstruction(cg, guardedLoadMnemonic, node, rQ, generateS390MemoryReference(rP, offsetNext, cg));

         cursor = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::CLG, node, rQ, 0, TR::InstOpCode::COND_CC0, insertLabel, false, false);
         }
      else
         {
         if (usesCompressedrefs)
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::LT, node, rQ, generateS390MemoryReference(rP, offsetNext, cg));
            cursor = generateRRInstruction(cg, TR::InstOpCode::LLGFR, node, rQ, rQ);
            if (shiftAmount != 0)
               {
               cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rQ, rQ, shiftAmount);
               }
            }
         else
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadTestOpCode(), node, rQ, generateS390MemoryReference(rP, offsetNext, cg));
            }

         cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, insertLabel);
         }

      cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, doneLabel);

      cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, insertLabel);

      if (usesCompressedrefs)
         {
         if (shiftAmount != 0)
            {
            cursor = generateRSInstruction(cg, TR::InstOpCode::SRLG, node, rQ, rN, shiftAmount);
            cursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, rQ, generateS390MemoryReference(rP, offsetNext, cg));
            cursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, rQ, generateS390MemoryReference(rThis, offsetTail, cg));
            }
         else
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, rN, generateS390MemoryReference(rP, offsetNext, cg));
            cursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, rN, generateS390MemoryReference(rThis, offsetTail, cg));
            }
         }
      else
         {
         cursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, rN, generateS390MemoryReference(rP, offsetNext, cg));
         cursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, rN, generateS390MemoryReference(rThis, offsetTail, cg));
         }

      cursor = generateRRInstruction(cg, TR::InstOpCode::XR, node, rReturn, rReturn);

      cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, deps);

      cursor = generateSInstruction(cg, TR::InstOpCode::TEND, node, generateS390MemoryReference(cg->machine()->getS390RealRegister(TR::RealRegister::GPR0),0,cg));
      }

   if (useNonConstrainedTM || disableTMOffer)
      cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, failLabel, deps);

   genWrtBarForTM(node, cg, rP, rN, rReturn, true);
   genWrtBarForTM(node, cg, rThis, rN, rReturn, true);

   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());
   cg->stopUsingRegister(rP);
   cg->stopUsingRegister(rQ);

   node->setRegister(rReturn);
   return rReturn;
   }

static TR::Register *
inlineConcurrentLinkedQueueTMPoll(
      TR::Node *node,
      TR::CodeGenerator *cg)
   {
   int32_t offsetHead = 0;
   int32_t offsetNext = 0;
   int32_t offsetItem = 0;
   TR_OpaqueClassBlock * classBlock1 = NULL;
   TR_OpaqueClassBlock * classBlock2 = NULL;

   TR::Register * rE = cg->allocateCollectedReferenceRegister();
   TR::Register * rP = cg->allocateCollectedReferenceRegister();
   TR::Register * rQ = cg->allocateCollectedReferenceRegister();
   TR::Register * rThis = cg->evaluate(node->getFirstChild());
   TR::Register * rTmp = NULL;
   TR::Instruction * cursor = NULL;
   TR::LabelSymbol * doneLabel =  TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * failLabel =  TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   TR::RegisterDependencyConditions *deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 5, cg);
   deps->addPostCondition(rE, TR::RealRegister::AssignAny);
   deps->addPostCondition(rP, TR::RealRegister::AssignAny);
   deps->addPostCondition(rQ, TR::RealRegister::AssignAny);
   deps->addPostCondition(rThis, TR::RealRegister::AssignAny);

   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());

   bool usesCompressedrefs = comp->useCompressedPointers();
   int32_t shiftAmount = TR::Compiler->om.compressedReferenceShift();

   if (usesCompressedrefs && shiftAmount !=0)
      {
      rTmp = cg->allocateRegister();
      deps->addPostCondition(rTmp, TR::RealRegister::AssignAny);
      }

   static char * disableTMPollenv = feGetEnv("TR_DisableTMPoll");
   bool disableTMPoll = disableTMPollenv;

   classBlock1 = fej9->getClassFromSignature("Ljava/util/concurrent/ConcurrentLinkedQueue;", 44, comp->getCurrentMethod(), true);
   classBlock2 = fej9->getClassFromSignature("Ljava/util/concurrent/ConcurrentLinkedQueue$Node;", 49, comp->getCurrentMethod(), true);

   if (classBlock1 && classBlock2)
      {
      offsetHead = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock1, "head", 4, "Ljava/util/concurrent/ConcurrentLinkedQueue$Node;", 49);
      offsetNext = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock2, "next", 4, "Ljava/util/concurrent/ConcurrentLinkedQueue$Node;", 49);
      offsetItem = fej9->getObjectHeaderSizeInBytes() + fej9->getInstanceFieldOffset(classBlock2, "item", 4, "Ljava/lang/Object;", 18);
      }
   else
      disableTMPoll = true;

   cursor = generateRRInstruction(cg, TR::InstOpCode::getXORRegOpCode(), node, rE, rE);

   static char * debugTM= feGetEnv("TR_DebugTM");

   if (debugTM)
      {
      if (disableTMPoll)
         {
         printf ("\nTM: disabling TM CLQ.Poll in %s (%s)", comp->signature(), comp->getHotnessName(comp->getMethodHotness()));
         fflush(stdout);
         }
      else
         {
         printf ("\nTM: use TM CLQ.Poll in %s (%s)", comp->signature(), comp->getHotnessName(comp->getMethodHotness()));
         fflush(stdout);
         }
      }

   static char * useNonConstrainedTM = feGetEnv("TR_UseNonConstrainedTM");
   static char * disableNIAI = feGetEnv("TR_DisableNIAI");

   if (!disableTMPoll)
      {
      if (useNonConstrainedTM)
         {
         /// immediate field described in TR::TreeEvaluator::tstartEvaluator(TR_Node * node, TR_CodeGenerator * cg)
         cursor = generateSILInstruction(cg, TR::InstOpCode::TBEGIN, node, generateS390MemoryReference(cg->machine()->getS390RealRegister(TR::RealRegister::GPR0),0,cg), 0xFF02);

         cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK7, node, failLabel);
         }
      else
         {
         cursor = generateSILInstruction(cg, TR::InstOpCode::TBEGINC, node, generateS390MemoryReference(cg->machine()->getS390RealRegister(TR::RealRegister::GPR0),0,cg), 0xFF00);  //GPRMask
         }

      if (!disableNIAI)
         cursor = generateS390IEInstruction(cg, TR::InstOpCode::NIAI, 1, 0, node);

      // We must make sure the hard-coded reference loads are guarded
      auto guardedLoadMnemonic = usesCompressedrefs ? TR::InstOpCode::LLGFSG : TR::InstOpCode::LGG;

      if (TR::Compiler->om.shouldGenerateReadBarriersForFieldLoads())
         {
         cursor = generateRXYInstruction(cg, guardedLoadMnemonic, node, rP, generateS390MemoryReference(rThis, offsetHead, cg));
         }
      else
         {
         if (usesCompressedrefs)
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::LLGF, node, rP, generateS390MemoryReference(rThis, offsetHead, cg));

            if (shiftAmount != 0)
               {
               cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rP, rP, shiftAmount);
               }
            }
         else
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, rP, generateS390MemoryReference(rThis, offsetHead, cg));
            }
         }

      if (!disableNIAI)
         cursor = generateS390IEInstruction(cg, TR::InstOpCode::NIAI, 1, 0, node);

      if (TR::Compiler->om.shouldGenerateReadBarriersForFieldLoads())
         {
         cursor = generateRXYInstruction(cg, guardedLoadMnemonic, node, rE, generateS390MemoryReference(rP, offsetItem, cg));
         }
      else
         {
         if (usesCompressedrefs)
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::LLGF, node, rE, generateS390MemoryReference(rP, offsetItem, cg));

            if (shiftAmount != 0)
               {
               cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rE, rE, shiftAmount);
               }
            }
         else
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadOpCode(), node, rE, generateS390MemoryReference(rP, offsetItem, cg));
            }
         }

      if (!disableNIAI)
         cursor = generateS390IEInstruction(cg, TR::InstOpCode::NIAI, 1, 0, node);

      if (TR::Compiler->om.shouldGenerateReadBarriersForFieldLoads())
         {
         cursor = generateRXYInstruction(cg, guardedLoadMnemonic, node, rQ, generateS390MemoryReference(rP, offsetNext, cg));

         if (usesCompressedrefs)
            {
            cursor = generateSILInstruction(cg, TR::InstOpCode::MVHI, node, generateS390MemoryReference(rP, offsetItem, cg), 0);
            }
         else
            {
            cursor = generateSILInstruction(cg, TR::InstOpCode::getMoveHalfWordImmOpCode(), node, generateS390MemoryReference(rP, offsetItem, cg), 0);
            }

         cursor = generateS390CompareAndBranchInstruction(cg, TR::InstOpCode::CLG, node, rQ, 0, TR::InstOpCode::COND_CC0, doneLabel, false, false);
         }
      else
         {
         if (usesCompressedrefs)
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::LT, node, rQ, generateS390MemoryReference(rP, offsetNext, cg));
            cursor = generateSILInstruction(cg, TR::InstOpCode::MVHI, node, generateS390MemoryReference(rP, offsetItem, cg), 0);
            }
         else
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadTestOpCode(), node, rQ, generateS390MemoryReference(rP, offsetNext, cg));
            cursor = generateSILInstruction(cg, TR::InstOpCode::getMoveHalfWordImmOpCode(), node, generateS390MemoryReference(rP, offsetItem, cg), 0);
            }

         cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, doneLabel);
         }

      if (usesCompressedrefs)
         {
         // Register rQ is implicitly shifted via guardedLoadMnemonic where as it is not when concurrent scavenger is
         // not enabled. As such for concurrent scavenger we have to compress and then store using a temp register.
         if (TR::Compiler->om.shouldGenerateReadBarriersForFieldLoads() && shiftAmount != 0)
            {
            cursor = generateRSInstruction(cg, TR::InstOpCode::SRLG, node, rTmp, rQ, shiftAmount);
            cursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, rTmp, generateS390MemoryReference(rThis, offsetHead, cg));
            }
         else
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, rQ, generateS390MemoryReference(rThis, offsetHead, cg));
            }

         if (shiftAmount != 0)
            {
            cursor = generateRSInstruction(cg, TR::InstOpCode::SRLG, node, rTmp, rP, shiftAmount);
            cursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, rTmp, generateS390MemoryReference(rP, offsetNext, cg));
            }
         else
            {
            cursor = generateRXInstruction(cg, TR::InstOpCode::ST, node, rP, generateS390MemoryReference(rP, offsetNext, cg));
            }
         }
      else
         {
         cursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, rQ, generateS390MemoryReference(rThis, offsetHead, cg));
         cursor = generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), node, rP, generateS390MemoryReference(rP, offsetNext, cg));
         }

      if (useNonConstrainedTM)
         cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel);
      else
         cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, deps);

      cursor = generateSInstruction(cg, TR::InstOpCode::TEND, node, generateS390MemoryReference(cg->machine()->getS390RealRegister(TR::RealRegister::GPR0),0,cg));
      }

   if (useNonConstrainedTM || disableTMPoll)
      cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, failLabel, deps);

   if (!TR::Compiler->om.shouldGenerateReadBarriersForFieldLoads() && usesCompressedrefs)
      {
      generateRRInstruction(cg, TR::InstOpCode::LLGFR, node, rQ, rQ);

      if (shiftAmount != 0)
         {
         cursor = generateRSInstruction(cg, TR::InstOpCode::SLLG, node, rQ, rQ, shiftAmount);
         }
      }

   genWrtBarForTM(node, cg, rThis, rQ, rQ, false);
   // we don't need wrtbar for P, it is dead (or has NULL)

   cg->decReferenceCount(node->getFirstChild());
   cg->stopUsingRegister(rP);
   cg->stopUsingRegister(rQ);

   if (usesCompressedrefs && shiftAmount != 0)
      {
      cg->stopUsingRegister(rTmp);
      }

   node->setRegister(rE);

   return rE;
   }

#define IS_OBJ      true
#define IS_NOT_OBJ  false

extern TR::Register* inlineStringHashCode(TR::Node *node, TR::CodeGenerator *cg, bool isCompressed);
extern TR::Register* inlineUTF16BEEncodeSIMD(TR::Node *node, TR::CodeGenerator *cg);
extern TR::Register* inlineUTF16BEEncode    (TR::Node *node, TR::CodeGenerator *cg);

extern TR::Register *inlineHighestOneBit(TR::Node *node, TR::CodeGenerator *cg, bool isLong);
extern TR::Register *inlineNumberOfLeadingZeros(TR::Node *node, TR::CodeGenerator * cg, bool isLong);
extern TR::Register *inlineNumberOfTrailingZeros(TR::Node *node, TR::CodeGenerator *cg, int32_t subfconst);
extern TR::Register *inlineTrailingZerosQuadWordAtATime(TR::Node *node, TR::CodeGenerator *cg);

extern TR::Register *inlineBigDecimalConstructor(TR::Node *node, TR::CodeGenerator *cg, bool isLong, bool exp);
extern TR::Register *inlineBigDecimalBinaryOp(TR::Node * node, TR::CodeGenerator *cg, TR::InstOpCode::Mnemonic op, bool scaled);
extern TR::Register *inlineBigDecimalScaledDivide(TR::Node * node, TR::CodeGenerator *cg);
extern TR::Register *inlineBigDecimalDivide(TR::Node * node, TR::CodeGenerator *cg);
extern TR::Register *inlineBigDecimalRound(TR::Node * node, TR::CodeGenerator *cg);
extern TR::Register *inlineBigDecimalCompareTo(TR::Node * node, TR::CodeGenerator * cg);
extern TR::Register *inlineBigDecimalUnaryOp(TR::Node * node, TR::CodeGenerator * cg, TR::InstOpCode::Mnemonic op);
extern TR::Register *inlineBigDecimalSetScale(TR::Node * node, TR::CodeGenerator * cg);
extern TR::Register *inlineBigDecimalUnscaledValue(TR::Node * node, TR::CodeGenerator * cg);
extern TR::Register *inlineBigDecimalFromPackedConverter(TR::Node * node, TR::CodeGenerator * cg);
extern TR::Register *inlineBigDecimalToPackedConverter(TR::Node * node, TR::CodeGenerator * cg);

extern TR::Register *inlineToUpper(TR::Node * node, TR::CodeGenerator * cg);
extern TR::Register *inlineToLower(TR::Node * node, TR::CodeGenerator * cg);
extern TR::Register *caseConversionHelper(TR::Node * node, TR::CodeGenerator * cg, bool isToUpper);
extern TR::Register *forwardArraycopyEvaluator(TR::Node * node, TR::CodeGenerator * cg);

extern TR::Register *inlineDoubleMax(TR::Node *node, TR::CodeGenerator *cg);
extern TR::Register *inlineDoubleMin(TR::Node *node, TR::CodeGenerator *cg);
extern TR::Register *doubleMaxMinHelper(TR::Node *node, TR::CodeGenerator *cg, bool isMaxOp);

bool
J9::Z::CodeGenerator::inlineDirectCall(
      TR::Node *node,
      TR::Register *&resultReg)
   {
   TR::CodeGenerator *cg = self();
   PRINT_ME("directCall", node, cg);

   TR::MethodSymbol * methodSymbol = node->getSymbol()->getMethodSymbol();

   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());

   // If the method to be called is marked as an inline method, see if it can
   // actually be generated inline.
   //
   if (comp->getSymRefTab()->isNonHelper(node->getSymbolReference(), TR::SymbolReferenceTable::currentTimeMaxPrecisionSymbol))
      {
      resultReg = inlineCurrentTimeMaxPrecision(cg, node);
      return true;
      }
   else if (comp->getSymRefTab()->isNonHelper(node->getSymbolReference(), TR::SymbolReferenceTable::singlePrecisionSQRTSymbol))
      {
      resultReg = inlineSinglePrecisionSQRT(node, cg);
      return true;
      }
   else if (comp->getSymRefTab()->isNonHelper(node->getSymbolReference(), TR::SymbolReferenceTable::synchronizedFieldLoadSymbol))
      {
      ReduceSynchronizedFieldLoad::inlineSynchronizedFieldLoad(node, cg);
      return true;
      }

   static const char * enableTRTRE = feGetEnv("TR_enableTRTRE");
   switch (methodSymbol->getRecognizedMethod())
      {
      case TR::sun_misc_Unsafe_compareAndSwapInt_jlObjectJII_Z:
         // In Java9 this can be either the jdk.internal JNI method or the sun.misc Java wrapper.
         // In Java8 it will be sun.misc which will contain the JNI directly.
         // We only want to inline the JNI methods, so add an explicit test for isNative().
         if (!methodSymbol->isNative())
            break;

         if ((!TR::Compiler->om.canGenerateArraylets() || node->isUnsafeGetPutCASCallOnNonArray()) && node->isSafeForCGToFastPathUnsafeCall())
            {
            resultReg = VMinlineCompareAndSwap(node, cg, TR::InstOpCode::CS, IS_NOT_OBJ);
            return true;
            }

      case TR::sun_misc_Unsafe_compareAndSwapLong_jlObjectJJJ_Z:
         // As above, we only want to inline the JNI methods, so add an explicit test for isNative()
         if (!methodSymbol->isNative())
            break;

         if (TR::Compiler->target.is64Bit() && (!TR::Compiler->om.canGenerateArraylets() || node->isUnsafeGetPutCASCallOnNonArray()) && node->isSafeForCGToFastPathUnsafeCall())
            {
            resultReg = VMinlineCompareAndSwap(node, cg, TR::InstOpCode::CSG, IS_NOT_OBJ);
            return true;
            }
         // Too risky to do Long-31bit version now.
         break;

      case TR::sun_misc_Unsafe_compareAndSwapObject_jlObjectJjlObjectjlObject_Z:
         // As above, we only want to inline the JNI methods, so add an explicit test for isNative()
         if (!methodSymbol->isNative())
            break;

         if ((!TR::Compiler->om.canGenerateArraylets() || node->isUnsafeGetPutCASCallOnNonArray()) && node->isSafeForCGToFastPathUnsafeCall())
            {
            resultReg = VMinlineCompareAndSwap(node, cg, (comp->useCompressedPointers() ? TR::InstOpCode::CS : TR::InstOpCode::getCmpAndSwapOpCode()), IS_OBJ);
            return true;
            }
         break;

      case TR::java_util_concurrent_atomic_Fences_reachabilityFence:
      case TR::java_util_concurrent_atomic_Fences_orderAccesses:
      case TR::java_util_concurrent_atomic_Fences_orderReads:
      case TR::java_util_concurrent_atomic_Fences_orderWrites:
         cg->decReferenceCount(node->getChild(0));
         break;

      case TR::java_util_concurrent_atomic_AtomicBoolean_getAndSet:
      case TR::java_util_concurrent_atomic_AtomicInteger_getAndAdd:
      case TR::java_util_concurrent_atomic_AtomicInteger_getAndIncrement:
      case TR::java_util_concurrent_atomic_AtomicInteger_getAndDecrement:
      case TR::java_util_concurrent_atomic_AtomicInteger_getAndSet:
      case TR::java_util_concurrent_atomic_AtomicInteger_addAndGet:
      case TR::java_util_concurrent_atomic_AtomicInteger_incrementAndGet:
      case TR::java_util_concurrent_atomic_AtomicInteger_decrementAndGet:
         resultReg = inlineAtomicOps(node, cg, 4, methodSymbol);
         return true;
         break;

      case TR::java_util_concurrent_atomic_AtomicIntegerArray_getAndAdd:
      case TR::java_util_concurrent_atomic_AtomicIntegerArray_getAndIncrement:
      case TR::java_util_concurrent_atomic_AtomicIntegerArray_getAndDecrement:
      case TR::java_util_concurrent_atomic_AtomicIntegerArray_getAndSet:
      case TR::java_util_concurrent_atomic_AtomicIntegerArray_addAndGet:
      case TR::java_util_concurrent_atomic_AtomicIntegerArray_incrementAndGet:
      case TR::java_util_concurrent_atomic_AtomicIntegerArray_decrementAndGet:
         resultReg = inlineAtomicOps(node, cg, 4, methodSymbol, true);
         return true;
         break;

      case TR::java_util_concurrent_atomic_AtomicLong_addAndGet:
      case TR::java_util_concurrent_atomic_AtomicLong_getAndAdd:
      case TR::java_util_concurrent_atomic_AtomicLong_incrementAndGet:
      case TR::java_util_concurrent_atomic_AtomicLong_getAndIncrement:
      case TR::java_util_concurrent_atomic_AtomicLong_decrementAndGet:
      case TR::java_util_concurrent_atomic_AtomicLong_getAndDecrement:
         if (cg->checkFieldAlignmentForAtomicLong() &&
             cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z196) &&
             (TR::Compiler->target.is64Bit() || TR::Compiler->target.isZOS()  ||
              (cg->supportsHighWordFacility() && !comp->getOption(TR_DisableHighWordRA))))
            {
            resultReg = inlineAtomicOps(node, cg, 8, methodSymbol);  // LAAG on 31-bit linux must have HPR support
            return true;
            }
         break;

      case TR::java_util_concurrent_atomic_AtomicLongArray_addAndGet:
      case TR::java_util_concurrent_atomic_AtomicLongArray_getAndAdd:
      case TR::java_util_concurrent_atomic_AtomicLongArray_incrementAndGet:
      case TR::java_util_concurrent_atomic_AtomicLongArray_getAndIncrement:
      case TR::java_util_concurrent_atomic_AtomicLongArray_decrementAndGet:
      case TR::java_util_concurrent_atomic_AtomicLongArray_getAndDecrement:
         if (cg->checkFieldAlignmentForAtomicLong() &&
             cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z196) &&
             (TR::Compiler->target.is64Bit() || TR::Compiler->target.isZOS()  ||
              (cg->supportsHighWordFacility() && !comp->getOption(TR_DisableHighWordRA))))
            {
            resultReg = inlineAtomicOps(node, cg, 8, methodSymbol);  // LAAG on 31-bit linux must have HPR support
            return true;
            }
         break;
         break;

      case TR::java_util_concurrent_atomic_AtomicMarkableReference_doubleWordCAS:
         if (cg->getSupportsDoubleWordCAS())
            {
            resultReg = inlineDoubleWordCAS(node, cg, true);
            return true;
            }
         break;

      case TR::java_util_concurrent_atomic_AtomicStampedReference_doubleWordCAS:
         if (cg->getSupportsDoubleWordCAS())
            {
            resultReg = inlineDoubleWordCAS(node, cg, false);
            return true;
            }
         break;

      case TR::java_util_concurrent_atomic_AtomicMarkableReference_doubleWordSet:
         if (cg->getSupportsDoubleWordSet())
            {
            resultReg = inlineDoubleWordSet(node, cg, true);
            return true;
            }
         break;

      case TR::java_util_concurrent_atomic_AtomicStampedReference_doubleWordSet:
         if (cg->getSupportsDoubleWordSet())
            {
            resultReg = inlineDoubleWordSet(node, cg, false);
            return true;
            }
         break;

      case TR::java_util_concurrent_atomic_AtomicMarkableReference_doubleWordCASSupported:
      case TR::java_util_concurrent_atomic_AtomicMarkableReference_doubleWordSetSupported:
         if (cg->getSupportsDoubleWordCAS())
            {
            resultReg = inlineDoubleWordCASOrSetSupported(node, cg, true);
            return true;
            }
         break;

      case TR::java_util_concurrent_atomic_AtomicStampedReference_doubleWordSetSupported:
      case TR::java_util_concurrent_atomic_AtomicStampedReference_doubleWordCASSupported:
         if (cg->getSupportsDoubleWordSet())
            {
            resultReg = inlineDoubleWordCASOrSetSupported(node, cg, false);
            return true;
            }
         break;

      case TR::java_util_concurrent_atomic_AtomicIntegerFieldUpdater_incrementAndGet:
      case TR::java_util_concurrent_atomic_AtomicIntegerFieldUpdater_decrementAndGet:
      case TR::java_util_concurrent_atomic_AtomicIntegerFieldUpdater_addAndGet:
      case TR::java_util_concurrent_atomic_AtomicIntegerFieldUpdater_getAndIncrement:
      case TR::java_util_concurrent_atomic_AtomicIntegerFieldUpdater_getAndDecrement:
      case TR::java_util_concurrent_atomic_AtomicIntegerFieldUpdater_getAndAdd:
         if (cg->getSupportsAtomicLoadAndAdd())
            {
            resultReg = inlineAtomicFieldUpdater(node, cg, methodSymbol);
            return true;
            }
         break;

      case TR::java_nio_Bits_keepAlive:
         resultReg = inlineKeepAlive(node, cg);
         return true;

      case TR::java_util_concurrent_ConcurrentHashMap_tmPut:
         if (cg->getSupportsTM())
            {
            resultReg = inlineConcurrentHashMapTmPut(node, cg);
            return true;
            }
         break;

      case TR::java_util_concurrent_ConcurrentHashMap_tmRemove:
         if (cg->getSupportsTM())
            {
            resultReg = inlineConcurrentHashMapTmRemove(node, cg);
            return true;
            }
         break;

      case TR::java_util_concurrent_ConcurrentLinkedQueue_tmOffer:
         if (cg->getSupportsTM())
            {
            resultReg = inlineConcurrentLinkedQueueTMOffer(node, cg);
            return true;
            }
         break;

      case TR::java_util_concurrent_ConcurrentLinkedQueue_tmPoll:
         if (cg->getSupportsTM())
            {
            resultReg = inlineConcurrentLinkedQueueTMPoll(node, cg);
            return true;
            }
         break;
       // HashCode routine for Compressed and Decompressed String Shares lot of code so combining them.
      case TR::java_lang_String_hashCodeImplDecompressed:
         if (!comp->getOption(TR_DisableSIMDStringHashCode))
            {
            if (cg->getSupportsVectorRegisters() && !TR::Compiler->om.canGenerateArraylets())
               return resultReg = inlineStringHashCode(node, cg, false);
            }
         break;

      case TR::java_lang_String_hashCodeImplCompressed:
         if (!comp->getOption(TR_DisableSIMDStringHashCode)){
            if (cg->getSupportsVectorRegisters() && !TR::Compiler->om.canGenerateArraylets()){
                return resultReg = inlineStringHashCode(node, cg, true);
            }
         }
        break;

      case TR::com_ibm_jit_JITHelpers_transformedEncodeUTF16Big:
         return resultReg = comp->getOption(TR_DisableUTF16BEEncoder) ? inlineUTF16BEEncodeSIMD(node, cg)
                                                                      : inlineUTF16BEEncode    (node, cg);
         break;

      case TR::com_ibm_dataaccess_ByteArrayUtils_trailingZerosQuadWordAtATime_:
         // TODO (Nigel): Is this deprecated? If so can we remove this?
         if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10) && !comp->getOption(TR_DisableIntrinsics) && !comp->getOption(TR_DisableDAATrailingZero) && !TR::Compiler->om.canGenerateArraylets())
            return resultReg = inlineTrailingZerosQuadWordAtATime(node, cg);
         break;

      default:
         break;

      }

   switch (methodSymbol->getRecognizedMethod())
      {
      case TR::java_lang_Integer_highestOneBit:
         resultReg = inlineHighestOneBit(node, cg, false);
         return true;
      case TR::java_lang_Integer_numberOfLeadingZeros:
         resultReg = inlineNumberOfLeadingZeros(node, cg, false);
         return true;
      case TR::java_lang_Integer_numberOfTrailingZeros:
         resultReg = inlineNumberOfTrailingZeros(node, cg, 32);
         return true;
      case TR::java_lang_Long_highestOneBit:
         resultReg = inlineHighestOneBit(node, cg, true);
         return true;
      case TR::java_lang_Long_numberOfLeadingZeros:
         resultReg = inlineNumberOfLeadingZeros(node, cg, true);
         return true;
      case TR::java_lang_Long_numberOfTrailingZeros:
         resultReg = inlineNumberOfTrailingZeros(node, cg, 64);
         return true;
      default:
         break;
      }

#ifdef J9VM_OPT_JAVA_CRYPTO_ACCELERATION
   if (self()->inlineCryptoMethod(node, resultReg))
      {
      return true;
      }
#endif

   if (!comp->getOption(TR_DisableSIMDStringCaseConv) && cg->getSupportsVectorRegisters())
      {
      switch (methodSymbol->getRecognizedMethod())
         {
         case TR::java_lang_String_toUpperHWOptimized:
         case TR::java_lang_String_toUpperHWOptimizedDecompressed:
            resultReg = inlineToUpper(node, cg, false);
            return true;
         case TR::java_lang_String_toUpperHWOptimizedCompressed:
            resultReg = inlineToUpper(node, cg, true);
            return true;
         case TR::java_lang_String_toLowerHWOptimized:
         case TR::java_lang_String_toLowerHWOptimizedDecompressed:
            resultReg = inlineToLower(node, cg, false);
            return true;
         case TR::java_lang_String_toLowerHWOptimizedCompressed:
            resultReg = inlineToLower(node, cg, true);
            return true;
         default:
            break;
         }
      }

      if (!comp->getOption(TR_DisableSIMDDoubleMaxMin) && cg->getSupportsVectorRegisters())
         {
         switch (methodSymbol->getRecognizedMethod())
            {
            case TR::java_lang_Math_max_D:
               resultReg = inlineDoubleMax(node, cg);
               return true;
            case TR::java_lang_Math_min_D:
               resultReg = inlineDoubleMin(node, cg);
               return true;
            default:
               break;
            }
         }

     switch (methodSymbol->getRecognizedMethod())
        {
        case TR::java_lang_Long_reverseBytes:
            resultReg = inlineLongReverseBytes(node, cg);
            return true;
        case TR::java_lang_Integer_reverseBytes:
            resultReg = inlineIntegerReverseBytes(node, cg);
            return true;
        case TR::java_lang_Short_reverseBytes:
            resultReg = inlineShortReverseBytes(node, cg);
            return true;
        default:
           break;
        }

   if (!comp->compileRelocatableCode() && !comp->getOption(TR_DisableDFP) &&
       TR::Compiler->target.cpu.getS390SupportsDFP())
      {
      TR_ASSERT( methodSymbol, "require a methodSymbol for DFP on Z\n");
      if (methodSymbol)
         {
         switch(methodSymbol->getMandatoryRecognizedMethod())
            {
            case TR::java_math_BigDecimal_DFPIntConstructor:
               resultReg = inlineBigDecimalConstructor(node, cg, false, false);
               return true;
            case TR::java_math_BigDecimal_DFPLongConstructor:
               resultReg = inlineBigDecimalConstructor(node, cg, true, false);
               return true;
            case TR::java_math_BigDecimal_DFPLongExpConstructor:
               resultReg = inlineBigDecimalConstructor(node, cg, true, true);
               return true;
            case TR::java_math_BigDecimal_DFPAdd:
               resultReg = inlineBigDecimalBinaryOp(node, cg, TR::InstOpCode::ADTR, false);
               return true;
            case TR::java_math_BigDecimal_DFPSubtract:
               resultReg = inlineBigDecimalBinaryOp(node, cg, TR::InstOpCode::SDTR, false);
               return true;
            case TR::java_math_BigDecimal_DFPMultiply:
               resultReg = inlineBigDecimalBinaryOp(node, cg, TR::InstOpCode::MDTR, false);
               return true;
            case TR::java_math_BigDecimal_DFPScaledAdd:
               resultReg = inlineBigDecimalBinaryOp(node, cg, TR::InstOpCode::ADTR, true);
               return true;
            case TR::java_math_BigDecimal_DFPScaledSubtract:
               resultReg = inlineBigDecimalBinaryOp(node, cg, TR::InstOpCode::SDTR, true);
               return true;
            case TR::java_math_BigDecimal_DFPScaledMultiply:
               resultReg = inlineBigDecimalBinaryOp(node, cg, TR::InstOpCode::MDTR, true);
               return true;
            case TR::java_math_BigDecimal_DFPRound:
               resultReg = inlineBigDecimalRound(node, cg);
               return true;
            case TR::java_math_BigDecimal_DFPSignificance:
               resultReg = inlineBigDecimalUnaryOp(node, cg, TR::InstOpCode::ESDTR);
               return true;
            case TR::java_math_BigDecimal_DFPExponent:
               resultReg = inlineBigDecimalUnaryOp(node, cg, TR::InstOpCode::EEDTR);
               return true;
            case TR::java_math_BigDecimal_DFPCompareTo:
               resultReg = inlineBigDecimalCompareTo(node, cg);
               return true;
            case TR::java_math_BigDecimal_DFPBCDDigits:
               resultReg = inlineBigDecimalUnaryOp(node, cg, TR::InstOpCode::CUDTR);
               return true;
            case TR::java_math_BigDecimal_DFPUnscaledValue:
               resultReg = inlineBigDecimalUnscaledValue(node, cg);
               return true;
            case TR::java_math_BigDecimal_DFPSetScale:
               resultReg = inlineBigDecimalSetScale(node, cg);
               return true;
            case TR::java_math_BigDecimal_DFPDivide:
               resultReg = inlineBigDecimalDivide(node, cg);
               return true;
            case TR::java_math_BigDecimal_DFPConvertPackedToDFP:
            case TR::com_ibm_dataaccess_DecimalData_DFPConvertPackedToDFP:
               resultReg = inlineBigDecimalFromPackedConverter(node, cg);
               return true;
            case TR::java_math_BigDecimal_DFPConvertDFPToPacked:
            case TR::com_ibm_dataaccess_DecimalData_DFPConvertDFPToPacked:
               resultReg = inlineBigDecimalToPackedConverter(node, cg);
               return true;
            default:
               break;
            }
         }
      }

   TR::MethodSymbol * symbol = node->getSymbol()->castToMethodSymbol();
   if ((symbol->isVMInternalNative() || symbol->isJITInternalNative()) || isKnownMethod(methodSymbol))
      {
      if (TR::TreeEvaluator::VMinlineCallEvaluator(node, false, cg))
         {
         resultReg = node->getRegister();
         return true;
         }
      }

   // No method specialization was done.
   //
   resultReg = NULL;
   return false;
   }

void
VMgenerateCatchBlockBBStartPrologue(
      TR::Node *node,
      TR::Instruction *fenceInstruction,
      TR::CodeGenerator *cg)
   {
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());
   if (comp->getOption(TR_FullSpeedDebug))
      {
      fenceInstruction->setNeedsGCMap(); // a catch entry is a gc point in FSD mode
      }

   TR::Block *block = node->getBlock();

   // Encourage recompilation
   if (fej9->shouldPerformEDO(block, comp))
      {
      TR::Register * biAddrReg = cg->allocateRegister();

      // Load address of counter into biAddrReg
      genLoadAddressConstant(cg, node, (uintptrj_t) comp->getRecompilationInfo()->getCounterAddress(), biAddrReg);

      // Counter is 32-bit, so only use 32-bit opcodes
      if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10))
         {
         TR::MemoryReference * recompMR = generateS390MemoryReference(biAddrReg, 0, cg);
         generateSIYInstruction(cg, TR::InstOpCode::ASI, node, recompMR, -1);
         recompMR->stopUsingMemRefRegister(cg);
         }
      else
         {
         TR::Register * recompCounterReg = cg->allocateRegister();
         TR::MemoryReference * loadbiMR = generateS390MemoryReference(biAddrReg, 0, cg);
         generateRXInstruction(cg, TR::InstOpCode::L, node, recompCounterReg, loadbiMR);
         generateRIInstruction(cg, TR::InstOpCode::AHI, node, recompCounterReg, -1);
         loadbiMR->stopUsingMemRefRegister(cg);
         TR::MemoryReference * storebiMR = generateS390MemoryReference(biAddrReg, 0, cg);
         generateRXInstruction(cg, TR::InstOpCode::ST, node, recompCounterReg, storebiMR);

         cg->stopUsingRegister(recompCounterReg);
         storebiMR->stopUsingMemRefRegister(cg);
         }

      // Check counter and induce recompilation if counter = 0
      TR::LabelSymbol * snippetLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol * restartLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

      snippetLabel->setEndInternalControlFlow();

      TR::Register * tempReg1 = cg->allocateRegister();
      TR::Register * tempReg2 = cg->allocateRegister();

      TR::RegisterDependencyConditions * dependencies = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 2, cg);
      dependencies->addPostCondition(tempReg1, cg->getEntryPointRegister());
      dependencies->addPostCondition(tempReg2, cg->getReturnAddressRegister());
      // Branch to induceRecompilation helper routine if counter is 0 - based on condition code of the precedeing adds.
      TR::Instruction * cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, snippetLabel);
      cursor->setStartInternalControlFlow();

      TR::Snippet * snippet = new (cg->trHeapMemory()) TR::S390ForceRecompilationSnippet(cg, node, restartLabel, snippetLabel);
      cg->addSnippet(snippet);
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, restartLabel, dependencies);

      cg->stopUsingRegister(tempReg1);
      cg->stopUsingRegister(tempReg2);

      cg->stopUsingRegister(biAddrReg);
      }
   }

void
TR_J9VMBase::generateBinaryEncodingPrologue(
      TR_BinaryEncodingData *beData,
      TR::CodeGenerator *cg)
   {
   TR_S390BinaryEncodingData *data = (TR_S390BinaryEncodingData *)beData;
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());

   data->cursorInstruction = cg->getFirstInstruction();
   data->estimate = 0;
   TR::Recompilation * recomp = comp->getRecompilationInfo();

   TR::ResolvedMethodSymbol * methodSymbol = comp->getJittedMethodSymbol();

   //  setup cursor for JIT to JIT transfer
   //
   if (comp->getJittedMethodSymbol()->isJNI() &&
      !comp->getOption(TR_FullSpeedDebug))
      {
      data->preProcInstruction = (TR::Compiler->target.is64Bit())?data->cursorInstruction->getNext()->getNext():data->cursorInstruction->getNext();
      }
   else
      {
      data->preProcInstruction = data->cursorInstruction;
      }

   data->jitTojitStart = data->preProcInstruction->getNext();

   // Generate code to setup argument registers for interpreter to JIT transfer
   // This piece of code is right before JIT-JIT entry point
   //
   TR::Instruction * preLoadArgs, * endLoadArgs;
   preLoadArgs = data->preProcInstruction;

   // We need full prolog if there is a call or a non-constant snippet
   //
   TR_BitVector * callBlockBV = cg->getBlocksWithCalls();

   // No exit points, hence we can
   //
   if (callBlockBV->isEmpty() && !cg->anyNonConstantSnippets())
      {
      cg->setExitPointsInMethod(false);
      }

   endLoadArgs = cg->getS390PrivateLinkage()->loadUpArguments(preLoadArgs);

   if (recomp != NULL)
      {
      if (preLoadArgs != endLoadArgs)
         {
         data->loadArgSize = CalcCodeSize(preLoadArgs->getNext(), endLoadArgs);
         }

      ((TR_S390Recompilation *) recomp)->setLoadArgSize(data->loadArgSize);
      recomp->generatePrePrologue();
      }
   else if (comp->getOption(TR_FullSpeedDebug) || comp->getOption(TR_SupportSwitchToInterpreter))
      {
      if (preLoadArgs != endLoadArgs)
         {
         data->loadArgSize = CalcCodeSize(preLoadArgs->getNext(), endLoadArgs);
         }

      cg->generateVMCallHelperPrePrologue(NULL);
      }

   data->cursorInstruction = cg->getFirstInstruction();

   static char *disableAlignJITEP = feGetEnv("TR_DisableAlignJITEP");

   // Padding for JIT Entry Point
   //
   if (!disableAlignJITEP && !comp->compileRelocatableCode())
      {
      data->estimate += 256;
      }

   while (data->cursorInstruction && data->cursorInstruction->getOpCodeValue() != TR::InstOpCode::PROC)
      {
      data->estimate = data->cursorInstruction->estimateBinaryLength(data->estimate);
      data->cursorInstruction = data->cursorInstruction->getNext();
      }

   // Emit the spill instruction to set up the vmThread reloads if needed
   // (i.e., if the vmThread was ever spilled to make room for another register)
   //
   // TODO take this part out when doing IL level vm thread work
   //
   if (comp->getOption(TR_Enable390FreeVMThreadReg))
      {
      TR::Instruction *vmThreadSpillCursor = cg->getVMThreadSpillInstruction();
      if (vmThreadSpillCursor && cg->getVMThreadRegister()->getBackingStorage())
         {
         if (vmThreadSpillCursor == (TR::Instruction *)0xffffffff ||
             comp->mayHaveLoops())
            {
            vmThreadSpillCursor = data->cursorInstruction;
            }

         TR::MemoryReference * tempMR = generateS390MemoryReference(vmThreadSpillCursor->getNode(), cg->getVMThreadRegister()->getBackingStorage()->getSymbolReference(), cg);
         TR::RealRegister::RegNum vmThreadIndex = cg->getS390PrivateLinkage()->getMethodMetaDataRegister();
         generateRXInstruction(cg, TR::InstOpCode::getStoreOpCode(), vmThreadSpillCursor->getNode(), cg->getS390Linkage()->getS390RealRegister(vmThreadIndex), tempMR, vmThreadSpillCursor);
         }
      }

   TR::Instruction* cursor = data->cursorInstruction;

   if (recomp != NULL)
      {
      cursor = recomp->generatePrologue(cursor);
      }

   cg->getLinkage()->createPrologue(cursor);
   }


TR::MemoryReference *
J9::Z::TreeEvaluator::asciiAndUnicodeToPackedHelper(TR::Node *node,
                                                    TR_PseudoRegister *targetReg,
                                                    TR::MemoryReference *sourceMR,
                                                    TR_PseudoRegister *childReg,
                                                    TR::CodeGenerator * cg)
   {
   TR::Node *child = node->getFirstChild();
   bool isUnicode = child->getType().isAnyUnicode();
   bool isZoned = child->getType().isAnyZoned();

   TR::DataType sourceType = TR::NoType;
   TR::Compilation *comp = cg->comp();
   if (isUnicode)
      sourceType = TR::UnicodeDecimal;
   else if (isZoned)
      sourceType = TR::ZonedDecimal;
   else
      TR_ASSERT(false,"unexpected type on node %s (%p)\n",child->getOpCode().getName(),child);

   TR_StorageReference *hint = node->getStorageReferenceHint();
   TR_StorageReference *targetStorageReference = NULL;
   int32_t destSize = isUnicode ? cg->getUnicodeToPackedFixedResultSize() : cg->getAsciiToPackedFixedResultSize();
   TR_ASSERT(TR::DataType::getBCDPrecisionFromSize(node->getDataType(), destSize) >= childReg->getDecimalPrecision(),
      "%s source precision of %d should not exceed the fixed precision of %d\n",
         node->getOpCode().getName(), childReg->getDecimalPrecision(), TR::DataType::getBCDPrecisionFromSize(node->getDataType(), destSize));

   if (hint)
      {
      if (childReg->isInitialized() && hint == childReg->getStorageReference())
         {
         TR_ASSERT( false,"ad2pd/ud2pd operands will overlap because child storageReference of ud2pd is initialized hint\n");
         }
      else
         {
         TR_ASSERT(hint->getSymbolSize() >= destSize, "ad2pd/ud2pd hint size of %d should be >= the fixed size of %d\n",hint->getSymbolSize(),destSize);
         targetStorageReference = hint;
         }
      }

   if (targetStorageReference == NULL)
      targetStorageReference = TR_StorageReference::createTemporaryBasedStorageReference(destSize, comp);

   targetReg->setStorageReference(targetStorageReference, node);

   int32_t sourcePrecision = childReg->getDecimalPrecision();
   bool isTruncation = sourcePrecision > node->getDecimalPrecision();
   int32_t pkxSourcePrecision = isTruncation ? node->getDecimalPrecision() : sourcePrecision;
   int32_t pkxSourceSize = TR::DataType::getSizeFromBCDPrecision(sourceType, pkxSourcePrecision);
   int32_t targetPrecision = pkxSourcePrecision;
   int32_t sourceEndByte = TR::DataType::getLeftMostByte(child->getDataType(), pkxSourceSize);

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tasciiAndUnicodeToPackedHelper %p : op %s, isTruncation=%s, fixedDestSize %d, targetRegPrec %d, sourcePrecision %d, sourceEndByte %d, sourceSize %d, pkuSourceSize %d\n",
         node,node->getOpCode().getName(),isTruncation?"yes":"no",destSize,targetPrecision,sourcePrecision,sourceEndByte,childReg->getSize(),pkxSourceSize);

   // For PKA/PKU the 1st operand (target) size is fixed at 16 bytes and the 2nd operand (source) is variable.
   // For this reason use left, instead of right, aligned memory references so the correct alignment is done for both operands
   // (using right aligned references with SS1 would apply the same bump to both operands)
   TR::MemoryReference *destMR = generateS390LeftAlignedMemoryReference(node, targetReg->getStorageReference(), cg, destSize);
   sourceMR = reuseS390LeftAlignedMemoryReference(sourceMR, child, childReg->getStorageReference(), cg, sourceEndByte);

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tgen %s with fixed dest size of %d and source size %d. Set targetRegPrec to sourcePrec (%d)\n",isUnicode?"PKU":"PKA",destSize,pkxSourceSize,sourcePrecision);

   generateSS1Instruction(cg, isUnicode ? TR::InstOpCode::PKU : TR::InstOpCode::PKA, node, pkxSourceSize-1, destMR, sourceMR);

   int32_t destSizeAsCeilingPrecision = TR::DataType::byteLengthToPackedDecimalPrecisionCeiling(destSize);
   if (destSizeAsCeilingPrecision > pkxSourcePrecision)
      targetReg->addRangeOfZeroDigits(pkxSourcePrecision, destSizeAsCeilingPrecision);

   if (node->getOpCode().isSetSign())
      {
      TR::Node *setSignNode = node->getSetSignValueNode();
      TR_ASSERT(setSignNode->getOpCode().isLoadConst() && setSignNode->getOpCode().getSize() <= 4,"expecting a <= 4 size integral constant set sign amount on node %p\n",setSignNode);
      int32_t sign = setSignNode->get32bitIntegralValue();
      if (sign == TR::DataType::getPreferredPlusCode())
         targetReg->setKnownSignCode(TR::DataType::getPreferredPlusCode());
      else
         cg->genSignCodeSetting(node, targetReg, targetReg->getSize(), destMR, sign, targetReg, 0, false); // numericNibbleIsZero=false
      cg->decReferenceCount(setSignNode);
      }
   else
      {
      // PKA/PKU always sets the preferred positive code and therefore a known clean sign is generated.
      targetReg->setKnownSignCode(TR::DataType::getPreferredPlusCode());
      }

   targetReg->setDecimalPrecision(targetPrecision);
   targetReg->transferDataState(childReg);
   targetReg->setIsInitialized();
   node->setRegister(targetReg);
   return destMR;
   }

TR::Register *
J9::Z::TreeEvaluator::ud2pdVectorEvaluatorHelper(TR::Node * node, TR::CodeGenerator * cg)
   {
   // 1. use ud2pd helper to put ud->pd in some storage reference
   TR_PseudoRegister *packedPseudoReg = cg->allocatePseudoRegister(node->getDataType());
   TR::Node *child = node->getFirstChild();
   TR_PseudoRegister *childReg = cg->evaluateBCDNode(child);
   childReg = cg->privatizeBCDRegisterIfNeeded(node, child, childReg);
   TR::MemoryReference *sourceMR = generateS390RightAlignedMemoryReference(child, childReg->getStorageReference(), cg);
   asciiAndUnicodeToPackedHelper(node, packedPseudoReg, sourceMR, childReg, cg);

   // 2. load packed decimal from storage reference to register.
   TR::Register * targetReg = cg->allocateRegister(TR_VRF);
   TR::MemoryReference * pdSourceMR = generateS390RightAlignedMemoryReference(node,
                                                                              packedPseudoReg->getStorageReference(),
                                                                              cg);

   // PKU always puts the result into 16 bytes space
   uint8_t lengthToLoad = TR_VECTOR_REGISTER_SIZE - 1;
   generateVSIInstruction(cg, TR::InstOpCode::VLRL, node, targetReg, pdSourceMR, lengthToLoad);

   cg->decReferenceCount(child);
   node->setRegister(targetReg);
   return targetReg;
   }

/**
 * Handles TR::ud2pd
 */
TR::Register *
J9::Z::TreeEvaluator::ud2pdEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("ud2pd",node);
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "PD-Op/%s", node->getOpCode().getName()),
                            1, TR::DebugCounter::Cheap);
   TR::Register* targetReg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() &&
           !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) ||
           isVectorBCDEnv)
      {
      targetReg = ud2pdVectorEvaluatorHelper(node, cg);
      }
   else
      {
      targetReg = cg->allocatePseudoRegister(node->getDataType());
      TR::Node *child = node->getFirstChild();
      TR_PseudoRegister *childReg = cg->evaluateBCDNode(child);
      childReg = cg->privatizeBCDRegisterIfNeeded(node, child, childReg);
      TR::MemoryReference *sourceMR = generateS390RightAlignedMemoryReference(child, childReg->getStorageReference(), cg);
      asciiAndUnicodeToPackedHelper(node, static_cast<TR_PseudoRegister*>(targetReg), sourceMR, childReg, cg);
      cg->decReferenceCount(child);
      node->setRegister(targetReg);
      }

   cg->traceBCDExit("ud2pd",node);
   return targetReg;
   }

/**
 * Handles TR::udsl2pd, TR::udst2pd
 */
TR::Register *
J9::Z::TreeEvaluator::udsl2pdEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR::Compilation *comp = cg->comp();
   cg->traceBCDEntry("udsl2pd",node);
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "PD-Op/%s", node->getOpCode().getName()),
                            1, TR::DebugCounter::Cheap);
   TR_PseudoRegister *targetReg = cg->allocatePseudoRegister(node->getDataType());
   TR::Node *child = node->getFirstChild();
   TR_PseudoRegister *childReg = cg->evaluateBCDNode(child);
   childReg = cg->privatizeBCDRegisterIfNeeded(node, child, childReg);

   bool isSrcTrailingSign = (child->getDataType() == TR::UnicodeDecimalSignTrailing);
   int32_t sourceSignEndByte = isSrcTrailingSign ? TR::DataType::getUnicodeSignSize() : childReg->getSize();
   TR::MemoryReference *sourceMR = generateS390LeftAlignedMemoryReference(child, childReg->getStorageReference(), cg, sourceSignEndByte);
   TR::MemoryReference *destMR = asciiAndUnicodeToPackedHelper(node, targetReg, sourceMR, childReg, cg);

   if (!node->getOpCode().isSetSign())
      {
      TR::LabelSymbol * startLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol * doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

      bool isImplicitValue = node->getNumChildren() < 2;

      TR::RegisterDependencyConditions * deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, isImplicitValue ? 4 : 2, cg);

      if (destMR->getIndexRegister())
         deps->addPostConditionIfNotAlreadyInserted(destMR->getIndexRegister(), TR::RealRegister::AssignAny);
      if (destMR->getBaseRegister())
         deps->addPostConditionIfNotAlreadyInserted(destMR->getBaseRegister(), TR::RealRegister::AssignAny);

      bool isTruncation = childReg->getDecimalPrecision() > node->getDecimalPrecision();

      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tudsl2pdEvaluator %p : op %s, isTruncation=%s, targetReg->isInit=%s, targetRegSize=%d, targetRegPrec=%d, srcRegSize=%d, srcRegPrec=%d, sourceSignEndByte=%d\n",
            node,node->getOpCode().getName(),isTruncation?"yes":"no",targetReg->isInitialized()?"yes":"no",targetReg->getSize(),targetReg->getDecimalPrecision(),childReg->getSize(),childReg->getDecimalPrecision(),sourceSignEndByte);

      if (isImplicitValue)
         {
         if (sourceMR->getIndexRegister())
            deps->addPostConditionIfNotAlreadyInserted(sourceMR->getIndexRegister(), TR::RealRegister::AssignAny);
         if (sourceMR->getBaseRegister())
            deps->addPostConditionIfNotAlreadyInserted(sourceMR->getBaseRegister(), TR::RealRegister::AssignAny);

         startLabel->setStartInternalControlFlow();
         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, startLabel, deps);

         // The primary (and currently the only) consumer of BCD evaluators in Java is the DAA intrinsics
         // library. The DAA library assumes all BCD types are positive, unless an explicit negative sign
         // code is present. Because of this deviation from the COBOL treatment of sign codes we must
         // take a specialized control path when generating instructions for Java.

         if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10))
            {
            generateSILInstruction(cg, TR::InstOpCode::CLHHSI, node, generateS390LeftAlignedMemoryReference(*sourceMR, node, 0, cg, sourceSignEndByte), 0x002D);
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, doneLabel);
            }
         else
            {
            generateSIInstruction(cg, TR::InstOpCode::CLI, node, generateS390LeftAlignedMemoryReference(*sourceMR, node, 0, cg, sourceSignEndByte), 0x00);
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, doneLabel);

            generateSIInstruction(cg, TR::InstOpCode::CLI, node, generateS390LeftAlignedMemoryReference(*sourceMR, node, 1, cg, sourceSignEndByte), 0x2D);
            generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, node, doneLabel);
            }
         }
      else
         {
         TR::Node *minusSign = node->getSecondChild();

         TR::MemoryReference *minusSignMR = generateS390ConstantAreaMemoryReference(cg, minusSign, true); // forSS=true

         generateSS1Instruction(cg, TR::InstOpCode::CLC, node,
                                TR::DataType::getUnicodeSignSize()-1,
                                generateS390LeftAlignedMemoryReference(*sourceMR, node, 0, cg, sourceSignEndByte),
                                minusSignMR);

         startLabel->setStartInternalControlFlow();
         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, startLabel, deps);

         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK7, node, doneLabel);
         }

      cg->genSignCodeSetting(node, NULL, targetReg->getSize(),
                                     generateS390RightAlignedMemoryReference(*destMR, node, 0, cg),
                                     TR::DataType::getPreferredMinusCode(), targetReg, 0, false); // numericNibbleIsZero=false

      doneLabel->setEndInternalControlFlow();
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, deps);

      targetReg->resetSignState();
      targetReg->setHasKnownPreferredSign();

      if (!isTruncation)
         targetReg->transferCleanSign(childReg);
      else
         traceMsg(comp,"\tudsx2p is a truncation (srcRegPrec %d > nodePrec %d) so do not transfer any clean sign flags\n",childReg->getDecimalPrecision(),node->getDecimalPrecision());
      }

   //at this point targetReg is PseudoRegister that has converted Packed decimal value.
   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if (TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() &&
           !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) ||
           isVectorBCDEnv)
      {
      TR::Register * pdVectorTargetReg = cg->allocateRegister(TR_VRF);
      TR::MemoryReference * pdSourceMR = generateS390RightAlignedMemoryReference(node,
                                                                                 targetReg->getStorageReference(),
                                                                                 cg);
      //PKU always puts the result into 16 bytes space
      uint8_t lengthToLoad = TR_VECTOR_REGISTER_SIZE - 1;
      generateVSIInstruction(cg, TR::InstOpCode::VLRL, node, pdVectorTargetReg, pdSourceMR, lengthToLoad);

      cg->decReferenceCount(child);
      node->setRegister(pdVectorTargetReg);
      cg->traceBCDExit("udsl2pd",node);
      return pdVectorTargetReg;
      }
   else
      {
      cg->decReferenceCount(child);
      node->setRegister(targetReg);
      cg->traceBCDExit("udsl2pd",node);
      return targetReg;
      }
   }

/**
 * Handles pd2udsl,pd2udst, where the Unicode decimal signs are separate.
 */
TR::Register *
J9::Z::TreeEvaluator::pd2udslEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pd2udsl",node);
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "PD-Op/%s", node->getOpCode().getName()),
                            1, TR::DebugCounter::Cheap);

   TR::Node* childNode = node->getFirstChild();
   TR::Compilation *comp = cg->comp();
   TR_PseudoRegister *childReg = NULL;
   TR::MemoryReference *sourceMR = NULL;
   TR_StorageReference* pdStorageRef = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      // Perform an intermediate vector store. See pd2udVectorEvaluateHelper().
      TR::Register* pdValueReg = cg->evaluate(childNode);
      pdStorageRef = TR_StorageReference::createTemporaryBasedStorageReference(TR_VECTOR_REGISTER_SIZE, comp);
      pdStorageRef->setIsSingleUseTemporary();

      TR::MemoryReference* pdMR = generateS390RightAlignedMemoryReference(node, pdStorageRef, cg);
      sourceMR = pdMR;

      childReg = cg->allocatePseudoRegister(childNode->getDataType());
      childReg->setIsInitialized();
      childReg->setSize(childNode->getSize());
      childReg->setHasKnownValidData();
      childReg->setDecimalPrecision(childNode->getDecimalPrecision());

      generateVSIInstruction(cg, TR::InstOpCode::VSTRL, node, pdValueReg, pdMR, TR_VECTOR_REGISTER_SIZE - 1);

      }
   else
      {
      int32_t byteLength = TR::DataType::packedDecimalPrecisionToByteLength(node->getDecimalPrecision());
      childReg = cg->evaluateBCDNode(childNode);
      childReg = cg->privatizeBCDRegisterIfNeeded(node, childNode, childReg);
      sourceMR = cg->materializeFullBCDValue(childNode, childReg,
                                             cg->getPackedToUnicodeFixedSourceSize(),
                                             byteLength);
      }

   // One of two sequences generated by the reset of this evaluator:
   // for non-setSign ops when the knownSign=negative (known positive signs are more common so '+' is the initial/default setting)
   //
   //    MVC      [destSign],[minusSign]  // [sign] <- 002B '+'
   //    UNPKU    [destData],[src]
   //    MVI      [destSign+1],0x2D       // '-'
   //
   // for non-setSign ops (pd2udsl/pd2udst)
   //
   //    MVC      [destSign],[minusSign]  // [sign] <- 002B '+'
   //    UNPKU    [destData],[src]
   //    BRC      0x8,done                // if src sign is + (cc=0) we are done, otherwise in '-' (cc=1) and invalid (cc=3) case fall through and set '-' sign
   //    MVI      [destSign+1],0x2D       // '-'
   // done:
   //
   // The MVC/UNPKU are generated by the shared routine packedToUnicodeHelper and the BRC/MVI by this routine


   TR_PseudoRegister *targetReg = cg->allocatePseudoRegister(node->getDataType());
   TR::MemoryReference *destMR = packedToUnicodeHelper(node, targetReg, sourceMR, childReg, true, cg, pdStorageRef); // isSeparateSign=true

   int32_t destSignEndByte = (node->getDataType() == TR::UnicodeDecimalSignTrailing) ? TR::DataType::getUnicodeSignSize() : targetReg->getSize();

   if (childReg->hasKnownSignCode())
      {
      int32_t convertedSign = TR::DataType::convertSignEncoding(childNode->getDataType(), node->getDataType(), childReg->getKnownSignCode());
      if (convertedSign == TR::DataType::getNationalSeparateMinus())
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tchildReg has negative knownSignCode 0x%x so generate an MVI of the converted sign 0x%x\n",childReg->getKnownSignCode(),convertedSign);
         generateSIInstruction(cg, TR::InstOpCode::MVI, node, generateS390LeftAlignedMemoryReference(*destMR, node, 1, cg, destSignEndByte), convertedSign);
         }
      else
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tchildReg has positive knownSignCode 0x%x so no more codegen is needed (an MVC of 002B was already done)\n", childReg->getKnownSignCode());
         TR_ASSERT(convertedSign == TR::DataType::getNationalSeparatePlus(), "converted sign should be nationalSeparatePlusSign of 0x%x and not 0x%x\n", TR::DataType::getNationalSeparatePlus(), convertedSign);
         }
      targetReg->setKnownSignCode(convertedSign);
      }
   else
      {
      TR_ASSERT(cg->getAppendInstruction()->getOpCodeValue() == TR::InstOpCode::UNPKU,
                "the previous instruction should be an UNPKU\n");

      TR::LabelSymbol * startLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol * doneLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

      TR::RegisterDependencyConditions * targetMRDeps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 2, cg);

      if (destMR->getIndexRegister())
         targetMRDeps->addPostConditionIfNotAlreadyInserted(destMR->getIndexRegister(), TR::RealRegister::AssignAny);
      if (destMR->getBaseRegister())
         targetMRDeps->addPostConditionIfNotAlreadyInserted(destMR->getBaseRegister(), TR::RealRegister::AssignAny);

      startLabel->setStartInternalControlFlow();
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, startLabel, targetMRDeps);

      // DAA library assumes all BCD types are positive, unless an explicit negative sign code is present
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK9, node, doneLabel);

      TR_ASSERT(TR::DataType::getNationalSeparateMinus() <= 0xFF, "expecting nationalSeparateMinusSign to be <= 0xFF and not 0x%x\n", TR::DataType::getNationalSeparateMinus());
      generateSIInstruction(cg, TR::InstOpCode::MVI, node, generateS390LeftAlignedMemoryReference(*destMR, node, 1, cg, destSignEndByte), TR::DataType::getNationalSeparateMinus());

      doneLabel->setEndInternalControlFlow();
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneLabel, targetMRDeps);

      targetReg->setHasKnownPreferredSign();
      }

   cg->decReferenceCount(childNode);
   node->setRegister(targetReg);
   cg->traceBCDExit("pd2udsl",node);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::pd2udEvaluatorHelper(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR::Node *child = node->getFirstChild();
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "PD-Op/%s", node->getOpCode().getName()),
                            1, TR::DebugCounter::Cheap);
   TR_PseudoRegister *childReg = cg->evaluateBCDNode(child);
   TR_PseudoRegister* targetReg = cg->allocatePseudoRegister(node->getDataType());
   childReg = cg->privatizeBCDRegisterIfNeeded(node, child, childReg);
   int32_t byteLength = TR::DataType::packedDecimalPrecisionToByteLength(node->getDecimalPrecision());
   TR::MemoryReference *sourceMR = cg->materializeFullBCDValue(child,
                                                               childReg,
                                                               cg->getPackedToUnicodeFixedSourceSize(),
                                                               byteLength);

   packedToUnicodeHelper(node, targetReg, sourceMR, childReg, false, cg, NULL); // isSeparateSign=false

   cg->decReferenceCount(child);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::pd2udVectorEvaluatorHelper(TR::Node *node, TR::CodeGenerator *cg)
   {
   // 1. Evalute child node and get a packed decimal in vector register
   TR::Node* childNode = node->getFirstChild();
   TR::Register* pdValueReg = cg->evaluate(childNode);

   // 2. Create a temp storage reference of size 16 bytes and dump all vector register contents there, to be picked up by UNPKU later
   //    This intermediate vector store is needed because vectorized pdloadi puts packed decimal in registers;
   //    but UNPKU is an SS instruction that takes inputs from memory.
   TR_StorageReference* pdStorageRef = TR_StorageReference::createTemporaryBasedStorageReference(TR_VECTOR_REGISTER_SIZE, cg->comp());
   pdStorageRef->setIsSingleUseTemporary();

   TR::MemoryReference* pdMR = generateS390RightAlignedMemoryReference(node, pdStorageRef, cg, true, true);
   generateVSIInstruction(cg, TR::InstOpCode::VSTRL, node, pdValueReg, pdMR, TR_VECTOR_REGISTER_SIZE - 1);

   // 3. Allocate and setup childReg PseudoRegister
   TR_PseudoRegister* childReg = cg->allocatePseudoRegister(childNode->getDataType());
   childReg->setIsInitialized();
   childReg->setSize(childNode->getSize());
   childReg->setDecimalPrecision(childNode->getDecimalPrecision());
   childReg->setHasKnownValidData();

   // 4. Generate UNPKU to unpack pdMR content to targetReg PseudoRegister
   TR_PseudoRegister* targetReg = cg->allocatePseudoRegister(node->getDataType());
   packedToUnicodeHelper(node, targetReg, pdMR, childReg, false, cg, pdStorageRef);  // isSeparateSign=false

   cg->decReferenceCount(childNode);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::pd2udEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pd2ud",node);
   TR::Register* targetReg = NULL;
   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      targetReg = pd2udVectorEvaluatorHelper(node, cg);
      }
   else
      {
      targetReg = pd2udEvaluatorHelper(node, cg);
      }

   node->setRegister(targetReg);
   cg->traceBCDExit("pd2ud",node);
   return targetReg;
   }

/**
 * \brief This evaluator helper is invoked by pd2ud Evaluator and pd2udsl Evaluator to generate unpack unicode
 * instruction (UNPKU).
 *
 * \param node              Parent node object.
 * \param targetReg         PseudoRegister object for the parent node (the node)
 * \param sourceMR          MemoryRefernece object pointer
 * \param childReg          PesudoRegister object for the child node (e.g. pdloadi node)
 * \param isSeparaeteSign   True if the opteration is pd2udsl or pd2udst, which all have separate sign code. Flase
 *                          if it's pd2ud.
 * \param cg                The codegen object
 * \param srcStorageReference If not null, this replaces the childReg's StorageReference for unpack to unicode
*/
TR::MemoryReference *
J9::Z::TreeEvaluator::packedToUnicodeHelper(TR::Node *node,
                                            TR_PseudoRegister *targetReg,
                                            TR::MemoryReference *sourceMR,
                                            TR_PseudoRegister *childReg,
                                            bool isSeparateSign,
                                            TR::CodeGenerator * cg,
                                            TR_StorageReference* srcStorageReference)
   {
   TR::Node *child = node->getFirstChild();
   TR_StorageReference *hint = node->getStorageReferenceHint();
   TR_StorageReference *targetStorageReference = NULL;
   TR::Compilation *comp = cg->comp();

   int32_t destSize = node->getStorageReferenceSize();

   if (hint)
      {
      if (childReg->isInitialized() && hint == childReg->getStorageReference())
         {
         TR_ASSERT( false,"pd2ud operands will overlap because child storageReference of pd2ud is initialized hint\n");
         }
      else
         {
         if (destSize <= hint->getSymbolSize())
            targetStorageReference = hint;
         else
            TR_ASSERT(false,"pd2ud destSize (%d) should be <= hint size (%d)\n",destSize,hint->getSymbolSize());
         }
      }

   if (targetStorageReference == NULL)
      targetStorageReference = TR_StorageReference::createTemporaryBasedStorageReference(destSize, comp);

   targetReg->setStorageReference(targetStorageReference, node);

   int32_t unpkuDestPrecision = node->getDecimalPrecision();
   targetReg->setDecimalPrecision(unpkuDestPrecision);
   int32_t unpkuDestSize = TR::DataType::getSizeFromBCDPrecision(TR::UnicodeDecimal, unpkuDestPrecision);
   int32_t unpkuDestEndByte = TR::DataType::getLeftMostByte(node->getDataType(), unpkuDestSize);

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tpackedToUnicodeHelper %p : op %s, targetRegSize %d, targetRegPrec %d, srcRegSize %d, srcRegPrec %d\n",
         node,node->getOpCode().getName(),targetReg->getSize(),targetReg->getDecimalPrecision(),childReg->getSize(),childReg->getDecimalPrecision());

   // For UNPKU the 1st operand (target-unicode) size is variable and the 2nd operand (source-packed) is fixed at 16 bytes.
   // For this reason use left, instead of right, aligned memory references so the correct alignment is done for both operands
   // (using right aligned references with SS1 would apply the same bump to both operands)
   TR::MemoryReference *destMR = generateS390LeftAlignedMemoryReference(node, targetReg->getStorageReference(), cg, unpkuDestEndByte);
   // The sourceMR should have been created by calling materializeFullBCDValue to ensure it is large enough to be used in the UNPKU
   int32_t fixedSourceSize = cg->getPackedToUnicodeFixedSourceSize();

   TR_ASSERT(sourceMR->getStorageReference()->getSymbolSize() >= fixedSourceSize,
      "source memRef %d is not large enough to be used in the UNPKU (%d)\n",sourceMR->getStorageReference()->getSymbolSize(),fixedSourceSize);

   sourceMR = reuseS390LeftAlignedMemoryReference(sourceMR, child,
                                                  (srcStorageReference == NULL) ? childReg->getStorageReference() : srcStorageReference,
                                                  cg, fixedSourceSize);

   if (isSeparateSign)
      {
      //TR_ASSERT((node->getOpCode().isSetSign() && node->getNumChildren() == 3) || (node->getNumChildren() == 2),
      //   "expected two (or three if setSign) children on %s and not %d child(ren)\n",node->getOpCode().getName(),node->getNumChildren());
      int32_t destSignEndByte = (node->getDataType() == TR::UnicodeDecimalSignTrailing) ? TR::DataType::getUnicodeSignSize() : unpkuDestEndByte + TR::DataType::getUnicodeSignSize();

      bool isImplicitValue = node->getNumChildren() < 2;

      if (isImplicitValue)
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp, "\tgen 2 MVIs of unicode sign with size of %d and destSignEndByte of %d\n", TR::DataType::getUnicodeSignSize(),destSignEndByte);
         generateSIInstruction(cg, TR::InstOpCode::MVI, node,
                               generateS390LeftAlignedMemoryReference(*destMR, node, 0, cg, destSignEndByte), 0x00);
         generateSIInstruction(cg, TR::InstOpCode::MVI, node,
                               generateS390LeftAlignedMemoryReference(*destMR, node, 1, cg, destSignEndByte), 0x2B);
         }
      else
         {
         TR::Node *signNode = node->getSecondChild();
         TR::MemoryReference *signMR = generateS390ConstantAreaMemoryReference(cg, signNode, true); // forSS=true
         if (cg->traceBCDCodeGen())
            traceMsg(comp, "\tgen MVC of unicode sign with size of %d and destSignEndByte of %d\n", TR::DataType::getUnicodeSignSize(),destSignEndByte);
         generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                                TR::DataType::getUnicodeSignSize()-1,
                                generateS390LeftAlignedMemoryReference(*destMR, node, 0, cg, destSignEndByte),
                                signMR);
         }
      if (node->getOpCode().isSetSign())
         {
         TR::Node *setSignValue = node->getSetSignValueNode();
         if (setSignValue->getOpCode().isLoadConst() && setSignValue->getOpCode().getSize() <= 4)
            {
            targetReg->setKnownSignCode(setSignValue->get32bitIntegralValue());
            }
         }
      }

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tgen UNPKU: unpkuDestSize %d, destEndByte %d and fixed source size %d\n",unpkuDestSize,unpkuDestEndByte,fixedSourceSize);

   generateSS1Instruction(cg, TR::InstOpCode::UNPKU, node,
                          unpkuDestSize-1,
                          destMR,
                          sourceMR);

   targetReg->transferDataState(childReg);
   targetReg->setIsInitialized();
   node->setRegister(targetReg);
   return destMR;
   }

void
J9::Z::TreeEvaluator::zonedToZonedSeparateSignHelper(TR::Node *node, TR_PseudoRegister *srcReg, TR_PseudoRegister *targetReg, TR::MemoryReference *sourceMR, TR::MemoryReference *destMR, TR::CodeGenerator * cg)
   {
   TR_ASSERT(targetReg->isInitialized(),"targetRegister must be initialized before calling zonedToZonedSeparateSignHelper\n");
   targetReg->resetSignState(); // reset any incoming sign state now as sign is being moved from embedded to separate by this routine (so embedded setting is no longer valid)
   bool isSetSign = node->getOpCode().isSetSign();
   int32_t sign = 0;
   TR::Node *signCodeNode = NULL;
   TR::Compilation *comp = cg->comp();

   if (isSetSign)
      {
      signCodeNode = node->getSecondChild();
      TR_ASSERT(signCodeNode->getOpCode().isLoadConst(),"excepting zdsle2zdSetSign sign code to be a const\n");
      sign = signCodeNode->get32bitIntegralValue();
      }
   bool isDestTrailingSign = (node->getDataType() == TR::ZonedDecimalSignTrailingSeparate);
   bool isTruncation = false;
   int32_t digitsToClear = 0;
   if (node->getDecimalPrecision() < targetReg->getDecimalPrecision())
      isTruncation = true;
   else if (node->getDecimalPrecision() > targetReg->getDecimalPrecision())
      digitsToClear = node->getDecimalPrecision()-targetReg->getDecimalPrecision();

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tzonedToZonedSeparateSignHelper %p : op %s, isTruncation=%s, targetReg->knownSign=0x%x, trgSignIsZone=%s, targetReg->size=%d, targetRegPrec=%d, , digitsToClear=%d, (isSetSign=%s, sign 0x%x)\n",
         node,node->getOpCode().getName(),isTruncation?"yes":"no",targetReg->hasKnownOrAssumedSignCode() ? targetReg->getKnownOrAssumedSignCode() : 0,targetReg->knownOrAssumedSignIsZone()?"yes":"no",
         targetReg->getSize(),targetReg->getDecimalPrecision(),digitsToClear,isSetSign?"yes":"no",sign);

   TR_ASSERT(!isTruncation,"a zd2zdsxs operation should not truncate\n");
   if (digitsToClear > 0)
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tdigitsToClear > 0 (%d) so set upper bytes to 0x%x and set targetRegPrec to nodePrec %d\n",digitsToClear,TR::DataType::getZonedZeroCode(),node->getDecimalPrecision());
      int32_t endByte = isDestTrailingSign ? node->getSize() : node->getSize() - TR::DataType::getZonedSignSize();
      cg->genZeroLeftMostZonedBytes(node, targetReg, endByte, digitsToClear, generateS390LeftAlignedMemoryReference(*destMR, node, 0, cg, endByte));
      targetReg->setDecimalPrecision(node->getDecimalPrecision());
      }

   int32_t endByteForDestSign = isDestTrailingSign ? TR::DataType::getZonedSignSize() : targetReg->getSize();
   TR::MemoryReference *destSignCodeMR = generateS390LeftAlignedMemoryReference(*destMR, node, 0, cg, endByteForDestSign);

   int32_t endByteForSourceSign = isDestTrailingSign ? (TR::DataType::getZonedSignSize() + TR::DataType::getZonedSignSize()) : TR::DataType::getZonedSignSize();
   TR::MemoryReference *srcSignCodeMR = generateS390LeftAlignedMemoryReference(*destMR, node, 0, cg, endByteForSourceSign);

   // no 'invalid sign' message is ever required for a setSign operation or when a known (but *not* assumed) sign is 0xc,0xd or 0xf
   intptr_t litPoolOffset = 0;
   if (isSetSign || (srcReg->hasKnownSignCode() && srcReg->knownSignIsEmbeddedPreferredOrUnsigned()))
      {
      int32_t signToSet = isSetSign ? sign :
                                      TR::DataType::convertSignEncoding(TR::ZonedDecimal, node->getDataType(), srcReg->getKnownSignCode());
      bool srcSignAlreadyZone = srcReg->knownOrAssumedSignIsZone(); // || targetReg->temporaryKnownSignCodeIs(TR::DataType::getZonedValue());
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\t%s case so gen MVI to set target sign to 0x%x (from source sign 0x%x) and do %sgen OI because srcReg->knownOrAssumedSignIsZone() = %s\n",
            isSetSign?"isSetSign=true":"srcReg->hasKnownSignCode",
            signToSet,
            isSetSign?sign:srcReg->getKnownSignCode(),
            srcSignAlreadyZone?"not ":"",
            srcSignAlreadyZone?"true":"false");

      TR_ASSERT(signToSet == TR::DataType::getZonedSeparatePlus() || signToSet == TR::DataType::getZonedSeparateMinus(),
         "signToSet value should be 0x%x ('+') or 0x%x ('-') and not 0x%x\n", TR::DataType::getZonedSeparatePlus(), TR::DataType::getZonedSeparateMinus(), sign);
      if (!srcSignAlreadyZone)
         {
         generateSIInstruction(cg, TR::InstOpCode::OI, node, srcSignCodeMR, TR::DataType::getZonedCode());
         }
      generateSIInstruction(cg, TR::InstOpCode::MVI, node, destSignCodeMR, (signToSet & 0xFF));
      targetReg->setKnownSignCode(signToSet);
      }
   else if (srcReg->hasKnownCleanSign())
      {
      TR_ASSERT(TR::DataType::getZonedSeparatePlus() == 0x4E && TR::DataType::getZonedSeparateMinus() == 0x60, "zd2zdsxs sequence only works when plus sign is 0x4E and minus sign is 0x60\n");
      TR::Register *tempReg1 = cg->allocateRegister(TR_GPR);
      TR::Register *tempReg2 = cg->allocateRegister(TR_GPR);

      generateRXInstruction(cg, TR::InstOpCode::IC, node, tempReg1, generateS390LeftAlignedMemoryReference(*srcSignCodeMR, node, 0, cg, srcSignCodeMR->getLeftMostByte()));

      generateRIInstruction(cg, TR::InstOpCode::NILL, node, tempReg1, 0x10);
      generateRSInstruction(cg, TR::InstOpCode::RLL, node, tempReg2, tempReg1, 29);  // rotate right by 3 (32-3=29)
      if (!targetReg->knownSignIsZone())
         {
         generateSIInstruction(cg, TR::InstOpCode::OI, node, generateS390LeftAlignedMemoryReference(*srcSignCodeMR, node, 0, cg, srcSignCodeMR->getLeftMostByte()), TR::DataType::getZonedCode());
         }
      generateRRInstruction(cg, TR::InstOpCode::OR, node, tempReg2, tempReg1);
      generateRIInstruction(cg, TR::InstOpCode::AHI, node, tempReg2, 0x4E);
      generateRXInstruction(cg, TR::InstOpCode::STC, node, tempReg2, destSignCodeMR);
      cg->stopUsingRegister(tempReg1);
      cg->stopUsingRegister(tempReg2);
      targetReg->setHasKnownPreferredSign();
      if (!isTruncation)
         targetReg->setHasKnownCleanSign();
      }
   else
      {
      // DAA library assumes all BCD types are positive, unless an explicit negative sign code is present
      TR::LabelSymbol * processSign     = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol * processPositive = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol * processNegative = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol * processEnd      = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

      processSign->setStartInternalControlFlow();
      processEnd   ->setEndInternalControlFlow();

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, processSign);

      // A negative sign code is represented by 0xB and 0xD (1011 and 1101 in binary). Due to the
      // symmetry in the binary encoding of the negative sign codes we can get away with two bit
      // mask tests to check if a sign code is negative:
      //
      // Step 1 : Test if bit 0 and bit 3 are set
      // Step 2 : Test if there is exactly one bit set from bit 1 and bit 2

      // Step 1
      generateSIInstruction(cg, TR::InstOpCode::TM, node, generateS390LeftAlignedMemoryReference(*srcSignCodeMR, node, 0, cg, srcSignCodeMR->getLeftMostByte()), 0x90);

      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK12, node, processPositive);

      // Step 2
      generateSIInstruction(cg, TR::InstOpCode::TM, node, generateS390LeftAlignedMemoryReference(*srcSignCodeMR, node, 0, cg, srcSignCodeMR->getLeftMostByte()), 0x60);

      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK9, node, processPositive);

      // ----------------- Incoming branch -----------------

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, processNegative);

      // Patch in the preferred negative sign code
      generateSIInstruction(cg, TR::InstOpCode::MVI, node, generateS390LeftAlignedMemoryReference(*destSignCodeMR, node, 0, cg, destSignCodeMR->getLeftMostByte()), TR::DataType::getZonedSeparateMinus());

      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK15, node, processEnd);

      // ----------------- Incoming branch -----------------

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, processPositive);

      // Patch in the preferred positive sign code
      generateSIInstruction(cg, TR::InstOpCode::MVI, node, generateS390LeftAlignedMemoryReference(*destSignCodeMR, node, 0, cg, destSignCodeMR->getLeftMostByte()), TR::DataType::getZonedSeparatePlus());

      // ----------------- Incoming branch -----------------

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, processEnd);

      // Clear the embedded sign code of the source
      TR::Instruction* cursor = generateSIInstruction(cg, TR::InstOpCode::OI, node, generateS390LeftAlignedMemoryReference(*srcSignCodeMR, node, 0, cg, srcSignCodeMR->getLeftMostByte()), TR::DataType::getZonedCode());

      // Set up the proper register dependencies
      TR::RegisterDependencyConditions* dependencies = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 2, cg);

      if (srcSignCodeMR->getIndexRegister())
         dependencies->addPostCondition(srcSignCodeMR->getIndexRegister(), TR::RealRegister::AssignAny);

      if (srcSignCodeMR->getBaseRegister())
         dependencies->addPostCondition(srcSignCodeMR->getBaseRegister(), TR::RealRegister::AssignAny);

      if (destSignCodeMR->getIndexRegister())
         dependencies->addPostConditionIfNotAlreadyInserted(destSignCodeMR->getIndexRegister(), TR::RealRegister::AssignAny);

      if (destSignCodeMR->getBaseRegister())
         dependencies->addPostConditionIfNotAlreadyInserted(destSignCodeMR->getBaseRegister(), TR::RealRegister::AssignAny);

      cursor->setDependencyConditions(dependencies);

      targetReg->setHasKnownPreferredSign();
      }
   }

/**
 * Handles pd2zdsls,pd2zdsts,pd2zdslsSetSign,pd2zdstsSetSign
 */
TR::Register *
J9::Z::TreeEvaluator::pd2zdslsEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pd2zdsls",node);
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "PD-Op/%s", node->getOpCode().getName()),
                            1, TR::DebugCounter::Cheap);
   TR_PseudoRegister *targetReg = cg->allocatePseudoRegister(node->getDataType());
   TR::Node *child = node->getFirstChild();
   TR_PseudoRegister *childReg = cg->evaluateBCDNode(child);
   childReg = cg->privatizeBCDRegisterIfNeeded(node, child, childReg);
   TR::MemoryReference *sourceMR = generateS390RightAlignedMemoryReference(child, childReg->getStorageReference(), cg);
   TR::MemoryReference *destMR = packedToZonedHelper(node, targetReg, sourceMR, childReg, cg);
   zonedToZonedSeparateSignHelper(node, childReg, targetReg, sourceMR, destMR, cg);
   cg->decReferenceCount(child);
   if (node->getOpCode().isSetSign())
      cg->decReferenceCount(node->getSecondChild());
   node->setRegister(targetReg);
   cg->traceBCDExit("pd2zdsls",node);
   return targetReg;
   }

void
J9::Z::TreeEvaluator::zonedSeparateSignToPackedOrZonedHelper(TR::Node *node, TR_PseudoRegister *targetReg, TR::MemoryReference *sourceMR, TR::MemoryReference *destMR, TR::CodeGenerator * cg)
   {
   TR_ASSERT( targetReg->isInitialized(),"targetRegister must be initialized before calling zonedSeparateSignToPackedOrZonedHelper\n");
   TR::Node *srcNode = node->getFirstChild();
   TR_PseudoRegister *srcReg = cg->evaluateBCDNode(srcNode);
   bool isTruncation = srcReg->getDecimalPrecision() > node->getDecimalPrecision();
   bool isSrcTrailingSign = (srcNode->getDataType() == TR::ZonedDecimalSignTrailingSeparate);
   int32_t sourceSignEndByte = isSrcTrailingSign ? TR::DataType::getZonedSignSize() : srcReg->getSize();
   TR::Compilation *comp = cg->comp();
   if (node->getOpCode().isSetSign())
      {
      TR::Node *signCodeNode = node->getSetSignValueNode();
      TR_ASSERT( signCodeNode->getOpCode().isLoadConst(),"excepting zonedSeparateSignToPackedOrZonedHelper sign code to be a const\n");
      int32_t sign = signCodeNode->get32bitIntegralValue();
      if (sign == TR::DataType::getIgnoredSignCode())
         {
         // just check for an invalid sign but do not set anything in this case
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tzonedSeparateSignToPackedOrZonedHelper %p : op %s, ignoredSetSign=true case, sign 0x%x\n",node,node->getOpCode().getName(),sign);

         TR::LabelSymbol * returnLabel     = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
         TR::LabelSymbol * callLabel       = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

         TR::LabelSymbol * cflowRegionStart   = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
         TR::LabelSymbol * cflowRegionEnd     = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

         TR::RegisterDependencyConditions * deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 2, cg);

         if (sourceMR->getIndexRegister())
            deps->addPostConditionIfNotAlreadyInserted(sourceMR->getIndexRegister(), TR::RealRegister::AssignAny);
         if (sourceMR->getBaseRegister())
            deps->addPostConditionIfNotAlreadyInserted(sourceMR->getBaseRegister(), TR::RealRegister::AssignAny);

         cflowRegionStart->setStartInternalControlFlow();
         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, cflowRegionStart, deps);

         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\t\ttargetReg->isInit=%s, targetRegSize=%d, targetRegPrec=%d, srcRegSize=%d, srcRegPrec=%d, sourceSignEndByte=%d\n",
               targetReg->isInitialized()?"yes":"no",targetReg->getSize(),targetReg->getDecimalPrecision(),srcReg->getSize(),srcReg->getDecimalPrecision(),sourceSignEndByte);

         generateSIInstruction(cg, TR::InstOpCode::CLI, node, generateS390LeftAlignedMemoryReference(*sourceMR, node, 0, cg, sourceSignEndByte), TR::DataType::getZonedSeparatePlus());
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK8, node, cflowRegionEnd);


         cflowRegionEnd->setEndInternalControlFlow();
         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, cflowRegionEnd, deps);

         targetReg->transferSignState(srcReg, isTruncation);
         }
      else
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tzonedSeparateSignToPackedOrZonedHelper %p : op %s, setSign=true case, sign 0x%x\n",node,node->getOpCode().getName(),sign);
         cg->genSignCodeSetting(node, targetReg, targetReg->getSize(), generateS390RightAlignedMemoryReference(*destMR, node, 0, cg), sign, targetReg, 0, false /* !numericNibbleIsZero */);
         }
      }
   else
      {
      TR::LabelSymbol * checkMinusLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol * returnLabel       = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol * callLabel       = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

      TR::LabelSymbol * cflowRegionStart   = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol * cflowRegionEnd     = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

      TR::RegisterDependencyConditions * deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 4, cg);

      if (sourceMR->getIndexRegister())
         deps->addPostConditionIfNotAlreadyInserted(sourceMR->getIndexRegister(), TR::RealRegister::AssignAny);
      if (sourceMR->getBaseRegister())
         deps->addPostConditionIfNotAlreadyInserted(sourceMR->getBaseRegister(), TR::RealRegister::AssignAny);

      if (destMR->getIndexRegister())
         deps->addPostConditionIfNotAlreadyInserted(destMR->getIndexRegister(), TR::RealRegister::AssignAny);
      if (destMR->getBaseRegister())
         deps->addPostConditionIfNotAlreadyInserted(destMR->getBaseRegister(), TR::RealRegister::AssignAny);


      cflowRegionStart->setStartInternalControlFlow();
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, cflowRegionStart, deps);

      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tzonedSeparateSignToPackedOrZonedHelper %p : op %s, targetReg->isInit=%s, targetRegSize=%d, targetRegPrec=%d, srcRegSize=%d, srcRegPrec=%d, sourceSignEndByte=%d\n",
            node,node->getOpCode().getName(),targetReg->isInitialized()?"yes":"no",targetReg->getSize(),targetReg->getDecimalPrecision(),srcReg->getSize(),srcReg->getDecimalPrecision(),sourceSignEndByte);

        // DAA library assumes all BCD types are positive, unless an explicit negative sign code is present
      generateSIInstruction(cg, TR::InstOpCode::CLI, node, generateS390LeftAlignedMemoryReference(*sourceMR, node, 0, cg, sourceSignEndByte), TR::DataType::getZonedSeparateMinus());
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_CC0, node, checkMinusLabel);

      cg->genSignCodeSetting(node, NULL, targetReg->getSize(), generateS390RightAlignedMemoryReference(*destMR, node, 0, cg), TR::DataType::getPreferredPlusCode(), targetReg, 0, false /* !numericNibbleIsZero */);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, cflowRegionEnd);

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, checkMinusLabel);


      cg->genSignCodeSetting(node, NULL, targetReg->getSize(), generateS390RightAlignedMemoryReference(*destMR, node, 0, cg), TR::DataType::getPreferredMinusCode(), targetReg, 0, false /* !numericNibbleIsZero */);



      cflowRegionEnd->setEndInternalControlFlow();
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, cflowRegionEnd, deps);

      targetReg->setHasKnownPreferredSign();
      }
   }

/**
 * Handles zdsls2pd,zdsts2pd
 */
TR::Register *
J9::Z::TreeEvaluator::zdsls2pdEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("zdsls2pd",node);
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "PD-Op/%s", node->getOpCode().getName()),
                            1, TR::DebugCounter::Cheap);
   TR_PseudoRegister *targetReg = cg->allocatePseudoRegister(node->getDataType());
   TR::Node *child = node->getFirstChild();
   TR_PseudoRegister *childReg = cg->evaluateBCDNode(child);
   childReg = cg->privatizeBCDRegisterIfNeeded(node, child, childReg);
   TR::MemoryReference *sourceMR = generateS390RightAlignedMemoryReference(child, childReg->getStorageReference(), cg);
   TR::MemoryReference *destMR = zonedToPackedHelper(node, targetReg, sourceMR, childReg, cg);
   targetReg->resetSignState();  // the conversion operation is not complete yet so reset any sign state transferred in the zonedToPackedHelper
   // zonedToPackedHelper with a separate sign source will pack a zone code into the packed sign code position so set the zone value on the
   // targetReg to improve the zonedSeparateSignToPackedOrZonedHelper code generation
   targetReg->setTemporaryKnownSignCode(TR::DataType::getZonedValue());
   zonedSeparateSignToPackedOrZonedHelper(node, targetReg, sourceMR, destMR, cg);
   cg->decReferenceCount(child);
   if (node->getOpCode().isSetSign())
      cg->decReferenceCount(node->getSecondChild());
   node->setRegister(targetReg);
   cg->traceBCDExit("zdsls2pd",node);
   return targetReg;
   }

/**
 * Handles zdsls2zd,zdsts2zd
 */
TR::Register *
J9::Z::TreeEvaluator::zdsls2zdEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("zdsls2zd",node);
   TR::Node *srcNode = node->getFirstChild();
   TR_PseudoRegister *srcReg = cg->evaluateBCDNode(srcNode);

   bool isSetSign = node->getOpCode().isSetSign();
   int32_t sign = 0;
   TR::Node *signCodeNode = NULL;
   TR::Compilation *comp = cg->comp();
   if (isSetSign)
      {
      signCodeNode = node->getSecondChild();
      TR_ASSERT( signCodeNode->getOpCode().isLoadConst(),"excepting zdsle2zdSetSign sign code to be a const\n");
      sign = signCodeNode->get32bitIntegralValue();
      }

   bool isSrcTrailingSign = (srcNode->getDataType() == TR::ZonedDecimalSignTrailingSeparate);
   int32_t sourceOffset = 0;
   bool isTruncation = false;
   int32_t targetPrecision = srcReg->getDecimalPrecision();
   if (srcReg->getDecimalPrecision() > node->getDecimalPrecision())  // a truncation
      {
      isTruncation = true;
      sourceOffset = srcReg->getDecimalPrecision() - node->getDecimalPrecision();   // reach into the source by sourceOffset bytes to get the correct digits
      targetPrecision = node->getDecimalPrecision();
      }

   bool isEffectiveNop = isZonedOperationAnEffectiveNop(node, 0, isTruncation, srcReg, isSetSign, sign, cg);
   TR_PseudoRegister *targetReg = NULL;
   TR::MemoryReference *sourceMR = NULL;
   TR::MemoryReference *destMR = NULL;
   if (isEffectiveNop)
      {
      targetReg = evaluateBCDSignModifyingOperand(node, isEffectiveNop, false, false, sourceMR, cg); // isNondestructiveNop=false,initTarget=false
      }
   else
      {
      targetReg = evaluateBCDValueModifyingOperand(node, false, sourceMR, cg); // initTarget=false
      sourceMR = generateS390RightAlignedMemoryReference(srcNode, srcReg->getStorageReference(), cg);
      destMR = generateS390RightAlignedMemoryReference(node, targetReg->getStorageReference(), cg);
      }

   targetReg->setDecimalPrecision(targetPrecision);
   bool isInitialized = targetReg->isInitialized();
   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tzdsls2zdEvaluator %p : op %s, isInitialized=%s, targetRegSize=%d, targetRegPrec=%d, srcRegSize=%d, srcRegPrec=%d, isEffectiveNop=%s (isSetSign %s, sign 0x%x)\n",
         node,node->getOpCode().getName(),isInitialized?"yes":"no",
            targetReg->getSize(),targetReg->getDecimalPrecision(),srcReg->getSize(),srcReg->getDecimalPrecision(),isEffectiveNop?"yes":"no",isSetSign?"yes":"no",sign);

   if (!isEffectiveNop)
      {
      if (!isInitialized)
         {
         int32_t mvcSize = targetReg->getDecimalPrecision();
         int32_t srcEndByte = isSrcTrailingSign ? srcReg->getSize() : srcReg->getSize() - TR::DataType::getZonedSignSize();
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tisInit=false so gen MVC to init with size=%d and sourceOffset=%d, srcEndByte=%d\n",mvcSize,sourceOffset,srcEndByte);
         generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                                mvcSize-1,
                                generateS390RightAlignedMemoryReference(*destMR, node, 0, cg),
                                generateS390LeftAlignedMemoryReference(*sourceMR, node, sourceOffset, cg, srcEndByte));
         targetReg->transferDataState(srcReg);
         targetReg->setIsInitialized();
         }
      targetReg->setTemporaryKnownSignCode(TR::DataType::getZonedValue());
      if (isInitialized && isSrcTrailingSign)
         {
         destMR->addToTemporaryNegativeOffset(node, -TR::DataType::getZonedSignSize(), cg);
         }
      zonedSeparateSignToPackedOrZonedHelper(node, targetReg, sourceMR, destMR, cg);
      }

   if (isSrcTrailingSign)
      {
      if (isEffectiveNop)
         {
         targetReg->addToRightAlignedIgnoredBytes(TR::DataType::getZonedSignSize());
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tisSrcTrailingSign=true and isEffectiveNop=true (zdsls2zd) : increment targetReg %s ignoredBytes %d -> %d (by the TR::DataType::getZonedSignSize())\n",
               cg->getDebug()->getName(targetReg),targetReg->getRightAlignedIgnoredBytes() - TR::DataType::getZonedSignSize(),targetReg->getRightAlignedIgnoredBytes());
         }
      else if (isInitialized)
         {
         targetReg->addToRightAlignedDeadBytes(TR::DataType::getZonedSignSize());
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tisSrcTrailingSign=true and isInitialized=true (zdsls2zd) : increment targetReg %s deadBytes %d -> %d (by the TR::DataType::getZonedSignSize())\n",
               cg->getDebug()->getName(targetReg),targetReg->getRightAlignedDeadBytes() - TR::DataType::getZonedSignSize(),targetReg->getRightAlignedDeadBytes());
         }
      }

   cg->decReferenceCount(srcNode);
   if (node->getOpCode().isSetSign())
      cg->decReferenceCount(node->getSecondChild());
   node->setRegister(targetReg);
   cg->traceBCDExit("zdsls2zd",node);
   return targetReg;
   }

/**
 * Handles zd2zdsls,zd2zdsts
 */
TR::Register *
J9::Z::TreeEvaluator::zd2zdslsEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("zd2zdsls",node);
   TR::Compilation *comp = cg->comp();
   TR::Node *srcNode = node->getFirstChild();
   TR_PseudoRegister *srcReg = cg->evaluateBCDNode(srcNode);

   TR_StorageReference *srcStorageReference = srcReg->getStorageReference();
   TR::MemoryReference *sourceMR = generateS390RightAlignedMemoryReference(srcNode, srcStorageReference, cg);

   TR_PseudoRegister *targetReg = evaluateBCDValueModifyingOperand(node, false, sourceMR, cg); // initTarget=false
   TR::MemoryReference *destMR = generateS390RightAlignedMemoryReference(node, targetReg->getStorageReference(), cg);

   bool isTrailingSign = (node->getDataType() == TR::ZonedDecimalSignTrailingSeparate);

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tzd2zdslsEvaluator %p : op %s, targetReg->isInit=%s, targetRegSize=%d, targetRegPrec=%d\n",
         node,node->getOpCode().getName(),targetReg->isInitialized()?"yes":"no",targetReg->getSize(),targetReg->getDecimalPrecision());

   bool isTruncation = node->getDecimalPrecision() < srcReg->getDecimalPrecision();
   TR_ASSERT( !isTruncation,"a zd2zdsxs operation should not truncate\n");

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tset targetReg->prec to srcReg->prec %d\n",srcReg->getDecimalPrecision());
   targetReg->setDecimalPrecision(srcReg->getDecimalPrecision());

   // the (targetReg->isInitialized() && isTrailingSign) case below is needed to move the initialized data left by 1 byte to make room for the trailing separate sign code
   if (!targetReg->isInitialized() || (targetReg->isInitialized() && isTrailingSign))
      {
      int32_t mvcSize = srcReg->getSize();
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\t%s so gen MVC to init with size %d\n",!targetReg->isInitialized()?"isInit=false":"isInit=true and isTrailingSign=true", mvcSize);
      generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                             mvcSize-1,
                             generateS390LeftAlignedMemoryReference(*destMR, node, 0, cg, isTrailingSign ? srcReg->getSize() + TR::DataType::getZonedSignSize() : srcReg->getSize()),
                             generateS390RightAlignedMemoryReference(*sourceMR, node, 0, cg));
      targetReg->setIsInitialized();
      }

   zonedToZonedSeparateSignHelper(node, srcReg, targetReg, sourceMR, destMR, cg);

   cg->decReferenceCount(srcNode);
   if (node->getOpCode().isSetSign())
      cg->decReferenceCount(node->getSecondChild());
   node->setRegister(targetReg);
   cg->traceBCDExit("zd2zdsls",node);
   return targetReg;
   }

/**
 * Handles zdsle2zd,zd2zdsle
 */
TR::Register *
J9::Z::TreeEvaluator::zdsle2zdEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("zdsle2zd",node);
   TR::Node *srcNode = node->getFirstChild();
   TR_PseudoRegister *srcReg = cg->evaluateBCDNode(srcNode);

   bool isSetSign = node->getOpCode().isSetSign();
   int32_t sign = 0;
   TR::Node *signCodeNode = NULL;
   TR::Compilation *comp = cg->comp();
   if (isSetSign)
      {
      signCodeNode = node->getSecondChild();
      TR_ASSERT(signCodeNode->getOpCode().isLoadConst(),"excepting zdsle2zdSetSign sign code to be a const\n");
      sign = signCodeNode->get32bitIntegralValue();
      }
   bool isTrailingDst = node->getDataType() == TR::ZonedDecimal;
   bool isLeadingDst = !isTrailingDst;
   bool isTrailingSrc = srcNode->getDataType() == TR::ZonedDecimal;
   bool isLeadingSrc = !isTrailingSrc;

   bool isTruncation = false;
   int32_t digitsToClear = 0;
   if (node->getDecimalPrecision() < srcReg->getDecimalPrecision())
      isTruncation = true;
   else if (node->getDecimalPrecision() > srcReg->getDecimalPrecision())
      digitsToClear = node->getDecimalPrecision()-srcReg->getDecimalPrecision();

   bool isEffectiveNop = isZonedOperationAnEffectiveNop(node, 0, isTruncation, srcReg, isSetSign, sign, cg);
   bool isNondestructiveNop = isEffectiveNop && !isTruncation;
   bool doWidening = true;

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tzdsle2zdEvaluator %p : op %s, isEffectiveNop=%s, isTruncation=%s, srcSignIsZone=%s, srcReg->getSize()=%d, (isSetSign=%s, sign 0x%x)\n",
         node,node->getOpCode().getName(),isEffectiveNop?"yes":"no",isTruncation?"yes":"no",srcReg->knownOrAssumedSignIsZone()?"yes":"no",srcReg->getSize(),isSetSign?"yes":"no",sign);

   TR::MemoryReference *sourceMR = NULL;
   TR_PseudoRegister *targetReg = NULL;
   if (!isEffectiveNop &&
       isLeadingDst &&     // only do for leading sign so the sign code doesn't have to be moved again later
       doWidening &&
       digitsToClear > 0)
      {
      sourceMR = generateS390RightAlignedMemoryReference(srcNode, srcReg->getStorageReference(), cg);
      targetReg = evaluateBCDValueModifyingOperand(node, true, sourceMR, cg); // initTarget=true
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tperform an explicit widening (digitsToClear=%d, doWidening=yes, isEffectiveNop=no) set targetReg->prec to node->prec %d\n",digitsToClear,node->getDecimalPrecision());
      targetReg->setDecimalPrecision(node->getDecimalPrecision());
      }
   else
      {
      if (!isEffectiveNop)
         sourceMR = generateS390RightAlignedMemoryReference(srcNode, srcReg->getStorageReference(), cg);
      targetReg = evaluateBCDSignModifyingOperand(node, isEffectiveNop, isNondestructiveNop, true /*initTarget*/, sourceMR, cg);
      int32_t targetPrecision = isTruncation ? node->getDecimalPrecision() : srcReg->getDecimalPrecision();
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tdo not perform an explicit widening (set digitsToClear=%d->0, doWidening=%s, isEffectiveNop=%s) set targetReg->prec to %d\n",
            digitsToClear,doWidening?"yes":"no",isEffectiveNop ?"yes":"no",targetPrecision);
      digitsToClear = 0;
      targetReg->setDecimalPrecision(targetPrecision);
      }

   if (!isEffectiveNop)
      {
      TR::MemoryReference *destMR = isTrailingDst ? generateS390RightAlignedMemoryReference(node, targetReg->getStorageReference(), cg) :
                                                       generateS390LeftAlignedMemoryReference(node, targetReg->getStorageReference(), cg, targetReg->getSize());
      int32_t clearLeftMostByte = targetReg->getSize();
      if (isSetSign)
         {
         if (sign == TR::DataType::getIgnoredSignCode())
            {
            if (cg->traceBCDCodeGen()) traceMsg(comp,"\tisSetSign=true with ignored sign=0x%x\n",sign);
            if (isTrailingDst) // zdsle2zd
               {
               if (srcReg->getSize() == 1)
                  targetReg->transferSignState(srcReg, isTruncation);
               else
                  targetReg->setKnownSignCode(TR::DataType::getZonedValue());
               }
            else // zd2zdsle
               {
               if (targetReg->getSize() == 1)
                  targetReg->transferSignState(srcReg, isTruncation);
               else if (targetReg->getSize() > srcReg->getSize())  // a widening in the leadingDst and ignored case leaves a bad sign code
                  targetReg->setHasKnownBadSignCode();
               else
                  targetReg->setKnownSignCode(TR::DataType::getZonedValue());
               }
            }
         else
            {
            if (cg->traceBCDCodeGen()) traceMsg(comp,"\tisSetSign=true : call genSignCodeSetting with sign=0x%x\n",sign);
            bool numericNibbleIsZero = false;
            if (isTrailingDst)  // zdsle2zd
               {
               // bytes above the leftmost one have a top nibble of 0xf so use this knowledge to improve the sign code setting
               if (srcReg->getSize() == 1)
                  targetReg->transferSignState(srcReg, isTruncation);
               else
                  targetReg->setTemporaryKnownSignCode(TR::DataType::getZonedValue());
               }
            else // zd2zdsle
               {
               // when not performing an explicit widening then the bytes above the first one have a top nibble of 0xf so use this knowledge to improve the sign code setting
               if (targetReg->getSize() == 1)
                  targetReg->transferSignState(srcReg, isTruncation);
               else if (targetReg->getSize() <= srcReg->getSize())
                  targetReg->setTemporaryKnownSignCode(TR::DataType::getZonedValue());

               if (digitsToClear > 0)
                  {
                  numericNibbleIsZero = true;
                  digitsToClear--;
                  clearLeftMostByte--;
                  }
               }
            int32_t digitsCleared = cg->genSignCodeSetting(node, targetReg, targetReg->getSize(), destMR, sign, targetReg, 0, numericNibbleIsZero);
            TR_ASSERT(!numericNibbleIsZero || digitsCleared == 1,"the sign code setting should have also cleared 1 digit (digitsCleared = %d)\n",digitsCleared);
            }
         }

      if (digitsToClear > 0)
         {
         cg->genZeroLeftMostZonedBytes(node, targetReg, clearLeftMostByte, digitsToClear, destMR);
         }

      if (!isSetSign)
         {
         if (cg->traceBCDCodeGen()) traceMsg(comp,"\tisSetSign=false : generate MVZ of size 1 to transfer left aligned zdsle sign to right aligned zd sign position\n");

         sourceMR = isTrailingSrc ? reuseS390RightAlignedMemoryReference(sourceMR, srcNode, srcReg->getStorageReference(), cg) :
                                    reuseS390LeftAlignedMemoryReference(sourceMR, srcNode, srcReg->getStorageReference(), cg, srcReg->getSize());
         destMR = isTrailingDst ? reuseS390RightAlignedMemoryReference(destMR, node, targetReg->getStorageReference(), cg) :
                                  reuseS390LeftAlignedMemoryReference(destMR, node, targetReg->getStorageReference(), cg, targetReg->getSize());
         int32_t mvzSize = 1;
         generateSS1Instruction(cg, TR::InstOpCode::MVZ, node,
                                mvzSize-1,
                                destMR,
                                sourceMR);
         targetReg->transferSignState(srcReg, isTruncation);
         }

      bool srcSignWillBeIgnored = false;
      bool srcSignResetRedundant = srcReg->knownOrAssumedSignIsZone() || (isLeadingSrc && isTruncation);
      bool srcSignResetIllegal = targetReg->getSize() == 1;

      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tcheck before resetting srcSignCode: srcSignWillBeIgnored %s, srcSignResetRedundant %s, srcSignResetIllegal %s\n",
            srcSignWillBeIgnored?"yes":"no",srcSignResetRedundant?"yes":"no",srcSignResetIllegal?"yes":"no");
      if (!(srcSignWillBeIgnored || srcSignResetRedundant || srcSignResetIllegal))
         {
            {
            if (cg->traceBCDCodeGen()) traceMsg(comp,"\tgenerate OI 0xF0 to force %s-aligned high nibble to 0xF\n",isTrailingSrc?"right":"left");
            generateSIInstruction(cg, TR::InstOpCode::OI, node, generateS390LeftAlignedMemoryReference(*destMR, node, 0, cg, isTrailingSrc ? 1 : targetReg->getSize()), TR::DataType::getZonedCode());
            }
         }
      targetReg->setIsInitialized();
      }

   cg->decReferenceCount(srcNode);
   if (isSetSign)
      cg->decReferenceCount(signCodeNode);
   node->setRegister(targetReg);
   cg->traceBCDExit("zdsle2zd",node);
   return targetReg;
   }

TR::MemoryReference *
J9::Z::TreeEvaluator::zonedToPackedHelper(TR::Node *node, TR_PseudoRegister *targetReg, TR::MemoryReference *sourceMR, TR_PseudoRegister *childReg, TR::CodeGenerator * cg)
   {
   TR::Node *child = node->getFirstChild();
   TR_StorageReference *hint = node->getStorageReferenceHint();
   TR_StorageReference *targetStorageReference = NULL;
   int32_t destPrecision = 0;
   int32_t destSize = 0;
   TR::Compilation *comp = cg->comp();
   if (hint)
      {
      TR_ASSERT( !childReg->isInitialized() || hint != childReg->getStorageReference(),"bcd conversion operands will overlap\n");
      destSize = hint->getSymbolSize(); // may be be larger than the node->getSize() so take this opportunity to widen as part of the PACK
      destPrecision = TR::DataType::getBCDPrecisionFromSize(node->getDataType(), destSize); // may be be larger than the node->getSize() so take this opportunity to widen as part of the PACK
      targetStorageReference = hint;
      }
   else
      {
      destSize = node->getSize();
      destPrecision = node->getDecimalPrecision();
      targetStorageReference = TR_StorageReference::createTemporaryBasedStorageReference(destSize, comp);
      }

   targetReg->setStorageReference(targetStorageReference, node);

   int32_t sourcePrecision = childReg->getDecimalPrecision();
   bool isTruncation = false;
   int32_t sourceOffsetForLeftAlignment = 0;

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tzonedToPackedHelper %p : op %s, destPrecision %d, destSize %d, sourcePrecision %d, sourceSize %d\n",
         node,node->getOpCode().getName(),destPrecision,destSize,sourcePrecision,childReg->getSize());

   if (node->getDecimalPrecision() < sourcePrecision)
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tnodePrec <= sourcePrecision (%d <= %d) so set sourcePrecision=nodePrec=%d,isTruncation=true,sourceOffsetForLeftAlignment=%d\n",
                     node->getDecimalPrecision(),sourcePrecision,node->getDecimalPrecision(),sourcePrecision - node->getDecimalPrecision());
      sourceOffsetForLeftAlignment = sourcePrecision - node->getDecimalPrecision();
      sourcePrecision = node->getDecimalPrecision();
      isTruncation = true;
      }

   TR::MemoryReference *destMR = NULL;
   if (destSize > 16)
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tdestSize %d > 16 so reduce destSize to 16 and destPrecision to 31 for PACK encoding and clear top %d byte(s)\n",destSize,(destSize-16));
      destMR = generateS390RightAlignedMemoryReference(node, targetStorageReference, cg);
      cg->genZeroLeftMostPackedDigits(node, targetReg, destSize, (destSize-16)*2, destMR);
      destSize = 16;
      destPrecision = 31;
      }

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tsetting targetReg->prec to sourcePrecision %d\n",sourcePrecision);
   targetReg->setDecimalPrecision(sourcePrecision);

   // skip over trailing sign for the unpack
   bool isSrcTrailingSign = (child->getDataType() == TR::ZonedDecimalSignTrailingSeparate);
   int32_t sourceEndByte = isSrcTrailingSign ? sourcePrecision + TR::DataType::getZonedSignSize() :
                                               sourcePrecision;

   if (sourcePrecision <= 16)
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tsourcePrecision %d <= 16 so generate a single PACK destSize %d, sourcePrecision %d, sourceEndByte %d\n",sourcePrecision,destSize,sourcePrecision,sourceEndByte);
      destMR = reuseS390RightAlignedMemoryReference(destMR, node, targetStorageReference, cg);
      generateSS2Instruction(cg, TR::InstOpCode::PACK, node,
                             destSize-1,
                             destMR,
                             sourcePrecision-1,
                             generateS390LeftAlignedMemoryReference(*sourceMR, node, 0, cg, sourceEndByte));
      int32_t destSizeAsCeilingPrecision = TR::DataType::byteLengthToPackedDecimalPrecisionCeiling(destSize);
      if (destSizeAsCeilingPrecision > sourcePrecision)
         targetReg->addRangeOfZeroDigits(sourcePrecision, destSizeAsCeilingPrecision);
      }
   else if (sourcePrecision >= 17 && sourcePrecision <= 31)
      {
      if (cg->traceBCDCodeGen())
         {
         if (sourcePrecision >= 17 && sourcePrecision <= 30)
            traceMsg(comp,"\tsourcePrecision 17 <= %d <= 30 so generate two PACKs with sourceEndByte %d\n",sourcePrecision,sourceEndByte);
         else
            traceMsg(comp,"\tsourcePrecision == 31  so generate three PACKs with sourceEndByte %d\n",sourceEndByte);
         }
      bool needsThirdPack = false;
      if (sourcePrecision == 31)
         {
         sourcePrecision = 29;   // The first two PACKs for the sourcePrecision=31 case are the same as for the sourcePrecision=29 case
         destPrecision = 29;
         needsThirdPack = true;
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tsourcePrecision == 31 so reduce sourcePrecision and destPrecision to 29 and update sourceEndByte to %d\n",sourceEndByte);
         }

      if (cg->traceBCDCodeGen())
         traceMsg(comp,"x^x : found large packed/zoned conv -- node %s (%p) prec %d, child %s (%p) prec %d (three=%s)\n",
            node->getOpCode().getName(),node,destPrecision,
            child->getOpCode().getName(),child,sourcePrecision,needsThirdPack?"yes":"no");

      destMR = reuseS390LeftAlignedMemoryReference(destMR, node, targetStorageReference, cg, destSize);
      sourceMR = generateS390LeftAlignedMemoryReference(*sourceMR, node, 0, cg, sourceEndByte);
      int32_t pack1SourceSize = sourcePrecision-14;
      int32_t pack1DestSize = TR::DataType::getSizeFromBCDPrecision(node->getDataType(), destPrecision-14);
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\t\t1st PACK destSize=%d,srcSize=%d\n",pack1DestSize,pack1SourceSize);
      generateSS2Instruction(cg, TR::InstOpCode::PACK, node,
                             pack1DestSize-1,
                             destMR,
                             pack1SourceSize-1,
                             sourceMR);
      int32_t pack1DestSizeAsPrecision = TR::DataType::byteLengthToPackedDecimalPrecisionCeiling(pack1DestSize);
      if (pack1DestSizeAsPrecision > pack1SourceSize)
         {
         int32_t rightMostDigits = (destSize-pack1DestSize)*2;
         targetReg->addRangeOfZeroDigits(pack1SourceSize+rightMostDigits, pack1DestSizeAsPrecision+rightMostDigits);
         }
      int32_t pack2SourceSize = 15;
      int32_t pack2SourceOffset = pack1SourceSize-1;
      int32_t pack2DestSize = TR::DataType::getSizeFromBCDPrecision(node->getDataType(), pack2SourceSize);
      int32_t pack2DestOffset = pack1DestSize-1;
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\t\t2nd PACK destSize=%d,destOffset=%d, srcSize=%d,srcOffset=%d\n",pack2DestSize,pack2DestOffset,pack2SourceSize,pack2SourceOffset);
      generateSS2Instruction(cg, TR::InstOpCode::PACK, node,
                             pack2DestSize-1,
                             generateS390LeftAlignedMemoryReference(*destMR, node, pack2DestOffset, cg, destMR->getLeftMostByte()),
                             pack2SourceSize-1,
                             generateS390LeftAlignedMemoryReference(*sourceMR, node, pack2SourceOffset, cg, sourceMR->getLeftMostByte()));
      if (needsThirdPack)
         {
         int32_t pack3SourceSize = 3;
         int32_t pack3SourceOffset = pack2SourceOffset+(pack2SourceSize-1);
         int32_t pack3DestSize = TR::DataType::getSizeFromBCDPrecision(node->getDataType(), pack3SourceSize);
         int32_t pack3DestOffset = pack2DestOffset+(pack2DestSize-1);
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\t\t3rd PACK destSize=%d,destOffset=%d, srcSize=%d,srcOffset=%d\n",pack3DestSize,pack3DestOffset,pack3SourceSize,pack3SourceOffset);
         generateSS2Instruction(cg, TR::InstOpCode::PACK, node,
                                pack3DestSize-1,
                                generateS390LeftAlignedMemoryReference(*destMR, node, pack3DestOffset, cg, destMR->getLeftMostByte()),
                                pack3SourceSize-1,
                                generateS390LeftAlignedMemoryReference(*sourceMR, node, pack3SourceOffset, cg, sourceMR->getLeftMostByte()));
         }
      }
   else
      {
      TR_ASSERT(false,"zd2pd unexpected sourcePrecision %d\n",sourcePrecision);
      }

   TR::Register* signCode     = cg->allocateRegister();
   TR::Register* signCode4Bit = cg->allocateRegister();

   TR::LabelSymbol * processSign     = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * processSignEnd  = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * processNegative = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * processEnd      = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   processSign->setStartInternalControlFlow();
   processEnd   ->setEndInternalControlFlow();

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, processSign);

   // Load the sign byte of the Packed Decimal from memory
   generateRXYInstruction(cg, TR::InstOpCode::LLC, node, signCode, generateS390LeftAlignedMemoryReference(*destMR, node, 0, cg, 1));

   generateRRInstruction(cg, TR::InstOpCode::LR, node, signCode4Bit, signCode);

   // Clear most significant 4 bits
   generateRIInstruction(cg, TR::InstOpCode::NILL, node, signCode4Bit, 0x000F);

   // Compare the sign byte against the preferred negative sign code
   generateRIInstruction(cg, TR::InstOpCode::CHI, node, signCode4Bit, TR::DataType::getPreferredMinusCode());

   // Branch if equal
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK8, node, processEnd);

   // Clear least significant 4 bits
   generateRIInstruction(cg, TR::InstOpCode::NILL, node, signCode, 0x00F0);

   // Compare the sign byte against the alternative negative sign code
   generateRIInstruction(cg, TR::InstOpCode::CHI, node, signCode4Bit, TR::DataType::getAlternateMinusCode());

   // Branch if equal
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK8, node, processNegative);

   // Patch in the preferred positive sign code
   generateRIInstruction(cg, TR::InstOpCode::OILL, node, signCode, TR::DataType::getPreferredPlusCode());

   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK15, node, processSignEnd);

   // ----------------- Incoming branch -----------------

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, processNegative);

   // Patch in the preferred negative sign code
   generateRIInstruction(cg, TR::InstOpCode::OILL, node, signCode, TR::DataType::getPreferredMinusCode());

   // ----------------- Incoming branch -----------------

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, processSignEnd);

   generateRXInstruction(cg, TR::InstOpCode::STC, node, signCode, generateS390LeftAlignedMemoryReference(*destMR, node, 0, cg, 1));

   TR::Instruction* cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, processEnd);

   // Set up the proper register dependencies
   TR::RegisterDependencyConditions* dependencies = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 2, cg);

   dependencies->addPostCondition(signCode,     TR::RealRegister::AssignAny);
   dependencies->addPostCondition(signCode4Bit, TR::RealRegister::AssignAny);

   if (destMR->getIndexRegister())
      dependencies->addPostCondition(destMR->getIndexRegister(), TR::RealRegister::AssignAny);

   if (destMR->getBaseRegister())
      dependencies->addPostCondition(destMR->getBaseRegister(), TR::RealRegister::AssignAny);

   cursor->setDependencyConditions(dependencies);

   // Cleanup registers before returning
   cg->stopUsingRegister(signCode);
   cg->stopUsingRegister(signCode4Bit);

   targetReg->transferSignState(childReg, isTruncation);
   targetReg->transferDataState(childReg);
   targetReg->setIsInitialized();
   node->setRegister(targetReg);
   return destMR;
   }

TR::Register *
J9::Z::TreeEvaluator::zd2pdEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("zd2pd",node);
   TR::Register* targetReg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      targetReg = zd2pdVectorEvaluatorHelper(node, cg);
      }
   else
      {
      targetReg = cg->allocatePseudoRegister(node->getDataType());
      TR::Node *child = node->getFirstChild();
      TR_PseudoRegister *childReg = cg->evaluateBCDNode(child);
      childReg = cg->privatizeBCDRegisterIfNeeded(node, child, childReg);
      TR::MemoryReference *sourceMR = generateS390RightAlignedMemoryReference(child, childReg->getStorageReference(), cg);
      zonedToPackedHelper(node, static_cast<TR_PseudoRegister*>(targetReg), sourceMR, childReg, cg);
      cg->decReferenceCount(child);
      node->setRegister(targetReg);
      }

   cg->traceBCDExit("zd2pd",node);
   return targetReg;
   }

/**
 * 1. Get zd value by evaluting child node. It's in zdNode's PseudoRegister
 * 2. Get the memory reference from the pseudo register.
 * 3. Allocate Vector register to return
 * 4. get size of the node( node->getsize)
 * 5. generateVSI instruction using the information above.
 * 6. attach Vector register to the node.
 * 7. decReference BCD node for the child/
 * 8. return targetRegister.
*/
TR::Register *
J9::Z::TreeEvaluator::zd2pdVectorEvaluatorHelper(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Register *targetReg = NULL;

   TR::Node *child = node->getFirstChild();
   TR_PseudoRegister *sourceReg = cg->evaluateBCDNode(child);
   sourceReg = cg->privatizeBCDRegisterIfNeeded(node, child, sourceReg);
   TR::MemoryReference *sourceMR = generateS390LeftAlignedMemoryReference(child, sourceReg->getStorageReference(), cg, child->getDecimalPrecision());
   targetReg = cg->allocateRegister(TR_VRF);
   int32_t destPrecision = std::min(node->getDecimalPrecision(), child->getDecimalPrecision());
   generateVSIInstruction(cg, TR::InstOpCode::VPKZ, node, targetReg, sourceMR, destPrecision - 1);

   node->setRegister(targetReg);
   cg->decReferenceCount(child);
   return targetReg;
   }

/**
 * \brief Check the sign of zd after pd2zd conversion.
 *
 * The UNPK instruction does not validate the digits nor the sign of the packed decimal.
 * We need to check the sign of PD and set ZD signs properly: use 0xc for positive, and 0xd for negative numbers.
 *
*/
void
J9::Z::TreeEvaluator::pd2zdSignFixup(TR::Node *node,
                                             TR::MemoryReference *destMR,
                                             TR::CodeGenerator * cg)
   {
   TR::Register* signCode     = cg->allocateRegister();
   TR::Register* signCode4Bit = cg->allocateRegister();

   TR::LabelSymbol * processSign     = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * processSignEnd  = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * processNegative = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::LabelSymbol * processEnd      = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

   processSign->setStartInternalControlFlow();
   processEnd  ->setEndInternalControlFlow();

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, processSign);

   // Load the sign byte of the Zoned Decimal from memory
   generateRXYInstruction(cg, TR::InstOpCode::LLC, node, signCode, generateS390LeftAlignedMemoryReference(*destMR, node, 0, cg, 1));

   generateRRInstruction(cg, TR::InstOpCode::LR, node, signCode4Bit, signCode);

   // Clear least significant 4 bits
   generateRIInstruction(cg, TR::InstOpCode::NILL, node, signCode4Bit, 0x00F0);

   // Compare the sign byte against the preferred negative sign code
   generateRIInstruction(cg, TR::InstOpCode::CHI, node, signCode4Bit, TR::DataType::getPreferredMinusCode() << 4);

   // Branch if equal
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK8, node, processEnd);

   // Clear most significant 4 bits
   generateRIInstruction(cg, TR::InstOpCode::NILL, node, signCode, 0x000F);

   // Compare the sign byte against the alternative negative sign code
   generateRIInstruction(cg, TR::InstOpCode::CHI, node, signCode4Bit, TR::DataType::getAlternateMinusCode() << 4);

   // Branch if equal
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK8, node, processNegative);

   // Patch in the preferred positive sign code
   generateRIInstruction(cg, TR::InstOpCode::OILL, node, signCode, TR::DataType::getPreferredPlusCode() << 4);

   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK15, node, processSignEnd);

   // ----------------- Incoming branch -----------------

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, processNegative);

   // Patch in the preferred negative sign code
   generateRIInstruction(cg, TR::InstOpCode::OILL, node, signCode, TR::DataType::getPreferredMinusCode() << 4);

   // ----------------- Incoming branch -----------------

   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, processSignEnd);

   generateRXInstruction(cg, TR::InstOpCode::STC, node, signCode, generateS390LeftAlignedMemoryReference(*destMR, node, 0, cg, 1));

   TR::Instruction* cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, processEnd);

   // Set up the proper register dependencies
   TR::RegisterDependencyConditions* dependencies = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 2, cg);

   dependencies->addPostCondition(signCode,     TR::RealRegister::AssignAny);
   dependencies->addPostCondition(signCode4Bit, TR::RealRegister::AssignAny);

   if (destMR->getIndexRegister())
      dependencies->addPostCondition(destMR->getIndexRegister(), TR::RealRegister::AssignAny);

   if (destMR->getBaseRegister())
      dependencies->addPostCondition(destMR->getBaseRegister(), TR::RealRegister::AssignAny);

   cursor->setDependencyConditions(dependencies);

   // Cleanup registers before returning
   cg->stopUsingRegister(signCode);
   cg->stopUsingRegister(signCode4Bit);
   }

TR::MemoryReference *
J9::Z::TreeEvaluator::packedToZonedHelper(TR::Node *node, TR_PseudoRegister *targetReg, TR::MemoryReference *sourceMR, TR_PseudoRegister *childReg, TR::CodeGenerator * cg)
   {
   TR::Node *child = node->getFirstChild();
   TR::Compilation *comp = cg->comp();

   TR_StorageReference *hint = node->getStorageReferenceHint();
   TR_StorageReference *targetStorageReference = NULL;
   int32_t destSize = 0;
   if (hint)
      {
      TR_ASSERT( !childReg->isInitialized() || hint != childReg->getStorageReference(),"bcd conversion operands will overlap\n");
      destSize = hint->getSymbolSize(); // may be be larger than the node->getSize() so take this opportunity to widen as part of the UNPK
      targetStorageReference = hint;
      }
   else
      {
      destSize = node->getSize();
      targetStorageReference = TR_StorageReference::createTemporaryBasedStorageReference(destSize, comp);
      }

   targetReg->setStorageReference(targetStorageReference, node);

   int32_t destPrecision = TR::DataType::getBCDPrecisionFromSize(node->getDataType(), destSize);
//   int32_t destPrecision = destSize;
   targetReg->setDecimalPrecision(destPrecision);
   int32_t sourcePrecision = childReg->getDecimalPrecision();
   int32_t sourceSize = childReg->getSize();

   // skip over trailing sign for the unpack
   bool isDestTrailingSign = (node->getDataType() == TR::ZonedDecimalSignTrailingSeparate);
   int32_t destEndByte = isDestTrailingSign ? destPrecision + TR::DataType::getZonedSignSize() :
                                              destPrecision;

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tpackedToZonedHelper %p : op %s, destPrecision %d, destSize %d, destEndByte %d, sourcePrecision %d, sourceSize %d\n",
         node,node->getOpCode().getName(),destPrecision,destSize,destEndByte,sourcePrecision,childReg->getSize());

   bool isTruncation = false;
   if (destPrecision < childReg->getDecimalPrecision())
      {
      isTruncation = true;
      sourcePrecision = destPrecision;
      sourceSize = TR::DataType::getSizeFromBCDPrecision(child->getDataType(), sourcePrecision);

      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tisTruncation=true (dstPrec %d < srcPrec %d) reduce srcPrec %d->%d, srcSize %d->%d\n",
            destPrecision,childReg->getDecimalPrecision(),childReg->getDecimalPrecision(),sourcePrecision,childReg->getSize(),sourceSize);
      }

   TR::Node *paddingAnchor = NULL;
   bool evaluatedPaddingAnchor = false;
   TR::MemoryReference *destMR = NULL;
   if (destPrecision <= 16 || sourcePrecision <= 16)
      {
      int32_t unpkDestOffset = 0;
      int32_t unpkDestSize = destPrecision;
      int32_t unpkSourceSize  = sourceSize;
      destMR = generateS390LeftAlignedMemoryReference(node, targetStorageReference, cg, destEndByte);

      if (destPrecision > 16)
         {
         int32_t bytesToSet = destPrecision-sourcePrecision;
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tdestPrecision %d > 16, sourcePrecision %d <= 16 gen %d leftmost bytes of 0xF0\n",destPrecision,sourcePrecision,bytesToSet);
         TR_ASSERT(bytesToSet > 0,"destPrecision (%d) should be > sourcePrecision (%d)\n",destPrecision,sourcePrecision);
         cg->genZeroLeftMostZonedBytes(node, targetReg, destEndByte, bytesToSet, destMR);
         evaluatedPaddingAnchor = true;
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\treduce unpkDestOffset %d->%d and unpkDestSize %d->%d\n",unpkDestOffset,bytesToSet,unpkDestSize,sourcePrecision);
         unpkDestOffset = bytesToSet;
         unpkDestSize = sourcePrecision;
         }

      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tdestPrecision %d <= 16 or sourcePrecision %d <= 16 so generate a single UNPK destPrecision %d, destOffset %d, unpkSourceSize %d\n",
                      destPrecision,sourcePrecision,unpkDestSize,unpkDestOffset,unpkSourceSize);
      generateSS2Instruction(cg, TR::InstOpCode::UNPK, node,
                             unpkDestSize-1,
                             generateS390LeftAlignedMemoryReference(*destMR, node, unpkDestOffset, cg, destMR->getLeftMostByte()),
                             unpkSourceSize-1,
                             generateS390RightAlignedMemoryReference(*sourceMR, node, 0, cg));
      if (unpkDestSize > sourcePrecision)
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tunpkDestSize %d > sourcePrecision %d adding range of zero digits for pd2zd op\n",unpkDestSize,sourcePrecision);
         targetReg->addRangeOfZeroDigits(sourcePrecision, unpkDestSize);
         }
      }
   else
      {
      TR_ASSERT(destPrecision <= 31,"pd2zd destPrecision should be <= 31 and not %d\n",destPrecision);
      TR_ASSERT(sourcePrecision <= 31,"pd2zd sourcePrecision should be <= 31 and not %d\n",sourcePrecision);
      if (cg->traceBCDCodeGen())
         {
         if (sourcePrecision >= 17 && sourcePrecision <= 30)
            traceMsg(comp,"\tsourcePrecision 17 <= %d <= 30 so generate two UNPKs\n",sourcePrecision);
         else
            traceMsg(comp,"\tsourcePrecision == 31 so generate three UNPKs\n");
         }
      bool needsThirdUnpk = false;
      int32_t precisionAdjustment = 14;
      if (sourcePrecision == 31)
         {
         precisionAdjustment=16;
         needsThirdUnpk = true;
         }
      else
         {
         // in this case can do the conversion in 2 UNPKs instead of 3. Keep the target precision up to 30 bytes to widen extra bytes.
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tsourcePrecision < 31 (%d) so reduce destPrecision to min(destPrecision,30) = min(%d,30) = %d ",
               sourcePrecision,destPrecision,std::min(destPrecision,30));
         destPrecision = std::min(destPrecision, 30);
         destEndByte = isDestTrailingSign ? destPrecision + TR::DataType::getZonedSignSize() :
                                            destPrecision;
         targetReg->setDecimalPrecision(destPrecision);
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"and update targetReg->prec to new destPrecision %d and update destEndByte to %d\n",destPrecision,destEndByte);
         }

      if (cg->traceBCDCodeGen())
         traceMsg(comp,"x^x : found large packed/zoned conv -- node %s (%p) prec %d, child %s (%p) prec %d (three=%s)\n",
            node->getOpCode().getName(),node,destPrecision,
            child->getOpCode().getName(),child,sourcePrecision,needsThirdUnpk?"yes":"no");

      destMR = generateS390LeftAlignedMemoryReference(node, targetStorageReference, cg, destEndByte);
      sourceMR = generateS390LeftAlignedMemoryReference(*sourceMR, node, 0, cg, sourceSize);
      int32_t unpk1DestSize   = destPrecision-precisionAdjustment;
      int32_t unpk1SourceSize = TR::DataType::getSizeFromBCDPrecision(child->getDataType(), sourcePrecision-precisionAdjustment);
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\t\t1st UNPK destSize=%d,srcSize=%d\n",unpk1DestSize,unpk1SourceSize);
      generateSS2Instruction(cg, TR::InstOpCode::UNPK, node,
                             unpk1DestSize-1,
                             destMR,
                             unpk1SourceSize-1,
                             sourceMR);
      int32_t unpk2DestSize = 15;
      int32_t unpk2DestOffset = unpk1DestSize-1;
      int32_t unpk2SourceSize = TR::DataType::getSizeFromBCDPrecision(child->getDataType(), 15);
      int32_t unpk2SourceOffset = unpk1SourceSize-1;
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\t\t2nd UNPK destSize=%d,destOffset=%d, srcSize=%d,srcOffset=%d\n",unpk2DestSize,unpk2DestOffset,unpk2SourceSize,unpk2SourceOffset);
      generateSS2Instruction(cg, TR::InstOpCode::UNPK, node,
                             unpk2DestSize-1,
                             generateS390LeftAlignedMemoryReference(*destMR, node, unpk2DestOffset, cg, destMR->getLeftMostByte()),
                             unpk2SourceSize-1,
                             generateS390LeftAlignedMemoryReference(*sourceMR, node, unpk2SourceOffset, cg, sourceMR->getLeftMostByte()));
      if (needsThirdUnpk)
         {
         int32_t unpk3DestSize = 3;
         int32_t unpk3DestOffset = unpk2DestOffset+(unpk2DestSize-1);
         int32_t unpk3SourceSize = TR::DataType::getSizeFromBCDPrecision(child->getDataType(), 3);
         int32_t unpk3SourceOffset = unpk2SourceOffset+(unpk2SourceSize-1);
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\t\t3rd UNPK destSize=%d,destOffset=%d, srcSize=%d,srcOffset=%d\n",unpk3DestSize,unpk3DestOffset,unpk3SourceSize,unpk3SourceOffset);
         generateSS2Instruction(cg, TR::InstOpCode::UNPK, node,
                                unpk3DestSize-1,
                                generateS390LeftAlignedMemoryReference(*destMR, node, unpk3DestOffset, cg, destMR->getLeftMostByte()),
                                unpk3SourceSize-1,
                                generateS390LeftAlignedMemoryReference(*sourceMR, node, unpk3SourceOffset, cg, sourceMR->getLeftMostByte()));
         }
      }

   if (!evaluatedPaddingAnchor)
      cg->processUnusedNodeDuringEvaluation(paddingAnchor);

   pd2zdSignFixup(node, destMR, cg);

   targetReg->transferSignState(childReg, isTruncation);
   targetReg->transferDataState(childReg);
   targetReg->setIsInitialized();
   node->setRegister(targetReg);
   return destMR;
   }

TR::Register *
J9::Z::TreeEvaluator::pd2zdVectorEvaluatorHelper(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Compilation* comp = cg->comp();
   traceMsg(comp, "DAA: Enter pd2zdVectorEvaluatorHelper\n");
   TR_PseudoRegister *targetReg = cg->allocatePseudoRegister(node->getDataType());

   // pd2zd we need to create storagerefence and save this value to the memoryreference
   // associated to that storagereference.
   // To do this, we need to
   //
   // 1. create NodeBasedStorageReference,
   // 2. creatememoryreference from the StorageREference,
   // 3. Use the memory reference to create VUPKZ instruction
   //
   // return the allocate PseudoRegister associate the storage refence to the Pseudo register
   // return this pseudoregister/
   //
   TR_StorageReference *hint = node->getStorageReferenceHint();
   int32_t sizeOfZonedValue = node->getSize(); //for zoned node, precision and the size must be the same.
   int32_t precision = node->getDecimalPrecision();
   TR_StorageReference* targetStorageReference = hint ? hint : TR_StorageReference::createTemporaryBasedStorageReference(sizeOfZonedValue, comp);

   targetReg->setStorageReference(targetStorageReference, node);
   TR::Node *child = node->getFirstChild(); //This child will evalueate to Vector Register
   TR::Register *valueRegister = cg->evaluate(child);
   TR_ASSERT((valueRegister->getKind() == TR_VRF || valueRegister->getKind() == TR_FPR),
             "valueChild should evaluate to Vector register.");

   TR::MemoryReference *targetMR = generateS390LeftAlignedMemoryReference(node, targetStorageReference, cg, sizeOfZonedValue, false);

   if (!targetStorageReference->isTemporaryBased())
      {
      TR::SymbolReference *memSymRef = targetStorageReference->getNode()->getSymbolReference();
      if (memSymRef)
         {
         targetMR->setListingSymbolReference(memSymRef);
         }
      }

   if(cg->traceBCDCodeGen())
      {
      traceMsg(comp, "gen VUKPZ, sizeOfZonedValue=%d, precision=%d\n", sizeOfZonedValue, precision);
      }

   generateVSIInstruction(cg, TR::InstOpCode::VUPKZ, node, valueRegister, targetMR, sizeOfZonedValue - 1);

   // Fix pd2zd signs. VUPKZ and its non-vector counterpart don't validate digits nor signs.
   pd2zdSignFixup(node, targetMR, cg);

   node->setRegister(targetReg);
   cg->decReferenceCount(child);
   targetReg->setIsInitialized();
   traceMsg(comp, "DAA: Leave pd2zdVectorEvaluatorHelper\n");
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::pd2zdEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pd2zd",node);
   TR::Register* targetReg = NULL;
   cg->generateDebugCounter("PD-Op/pd2zd", 1, TR::DebugCounter::Cheap);

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() &&
           !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) ||
           isVectorBCDEnv)
      {
      targetReg = pd2zdVectorEvaluatorHelper(node, cg);
      }
   else
      {
      targetReg = cg->allocatePseudoRegister(node->getDataType());
      TR::Node *child = node->getFirstChild();
      TR_PseudoRegister *childReg = cg->evaluateBCDNode(child);
      childReg = cg->privatizeBCDRegisterIfNeeded(node, child, childReg);
      TR::MemoryReference *sourceMR = generateS390RightAlignedMemoryReference(child, childReg->getStorageReference(), cg);
      packedToZonedHelper(node, static_cast<TR_PseudoRegister*>(targetReg), sourceMR, childReg, cg);
      cg->decReferenceCount(child);
      node->setRegister(targetReg);
      }

   cg->traceBCDExit("pd2zd",node);
   return targetReg;
   }

// mask is SZPF
//         0123

#define TR_DFP_TO_ZONED_SIGN           (0x8) ///< S: does target zoned operand have a sign field (S=0 no, S=1 yes)
#define TR_DFP_TO_ZONED_ZONE           (0x4) ///< Z: encode zone field as 0xf (Z=0) or as 0x3 (Z=1)
#define TR_DFP_TO_ZONED_PLUS           (0x2) ///< P: encode plus sign as 0xc (P=0) or as 0xf (P=1). Ignored when S=0 and sign is then determined by Z.
#define TR_DFP_TO_ZONED_FORCE_CLEAN    (0x1) ///< F: force negative zero to positive zero when F=1. The plus sign 0xc vs 0xf is determined by P.  Ignored when S=0.

#define TR_MAX_DFP_ZONED_FAST_SIZE  (32) ///< these conversion instructions slow down when the actual length is > 32
#define TR_MAX_DFP_ZONED_SIZE       (34) ///< max actual length (<=34) these conversion instructions can handle

/**
 * Handles TR::df2zd,TR::dd2zd,TR::de2zd,TR::df2zdSetSign,TR::dd2zdSetSign,TR::de2zdSetSign,TR::df2zdClean,TR::dd2zdClean,TR::de2zdClean
 */
TR::Register *
J9::Z::TreeEvaluator::df2zdEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDExit("df2zd",node);

   TR_ASSERT( cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_zEC12),"CDZT/CXZT only valid on >= arch(10)\n");
   TR_ASSERT(node->getDecimalFraction() == 0,"frac should be 0 and not %d\n",node->getDecimalFraction());

   TR::Node *srcNode = node->getFirstChild();
   TR::Register *srcFPReg = cg->evaluate(srcNode);
   TR::Compilation *comp = cg->comp();
   TR_J9VMBase *fej9 = (TR_J9VMBase *)(comp->fe());

   bool isFloat      = srcNode->getDataType() == TR::DecimalFloat;
   bool isDouble     = srcNode->getDataType() == TR::DecimalDouble;
   bool isLongDouble = srcNode->getDataType() == TR::DecimalLongDouble;

   if (isFloat)
      {
      TR::Register *srcFPRegTemp = cg->allocateRegister(TR_FPR);
      generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, srcFPRegTemp, srcFPReg, 0, false); // m4=0
      srcFPReg = srcFPRegTemp;
      cg->stopUsingRegister(srcFPRegTemp);
      isFloat = false;
      isDouble = true;
      }

   bool isSetSign = node->isSetSignValueOnNode();
   bool isClean = node->getOpCodeValue() == TR::df2zdClean || node->getOpCodeValue() == TR::dd2zdClean || node->getOpCodeValue() == TR::de2zdClean;

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\t%s : isSetSign %s, isClean %s\n",node->getOpCode().getName(),isSetSign?"yes":"no",isClean?"yes":"no");

   uint8_t mask = 0; // 0 is unsigned with ebcdic zone fields

   if (cg->traceBCDCodeGen()) traceMsg(comp,"\tinit mask to 0x%x\n",mask);

   bool needsSetSign = isSetSign;
   int32_t setSignValue = TR::DataType::getInvalidSignCode();
   bool signIsPreferred = true;
   bool signIsClean = false;
   bool resultSignIsUnsigned = false;
   TR::InstOpCode::Mnemonic setSignOpCode  = TR::InstOpCode::BAD;
   if (isSetSign)
      {
      // for all setSign cases do not set TR_DFP_TO_ZONED_SIGN in the mask -- for 0xf there is then nothing to do and for 0xc/0xd the sign is easier to set on top of 0xf
      resultSignIsUnsigned = true;
      TR_ASSERT(!isClean,"setsign and clean must not be set together on node %s (%p)\n",node->getOpCode().getName(),node);
      TR_ASSERT(TR::DataType::getUnsignedCode() == 0xf,"expecting unsigned code to be 0xf and not 0x%x for node %s (%p)\n",
              TR::DataType::getUnsignedCode(),node->getOpCode().getName(),node);
      TR_RawBCDSignCode sign = node->getSetSign();
      if (sign == raw_bcd_sign_0xf)
         {
         needsSetSign = false;
         signIsPreferred = false;
         if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tsetSign 0xf: leave mask at 0x%x for setSign 0xf\n",mask);
         }
      else if (sign == raw_bcd_sign_0xc)
         {
         setSignValue = TR::DataType::getPreferredPlusCode();
         if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tsetSign 0xc: leave mask at 0x%x and encode setSign 0xc afterwards on top of 0xf\n",mask);
         TR_ASSERT(TR::DataType::getPreferredPlusCode() == 0xc,"expecting preferred plus code to be 0xc and not 0x%x for node %s (%p)\n",
                 TR::DataType::getPreferredPlusCode(),node->getOpCode().getName(),node);

         setSignOpCode = TR::InstOpCode::LPDFR;
         }
      else if (sign == raw_bcd_sign_0xd)
         {
         setSignValue = TR::DataType::getPreferredMinusCode();
         if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tsetSign 0xd: leave mask at 0x%x and encode setSign 0xd afterwards on top of 0xf\n",mask);
         TR_ASSERT(TR::DataType::getPreferredMinusCode() == 0xd,"expecting preferred minus code to be 0xd and not 0x%x for node %s (%p)\n",
                 TR::DataType::getPreferredMinusCode(),node->getOpCode().getName(),node);

         setSignOpCode = TR::InstOpCode::LNDFR;
         }
      else
         {
         TR_ASSERT(false,"unsupported sign %d for %s (%p)\n",sign,node->getOpCode().getName(),node);
         }
      }
   else
      {
      mask |= TR_DFP_TO_ZONED_SIGN; // encode result as signed
      if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tsigned: update mask to 0x%x (+Sign 0x%x)\n",mask,TR_DFP_TO_ZONED_SIGN);
      if (isClean)
         {
         // TODO : signIsClean can also be set in non-setSign 0xf (TR_DFP_TO_ZONED_PLUS) cases where there is no truncation
         //      : or could always set TR_DFP_TO_ZONED_FORCE_CLEAN (no harm unless this somehow makes the instruction more expensive)
         mask |= TR_DFP_TO_ZONED_FORCE_CLEAN;
         signIsClean = true;
         if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tclean: update mask to 0x%x (+ForcePlus 0x%x to clean the sign)\n",mask,TR_DFP_TO_ZONED_FORCE_CLEAN);
         }
      }

   // DFP abs or set negative; the CZDT/CZXT will set the sign to 0xc or 0xd
   if (setSignOpCode != TR::InstOpCode::BAD)
      {
      TR::Register *setSignTempReg;
      if (isLongDouble)
         {
         setSignTempReg = cg->allocateFPRegisterPair();
         generateRRInstruction(cg, setSignOpCode, node, setSignTempReg->getHighOrder(), srcFPReg->getHighOrder());
         }
      else
         {
         setSignTempReg = cg->allocateRegister(TR_FPR);
         generateRRInstruction(cg, setSignOpCode, node, setSignTempReg, srcFPReg);
         }

      srcFPReg = setSignTempReg;
      cg->stopUsingRegister(setSignTempReg);
      }


   TR_PseudoRegister *targetReg = cg->allocatePseudoRegister(node->getDataType());
   TR_StorageReference *hint = node->getStorageReferenceHint();
   TR_StorageReference *targetStorageReference = NULL;
   int32_t memSize = 0; // Amount of memory allocated for the destination value
   int32_t regSize = node->getSize(); // Size used to determine the precision for the target register

   if (node->hasSourcePrecision() && node->getSourcePrecision() <= TR::DataType::getMaxExtendedDFPPrecision())
      {
      memSize = std::max<int32_t>(node->getDecimalPrecision(), node->getSourcePrecision());
      }
   else
      {
      // If source precision is unknown, assume the maximum possible value to avoid overflow errors
      if (isFloat || isDouble)
         memSize = TR::DataType::getMaxLongDFPPrecision();
      else
         memSize = TR::DataType::getMaxExtendedDFPPrecision();
      }

   if (hint)
      {
      // If there is no truncation, use the hint size to possibly widen here for free, rather than on a store.
      // If there is a truncation, we can't use the hint size without producing an incorrect result.
      // zdstore p=9      zdstore p = 6   zdstore p=3
      //   dd2zd p=8        dd2zd p = 4     dd2zd p=4
      //     ddX p=8          ddX p = 7       ddX p=7
      // For case 1, using the hint size is good. For case 2, it's incorrect, as we'd lose the truncation to 4 digits.
      // In case 3, using the hint size is fine, but there shouldn't be a hint generated since the p=4 dd2zd result can't fit
      // in the p=3 zdstore field
      if (node->hasSourcePrecision() && !node->isTruncating())
         {
         // Don't widen if doing so would require a conversion from double to long double
         if (!isDouble || (hint->getSymbolSize() <= TR::DataType::getMaxLongDFPPrecision()))
             {
            // Widen up to 32 digits (33 and 34 are slower)
            if (regSize <= TR_MAX_DFP_ZONED_FAST_SIZE && hint->getSymbolSize() > TR_MAX_DFP_ZONED_FAST_SIZE)
               regSize = TR_MAX_DFP_ZONED_FAST_SIZE;
            else
               regSize = hint->getSymbolSize(); // Widen up to the symbol size

            // Enlarge the memory required if it's now smaller than the precision we'll set on the target register
            if (regSize > memSize)
               memSize = regSize;
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tset memSize = %d and regSize = %d based on hint #%d\n",memSize,regSize,hint->getReferenceNumber());
             }
         }
      targetStorageReference = hint;

      }
   else
      {
      targetStorageReference = TR_StorageReference::createTemporaryBasedStorageReference(memSize, comp);
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tset memSize = %d based on node size\n",memSize);
      }

   // regardless of how the memSize and regSize were set up earlier ensure they do not exceed the limits for the CZDT or CZXT instructions
   // and assert below if these max instruction settings are >= the max # of significant digits that can be represented for each DFP type
   if (isFloat)
      {
      TR_ASSERT(TR_DECIMAL_FLOAT_TO_ZONED_MAX_PRECISION >= TR::DataType::getMaxShortDFPPrecision(),"CZDT max %d must be >= DFP short max %d\n",
         TR_DECIMAL_FLOAT_TO_ZONED_MAX_PRECISION, TR::DataType::getMaxShortDFPPrecision());
      memSize = std::min(memSize, TR_DECIMAL_FLOAT_TO_ZONED_MAX_PRECISION);   // cannot get more than 16 digits from the DFP source (and larger encodings are illegal)
      regSize = std::min(regSize, TR_DECIMAL_FLOAT_TO_ZONED_MAX_PRECISION);
      }
   else if (isDouble)
      {
      TR_ASSERT(TR_DECIMAL_DOUBLE_TO_ZONED_MAX_PRECISION >= TR::DataType::getMaxLongDFPPrecision(),"CZDT max %d must be >= DFP long max %d\n",
         TR_DECIMAL_DOUBLE_TO_ZONED_MAX_PRECISION, TR::DataType::getMaxLongDFPPrecision());
      memSize = std::min(memSize, TR_DECIMAL_DOUBLE_TO_ZONED_MAX_PRECISION);   // cannot get more than 16 digits from the DFP source (and larger encodings are illegal)
      regSize = std::min(regSize, TR_DECIMAL_DOUBLE_TO_ZONED_MAX_PRECISION);
      }
   else
      {
      TR_ASSERT(TR_DECIMAL_LONG_DOUBLE_TO_ZONED_MAX_PRECISION >= TR::DataType::getMaxExtendedDFPPrecision(),"CZXT max %d must be >= DFP long double max %d\n",
         TR_DECIMAL_LONG_DOUBLE_TO_ZONED_MAX_PRECISION, TR::DataType::getMaxExtendedDFPPrecision());
      memSize = std::min(memSize, TR_DECIMAL_LONG_DOUBLE_TO_ZONED_MAX_PRECISION);   // cannot get more than 34 digits from the DFP source (and larger encodings are illegal)
      regSize = std::min(regSize, TR_DECIMAL_LONG_DOUBLE_TO_ZONED_MAX_PRECISION);
      }

   if (regSize > memSize)
      {
      // since the memSize is the max # of digits possibly converted then cannot set a higher regSize as these upper digits/bytes would be uninitialized
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tregSize %d > memSize %d : reduce regSize to %d\n",regSize,memSize,memSize);
      regSize = memSize;
      }

   int32_t destPrecision = TR::DataType::getBCDPrecisionFromSize(node->getDataType(), regSize);
   targetReg->setDecimalPrecision(destPrecision);

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tset destPrecision = %d\n",destPrecision);

   targetReg->setStorageReference(targetStorageReference, node);

   bool enforceSSLimits = true;  // RSL has same limits as SS (no index and 12 bit displacment)
   TR::MemoryReference *destMR = generateS390LeftAlignedMemoryReference(node, targetStorageReference, cg, memSize, enforceSSLimits);

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tgenerate DFP to zoned %s (%p) with op=%s and target zoned size %d, mask 0x%x (signIsClean %s, signIsPreferred %s)\n",
              node->getOpCode().getName(),node,isLongDouble ? "TR::InstOpCode::CZXT" : "TR::InstOpCode::CZDT",memSize,mask,signIsClean?"yes":"no",signIsPreferred?"yes":"no");

   if (isFloat)
      {
      TR_ASSERT(memSize > 0 && memSize <= TR_DECIMAL_FLOAT_TO_ZONED_MAX_PRECISION,"memSize %d out of allowed range 1 -> %d for convert DFP to zoned (CZDT)\n",
         memSize,TR_DECIMAL_FLOAT_TO_ZONED_MAX_PRECISION);
      }
   else if (isDouble)
      {
      TR_ASSERT(memSize > 0 && memSize <= TR_DECIMAL_DOUBLE_TO_ZONED_MAX_PRECISION,"memSize %d out of allowed range 1 -> %d for convert DFP to zoned (CZDT)\n",
         memSize,TR_DECIMAL_DOUBLE_TO_ZONED_MAX_PRECISION);
      }
   else
      {
      TR_ASSERT(isLongDouble,"type should be isLongDouble for node %s (%p)\n",node->getOpCode().getName(),node);
      TR_ASSERT(memSize > 0 && memSize <= TR_DECIMAL_LONG_DOUBLE_TO_ZONED_MAX_PRECISION,"memSize %d out of allowed range 1 -> %d for convert DFP to zoned (CZXT)\n",
         memSize,TR_DECIMAL_LONG_DOUBLE_TO_ZONED_MAX_PRECISION);
      }

   generateRSLbInstruction(cg, isLongDouble ? TR::InstOpCode::CZXT : TR::InstOpCode::CZDT, node, srcFPReg, memSize-1, destMR, mask);

   if (needsSetSign)
      {
      targetReg->setKnownSignCode(setSignValue);
      }
   else
      {
      if (signIsClean)
         targetReg->setHasKnownCleanSign();
      else if (signIsPreferred)
         targetReg->setHasKnownPreferredSign();
      }

   if (cg->traceBCDCodeGen())
      {
      traceMsg(comp,"\ttargetReg %s signState : cleanSign=%s, preferredSign=%s, knownSign=%s (0x%x)\n",
              cg->getDebug()->getName(targetReg),
              targetReg->hasKnownCleanSign() ? "yes" : "no", targetReg->hasKnownPreferredSign() ? "yes" : "no",
              targetReg->hasKnownSignCode() ? "yes" : "no", targetReg->hasKnownSignCode() ? targetReg->getKnownSignCode() : TR::DataType::getInvalidSignCode());
      }

   targetReg->setIsInitialized();
   targetReg->setHasKnownValidSignAndData();

   node->setRegister(targetReg);
   cg->decReferenceCount(srcNode);
   cg->traceBCDExit("df2zd",node);

   return targetReg;
   }

#define TR_ZONED_TO_DFP_SIGNED   (0x8)
#define TR_ZONED_TO_DFP_UNSIGNED (0x0)

/**
 * Handles TR::zd2df,TR::zd2dd,TR::zd2de,TR::zd2dfAbs,TR::zd2ddAbs,TR::zd2deAbs
 */
TR::Register *
J9::Z::TreeEvaluator::zd2ddEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("zd2dd",node);

   TR_ASSERT( cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_zEC12),"CDZT/CXZT only valid on >= arch(10)\n");
   TR_ASSERT(node->getDataType() == TR::DecimalDouble || node->getDataType() == TR::DecimalLongDouble,"expecting op to be zd2dd or zd2de and not %d\n",node->getOpCodeValue());
   TR_ASSERT(node->getDecimalFraction() == 0,"frac should be 0 and not %d\n",node->getDecimalFraction());

   bool isAbs = node->getOpCodeValue() == TR::zd2dfAbs || node->getOpCodeValue() == TR::zd2ddAbs || node->getOpCodeValue() == TR::zd2deAbs;
   bool isLongDouble = node->getDataType() == TR::DecimalLongDouble;
   uint8_t mask = isAbs ? TR_ZONED_TO_DFP_UNSIGNED : TR_ZONED_TO_DFP_SIGNED;

   TR::Compilation *comp = cg->comp();
   TR::Node *srcNode = node->getFirstChild();
   TR_PseudoRegister *srcReg = cg->evaluateBCDNode(srcNode);
   TR_StorageReference *srcStorageReference = srcReg->getStorageReference();
   int32_t srcRegSize = srcReg->getSize();

   bool enforceSSLimits = true;  // RSL has same limits as SS (no index and 12 bit displacment)
   TR::MemoryReference *sourceMR = generateS390LeftAlignedMemoryReference(srcNode, srcStorageReference, cg, srcRegSize, enforceSSLimits);

   TR::Register *fprTargetReg = isLongDouble ? cg->allocateFPRegisterPair() : cg->allocateRegister(TR_FPR);

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tgenerate zoned to DFP %s (%p) with op=%s and src zoned size %d, mask 0x%x (%ssigned)\n",
         node->getOpCode().getName(),node,isLongDouble ? "CXZT" : "CDZT",srcRegSize,mask,isAbs?"un":"");

   if (isLongDouble)
      {
      TR_ASSERT(srcRegSize > 0 && srcRegSize <= TR_ZONED_TO_DECIMAL_LONG_DOUBLE_MAX_SIZE,"srcRegSize %d not in valid CXZT range %d -> %d\n",
         srcRegSize,0,TR_ZONED_TO_DECIMAL_LONG_DOUBLE_MAX_SIZE);
      }
   else
      {
      TR_ASSERT(srcRegSize > 0 && srcRegSize <= TR_ZONED_TO_DECIMAL_DOUBLE_MAX_SIZE,"srcRegSize %d not in valid CDZT range %d -> %d\n",
         srcRegSize,0,TR_ZONED_TO_DECIMAL_DOUBLE_MAX_SIZE);
      }

   generateRSLbInstruction(cg, isLongDouble ? TR::InstOpCode::CXZT : TR::InstOpCode::CDZT, node, fprTargetReg, srcRegSize-1, sourceMR, mask);

   node->setRegister(fprTargetReg);
   cg->decReferenceCount(srcNode);
   cg->traceBCDExit("zd2dd",node);

   return fprTargetReg;
   }

bool
J9::Z::TreeEvaluator::isZonedOperationAnEffectiveNop(TR::Node * node, int32_t shiftAmount, bool isTruncation, TR_PseudoRegister *srcReg, bool isSetSign, int32_t signToSet, TR::CodeGenerator * cg)
   {
   bool isEffectiveNop = false;
   int32_t zone = TR::DataType::getZonedValue();
   // For skipLeadingSignReset to be correct the node refCount must be 1 otherwise a commoned reference may be exposed to an incorrect
   // zone nibble (it will be the source's sign code and not the correct zone value)
   bool skipLeadingSignReset = false;
   bool srcSignIsZone = srcReg->knownOrAssumedSignIsZone();
   bool signIsAlreadySet = srcReg->hasKnownOrAssumedSignCode() && (srcReg->getKnownOrAssumedSignCode()==signToSet);
   bool signToSetIsZone          = signToSet == zone;
   bool signToSetIsIgnored       = signToSet == TR::DataType::getIgnoredSignCode();
   bool signToSetIsZoneOrIgnored = signToSetIsZone || signToSetIsIgnored;
   TR::Compilation *comp = cg->comp();

   TR_ASSERT(!node->getOpCode().isRightShift() || shiftAmount > 0,"shiftAmount should be > 0 for zoned right shifts and not a %d\n",shiftAmount);
   switch (node->getOpCodeValue())
      {
      case TR::zd2zdsle:
         isEffectiveNop = srcSignIsZone || (node->getDecimalPrecision() == 1);
         break;
      case TR::zdsle2zd:
         isEffectiveNop = srcSignIsZone || (srcReg->getDecimalPrecision() == 1);
         break;
      case TR::zdsts2zd:
      case TR::zdsls2zd:
         break;
      default:
         TR_ASSERT(false,"unexpected zoned opcode %d\n",node->getOpCodeValue());
         break;
      }
   return isEffectiveNop;
   }


float
J9::Z::TreeEvaluator::interpreterProfilingInstanceOfOrCheckCastTopProb(TR::CodeGenerator * cg, TR::Node * node)
   {
   TR::Compilation *comp = cg->comp();
   TR_ByteCodeInfo bcInfo = node->getByteCodeInfo();
   TR_ValueProfileInfoManager * valueProfileInfo = TR_ValueProfileInfoManager::get(comp);

   if (!valueProfileInfo)
      return 0;

   TR_AddressInfo * valueInfo = (TR_AddressInfo *)valueProfileInfo->getValueInfo(bcInfo, comp,
                                                                                 TR_ValueProfileInfoManager::justInterpreterProfileInfo);
   if (!valueInfo || valueInfo->getNumProfiledValues()==0)
      {
      return 0;
      }

   TR_OpaqueClassBlock *topValue = (TR_OpaqueClassBlock *) valueInfo->getTopValue();
   if (!topValue)
      {
      return 0;
      }

   if (valueInfo->getTopProbability() < TR::Options::getMinProfiledCheckcastFrequency())
      return 0;

   if (comp->getPersistentInfo()->isObsoleteClass(topValue, cg->fe()))
      {
      return 0;
      }

   return valueInfo->getTopProbability();
   }


/**
 * countDigitsEvaluator - count the number of decimal digits of an integer/long binary
 * value (excluding the negative sign).  The original counting digits Java loop is
 * reduced to this IL node by idiom recognition.
 */
TR::Register *
J9::Z::TreeEvaluator::countDigitsEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   // Idiom recognition will reduce the appropriate loop into the following
   // form:
   //    TR::countDigits
   //        inputValue  // either int or long
   //        digits10LookupTable
   //
   // Original loop:
   //      do { count ++; } while((l /= 10) != 0);
   //
   // Since the maximum number of decimal digits for an int is 10, and a long is 19,
   // we can perform binary search comparing the input value with pre-computed digits.


   TR::Node * inputNode = node->getChild(0);
   TR::Register * inputReg = cg->gprClobberEvaluate(inputNode);
   TR::Register * workReg = cg->evaluate(node->getChild(1));
   TR::Register * countReg = cg->allocateRegister();

   TR_ASSERT( inputNode->getDataType() == TR::Int64 || inputNode->getDataType() == TR::Int32, "child of TR::countDigits must be of integer type");

   bool isLong = (inputNode->getDataType() == TR::Int64);
   TR_ASSERT( !isLong || TR::Compiler->target.is64Bit(), "CountDigitEvaluator requires 64-bit support for longs");

   TR::RegisterDependencyConditions * dependencies;
   dependencies = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 3, cg);
   dependencies->addPostCondition(inputReg, TR::RealRegister::AssignAny);
   dependencies->addPostCondition(workReg, TR::RealRegister::AssignAny);
   dependencies->addPostCondition(countReg, TR::RealRegister::AssignAny);

   TR::MemoryReference * work[18];
   TR::LabelSymbol * label[18];
   TR::LabelSymbol * labelEnd = TR::LabelSymbol::create(cg->trHeapMemory());

   TR::Instruction *cursor;

   // Get the negative input value (2's complement) - We treat all numbers as
   // negative to simplify the absolute comparison, and take advance of the
   // CC trick in countsDigitHelper.

   // If the input is a 32-bit value on 64-bit architecture, we cannot simply use TR::InstOpCode::LNGR because the input may not be sign-extended.
   // If you want to use TR::InstOpCode::LNGR for a 32-bit value on 64-bit architecture, you'll need to additionally generate TR::InstOpCode::LGFR for the input.
   generateRRInstruction(cg, !isLong ? TR::InstOpCode::LNR : TR::InstOpCode::LNGR, node, inputReg, inputReg);

   TR::LabelSymbol *startLabel = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   startLabel->setStartInternalControlFlow();
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, startLabel);

   if (isLong)
      {
      for (int32_t i = 0; i < 18; i++)
         {
         work[i] = generateS390MemoryReference(workReg, i*8, cg);
         label[i] = TR::LabelSymbol::create(cg->trHeapMemory());
         }

      generateRXYInstruction(cg, TR::InstOpCode::CG, node, inputReg, work[7]);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, label[11]);

      // LABEL 3
      generateRXYInstruction(cg, TR::InstOpCode::CG, node, inputReg, work[3]);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, label[5]);

      // LABEL 1
      generateRXYInstruction(cg, TR::InstOpCode::CG, node, inputReg, work[1]);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, label[2]);

      countDigitsHelper(node, cg, 0, work[0], inputReg, countReg, labelEnd, isLong);           // 0 and 1

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, label[2]);       // LABEL 2
      countDigitsHelper(node, cg, 2, work[2], inputReg, countReg, labelEnd, isLong);           // 2 and 3

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, label[5]);       // LABEL 5

      generateRXYInstruction(cg, TR::InstOpCode::CG, node, inputReg, work[5]);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, label[6]);

      countDigitsHelper(node, cg, 4, work[4], inputReg, countReg, labelEnd, isLong);           // 4 and 5

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, label[6]);       // LABEL 6
      countDigitsHelper(node, cg, 6, work[6], inputReg, countReg, labelEnd, isLong);          // 6 and 7

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, label[11]);      // LABEL 11

      generateRXYInstruction(cg, TR::InstOpCode::CG, node, inputReg, work[11]);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, label[14]);

      // LABEL 9
      generateRXYInstruction(cg, TR::InstOpCode::CG, node, inputReg, work[9]);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, label[10]);

      countDigitsHelper(node, cg, 8, work[8], inputReg, countReg, labelEnd, isLong);           // 8 and 9

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, label[10]);      // LABEL 10
      countDigitsHelper(node, cg, 10, work[10], inputReg, countReg, labelEnd, isLong);  // 10 and 11

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, label[14]);      // LABEL 14

      generateRXYInstruction(cg, TR::InstOpCode::CG, node, inputReg, work[14]);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, label[16]);

      // LABEL 12
      generateRXYInstruction(cg, TR::InstOpCode::CG, node, inputReg, work[12]); // 12
      generateRIInstruction(cg, TR::InstOpCode::getLoadHalfWordImmOpCode(), node, countReg, 12+1);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BH, node, labelEnd);

      // LABEL 13
      countDigitsHelper(node, cg, 13, work[13], inputReg, countReg, labelEnd, isLong);  // 13 and 14

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, label[16]);      // LABEL 16

      generateRXYInstruction(cg, TR::InstOpCode::CG, node, inputReg, work[16]);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, label[17]);
      // LABEL 15
      countDigitsHelper(node, cg, 15, work[15], inputReg, countReg, labelEnd, isLong);  // 15 and 16

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, label[17]);      // LABEL 17
      countDigitsHelper(node, cg, 17, work[17], inputReg, countReg, labelEnd, isLong);  // 17 and 18

      for (int32_t i = 0; i < 18; i++)
         {
         work[i]->stopUsingMemRefRegister(cg);
         }
      }
   else
      {
      for (int32_t i = 0; i < 9; i++)
         {
         work[i] = generateS390MemoryReference(workReg, i*8+4, cg);     // lower 32-bit
         label[i] = TR::LabelSymbol::create(cg->trHeapMemory());
         }

      // We already generate the label instruction, why would we generate it again?
      //generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, startLabel);

      generateRXInstruction(cg, TR::InstOpCode::C, node, inputReg, work[3]);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, label[5]);

      // LABEL 1
      generateRXInstruction(cg, TR::InstOpCode::C, node, inputReg, work[1]);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, label[2]);

      countDigitsHelper(node, cg, 0, work[0], inputReg, countReg, labelEnd, isLong);           // 0 and 1

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, label[2]);       // LABEL 2
      countDigitsHelper(node, cg, 2, work[2], inputReg, countReg, labelEnd, isLong);           // 2 and 3

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, label[5]);       // LABEL 5

      generateRXInstruction(cg, TR::InstOpCode::C, node, inputReg, work[5]);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, label[7]);

      countDigitsHelper(node, cg, 4, work[4], inputReg, countReg, labelEnd, isLong);           // 4 and 5

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, label[7]);       // LABEL 7

      generateRXInstruction(cg, TR::InstOpCode::C, node, inputReg, work[7]);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, node, label[8]);

      countDigitsHelper(node, cg, 6, work[6], inputReg, countReg, labelEnd, isLong);           // 6 and 7

      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, label[8]);       // LABEL 8
      countDigitsHelper(node, cg, 8, work[8], inputReg, countReg, labelEnd, isLong);           // 8 and 9


      for (int32_t i = 0; i < 9; i++)
         {
         work[i]->stopUsingMemRefRegister(cg);
         }
      }

   cg->stopUsingRegister(inputReg);
   cg->stopUsingRegister(workReg);

   // End
   cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, labelEnd);
   labelEnd->setEndInternalControlFlow();
   cursor->setDependencyConditions(dependencies);

   node->setRegister(countReg);

   cg->decReferenceCount(inputNode);
   cg->decReferenceCount(node->getChild(1));
   return countReg;
   }

/**
 * countDigitsHelper emits code to determine whether the given input value has
 * memRefIndex or memRefIndex+1 digits.
 */
void
J9::Z::TreeEvaluator::countDigitsHelper(TR::Node * node, TR::CodeGenerator * cg,
                                        int32_t memRefIndex, TR::MemoryReference * memRef,
                                        TR::Register* inputReg, TR::Register* countReg,
                                        TR::LabelSymbol *doneLabel, bool isLong)
   {
   // Compare input value with the binary memRefIndex value. The instruction
   // sets CC1 if input <= [memRefIndex], which is also the borrow CC.  Since
   // the numbers are all negative, the equivalent comparison is set if
   // inputValue > [memRefIndex].
   generateRXInstruction(cg, (isLong)?TR::InstOpCode::CG:TR::InstOpCode::C, node, inputReg, memRef);        \

   // Clear countRegister and set it to 1 if inputValue > [memRefIndex].
   generateRRInstruction(cg, TR::InstOpCode::getSubtractWithBorrowOpCode(), node, countReg, countReg);
   generateRRInstruction(cg, TR::InstOpCode::getLoadComplementOpCode(), node, countReg, countReg);

   // Calculate final count of digits by adding to memRefIndex + 1.  The +1 is
   // required as our memRefIndex starts with index 0, but digit counts starts with 1.
   generateRIInstruction(cg, TR::InstOpCode::getAddHalfWordImmOpCode(), node, countReg, memRefIndex+1);

   // CountReg has the number of digits.  Jump to done label.
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, doneLabel);

   }


/**
 * tstartEvaluator:  begin a transaction
 */
TR::Register *
J9::Z::TreeEvaluator::tstartEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
#ifndef PUBLIC_BUILD
   PRINT_ME("tstart", node, cg);

   //   [0x00000000803797c8] (  0)  tstart
   //   [0x0000000080379738] (  1)    branch --> block 28 BBStart at [0x0000000080378bc8]
   //   [0x00000000803f15f8] (  1)      GlRegDeps
   //                        (  3)        ==>aRegLoad at [0x00000000803f1568] (in &GPR_0048)
   //                        (  2)        ==>aRegLoad at [0x00000000803f15b0] (in &GPR_0049)
   //   [0x0000000080379780] (  1)    branch --> block 29 BBStart at [0x0000000080378ed8]
   //   [0x00000000803f1640] (  1)      GlRegDeps
   //                        (  3)        ==>aRegLoad at [0x00000000803f1568] (in &GPR_0048)
   //                        (  2)        ==>aRegLoad at [0x00000000803f15b0] (in &GPR_0049)
   //   [0x00000000803796f0] (  1)    aload #422[0x000000008035e4b0]  Auto[<temp slot 2 holds monitoredObject syncMethod>]   <flags:"0x4" (X!=0 )/>
   //   [0x00000000803f1688] (  1)    GlRegDeps
   //                        (  3)      ==>aRegLoad at [0x00000000803f1568] (in &GPR_0048)


   // TEBGIN 0(R0),0xFF00
   // BRNEZ  OOL TM                        ; CC0 = success
   // ------ OOL TM ----
   // BRH    Block_Transient_Handler       ; CC2 = transient failure
   //    POST deps (persistent path)
   // BRC    Block_Persistent_Handler      ; CC1,CC3 = persistent failure
   //    Post deps (transient path)
   // BRC    mainline                      ; we need this brc for OOL mechanism, though it's never taken
   // -----------------------
   // LT     Rlw, lockword (obj)
   // BEQ    Label Start
   // TEND
   // BRC    Block_Transient_Handler
   // Label Start
   //    POST Deps

   TR::Compilation *comp = cg->comp();
   TR::Instruction * cursor = NULL;

   TR::Node * brPersistentNode = node->getFirstChild();
   TR::Node * brTransientNode = node->getSecondChild();
   TR::Node * fallThrough = node->getThirdChild();
   TR::Node * objNode = node->getChild(3);
   TR::Node * GRAChild = NULL;

   static char *extractTDB = feGetEnv("TR_ExtractTDB");
   TR::Register * tdbAddressReg;
   TR::MemoryReference * TDBMemRef;
   if (extractTDB)
      {
      tdbAddressReg = cg->allocateRegister();
#if 1
      printf("tstartEvaluator: please make sure J9VMThread includes a 'tdb' member.\n"); fflush(stdout);
      TDBMemRef = generateS390MemoryReference(node->getChild(3), cg);
#else
      TDBMemRef = generateS390MemoryReference(cg->getMethodMetaDataRealRegister(), offsetof(J9VMThread, tdb), cg);
#endif
      }

   TR::LabelSymbol * labelPersistentFailure = brPersistentNode->getBranchDestination()->getNode()->getLabel();
   TR::LabelSymbol * labelTransientFailure = brTransientNode->getBranchDestination()->getNode()->getLabel();
   TR::LabelSymbol * startLabel = fallThrough->getBranchDestination()->getNode()->getLabel();

   TR::Register * objReg = cg->evaluate(objNode);
   TR::Register * monitorReg = cg->allocateRegister();

   TR::RegisterDependencyConditions *deps = NULL;
   TR::RegisterDependencyConditions *depsPersistent = NULL;
   TR::RegisterDependencyConditions *depsTransient = NULL;

   // GRA
   if (fallThrough->getNumChildren() !=0)
      {
      GRAChild = fallThrough->getFirstChild();
      cg->evaluate(GRAChild);
      deps = generateRegisterDependencyConditions(cg, GRAChild, 0);
      cg->decReferenceCount(GRAChild);
      }

   if (brPersistentNode->getNumChildren() != 0)
      {
      GRAChild = brPersistentNode->getFirstChild();
      cg->evaluate(GRAChild);
      depsPersistent = generateRegisterDependencyConditions(cg, GRAChild, 0);
      cg->decReferenceCount(GRAChild);
      }

   if (brTransientNode->getNumChildren() != 0)
      {
      GRAChild = brTransientNode->getFirstChild();
      cg->evaluate(GRAChild);
      depsTransient = generateRegisterDependencyConditions(cg, GRAChild, 0);
      cg->decReferenceCount(GRAChild);
      }

   TR::MemoryReference* tempMR = generateS390MemoryReference(cg->machine()->getS390RealRegister(TR::RealRegister::GPR0),0,cg);

   static char * debugTM = feGetEnv("debugTM");

   if (debugTM)
      {
      // artificially set CC to transientFailure, objReg is always > 0
      cursor = generateRRInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::LTGR : TR::InstOpCode::LTR, node, objReg, objReg);
      }
   else
      {
      /// Immediate field of TBEGIN:
      /// bits 0-7:  FF - General Register Save Mask used to tell the hardware which pairs of registers need to be rolled back.
      ///                 always set to FF here because GRA will later decide which registers we actually need to roll back.
      /// bits 8-11:  0 - not used by hardware, always zero.
      /// bit 12:     0 - Allow access register modification
      /// bit 13:     0 - Allow floating-point operation
      /// bits 14-15: 2 - Program-Interruption-Filtering Control
      ///        PIFC bits needs to be set to 2, to allow 0C4 and 0C7 interrupts to resume, instead of being thrown.
      ///        Since all interrupts cause aborts, the PSW is rolled back to TBEGIN on interrupts. The 0C7 interrupts
      ///        are generated by trap instructions for Java exception handling. The 0C4 interrupts are used by z/OS LE to
      ///        detect guarded page exceptions which are used to trigger XPLINK stack growth. In both cases, either the
      ///        LE or JIT signal handler need the PSW of the actual instruction that generated the interrupt, not the
      ///        rolled back PSW pointing to TBEGIN. Without filtering these interrupts, the program will crash. Filtering
      ///        the interrupts allows us to resume execution following the abort and go to slow path so the exceptions
      ///        can be properly caught and handled.
      if (extractTDB)
         {
         cursor = generateSILInstruction(cg, TR::InstOpCode::TBEGIN, node, TDBMemRef, 0xFF02);
         }
      else
         {
       cursor = generateSILInstruction(cg, TR::InstOpCode::TBEGIN, node, tempMR, 0xFF02);
         }
      }

   if (labelTransientFailure == labelPersistentFailure)
      {
      if (depsPersistent != depsTransient) //only possible to be equal if they are NULL (i.e. non existent)
         {
         TR_ASSERT( depsPersistent && depsTransient, "regdeps wrong in tstart evaluator");
         uint32_t i = depsPersistent->getNumPostConditions();
         uint32_t j = depsTransient->getNumPostConditions();
         TR_ASSERT( i == j, "regdep postcondition number not the same");
         depsPersistent->getPostConditions()->getRegisterDependency(i);
         i = depsPersistent->getNumPreConditions();
         j = depsTransient->getNumPreConditions();
         TR_ASSERT( i == j, "regdep precondition number not the same");
         }
      cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK7, node, labelTransientFailure, depsPersistent);
      }
   else
      {
      cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BH, node, labelTransientFailure, depsTransient);
      cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK7, node, labelPersistentFailure, depsPersistent);
      }


   int32_t lwOffset = cg->fej9()->getByteOffsetToLockword((TR_OpaqueClassBlock *) cg->getMonClass(node));

   if (TR::Compiler->target.is64Bit() && cg->fej9()->generateCompressedLockWord())
      cursor = generateRXInstruction(cg, TR::InstOpCode::LT, node, monitorReg, generateS390MemoryReference(objReg, lwOffset, cg), cursor);
   else
      cursor = generateRXInstruction(cg, TR::InstOpCode::getLoadTestOpCode(), node, monitorReg, generateS390MemoryReference(objReg, lwOffset, cg),cursor);

   cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, node, startLabel, deps, cursor);

   TR::MemoryReference * tempMR1 = generateS390MemoryReference(cg->machine()->getS390RealRegister(TR::RealRegister::GPR0),0,cg);

   // use TEND + BRC instead of TABORT for better performance
   cursor = generateSInstruction(cg, TR::InstOpCode::TEND, node, tempMR1, cursor);

   cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, labelTransientFailure, depsTransient, cursor);

   if (extractTDB)
      {
    if (tdbAddressReg)
       {
         cg->stopUsingRegister(tdbAddressReg);
       }
      }
   cg->stopUsingRegister(monitorReg);
   cg->decReferenceCount(objNode);
   cg->decReferenceCount(brPersistentNode);
   cg->decReferenceCount(brTransientNode);
   cg->decReferenceCount(fallThrough);
#endif

   return NULL;
   }

/**
 * tfinshEvaluator:  end a transaction
 */
TR::Register *
J9::Z::TreeEvaluator::tfinishEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
#ifndef PUBLIC_BUILD
   PRINT_ME("tfinish", node, cg);
   TR::MemoryReference * tempMR1 = generateS390MemoryReference(cg->machine()->getS390RealRegister(TR::RealRegister::GPR0),0,cg);
   TR::Instruction * cursor = generateSInstruction(cg, TR::InstOpCode::TEND, node, tempMR1);
#endif

   return NULL;
   }

/**
 * tabortEvaluator:  abort a transaction
 */
TR::Register *
J9::Z::TreeEvaluator::tabortEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
#ifndef PUBLIC_BUILD
   TR::Instruction *cursor;
   TR::LabelSymbol * labelDone = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
   TR::Register *codeReg = cg->allocateRegister();
   generateRIInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::LGHI : TR::InstOpCode::LHI, node, codeReg, 0);
   //Get the nesting depth
   cursor = generateRREInstruction(cg, TR::InstOpCode::ETND, node, codeReg, codeReg);

   generateRIInstruction(cg, TR::InstOpCode::CHI, node, codeReg, 0);
   //branch on zero to done label
   generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK8, node, labelDone);
   generateRIInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::LGHI : TR::InstOpCode::LHI, node, codeReg, 0x100);
   TR::MemoryReference *codeMR = generateS390MemoryReference(codeReg, 0, cg);
   cursor = generateSInstruction(cg, TR::InstOpCode::TABORT, node, codeMR);
   generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, labelDone);
   cg->stopUsingRegister(codeReg);
#endif
   return NULL;
   }

TR::Register *
J9::Z::TreeEvaluator::BCDCHKEvalHelper(TR::Node *node, TR::Node * pdopNode, TR::CodeGenerator *cg)
   {
   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   bool isEnableVectorBCD = TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() &&
           !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) ||
           isVectorBCDEnv;

   switch (pdopNode->getOpCodeValue())
      {
      case TR::pdcmpgt:
      case TR::pdcmplt:
      case TR::pdcmpge:
      case TR::pdcmple:
      case TR::pdcmpeq:
      case TR::pdcmpne:
      case TR::pd2l:
      case TR::pd2i:
      case TR::pd2iOverflow:
      case TR::pd2lOverflow:
         {
         return BCDCHKEvaluatorImpl(node, pdopNode, cg, node->getNumChildren() - 1, 1, false, isEnableVectorBCD);
         }
      case TR::i2pd:
      case TR::l2pd:
      case TR::pdshlOverflow:
      case TR::pdshr:
         {
         return BCDCHKEvaluatorImpl(node, pdopNode, cg, node->getNumChildren() - 2, 2, true, isEnableVectorBCD);
         }
      // Handle variable precision
      case TR::lcall:
      case TR::icall:
         {
         switch (pdopNode->getSymbol()->getMethodSymbol()->getMethod()->getRecognizedMethod())
            {
            case TR::com_ibm_dataaccess_DecimalData_convertPackedDecimalToInteger_:
            case TR::com_ibm_dataaccess_DecimalData_convertPackedDecimalToInteger_ByteBuffer_:
            case TR::com_ibm_dataaccess_DecimalData_convertPackedDecimalToLong_:
            case TR::com_ibm_dataaccess_DecimalData_convertPackedDecimalToLong_ByteBuffer_:
               {
               return BCDCHKEvaluatorImpl(node, pdopNode, cg, pdopNode->getNumChildren(), 0, false, isEnableVectorBCD);
               }

            default: TR_ASSERT(0, "BCDCHKEvaluator: Could not find recognized method for variable precision DAA operation.\n");
            }
         }

      default: TR_ASSERT(0, "Operation Code not supported in BCDCHKEvaluator.\n");
      }

   return NULL;
   }

/**
 * \brief This evaluator helper function handles pdOp node evaluation under pdshloverflow and BCDCHK nodes.
 *
 * The following PD opts are currently handled by this function:
 * -- i2pd, l2pd
 * -- pdadd, pdsub, pdmul, pddiv, pdrem
 *
 * With the new DAA BCDCHK node tree structure, the first child of a BCDCHK node is always the PD opNode that
 * could throw PD related exceptions (decimal exception, and etc); and the second child of a BCDCHK node
 * should always be an address node.
 *
 * The steps to evaluate the new BCDCHK node is the following:
 *
 * 1. Create a callNode and attached BCDCHK's call parameter children to it. This callNode is to be evaluated
 *    later in the OOL section
 *
 * 2. Evaluate callNode's children that are needed by the mainline code (with refCount > 2).
 *    OOL-only children evaluation is defered to the OOL path, after the call to
 *    swapInstructionListsWithCompilation()
 *
 * 3. If applicable, evaluate address node's children (e.g. this is applicable to i2pd but not to PD comparisons)
 *
 * 4. Create a handlerLabel that points to the start of the OOL section and replace the second child
 *    with this handlerLabel
 *
 * 5. Evaluate the pdopNode (first child) and decrement its refCount.
 *
 * 6. Emit a NOP BRC bearing the handlerLabel right after evaluating the pdopNode. This is for SignalHandler.c
 *
 * 7. Undo step 4 by restoring the second child
 *
 * 8. Switch to OOL code generation and evaluate the callNode
 *
 * 9. Evaluate the addressNode (second child of BCDCHK node) to yield a correct address into the byte[]
 *
 * 10. Copy the results produced by the call from byte[] back to mainline storage reference
 *
 * 11. Finish up by decRefCount on callNode and addressNode
 *
 * \param node the BCDCHK node
 * \param pdopNode pdshlOverflow, i2pd or l2pd node
 * \param cg codegen object
 * \param numCallChildre  number of callNode children
 * \param callChildStartIndex  the index of the first callChild under the BCDCHK node
 * \param isResultPD   True if the result of the pdOpNode a PD; false if the result is a binary integer/long
 *                     This also implies that the second node of the BCDCHK node is an address node.
*/
TR::Register *
J9::Z::TreeEvaluator::BCDCHKEvaluatorImpl(TR::Node * node,
                                          TR::Node * pdopNode,
                                          TR::CodeGenerator * cg,
                                          uint32_t numCallChildren,
                                          uint32_t callChildStartIndex,
                                          bool isResultPD,
                                          bool isUseVector)
   {
   TR_Debug* debugObj = cg->getDebug();
   TR::Node * secondChild = node->getChild(1);
   bool isVariableParam = pdopNode->getOpCodeValue() == TR::lcall ||
                          pdopNode->getOpCodeValue() == TR::icall;

   bool isResultLong = pdopNode->getOpCodeValue() == TR::pd2l ||
                       pdopNode->getOpCodeValue() == TR::pd2lOverflow ||
                       pdopNode->getOpCodeValue() == TR::lcall;

   TR::LabelSymbol* handlerLabel     = TR::LabelSymbol::create(INSN_HEAP, cg);
   TR::LabelSymbol* passThroughLabel = TR::LabelSymbol::create(INSN_HEAP,cg);
   cg->setCurrentBCDCHKHandlerLabel(handlerLabel);

   // This is where the call children node come from and the node that has the call symRef
   TR::Node* childRootNode = isVariableParam ? pdopNode : node;

   // Create a call
   TR::ILOpCodes callType = isResultPD ? TR::call : (isResultLong ? TR::lcall : TR::icall);

   TR::Node * callNode = TR::Node::createWithSymRef(node, callType, numCallChildren,
                                                    childRootNode->getSymbolReference());
   cg->incReferenceCount(callNode);
   callNode->setNumChildren(numCallChildren);

   // Setup callNode children
   for (int i = 0; i < numCallChildren; ++i)
      {
      if(isResultPD)
         callNode->setAndIncChild(i, childRootNode->getChild(i + callChildStartIndex));
      else
         callNode->setChild(i, childRootNode->getChild(i + callChildStartIndex));
      }

   // Evaluate callNode children, if needed by the mainline code
   for (uint32_t i = 0; i < numCallChildren; ++i)
      {
      TR::Node* child = callNode->getChild(i);
      if(child->getReferenceCount() > 2)
         {
         cg->evaluate(child);
         }
      }

   // Evaluate secondChild's children, if the secondChild is an address node into a byte[]
   if(isResultPD && secondChild->getNumChildren() == 2)
      {
      cg->evaluate(secondChild->getFirstChild());
      cg->evaluate(secondChild->getSecondChild());
      }

   // Evaluate intrinsics node
   TR::Register* bcdOpResultReg = NULL;
   if(isVariableParam)
      {
      bcdOpResultReg = pd2lVariableEvaluator(node, cg, isUseVector);
      }
   else if(isResultPD && !isUseVector)
      {
      bcdOpResultReg = cg->evaluateBCDNode(pdopNode);
      }
   else
      {
      bcdOpResultReg = cg->evaluate(pdopNode);
      }

   // start of OOL section
   traceMsg(cg->comp(), "starting OOL section generation.\n");
   TR_S390OutOfLineCodeSection* outlinedHelperCall = new (INSN_HEAP) TR_S390OutOfLineCodeSection(handlerLabel, passThroughLabel, cg);
   cg->getS390OutOfLineCodeSectionList().push_front(outlinedHelperCall);
   outlinedHelperCall->swapInstructionListsWithCompilation();
   // snippetLabel : OOL Start label
   TR::Instruction* cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, handlerLabel);

   if(debugObj)
      {
      debugObj->addInstructionComment(cursor, "Start of BCDCHK OOL sequence");
      }

   // Debug counter for tracking how often we fall back to the OOL path of the DAA intrinsic
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "DAA/OOL/(%s)/%p", cg->comp()->signature(), node), 1, TR::DebugCounter::Undetermined);

   // Evaluate the callNode, duplicate and evaluate the address node, and then copy the
   // correct results back to the mainline storage ref or register
   TR::Register* callResultReg = cg->evaluate(callNode);

   if(isResultPD)
      {
      TR::Register* srcBaseReg = cg->evaluate(secondChild);

      if(isUseVector)
         {
         TR_ASSERT(bcdOpResultReg && (bcdOpResultReg->getKind() == TR_VRF || bcdOpResultReg->getKind() == TR_FPR),
                   "Vector register expected\n");

         int32_t resultSize = TR::DataType::packedDecimalPrecisionToByteLength(pdopNode->getDecimalPrecision());
         TR::MemoryReference* srcMR = generateS390MemoryReference(srcBaseReg, 0, cg);
         generateVSIInstruction(cg, TR::InstOpCode::VLRL, node, bcdOpResultReg, srcMR, resultSize - 1);
         }
      else
         {
         int32_t resultSize = TR::DataType::packedDecimalPrecisionToByteLength(pdopNode->getDecimalPrecision());
         TR::MemoryReference* srcMR = generateS390MemoryReference(srcBaseReg, 0, cg);
         TR::MemoryReference* targetMR = generateS390RightAlignedMemoryReference(pdopNode, static_cast<TR_PseudoRegister*>(bcdOpResultReg)->getStorageReference(), cg);
         generateSS1Instruction(cg, TR::InstOpCode::MVC, node, resultSize - 1, targetMR, srcMR);
         }

      cg->decReferenceCount(secondChild);
      cg->stopUsingRegister(callResultReg);
      }
   else
      {
      if(isResultLong)
         {
         if(TR::Compiler->target.is32Bit())
            {
            TR::RegisterPair* bcdOpPair = bcdOpResultReg->getRegisterPair();
            generateRRInstruction(cg, TR::InstOpCode::LR, node, bcdOpPair->getLowOrder(), callResultReg->getLowOrder());
            generateRRInstruction(cg, TR::InstOpCode::LR, node, bcdOpPair->getHighOrder(), callResultReg->getHighOrder());
            }
         else
            {
            generateRREInstruction(cg, TR::InstOpCode::LGR, node, bcdOpResultReg, callResultReg);
            }
         }
      else
         {
         generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, bcdOpResultReg, callResultReg);
         }
      }

   cg->stopUsingRegister(callResultReg);
   cursor = generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, passThroughLabel);

   // Decrement reference counts
   cg->recursivelyDecReferenceCount(callNode);
   if(isVariableParam)
      {
      // variable parameter l2pd is a call node
      cg->recursivelyDecReferenceCount(pdopNode);
      }
   else
      {
      cg->decReferenceCount(pdopNode);
      }

   if(debugObj)
      {
      debugObj->addInstructionComment(cursor, "End of BCDCHK OOL sequence: return to mainline");
      }

   traceMsg(cg->comp(), "Finished OOL section generation.\n");

   // ***Done using OOL with manual code generation *** //
   outlinedHelperCall->swapInstructionListsWithCompilation();
   cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, passThroughLabel, cg->getCurrentCheckNodeRegDeps());

   cg->setCurrentBCDCHKHandlerLabel(NULL);
   return bcdOpResultReg;
   }

/**
 * BCDCHKEvaluator -
 */
TR::Register *
J9::Z::TreeEvaluator::BCDCHKEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   PRINT_ME("BCDCHK", node, cg);
   TR::Register* rv = node->getFirstChild()->getRegister();

   // Avoid evaluating an evaluated pdOpNode (first child of BCDCHK) under a BCDCHK node.
   // This is to avoid generating unnecessary labels that points to non-existant OOL paths
   // that can eventually cause RA to produce incorrect register use counts.
   if(rv != NULL)
      {
      for(int i = 0; i < node->getNumChildren(); ++i)
         {
         cg->recursivelyDecReferenceCount(node->getChild(i));
         }
      return rv;
      }

   TR::RegisterDependencyConditions * daaDeps =  new (INSN_HEAP) TR::RegisterDependencyConditions(0, 13, cg);

   cg->setCurrentCheckNodeRegDeps(daaDeps);
   cg->setCurrentCheckNodeBeingEvaluated(node);

   rv = BCDCHKEvalHelper(node, node->getFirstChild(), cg);

   cg->setCurrentCheckNodeRegDeps(NULL);
   cg->setCurrentCheckNodeBeingEvaluated(NULL);

   return rv;
   }

TR::Register*
J9::Z::TreeEvaluator::pdcmpVectorEvaluatorHelper(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR::Register* resultReg = cg->allocateRegister(TR_GPR);
   generateRRInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::XGR : TR::InstOpCode::XR, node, resultReg, resultReg);
   generateLoad32BitConstant(cg, node, 1, resultReg, true);

   TR::RegisterDependencyConditions* deps = new(cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 1, cg);
   TR::LabelSymbol* doneCompareLabel = TR::LabelSymbol::create(cg->trHeapMemory(), cg);

   TR::Node* pd1Node = node->getFirstChild();
   TR::Node* pd2Node = node->getSecondChild();

   TR::Register* pd1Value = cg->evaluate(pd1Node);
   TR::Register* pd2Value = cg->evaluate(pd2Node);

   // TODO: should we correct bad sign before comparing them
   TR::Instruction* cursor = generateVRRhInstruction(cg, TR::InstOpCode::VCP, node, pd1Value, pd2Value, 0);

   cursor->setStartInternalControlFlow();
   deps->addPostConditionIfNotAlreadyInserted(resultReg, TR::RealRegister::AssignAny);

   // Generate Branch Instructions
   switch(node->getOpCodeValue())
      {
      case TR::pdcmpeq:
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_CC0, node, doneCompareLabel);
         break;
      case TR::pdcmpne:
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_CC1, node, doneCompareLabel);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_CC2, node, doneCompareLabel);
         break;
      case TR::pdcmplt:
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_CC1, node, doneCompareLabel);
         break;
      case TR::pdcmple:
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_CC0, node, doneCompareLabel);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_CC1, node, doneCompareLabel);
         break;
      case TR::pdcmpgt:
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_CC2, node, doneCompareLabel);
         break;
      case TR::pdcmpge:
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_CC0, node, doneCompareLabel);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_CC2, node, doneCompareLabel);
         break;
      default:
         TR_ASSERT(0, "Unrecognized op code in pd cmp vector evaluator helper.");
      }

   cursor = generateLoad32BitConstant(cg, node, 0, resultReg, true);
   cursor = generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, doneCompareLabel);
   cursor->setDependencyConditions(deps);
   cursor->setEndInternalControlFlow();

   node->setRegister(resultReg);

   cg->decReferenceCount(pd1Node);
   cg->decReferenceCount(pd2Node);

   return resultReg;
   }

TR::Register *J9::Z::TreeEvaluator::pdcmpeqEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pdcmpeq",node);
   cg->generateDebugCounter("PD-Op/pdcmpeq", 1, TR::DebugCounter::Cheap);

   // to support castedToBCD have to ensure generateS390CompareBool generates logical comparision only and not CP
   TR_ASSERT(node->castedToBCD() == false,"castedToBCD=true not supported for %s (%p)\n",node->getOpCode().getName(),node);
   TR::Register *targetReg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      targetReg = pdcmpVectorEvaluatorHelper(node, cg);
      }
   else
      {
      targetReg = generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, TR::InstOpCode::COND_BE, false);
      }

   cg->traceBCDExit("pdcmpeq",node);
   return targetReg;
   }

TR::Register *J9::Z::TreeEvaluator::pdcmpneEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pdcmpne",node);
   cg->generateDebugCounter("PD-Op/pdcmpne", 1, TR::DebugCounter::Cheap);

   TR_ASSERT(node->castedToBCD() == false,"castedToBCD=true not supported for %s (%p)\n",node->getOpCode().getName(),node);
   TR::Register *targetReg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      targetReg = pdcmpVectorEvaluatorHelper(node, cg);
      }
   else
      {
      targetReg = generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, TR::InstOpCode::COND_BNE, false);
      }

   cg->traceBCDExit("pdcmpne",node);
   return targetReg;
   }

TR::Register *J9::Z::TreeEvaluator::pdcmpltEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pdcmplt",node);
   cg->generateDebugCounter("PD-Op/pdcmplt", 1, TR::DebugCounter::Cheap);

   TR_ASSERT(node->castedToBCD() == false,"castedToBCD=true not supported for %s (%p)\n",node->getOpCode().getName(),node);
   TR::Register *targetReg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      targetReg = pdcmpVectorEvaluatorHelper(node, cg);
      }
   else
      {
      targetReg = generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BL, TR::InstOpCode::COND_BH, false);
      }

   cg->traceBCDExit("pdcmplt",node);
   return targetReg;
   }

TR::Register *J9::Z::TreeEvaluator::pdcmpgeEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pdcmpge",node);
   cg->generateDebugCounter("PD-Op/pdcmpge", 1, TR::DebugCounter::Cheap);

   TR_ASSERT(node->castedToBCD() == false,"castedToBCD=true not supported for %s (%p)\n",node->getOpCode().getName(),node);
   TR::Register *targetReg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      targetReg = pdcmpVectorEvaluatorHelper(node, cg);
      }
   else
      {
      targetReg = generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNL, TR::InstOpCode::COND_BNH, false);
      }

   cg->traceBCDExit("pdcmpge",node);
   return targetReg;
   }

TR::Register *J9::Z::TreeEvaluator::pdcmpgtEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pdcmpgt",node);
   cg->generateDebugCounter("PD-Op/pdcmpgt", 1, TR::DebugCounter::Cheap);

   TR_ASSERT(node->castedToBCD() == false,"castedToBCD=true not supported for %s (%p)\n",node->getOpCode().getName(),node);
   TR::Register *targetReg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      targetReg = pdcmpVectorEvaluatorHelper(node, cg);
      }
   else
      {
      targetReg = generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BH, TR::InstOpCode::COND_BL, false);
      }

   cg->traceBCDExit("pdcmpgt",node);
   return targetReg;
   }

TR::Register *J9::Z::TreeEvaluator::pdcmpleEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pdcmple",node);
   cg->generateDebugCounter("PD-Op/pdcmple", 1, TR::DebugCounter::Cheap);

   TR_ASSERT(node->castedToBCD() == false,"castedToBCD=true not supported for %s (%p)\n",node->getOpCode().getName(),node);
   TR::Register *targetReg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      targetReg = pdcmpVectorEvaluatorHelper(node, cg);
      }
   else
      {

      targetReg = generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, TR::InstOpCode::COND_BNL, false);
      }

   cg->traceBCDExit("pdcmple",node);
   return targetReg;
   }

TR::RegisterDependencyConditions *setupPackedDFPConversionGPRs(TR::Register *&gpr64, TR::Register *&gpr64Hi, TR::Register *&gpr64Lo, bool isLongDouble, TR::CodeGenerator *cg)
   {
   TR::RegisterDependencyConditions *deps = NULL;
   if (isLongDouble)
      {
      gpr64 = cg->allocateConsecutiveRegisterPair(cg->allocate64bitRegister(), cg->allocate64bitRegister());
      gpr64Hi = gpr64->getHighOrder(); // 0-63
      gpr64Lo = gpr64->getLowOrder();  // 64-127
      }
   else
      {
      gpr64Hi = cg->allocate64bitRegister();
      gpr64 = gpr64Hi;
      }

   if (TR::Compiler->target.is64Bit() || cg->use64BitRegsOn32Bit())
      {
      if (isLongDouble)
         {
         deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 3, cg);
         deps->addPostCondition(gpr64, TR::RealRegister::EvenOddPair);
         deps->addPostCondition(gpr64Hi, TR::RealRegister::LegalEvenOfPair);
         deps->addPostCondition(gpr64Lo, TR::RealRegister::LegalOddOfPair);
         }
      }
   else
      {
      uint8_t depsNeeded = isLongDouble ? 2 : 1;
      deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, depsNeeded, cg);
      // the 64 bit registers gpr64Hi/gpr64Lo are going to be clobbered and R0/R1 are safe to clobber regardless of the hgpr (use64BitRegsOn32Bit) setting
      deps->addPostCondition(gpr64Hi, TR::RealRegister::GPR0);
      if (isLongDouble)
         deps->addPostCondition(gpr64Lo, TR::RealRegister::GPR1);
      }
   return deps;
   }

#define TR_PACKED_TO_DFP_NOABS   (0x8)
#define TR_PACKED_TO_DFP_ABS     (0x9)

/**
 * Handles TR::pd2dd,TR::pd2de
 */
TR::Register *
J9::Z::TreeEvaluator::pd2ddEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pd2dd",node);

   TR_ASSERT(node->getDataType() == TR::DecimalDouble || node->getDataType() == TR::DecimalLongDouble,"expecting op to be pd2dd or pd2de and not %d\n",node->getOpCodeValue());
   TR_ASSERT(node->getDecimalFraction() == 0,"frac should be 0 and not %d\n",node->getDecimalFraction());

   bool isLongDouble = node->getDataType() == TR::DecimalLongDouble;
   bool isAbs = node->getOpCodeValue() == TR::pd2dfAbs || node->getOpCodeValue() == TR::pd2ddAbs || node->getOpCodeValue() == TR::pd2deAbs;
   TR::Node *srcNode = node->getFirstChild();
   TR_PseudoRegister *srcReg = cg->evaluateBCDNode(srcNode);
   TR_StorageReference *srcStorageReference = srcReg->getStorageReference();
   int32_t srcRegSize = srcReg->getSize();
   int32_t srcFixedSize = cg->getPackedToDecimalLongDoubleFixedSize(); // max that can be handled by TR::InstOpCode::CXSTR
   TR_ASSERT(srcRegSize <= srcFixedSize,"srcRegSize %d must be <= %d in pd2ddEvaluator\n",srcRegSize,srcFixedSize);
   TR::Register *fprTargetReg = NULL;
   TR::Compilation *comp = cg->comp();

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"%s %p : srcRegPrec %d, srcRegSize %d  (srcFixedSize = %d, isInit = %s)\n",
         node->getOpCode().getName(),node,srcReg->getDecimalPrecision(),srcRegSize,srcFixedSize,srcReg->isInitialized()?"yes":"no");

   // At arch(11), we have an efficient instruction that converts the packed value, in memory, to the DFP value, in an FP register
   if (cg->supportsFastPackedDFPConversions())
      {
      uint8_t mask = isAbs ? TR_PACKED_TO_DFP_ABS : TR_PACKED_TO_DFP_NOABS;

      bool enforceSSLimits = true;  // RSL has same limits as SS (no index and 12 bit displacment)
      TR::MemoryReference *sourceMR = generateS390LeftAlignedMemoryReference(srcNode, srcStorageReference, cg, srcRegSize, enforceSSLimits);

      fprTargetReg = isLongDouble ? cg->allocateFPRegisterPair() : cg->allocateRegister(TR_FPR);

      int32_t srcPrec = srcReg->getDecimalPrecision();
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tgenerate packed to DFP %s (%p) with op=%s and src packed size %d (prec=%d), mask 0x%x%s\n",
            node->getOpCode().getName(),node,isLongDouble ? "CXPT" : "CDPT",srcRegSize,srcPrec,mask,isAbs?" (abs)":"");

      if (isLongDouble)
         {
         // 1 -> 18 bytes but for 18 bytes only 34 and not 35 digits are allowed (data exception otherwise)
         TR_ASSERT(srcPrec > 0 && srcPrec <= TR_PACKED_TO_DECIMAL_LONG_DOUBLE_PRECISION_ARCH11,"srcPrec %d not in valid CXPT range %d -> %d\n",
            srcPrec,0,TR_PACKED_TO_DECIMAL_LONG_DOUBLE_PRECISION_ARCH11);
         }
      else
         {
         // 1 -> 9 bytes but for 9 bytes only 16 and not 17 digits are allowed (data exception otherwise)
         TR_ASSERT(srcPrec > 0 && srcPrec <= TR_PACKED_TO_DECIMAL_DOUBLE_PRECISION_ARCH11,"srcPrec %d not in valid CDPT range %d -> %d\n",
            srcPrec,0,TR_PACKED_TO_DECIMAL_DOUBLE_PRECISION_ARCH11);
         }

      generateRSLbInstruction(cg, isLongDouble ? TR::InstOpCode::CXPT : TR::InstOpCode::CDPT, node, fprTargetReg, srcRegSize-1, sourceMR, mask);
      }
   else
      {
      // Pre-arch(11): Need to load from memory into a GPR and then convert to DFP in an FPR

      TR::Register *gpr64 = NULL;
      TR::Register *gpr64Hi = NULL;
      TR::Register *gpr64Lo = NULL;

      bool isForcedLongDouble = false;
      if (!isLongDouble && srcRegSize > cg->getPackedToDecimalDoubleFixedSize())
         {
         // There is a mismatch between the max prec supported by CDSTR (15 digits + sign) and the max prec supported in long (8-byte) DFP format (16 digits)
         // For this case use the larger convert instruction CXSTR and round down afterwards
         // CXSTR can convert up to 34 digits but the subsequent round down will lose precision due to rounding for any value with > 16 digits so only 9 bytes (16 or 17 digits)
         // of packed digits will be loaded and if the srcReg precision is > 16 then it will corrected back to a max of 16 digits with the NILL instruction below
         isForcedLongDouble = true;
         isLongDouble = true;
         srcRegSize = 9;
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tsrcRegSize %d  > max of %d for CDSTR : set isLongDouble=true and reduce srcRegSize %d -> %d\n",
               srcRegSize,cg->getPackedToDecimalDoubleFixedSize(),srcRegSize+9,srcRegSize);
         }

      // TODO: examine the leftAlignedZeroDigits on the srcReg to see if  srcRegSize can be widened to the next 2,4,8 byte boundary so the load code below can be simplified
      bool enforceSSLimits = false;
      TR::MemoryReference *sourceMR = generateS390LeftAlignedMemoryReference(srcNode, srcStorageReference, cg, srcRegSize, enforceSSLimits);

      TR::RegisterDependencyConditions *deps = setupPackedDFPConversionGPRs(gpr64, gpr64Hi, gpr64Lo, isLongDouble, cg);
      if (isLongDouble)
         fprTargetReg = cg->allocateFPRegisterPair();
      else
         fprTargetReg = cg->allocateRegister(TR_FPR);

      int32_t partialSize = srcRegSize;
      TR::Register *gpr64Partial = gpr64Hi;
      if (isLongDouble)
         {
         if (srcRegSize > 8)
            partialSize -= 8;
         else
            gpr64Partial = gpr64Lo;
         }

      switch (partialSize)
         {
         case 1:
            generateRXYInstruction(cg, TR::InstOpCode::LLGC, srcNode, gpr64Partial, sourceMR);
            break;
         case 2:
            generateRXYInstruction(cg, TR::InstOpCode::LLGH, srcNode, gpr64Partial, sourceMR);
            break;
         case 3:
            generateRRInstruction(cg, TR::InstOpCode::XGR, srcNode, gpr64Partial, gpr64Partial);
            generateRSInstruction(cg, TR::InstOpCode::ICM, srcNode, gpr64Partial, (uint32_t) 0x7, sourceMR);
            break;
         case 4:
            generateRXYInstruction(cg, TR::InstOpCode::LLGF, srcNode, gpr64Partial, sourceMR);
            break;
         case 5:
         case 6:
         case 7:
            generateRRInstruction(cg, TR::InstOpCode::XGR, srcNode, gpr64Partial, gpr64Partial);
            generateRSYInstruction(cg, TR::InstOpCode::ICMH, node, gpr64Partial, (uint32_t)((1 << (partialSize-4)) - 1), sourceMR);  // 5->mask=1, 6->mask=3, 7->mask=7
            generateRXYInstruction(cg, TR::InstOpCode::L, srcNode, gpr64Partial, generateS390LeftAlignedMemoryReference(*sourceMR, srcNode, partialSize-4, cg, sourceMR->getLeftMostByte(), enforceSSLimits));
            break;
         case 8:
            generateRXYInstruction(cg, TR::InstOpCode::LG, srcNode, gpr64Partial, sourceMR);
            break;
         default:
            TR_ASSERT(false,"unexpected partialSize %d\n",partialSize);
         }

      if (isLongDouble)
         {
         if (srcRegSize > 8)
            generateRXYInstruction(cg, TR::InstOpCode::LG, srcNode, gpr64Lo, generateS390LeftAlignedMemoryReference(*sourceMR, srcNode, partialSize, cg, sourceMR->getLeftMostByte(), enforceSSLimits));
         else
            generateRRInstruction(cg, TR::InstOpCode::XGR, srcNode, gpr64Hi, gpr64Hi);
         }

      if (isForcedLongDouble &&
          srcReg->getDecimalPrecision() > TR::DataType::getMaxLongDFPPrecision())
         {
         // 9 bytes have been loaded from source and this many bytes can hold 16 or 17 digits
         // The NILL is to clear the 17th digit so the LDXTR generated later in de2dxHelperAndSetRegister
         // doesn't round incorrectly (there is no 'leftmost' truncation rounding mode for this instructions)
         // if the srcReg->getDecimalPrecision() == TR::DataType::getMaxLongDFPPrecision() (16) then the NILL is not needed.
         TR_ASSERT(srcRegSize == 9,"expecting srcRegSize == 9 and not %d on %s (%p) for the isForcedLongDouble case\n",
            srcRegSize,node->getOpCode().getName(),node);
         generateRIInstruction(cg, TR::InstOpCode::NILL, node, gpr64Hi, 0x000F);
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tgen NILL %s, 0x000F to clear out possible 17th digit from CXSTR in forced longDouble case\n",cg->getDebug()->getName(gpr64Hi));
         }

      generateRRInstruction(cg, isLongDouble ? TR::InstOpCode::CXSTR : TR::InstOpCode::CDSTR, node, fprTargetReg, gpr64, deps);

      // For a pre-arch(11) pd2ddAbs, need to force the positive sign separately from the conversion
      if (isAbs)
         generateRRInstruction(cg, TR::InstOpCode::LPDFR, node, isLongDouble ? fprTargetReg->getHighOrder() : fprTargetReg, isLongDouble ? fprTargetReg->getHighOrder() : fprTargetReg);

      if (isForcedLongDouble)
         fprTargetReg = de2dxHelperAndSetRegister(fprTargetReg, fprTargetReg, node, cg);

      cg->stopUsingRegister(gpr64);
      }

   if (node->getRegister() == NULL) // may already be set by de2ddHelperAndSetRegister
      node->setRegister(fprTargetReg);
   cg->decReferenceCount(srcNode);
   cg->traceBCDExit("pd2dd",node);

   return fprTargetReg;
   }

// mask at arch(10) is ---P
//                     0123
//
// mask at arch(11) is S-PF
//                     0123

#define TR_DFP_TO_PACKED_DEFAULT_MASK_ARCH10       (0x0) ///< Encode plus sign as 0xc
// RTC 93015: Using TypeReduction to treat all pdnegs as arith ops at ARCH(11) means that a tree with ipdstore -> pdneg -> pdX would get
// converted to ipdstore -> dd2pd -> ddneg -> ddX. Since the dd2pd could generate a CPDT that stores in place (rather than using a ZAP),
// this could mean that a ddneg producing a negative zero won't get cleaned; we'll use an LCDFR to flip the sign bit in DFP, then use a CPDT
// to write the final value. If we've decided to clean on the store, the clean isn't being generated, so we end up with a negative zero.
// The simplest solution is to *ALWAYS* clean the sign on the CPDT at ARCH(11), as there's no performance penalty in doing so.
#define TR_DFP_TO_PACKED_DEFAULT_MASK_ARCH11       (0x9) ///< Result has a sign field (S=1), encode plus sign as 0xc (P=0) and clean (F=1)
#define TR_DFP_TO_PACKED_UNSIGNED_ARCH10           (0x1) ///< P: encode plus sign as 0xc (P=0) or as 0xf (P=1).
#define TR_DFP_TO_PACKED_UNSIGNED_ARCH11           (0x2) ///< P: encode plus sign as 0xc (P=0) or as 0xf (P=1).
#define TR_DFP_TO_PACKED_CLEAN_ARCH11              (0x1) ///< F: force positive zero (F=1)

#define TR_MAX_DFP_PACKED_FAST_SIZE  (32) ///< these conversion instructions slow down when the actual length is > 32
#define TR_MAX_DFP_PACKED_SIZE       (34) ///< max actual length (<=34) these conversion instructions can handle

/**
 * Handles TR::df2pd,TR::dd2pd,TR::de2pd
 */
TR::Register *
J9::Z::TreeEvaluator::df2pdEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("df2pd",node);

   TR_ASSERT(node->getDecimalFraction() == 0,"frac should be 0 and not %d\n",node->getDecimalFraction());

   TR::Compilation *comp = cg->comp();

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"%s %p : resultPrec %d, resultSize %d\n",
         node->getOpCode().getName(),node,node->getDecimalPrecision(),node->getSize());

   bool isFloat      = node->getFirstChild()->getDataType() == TR::DecimalFloat;
   bool isDouble     = node->getFirstChild()->getDataType() == TR::DecimalDouble;
   bool isLongDouble = node->getFirstChild()->getDataType() == TR::DecimalLongDouble;

   TR_ASSERT(isFloat || isDouble || isLongDouble,  "conversion should be short, long or extended\n");

   bool isSetSign = node->isSetSignValueOnNode();
   bool signIsPreferred = true;
   bool isSignNegative = false;


   // Set up the masks for arch(10) and arch(11)
   uint8_t mask = TR_DFP_TO_PACKED_DEFAULT_MASK_ARCH10;
   uint8_t setUnsigned = TR_DFP_TO_PACKED_UNSIGNED_ARCH10;
   int32_t setSignValue = TR::DataType::getInvalidSignCode();

   if (cg->supportsFastPackedDFPConversions())
      {
      mask = TR_DFP_TO_PACKED_DEFAULT_MASK_ARCH11;
      setUnsigned = TR_DFP_TO_PACKED_UNSIGNED_ARCH11;
      }

   if (isSetSign)
      {
      TR_RawBCDSignCode sign = node->getSetSign();
      if (sign == raw_bcd_sign_0xf)
         {
         mask |= setUnsigned;
         setSignValue = TR::DataType::getUnsignedCode();
         signIsPreferred = false;
         if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tsetSign 0xf: set mask to 0x%x\n",mask);
         TR_ASSERT(TR::DataType::getUnsignedCode() == 0xf,"expecting unsigned code to be 0xf and not 0x%x for node %s (%p)\n",
                   TR::DataType::getUnsignedCode(),node->getOpCode().getName(),node);
         }
      else if (sign == raw_bcd_sign_0xc)
         {
         setSignValue = TR::DataType::getPreferredPlusCode();
         if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tsetSign 0xc: leave mask at 0x%x\n",mask);
         TR_ASSERT(TR::DataType::getPreferredPlusCode() == 0xc,"expecting preferred plus code to be 0xc and not 0x%x for node %s (%p)\n",
                 TR::DataType::getPreferredPlusCode(),node->getOpCode().getName(),node);
         }
      else if (sign == raw_bcd_sign_0xd)
         {
         setSignValue = TR::DataType::getPreferredMinusCode();
         isSignNegative = true;
         if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tsetSign 0xd: leave mask at 0x%x\n",mask);
         TR_ASSERT(TR::DataType::getPreferredMinusCode() == 0xd,"expecting preferred minus code to be 0xd and not 0x%x for node %s (%p)\n",
                 TR::DataType::getPreferredMinusCode(),node->getOpCode().getName(),node);
         }
      else
         {
         TR_ASSERT(false,"unsupported sign %d for %s (%p)\n",sign,node->getOpCode().getName(),node);
         }
      }

   int32_t maxBytesFromConv = 0;    // how many digits CSDTR/CSXTR can at most produce
   int32_t maxDigitsInSrc = 0;   // how many signif digits are possible from source dfp
   if (isFloat)
      {
      maxBytesFromConv = cg->getDecimalFloatToPackedFixedSize();  // CSDTR produces 15 digits == 8 bytes; CPDT produces 16 digits == 9 bytes
      maxDigitsInSrc = std::min(node->getSourcePrecision(), TR::DataType::getMaxShortDFPPrecision());    // TR::DataType::getMaxShortDFPPrecision() == 7 digits == 4 bytes
      }
   else if (isDouble)
      {
      maxBytesFromConv = cg->getDecimalDoubleToPackedFixedSize(); // CSDTR produces 15 digits == 8 bytes; CPDT produces 16 digits == 9 bytes
      maxDigitsInSrc = std::min(node->getSourcePrecision(), TR::DataType::getMaxLongDFPPrecision());     // TR::DataType::getMaxLongDFPPrecision() == 16 digits == 9 bytes
      }
   else if (isLongDouble)
      {
      maxBytesFromConv = cg->getDecimalLongDoubleToPackedFixedSize();  // CSXTR produces 31 digits == 16 bytes; CPXT produces 34 digits == 18 bytes
      maxDigitsInSrc = std::min(node->getSourcePrecision(), TR::DataType::getMaxExtendedDFPPrecision()); // TR::DataType::getMaxExtendedDFPPrecision() == 34 digits == 18 bytes
      }
   else
      {
      TR_ASSERT(false, "expecting conversion to be short, long or extended\n");
      }

   TR::Node *srcNode = node->getFirstChild();
   TR::Register *srcFPReg = cg->evaluate(srcNode);
   TR::Register *srcFPRegTemp = NULL;

   bool usesFPRegPair = false;
   bool releaseTempReg = false;

   // Allocate temporary registers for load positive/load negative and/or loading a larger size
   bool canClobber = cg->canClobberNodesRegister(srcNode);
   if (isLongDouble && isSetSign)
      {
      usesFPRegPair = true;
      if (canClobber)
         {
         srcFPRegTemp = srcFPReg;
         }
      else
         {
         srcFPRegTemp = cg->allocateFPRegisterPair();
         releaseTempReg = true;
         }
      }
   else if (isDouble && node->getSize() > maxBytesFromConv)
      {
      // Lengthening; will always need to allocate a register pair
      usesFPRegPair = true;
      releaseTempReg = true;
      srcFPRegTemp = cg->allocateFPRegisterPair();
      }
   else if (isDouble && isSetSign)
      {
      if (canClobber)
         {
         srcFPRegTemp = srcFPReg;
         releaseTempReg = true;
         }
      else
         {
         srcFPRegTemp = cg->allocateRegister(TR_FPR);
         releaseTempReg = true;
         }
      }
   else if (isFloat)
      {
      // Lengthening; will always need to allocate a register
      srcFPRegTemp = cg->allocateRegister(TR_FPR);
      releaseTempReg = true;
      }

   // Lengthen float values before load positive/load negative; those need double-size values
   if (isFloat)
      {
      generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, srcFPRegTemp, srcFPReg, 0, false); // m4=0
      srcFPReg = srcFPRegTemp;
      isFloat = false;
      isDouble = true;
      maxBytesFromConv = cg->getDecimalDoubleToPackedFixedSize();
      }

   if (isSetSign)
      {
      // Generate a load positive or load negative
      TR::InstOpCode::Mnemonic opCode  = TR::InstOpCode::LPDFR;
      if (isSignNegative)
         opCode = TR::InstOpCode::LNDFR;

      if (isLongDouble) // Existing node was long double; lengthening from double to long double is performed later
         {
         generateRRInstruction(cg, opCode, node, srcFPRegTemp->getHighOrder(), srcFPReg->getHighOrder());

         // Only load the lower half if we're not clobbering
         if (!canClobber)
            generateRRInstruction(cg, TR::InstOpCode::LDR, node, srcFPRegTemp->getLowOrder(), srcFPReg->getLowOrder());
         }
      else if (isDouble && usesFPRegPair)
         {
         // Double that will be lengthened; load into the lower half, and lengthen from lower half to full pair later
         generateRRInstruction(cg, opCode, node, srcFPRegTemp->getLowOrder(), srcFPReg);
         }
      else
         {
         generateRRInstruction(cg, opCode, node, srcFPRegTemp, srcFPReg);
         }

      srcFPReg = srcFPRegTemp;
      }

   // If we need to lengthen double values, do so after the load positive/load negative, to avoid
   // generating the LDR unnecessarily
   if (isDouble && node->getSize() > maxBytesFromConv)
      {
      if (isSetSign)
         generateRRFInstruction(cg, TR::InstOpCode::LXDTR, node, srcFPRegTemp, srcFPReg->getLowOrder(), 0, false); // m4=0
      else
         generateRRFInstruction(cg, TR::InstOpCode::LXDTR, node, srcFPRegTemp, srcFPReg, 0, false); // m4=0
      srcFPReg = srcFPRegTemp;
      isDouble = false;
      isLongDouble = true;
      maxBytesFromConv = cg->getDecimalLongDoubleToPackedFixedSize();
      }

   if (releaseTempReg)
      cg->stopUsingRegister(srcFPRegTemp);

   int32_t maxDigitsFromConv = TR::DataType::byteLengthToPackedDecimalPrecisionCeiling(maxBytesFromConv);

   TR_ASSERT(isDouble || isLongDouble,"only long and extended types should now remain\n");


   if (cg->supportsFastPackedDFPConversions())
      {
      TR_PseudoRegister *targetReg = cg->allocatePseudoRegister(node->getDataType());
      TR_StorageReference *hint = node->getStorageReferenceHint();
      TR_StorageReference *targetStorageReference = NULL;
      int32_t memSize = 0; // Amount of memory allocated for the destination value
      int32_t regSize = maxBytesFromConv; // Minimal amount of memory needed to hold the converted value
      targetReg->setDecimalPrecision(node->getDecimalPrecision());

      if (node->hasSourcePrecision() && node->getSourcePrecision() <= TR::DataType::getMaxExtendedDFPPrecision())
         {
         // CPDT can be used to truncate, but it will cause an overflow error if it does. If overflow
         // is suppressed, as it is on COBOL, we can use the lower precision anyway; otherwise we need
         // to store the zoned value in a temp and use MVC to truncate.

         memSize = std::max(targetReg->getSize(), TR::DataType::packedDecimalPrecisionToByteLength(node->getSourcePrecision()));
         }
      else
         {
         // If source precision is unknown, assume the maximum possible value to avoid overflow errors
         if (isFloat || isDouble)
            memSize = TR::DataType::packedDecimalPrecisionToByteLength(TR::DataType::getMaxLongDFPPrecision());
         else
            memSize = TR::DataType::packedDecimalPrecisionToByteLength(TR::DataType::getMaxExtendedDFPPrecision());
         }

      if (hint)
         {
         // If there is no truncation, use the hint size to possibly widen here for free, rather than on a store.
         // If there is a truncation, we can't use the hint size without producing an incorrect result.
         // pdstore p=8      pdstore p = 8   pdstore p=4
         //   dd2pd p=7        dd2pd p = 4     dd2pd p=5
         //     ddX p=7          ddX p = 7       ddX p=7
         // For case 1, using the hint size is good. For case 2, it's incorrect, as we'd lose the truncation to 4 digits.
         // In case 3, using the hint size is fine, but there shouldn't be a hint generated since the p=5 dd2pd result can't fit
         // in the p=4 pdstore field
         if (node->hasSourcePrecision() && !node->isTruncating())
            {
            // Don't widen if doing so would require a conversion from double to long double
            if (!isDouble || (hint->getSymbolSize() <= TR::DataType::packedDecimalPrecisionToByteLength(TR::DataType::getMaxLongDFPPrecision())))
                {
               // Widen up to 32 digits (33 and 34 are slower)
               if (regSize <= TR::DataType::packedDecimalPrecisionToByteLength(TR_MAX_DFP_PACKED_FAST_SIZE) && hint->getSymbolSize() >= TR::DataType::packedDecimalPrecisionToByteLength(TR_MAX_DFP_PACKED_FAST_SIZE))
                  regSize = TR::DataType::packedDecimalPrecisionToByteLength(TR_MAX_DFP_PACKED_FAST_SIZE);
               else
                  regSize = hint->getSymbolSize(); // Widen up to the symbol size

               // Enlarge the memory required if it's now smaller than the precision we'll set on the target register
               if (regSize > memSize)
                  memSize = regSize;
               if (cg->traceBCDCodeGen())
                  traceMsg(comp,"\tset memSize = %d and regSize = %d based on hint #%d\n",memSize,regSize,hint->getReferenceNumber());
                }
            }
         targetStorageReference = hint;
         }
      else
         {
         targetStorageReference = TR_StorageReference::createTemporaryBasedStorageReference(memSize, comp);
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tset memSize = %d based on node size\n",memSize);
         }

      // regardless of how the memSize and targetPrec were set up earlier ensure they do not exceed the limits for the CPDT or CPXT instructions
      // and assert below if these max instruction settings are >= the max # of significant digits that can be represented for each DFP type
      int32_t maxConvertedPrecision = 0;
      if (isFloat)
         {
         TR_ASSERT(TR_DECIMAL_FLOAT_TO_PACKED_PRECISION_ARCH11 >= TR::DataType::getMaxShortDFPPrecision(),"CPDT max %d must be >= DFP short max %d\n",
            TR_DECIMAL_FLOAT_TO_PACKED_PRECISION_ARCH11, TR::DataType::getMaxShortDFPPrecision());
         memSize = std::min(memSize, TR_DECIMAL_FLOAT_TO_PACKED_SIZE_ARCH11);   // cannot get more than 9 bytes (16 digits) from the DFP source (and larger encodings are illegal)
         maxConvertedPrecision = TR_DECIMAL_FLOAT_TO_PACKED_PRECISION_ARCH11;
         }
      else if (isDouble)
         {
         TR_ASSERT(TR_DECIMAL_DOUBLE_TO_PACKED_PRECISION_ARCH11 >= TR::DataType::getMaxLongDFPPrecision(),"CPDT max %d must be >= DFP long max %d\n",
            TR_DECIMAL_DOUBLE_TO_PACKED_PRECISION_ARCH11, TR::DataType::getMaxLongDFPPrecision());
         memSize = std::min(memSize, TR_DECIMAL_DOUBLE_TO_PACKED_SIZE_ARCH11);   // cannot get more than 9 bytes (16 digits) from the DFP source (and larger encodings are illegal)
         maxConvertedPrecision = TR_DECIMAL_DOUBLE_TO_PACKED_PRECISION_ARCH11;
         }
      else
         {
         TR_ASSERT(TR_DECIMAL_LONG_DOUBLE_TO_PACKED_PRECISION_ARCH11 >= TR::DataType::getMaxExtendedDFPPrecision(),"CPXT max %d must be >= DFP long double max %d\n",
            TR_DECIMAL_LONG_DOUBLE_TO_PACKED_PRECISION_ARCH11, TR::DataType::getMaxExtendedDFPPrecision());
         memSize = std::min(memSize, TR_DECIMAL_LONG_DOUBLE_TO_PACKED_SIZE_ARCH11);   // cannot get more than 18 bytes (34 digits) from the DFP source (and larger encodings are illegal)
         maxConvertedPrecision = TR_DECIMAL_LONG_DOUBLE_TO_PACKED_PRECISION_ARCH11;
         }

      if (targetReg->getDecimalPrecision() > maxConvertedPrecision)
         {
         // since the finalPrecision is the max # of digits possibly converted then cannot set a higher targetPrec as these upper digits would be uninitialized
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\ttargetRegPrec %d > maxConvertedPrecision %d : reduce targetPrec to %d\n",targetReg->getDecimalPrecision(),maxConvertedPrecision,maxConvertedPrecision);
         targetReg->setDecimalPrecision(maxConvertedPrecision);
         }

      targetReg->setStorageReference(targetStorageReference, node);

      bool enforceSSLimits = true;  // RSL has same limits as SS (no index and 12 bit displacment)
      TR::MemoryReference *destMR = generateS390LeftAlignedMemoryReference(node, targetStorageReference, cg, memSize, enforceSSLimits);

      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tgenerate DFP to packed %s (%p) with op=%s and target packed size %d, mask 0x%x (signIsPreferred %s)\n",
                 node->getOpCode().getName(),node,isLongDouble ? "TR::InstOpCode::CPXT" : "TR::InstOpCode::CPDT",memSize,mask,signIsPreferred?"yes":"no");

      generateRSLbInstruction(cg, isLongDouble ? TR::InstOpCode::CPXT : TR::InstOpCode::CPDT, node, srcFPReg, memSize-1, destMR, mask);

      bool evenDigitNeedsClearing = !node->canSkipPadByteClearing() && isEven(node->getDecimalPrecision()) && node->isTruncating();
      // Clear the top nibble if we're truncating and have an even precision
      if (evenDigitNeedsClearing)
         generateSIInstruction(cg, TR::InstOpCode::NI, node, destMR = generateS390LeftAlignedMemoryReference(*destMR, node, 0, cg, memSize, enforceSSLimits), 0x0F);

      if (isSetSign)
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tisSetSign = true : set setKnownSignCode to 0x%x on %s\n",setSignValue,cg->getDebug()->getName(targetReg));
         targetReg->setKnownSignCode(setSignValue);
         }
      else
         {
         if (srcNode->isNonNegative())
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tsrcNode %s (%p) isNonNegative = true : set setKnownSignCode to 0x%x on %s\n",
                  srcNode->getOpCode().getName(), srcNode, TR::DataType::getPreferredPlusCode(), cg->getDebug()->getName(targetReg));
            targetReg->setKnownSignCode(TR::DataType::getPreferredPlusCode());
            }
         else if (!evenDigitNeedsClearing)
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tisClean op = true (always clean when using %s) : setHasKnownCleanSign on %s\n",isLongDouble ? "TR::InstOpCode::CPXT" : "TR::InstOpCode::CPDT",cg->getDebug()->getName(targetReg));
            targetReg->setHasKnownCleanSign();
            }
         else if (signIsPreferred)
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tsignIsPreferred = true : setHasKnownPreferredSign on %s\n",cg->getDebug()->getName(targetReg));
            targetReg->setHasKnownPreferredSign();
            }
         }

      if (cg->traceBCDCodeGen())
         {
         traceMsg(comp,"\ttargetReg %s signState : cleanSign=%s, preferredSign=%s, knownSign=%s (0x%x)\n",
                 cg->getDebug()->getName(targetReg),
                 targetReg->hasKnownCleanSign() ? "yes" : "no", targetReg->hasKnownPreferredSign() ? "yes" : "no",
                 targetReg->hasKnownSignCode() ? "yes" : "no", targetReg->hasKnownSignCode() ? targetReg->getKnownSignCode() : TR::DataType::getInvalidSignCode());
         }

      targetReg->setIsInitialized();
      targetReg->setHasKnownValidSignAndData();

      node->setRegister(targetReg);
      cg->decReferenceCount(srcNode);
      cg->traceBCDExit("df2pd",node);

      return targetReg;
      }
   else
      {
      TR::Register *gpr64 = NULL;
      TR::Register *gpr64Hi = NULL;
      TR::Register *gpr64Lo = NULL;

      TR::RegisterDependencyConditions *deps = setupPackedDFPConversionGPRs(gpr64, gpr64Hi, gpr64Lo, isLongDouble, cg);

      TR_PseudoRegister *targetReg = cg->allocatePseudoRegister(node->getDataType());

      bool isTruncation = maxDigitsInSrc > node->getDecimalPrecision();
      int32_t targetPrec = std::min<int32_t>(maxDigitsInSrc, node->getDecimalPrecision());
      targetReg->setDecimalPrecision(targetPrec);

      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tset targetRegPrec to min(maxDigitsInSrc,nodePrec) = min(%d,%d) = %d (isTrunc = %s)\n",maxDigitsInSrc,node->getDecimalPrecision(),targetPrec,isTruncation?"yes":"no");

      TR_StorageReference *hint = node->getStorageReferenceHint();
      TR_StorageReference *targetStorageReference = NULL;
      if (hint)
         targetStorageReference = hint;
      else
         targetStorageReference = TR_StorageReference::createTemporaryBasedStorageReference(targetReg->getSize(), comp);
      targetReg->setStorageReference(targetStorageReference, node);

      bool enforceSSLimits = false; // RX/RS form inst are being used so Y-form is available for these
      TR::MemoryReference *destMR = generateS390LeftAlignedMemoryReference(node, targetStorageReference, cg, targetReg->getSize(), enforceSSLimits);

      int32_t remainingTargetDigits = targetPrec;
      if (targetPrec > maxDigitsFromConv)
         {
         int32_t highDigits = targetPrec - maxDigitsFromConv;
         remainingTargetDigits -= highDigits;
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\ttargetPrec %d > maxDigitsFromConv %d : first convert high %d digit(s)\n",targetPrec,maxDigitsFromConv,targetPrec-maxDigitsFromConv);
         // float cases have max targetPrec of 7 and a min maxDigitsFromConv of 15 so can never reach here
         // double case have max targetPrec of 16 and a maxDigitsFromConv of 15 (but only when targetPrec is <=15) or a maxDigitsFromConv of 31 when up-converted to longDouble
         TR_ASSERT(isLongDouble, "only longDouble cases require extra conversion on node %s (%p)\n",node->getOpCode().getName(),node);
         TR::Register *srcFPRegTemp = cg->allocateFPRegisterPair();
         TR::MemoryReference *shiftRef = generateS390MemoryReference(maxDigitsFromConv, cg);
         generateRXFInstruction(cg, TR::InstOpCode::SRXT, node, srcFPRegTemp, srcFPReg, shiftRef);  // shift away low digits
         generateRRInstruction(cg, TR::InstOpCode::CSXTR, node, gpr64, srcFPRegTemp, deps);         // convert high digits to packed
         generateRSInstruction(cg, TR::InstOpCode::SRL, node, gpr64Lo, gpr64Lo, 4);                 // get rid of packed sign code
         cg->stopUsingRegister(srcFPRegTemp);
         int32_t offsetBump = 0;
         switch (highDigits)
            {
            case 1:
            case 2:
               generateRXInstruction(cg, TR::InstOpCode::STC, node, gpr64Lo, destMR);
               offsetBump = 1;
               break;
            case 3:
               generateRXInstruction(cg, TR::InstOpCode::STH, node, gpr64Lo, destMR);
               offsetBump = 2;
               break;
            default:
               TR_ASSERT(false, "unexpected highDigits %d on node %s (%p)\n",highDigits,node->getOpCode().getName(),node);
            }
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tadd offsetBump = %d to destMR\n",offsetBump);
         destMR = generateS390LeftAlignedMemoryReference(*destMR, node, offsetBump, cg, targetReg->getSize());
         }

      TR::InstOpCode::Mnemonic convOp = isDouble ? TR::InstOpCode::CSDTR : TR::InstOpCode::CSXTR;
      generateRRFInstruction(cg, convOp, node, gpr64, srcFPReg, mask, false, deps);

      int32_t remainingTargetBytes = TR::DataType::packedDecimalPrecisionToByteLength(remainingTargetDigits);
      int32_t partialSize = std::min(maxBytesFromConv, remainingTargetBytes);
      TR::Register *gpr64Partial = gpr64Hi;
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tpartialSize = min(maxBytesFromConv, remainingTargetBytes) = min(%d, %d) = %d\n",maxBytesFromConv,remainingTargetBytes,partialSize);
      if (isLongDouble)
         {
         if (partialSize > 8)
            {
            partialSize -= 8;
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tisExt=true and partialSize %d > 8 so reduce partialSize by 8 to %d\n",partialSize+8,partialSize);
            }
         else
            {
            gpr64Partial = gpr64Lo;
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tisExt=true and partialSize %d <= 8 so store from the low gpr64 only\n",partialSize);
            }
         }

      bool needsClear = false;
      if (!node->canSkipPadByteClearing() && isEven(remainingTargetDigits) && isTruncation)
         {
         needsClear = true;
         TR::InstOpCode::Mnemonic clearOp = TR::InstOpCode::BAD;
         int32_t mask = 0;
         switch (partialSize)
            {
            case 1:
               TR_ASSERT(remainingTargetBytes > 1,"an even precision %d size 1 register is not valid\n",remainingTargetDigits);
               clearOp = TR::InstOpCode::NILL;
               mask = 0x000F;
               break;
            case 2:  // prec=2
               clearOp = TR::InstOpCode::NILL;
               mask = 0x0FFF;
               break;
            case 3:  // prec=4
               clearOp = TR::InstOpCode::NILH;
               mask = 0x000F;
               break;
            case 4:  // prec=6
               clearOp = TR::InstOpCode::NILH;
               mask = 0x0FFF;
               break;
            case 5:  // prec=8
               clearOp = TR::InstOpCode::NIHL;
               mask = 0x000F;
               break;
            case 6:  // prec=10
               clearOp = TR::InstOpCode::NIHL;
               mask = 0x0FFF;
               break;
            case 7:  // prec=12
               clearOp = TR::InstOpCode::NIHH;
               mask = 0x000F;
               break;
            case 8:  // prec=14
               clearOp = TR::InstOpCode::NIHH;
               mask = 0x0FFF;
               break;
            default:
               break;
               // will just use an NI clear in packed in this case
            }
         if (clearOp != TR::InstOpCode::BAD)
            {
            needsClear = false;
            generateRIInstruction(cg, clearOp, node, gpr64Partial, mask);
            if (cg->traceBCDCodeGen()) traceMsg(comp,"\tisTruncation=true and remainingTargetDigits isEven (%d) so perform regBased clear of top nibble with NIxx\n",remainingTargetDigits);
            }
         }

      switch (partialSize)
         {
         case 1:
            generateRXInstruction(cg, TR::InstOpCode::STC, node, gpr64Partial, destMR);
            break;
         case 2:
            generateRXInstruction(cg, TR::InstOpCode::STH, node, gpr64Partial, destMR);
            break;
         case 3:
            generateRSInstruction(cg, TR::InstOpCode::STCM, node, gpr64Partial, (uint32_t)0x7, destMR);
            break;
         case 4:
            generateRXInstruction(cg, TR::InstOpCode::ST, node, gpr64Partial, destMR);
            break;
         case 5:
         case 6:
         case 7:
            generateRSYInstruction(cg, TR::InstOpCode::STCMH, node, gpr64Partial, (uint32_t)((1 << (partialSize-4)) - 1), destMR);
            generateRXInstruction(cg, TR::InstOpCode::ST, node, gpr64Partial, generateS390LeftAlignedMemoryReference(*destMR, node, partialSize-4, cg, destMR->getLeftMostByte(), enforceSSLimits));
            break;
         case 8:
            generateRXInstruction(cg, TR::InstOpCode::STG, node, gpr64Partial, destMR);
            break;
         default:
            TR_ASSERT(false,"unexpected partialSize %d\n", partialSize);
         }

      if (isLongDouble && remainingTargetBytes > 8)
         generateRXYInstruction(cg, TR::InstOpCode::STG, node, gpr64Lo, generateS390LeftAlignedMemoryReference(*destMR, node, partialSize, cg, destMR->getLeftMostByte(), enforceSSLimits));

      if (deps)
         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, TR::LabelSymbol::create(cg->trHeapMemory(),cg), deps);

      if (needsClear)
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tisTruncation=true and targetReg->isEvenPrec (%d) so perform memBased clear of top nibble with NI\n",targetReg->getDecimalPrecision());
         cg->genZeroLeftMostPackedDigits(node, targetReg, remainingTargetBytes, 1, destMR);
         }

      targetReg->setIsInitialized();
      targetReg->setHasKnownValidSignAndData();

      if (isSetSign)
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tisSetSign = true : set setKnownSignCode to 0x%x on %s\n",setSignValue,cg->getDebug()->getName(targetReg));
         targetReg->setKnownSignCode(setSignValue);
         }
      else
         {
         if (srcNode->isNonNegative())
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tsrcNode %s (%p) isNonNegative = true : set setKnownSignCode to 0x%x on %s\n",
                  srcNode->getOpCode().getName(), srcNode, TR::DataType::getPreferredPlusCode(), cg->getDebug()->getName(targetReg));
            targetReg->setKnownSignCode(TR::DataType::getPreferredPlusCode());
            }
         else if (node->hasKnownCleanSign()) // perhaps a ddclean/declean has been inserted below in IL
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\t%s (%p) hasKnownCleanSign() = true : setHasKnownCleanSign on %s\n",node->getOpCode().getName(),node,cg->getDebug()->getName(targetReg));
            targetReg->setHasKnownCleanSign();
            }
         else if (!isTruncation &&
                  srcNode->getOpCode().isSub() &&
                  srcNode->getFirstChild()->isNonNegative() &&
                  srcNode->getSecondChild()->isNonNegative())
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\t%s (%p) srcNode %s (%p) has two nonNegative children : setHasKnownCleanSign on %s\n",
                  node->getOpCode().getName(),node,
                  srcNode->getOpCode().getName(),srcNode,
                  cg->getDebug()->getName(targetReg));
            targetReg->setHasKnownCleanSign();
            }
         else if (signIsPreferred)
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tsignIsPreferred = true : setHasKnownPreferredSign to 0x%x on %s\n",cg->getDebug()->getName(targetReg));
            targetReg->setHasKnownPreferredSign();
            }
         }

      if (cg->traceBCDCodeGen())
         {
         traceMsg(comp,"\ttargetReg %s signState : cleanSign=%s, preferredSign=%s, knownSign=%s (0x%x)\n",
                 cg->getDebug()->getName(targetReg),
                 targetReg->hasKnownCleanSign() ? "yes" : "no", targetReg->hasKnownPreferredSign() ? "yes" : "no",
                 targetReg->hasKnownSignCode() ? "yes" : "no", targetReg->hasKnownSignCode() ? targetReg->getKnownSignCode() : TR::DataType::getInvalidSignCode());
         }

      cg->stopUsingRegister(gpr64);
      node->setRegister(targetReg);
      cg->decReferenceCount(srcNode);
      cg->traceBCDExit("df2pd",node);
      return targetReg;
      }
   }

inline TR::Register *
dfp2fpHelper(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * srcReg = cg->evaluate(firstChild);

   TR::DataType srcType = firstChild -> getDataType();
   TR::DataType tgtType = node -> getDataType();

   TR::Register *r0Reg = cg->allocateRegister();
   TR::Register *r1Reg = cg->allocateRegister();
   TR::RegisterDependencyConditions * deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(3, 6, cg);
   deps->addPreCondition(r0Reg, TR::RealRegister::GPR0);
   deps->addPostCondition(r0Reg, TR::RealRegister::GPR0);
   deps->addPostCondition(r1Reg, TR::RealRegister::GPR1);

   TR::Register * srcCopy;
   TR::Register * lowSrcReg;
   TR::Register * highSrcReg;
   if (srcType == TR::DecimalLongDouble)
      {
      lowSrcReg = cg->allocateRegister(TR_FPR);
      highSrcReg = cg->allocateRegister(TR_FPR);
      deps->addPreCondition(highSrcReg, TR::RealRegister::FPR4);
      deps->addPostCondition(highSrcReg, TR::RealRegister::FPR4);
      deps->addPreCondition(lowSrcReg, TR::RealRegister::FPR6);
      deps->addPostCondition(lowSrcReg, TR::RealRegister::FPR6);
      srcCopy = cg->allocateFPRegisterPair(lowSrcReg, highSrcReg);
      }
   else
      {
      srcCopy = cg->allocateRegister(TR_FPR);
      deps->addPreCondition(srcCopy, TR::RealRegister::FPR4);
      deps->addPostCondition(srcCopy, TR::RealRegister::FPR4);
      }

   TR::InstOpCode::Mnemonic loadOp;
   if (srcType == TR::Float || srcType == TR::DecimalFloat)
      loadOp = TR::InstOpCode::LER;
   else if (srcType == TR::Double || srcType == TR::DecimalDouble)
      loadOp = TR::InstOpCode::LDR;
   else // must be long double
      loadOp = TR::InstOpCode::LXR;

   generateRRInstruction(cg, loadOp, node, srcCopy, srcReg);

   TR::Register * tgtCopy;
   TR::Register * lowTgtCopy;
   TR::Register * highTgtCopy;
   if (tgtType == TR::DecimalLongDouble)
      {
      lowTgtCopy = cg->allocateRegister(TR_FPR);
      highTgtCopy = cg->allocateRegister(TR_FPR);
      deps->addPostCondition(highTgtCopy, TR::RealRegister::FPR0);
      deps->addPostCondition(lowTgtCopy, TR::RealRegister::FPR2);
      tgtCopy = cg->allocateFPRegisterPair(lowTgtCopy, highTgtCopy);
      }
   else
      {
      tgtCopy = cg->allocateRegister(TR_FPR);
      deps->addPostCondition(tgtCopy, TR::RealRegister::FPR0);
      }

   // The conversion operation is specified by the function code in general register 0
   // condition code is set to indicate the result. When there are no exceptional
   // conditions, condition code 0 is set. When an IEEE nontrap exception is recognized, condition
   // code 1 is set. When an IEEE trap exception with alternate action is recognized, condition code 2
   // is set. A 32-bit return code is placed in bits 32-63 of general register 1; bits 0-31 of
   // general register 1 remain unchanged.

   // For the PFPO-convert-floatingpoint-radix operation, the second operand is converted
   // to the format of the first operand and placed at the first-operand location, a return code is placed in
   // bits 32-63 of general register 1, and the condition code is set to indicate whether an exceptional condition
   // was recognized.  The first and second operands are in implicit floatingpoint registers. The first operand
   // is in FPR0 (paired with FPR2 for extended). The second operand is in FPR4 (paired with FPR6 for extended).
/*******************************************************
     bit 32: test bit
               0 -- operation is performed based on bit 33-63 (must be valid values);
               1 -- operation is not performed, but set condition code, but, instead, the
                    condition code is set to indicate whether these bits specify a valid and installed function;
      bits 33-39:   specify the operation type. Only one operation type is currently defined: 01, hex,
                    is PFPO Convert Floating-Point Radix.
      bits 40-47:   PFPO-operand-format code for operand 1
      bits 48-55:   PFPO-operand-format code for operand 2
      bits 56:      Inexact-suppression control
      bits 57:      Alternate-exception-action control
      bits 58-59:   Target-radix-dependent controls
      bits 60-63:   PFPO rounding method
**********************************************************/
   int32_t funcCode = 0x01 << 24;   // perform radix convertion
   int32_t srcTypeCode, tgtTypeCode;
   switch (tgtType)
      {
      case TR::DecimalFloat:
         tgtTypeCode = 0x8;
         break;
      case TR::DecimalDouble:
         tgtTypeCode = 0x9;
         break;
      case TR::DecimalLongDouble:
         tgtTypeCode = 0xA;
         break;
      case TR::Float:
         tgtTypeCode = 0x5;
         break;
      case TR::Double:
         tgtTypeCode = 0x6;
         break;
      default:
         TR_ASSERT( 0, "Error: unsupported target data type for PFPO");
         break;
      }
   funcCode |= tgtTypeCode << 16;

   switch (srcType)
      {
      case TR::DecimalFloat:
         srcTypeCode = 0x8;
         break;
      case TR::DecimalDouble:
         srcTypeCode = 0x9;
         break;
      case TR::DecimalLongDouble:
         srcTypeCode = 0xA;
         break;
      case TR::Float:
         srcTypeCode = 0x5;
         break;
      case TR::Double:
         srcTypeCode = 0x6;
         break;
      default:
         TR_ASSERT( 0, "Error: unsupported src data type for PFPO");
         break;
      }

   funcCode |= srcTypeCode << 8;


   generateRILInstruction(cg, TR::InstOpCode::IILF, node, r0Reg, funcCode);

   generateS390EInstruction(cg, TR::InstOpCode::PFPO, node, tgtCopy, r1Reg, srcCopy, r0Reg, deps);

   cg->stopUsingRegister(r0Reg);
   cg->stopUsingRegister(r1Reg);
   cg->stopUsingRegister(srcCopy);
   cg->decReferenceCount(firstChild);
   node->setRegister(tgtCopy);
   return tgtCopy;
   }

TR::Register *
J9::Z::TreeEvaluator::df2fEvaluator( TR::Node * node, TR::CodeGenerator * cg)
   {
   return dfp2fpHelper(node, cg);
   }

TR::Register *
J9::Z::TreeEvaluator::f2dfEvaluator( TR::Node * node, TR::CodeGenerator * cg)
   {
   return dfp2fpHelper(node, cg);
   }

/**
 * Convert Decimal float/Double/LongDouble to signed long int in 32 bit mode;
 */
inline TR::Register *
dfp2l(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * srcReg = cg->evaluate(firstChild);
   TR::Register * targetReg;
   TR::Register * tempDDReg;
   TR::Register * evenReg = cg->allocateRegister();
   TR::Register * oddReg = cg->allocateRegister();
   targetReg = cg->allocateConsecutiveRegisterPair(oddReg, evenReg);

   TR::InstOpCode::Mnemonic convertOpCode;
   switch (firstChild->getDataType())
      {
      case TR::DecimalFloat:
         convertOpCode = TR::InstOpCode::CGDTR;
         tempDDReg = cg->allocateRegister(TR_FPR);
         break;
      case TR::DecimalDouble:
         convertOpCode = TR::InstOpCode::CGDTR;
         tempDDReg = srcReg;
         break;
      case TR::DecimalLongDouble:
         convertOpCode = TR::InstOpCode::CGXTR;
         tempDDReg = srcReg;
         break;
      default:
         TR_ASSERT( 0, "dfpToLong: unsupported opcode\n");
         break;
      }

   // Float to double
    if (firstChild->getDataType() == TR::DecimalFloat)
        generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, tempDDReg, srcReg, 0, false);

   TR::RegisterDependencyConditions * deps = NULL;
   deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 1, cg);
   TR::Register * tempReg = cg->allocate64bitRegister();
   deps->addPostCondition(tempReg, TR::RealRegister::GPR0);

   generateRRFInstruction(cg, convertOpCode, node, tempReg, tempDDReg, 0x9, true);

   generateRRInstruction(cg, TR::InstOpCode::LR, node, targetReg->getLowOrder(), tempReg);
   generateRSInstruction(cg, TR::InstOpCode::SRLG, node, tempReg, tempReg, 32);
   generateRRInstruction(cg, TR::InstOpCode::LR, node, targetReg->getHighOrder(), tempReg);

   cg->decReferenceCount(firstChild);
   cg->stopUsingRegister(tempReg);
   if (firstChild->getDataType() == TR::DecimalFloat)
     cg->stopUsingRegister(tempDDReg);

   node->setRegister(targetReg);
   return targetReg;

   }

/**
 * Convert Decimal float/Double/LongDouble to signed long int in 64 bit mode;
 */
inline TR::Register *
dfp2l64(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * srcReg = cg->evaluate(firstChild);
   TR::Register * tempDDReg = NULL;
   TR::Register * targetReg = cg->allocate64bitRegister();

   TR::InstOpCode::Mnemonic convertOpCode;
   switch (firstChild->getDataType())
      {
      case TR::DecimalFloat:
         convertOpCode = TR::InstOpCode::CGDTR;
         tempDDReg = cg->allocateRegister(TR_FPR);
         break;
      case TR::DecimalDouble:
         convertOpCode = TR::InstOpCode::CGDTR;
         tempDDReg = srcReg;
         break;
      case TR::DecimalLongDouble:
         convertOpCode = TR::InstOpCode::CGXTR;
         tempDDReg = srcReg;
         break;
      default:
         TR_ASSERT( 0, "dfpToLong: unsupported opcode\n");
         break;
      }

   // Float to double
    if (firstChild->getDataType() == TR::DecimalFloat)
        generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, tempDDReg, srcReg, 0, false);

   generateRRFInstruction(cg, convertOpCode, node, targetReg, tempDDReg, 0x9, true);

   cg->decReferenceCount(firstChild);
   if (firstChild->getDataType() == TR::DecimalFloat)
     cg->stopUsingRegister(tempDDReg);

   node->setRegister(targetReg);
   return targetReg;
   }

/**
 * Convert Decimal float/Double/LongDouble to unsigned long int in 32 bit mode;
 */
inline TR::Register *
dfp2lu(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * srcReg = cg->evaluate(firstChild);
   TR::Register * tempDDReg;
   TR::Register * tempDEReg = cg->allocateFPRegisterPair();
   TR::Register * tempMaxReg = cg->allocateFPRegisterPair();
   TR::Register * evenReg = cg->allocateRegister();
   TR::Register * oddReg = cg->allocateRegister();
   TR::Register * targetReg = cg->allocateConsecutiveRegisterPair(oddReg, evenReg);
   TR::Compilation *comp = cg->comp();

   uint8_t m4 =0x0;
   TR::InstOpCode::Mnemonic convertOpCode;
   switch (firstChild->getDataType())
      {
      case TR::DecimalFloat:
         tempDDReg = cg->allocateRegister(TR_FPR);
         generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, tempDDReg, srcReg, m4, false);
         generateRRFInstruction(cg, TR::InstOpCode::LXDTR, node, tempDEReg, tempDDReg, m4, false);
         break;
      case TR::DecimalDouble:
         generateRRFInstruction(cg, TR::InstOpCode::LXDTR, node, tempDEReg, srcReg, m4, false);
         break;
      case TR::DecimalLongDouble:
         generateRRInstruction(cg, TR::InstOpCode::LXR, node, tempDEReg, srcReg);
         break;
      default:
         TR_ASSERT( 0, "dfpTolu: unsupported opcode\n");
         break;
      }

   // subtract (INTMAX + 1) from the decimal float operand
   int64_t value1 = 0x2208000000000000LL;
   int64_t value2 = 0x948DF20DA5CFD42ELL;

   size_t offset1 = cg->fe()->findOrCreateLiteral(comp, &value1, 8);
   size_t offset2 = cg->fe()->findOrCreateLiteral(comp, &value2, 8);

   TR::Register * litReg = cg->allocateRegister();
   generateLoadLiteralPoolAddress(cg, node, litReg);

   TR::MemoryReference * mrHi = new (cg->trHeapMemory()) TR::MemoryReference(litReg, offset1, cg);
   TR::MemoryReference * mrLo = new (cg->trHeapMemory()) TR::MemoryReference(litReg, offset2, cg);

   generateRXInstruction(cg, TR::InstOpCode::LD, node, tempMaxReg->getHighOrder(), mrHi);
   generateRXInstruction(cg, TR::InstOpCode::LD, node, tempMaxReg->getLowOrder(), mrLo);

   generateRRRInstruction(cg, TR::InstOpCode::SXTR, node, tempDEReg, tempDEReg, tempMaxReg);

   // now convert from Decimal128 to long long
   TR::RegisterDependencyConditions * deps = NULL;
   deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 1, cg);
   TR::Register * tempLReg = cg->allocate64bitRegister();
   deps->addPostCondition(tempLReg, TR::RealRegister::GPR0);

   generateRRFInstruction(cg, TR::InstOpCode::CGXTR, node, tempLReg, tempDEReg, 0xB, true);

   generateRRInstruction(cg, TR::InstOpCode::LR, node, targetReg->getLowOrder(), tempLReg);
   generateRSInstruction(cg, TR::InstOpCode::SRLG, node, tempLReg, tempLReg, 32);
   generateRRInstruction(cg, TR::InstOpCode::LR, node, targetReg->getHighOrder(), tempLReg);

   // add back (INTMAX + 1)
   generateRILInstruction(cg, TR::InstOpCode::XILF, node, targetReg->getHighOrder(), 0x80000000);

   cg->decReferenceCount(firstChild);
   if (firstChild->getDataType() == TR::DecimalFloat)
     cg->stopUsingRegister(tempDDReg);

   cg->stopUsingRegister(tempDEReg);
   cg->stopUsingRegister(tempMaxReg);
   cg->stopUsingRegister(tempLReg);
   mrHi->stopUsingMemRefRegister(cg);
   mrLo->stopUsingMemRefRegister(cg);
   node->setRegister(targetReg);
   return targetReg;
   }

/**
 * Convert Decimal float/Double/LongDouble to signed long int in 64 bit mode;
 */
inline TR::Register *
dfp2lu64(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * srcReg = cg->evaluate(firstChild);
   TR::Register * tempDDReg = NULL;
   TR::Register * targetReg = cg->allocate64bitRegister();

   TR::InstOpCode::Mnemonic convertOpCode;
   switch (firstChild->getDataType())
      {
      case TR::DecimalFloat:
         convertOpCode = TR::InstOpCode::CGDTR;
         tempDDReg = cg->allocateRegister(TR_FPR);
         break;
      case TR::DecimalDouble:
         convertOpCode = TR::InstOpCode::CGDTR;
         tempDDReg = srcReg;
         break;
      case TR::DecimalLongDouble:
         convertOpCode = TR::InstOpCode::CGXTR;
         tempDDReg = srcReg;
         break;
      default:
         TR_ASSERT( 0, "dfpToLong: unsupported opcode\n");
         break;
      }

   // Float to double
    if (firstChild->getDataType() == TR::DecimalFloat)
        generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, tempDDReg, srcReg, 0, false);

   generateRRFInstruction(cg, convertOpCode, node, targetReg, tempDDReg, 0x9, true);

   cg->decReferenceCount(firstChild);
   if (firstChild->getDataType() == TR::DecimalFloat)
     cg->stopUsingRegister(tempDDReg);

   node->setRegister(targetReg);
   return targetReg;

   }

/**
 * Convert to signed long to Decimal float/Double/LongDouble in 32bit mode
 */
inline TR::Register *
l2dfp(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * srcReg = cg->evaluate(firstChild);

   TR::Register * targetReg;

   TR::InstOpCode::Mnemonic convertOpCode;
   bool isFloatTgt = false;
   if( node->getDataType() != TR::DecimalLongDouble)
      targetReg = cg->allocateRegister(TR_FPR);
   else
      targetReg = cg->allocateFPRegisterPair();

   TR::Register *tempReg = cg->allocate64bitRegister();
   TR::RegisterDependencyConditions * deps = NULL;
   deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 1, cg);
   deps->addPostCondition(tempReg, TR::RealRegister::GPR0);

   generateRSInstruction(cg, TR::InstOpCode::SLLG, node, tempReg, srcReg->getHighOrder(), 32);
   generateRRInstruction(cg, TR::InstOpCode::OR, node, tempReg, srcReg->getLowOrder());

   switch (node->getDataType())
      {
      case TR::DecimalDouble  :
         convertOpCode = TR::InstOpCode::CDGTR;
         break;
      case TR::DecimalLongDouble  :
         convertOpCode = TR::InstOpCode::CXGTR;
         break;
      default         :
         TR_ASSERT( 0,"l2dfp: unsupported data types");
         return NULL;
      }
   //convert to DFP
   generateRRInstruction(cg, convertOpCode, node, targetReg, tempReg);
   //clear upper 32bit for r0
   generateRSInstruction(cg, TR::InstOpCode::SRLG, node, tempReg, tempReg, 32);
   cg->stopUsingRegister(tempReg);
   node->setRegister(targetReg);
   cg->decReferenceCount(firstChild);
   return targetReg;
   }

/**
 * Convert to signed long to Decimal float/Double/LongDouble in 64bit mode
 */
inline TR::Register *
l2dfp64(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * srcReg = cg->evaluate(firstChild);

   TR::Register * targetReg;

   TR::InstOpCode::Mnemonic convertOpCode;
   bool isFloatTgt = false;
   if( node->getDataType() != TR::DecimalLongDouble)
      targetReg = cg->allocateRegister(TR_FPR);
   else
      targetReg = cg->allocateFPRegisterPair();

   switch (node->getDataType())
      {
      case TR::DecimalDouble  :
         convertOpCode = TR::InstOpCode::CDGTR;
         break;
      case TR::DecimalLongDouble  :
         convertOpCode = TR::InstOpCode::CXGTR;
         break;
      default         :
         TR_ASSERT( 0,"l2dfp: unsupported data types");
         return NULL;
      }
   //convert to DFP
   generateRRInstruction(cg, convertOpCode, node, targetReg, srcReg);
   node->setRegister(targetReg);
   cg->decReferenceCount(firstChild);
   return targetReg;
   }

/**
 * Convert to unsigned long to Decimal float/Double/LongDouble in 32bit mode
 */
inline TR::Register *
lu2dfp(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * srcReg = cg->evaluate(firstChild);
   TR::Register * tempDEReg = NULL;
   TR::Compilation *comp = cg->comp();

   TR::Register *tempReg = cg->allocate64bitRegister();
   TR::RegisterDependencyConditions * deps = NULL;
   deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 1, cg);
   deps->addPostCondition(tempReg, TR::RealRegister::GPR0);

   // subtract (INTMAX + 1) from the upper 32 bit register using x_or operation.
   generateRSInstruction(cg, TR::InstOpCode::SLLG, node, tempReg, srcReg->getHighOrder(), 32);
   generateRILInstruction(cg, TR::InstOpCode::XIHF, node, tempReg, 0x80000000);
   generateRRInstruction(cg, TR::InstOpCode::OR, node, tempReg, srcReg->getLowOrder());

   TR::Register * targetReg;
   if( node->getDataType() != TR::DecimalLongDouble)
      {
      targetReg = cg->allocateRegister(TR_FPR);
      tempDEReg = cg->allocateFPRegisterPair();
      generateRRInstruction(cg, TR::InstOpCode::CXGTR, node, tempDEReg, tempReg);
      }
   else
      {
      targetReg = cg->allocateFPRegisterPair();
      generateRRInstruction(cg, TR::InstOpCode::CXGTR, node, targetReg, tempReg);
      }

   // add back (INTMAX + 1)
   int64_t value1 = 0x2208000000000000LL;
   int64_t value2 = 0x948DF20DA5CFD42ELL;

   size_t offset1 = cg->fe()->findOrCreateLiteral(comp, &value1, 8);
   size_t offset2 = cg->fe()->findOrCreateLiteral(comp, &value2, 8);

   TR::Register * litReg = cg->allocateRegister();
   generateLoadLiteralPoolAddress(cg, node, litReg);

   TR::MemoryReference * mrHi = new (cg->trHeapMemory()) TR::MemoryReference(litReg, offset1, cg);
   TR::MemoryReference * mrLo = new (cg->trHeapMemory()) TR::MemoryReference(litReg, offset2, cg);

   TR::Register * tempMaxReg = cg->allocateFPRegisterPair();
   generateRXInstruction(cg, TR::InstOpCode::LD, node, tempMaxReg->getHighOrder(), mrHi);
   generateRXInstruction(cg, TR::InstOpCode::LD, node, tempMaxReg->getLowOrder(), mrLo);

   TR::Register * tempTgtReg = NULL;

   if( node->getDataType() != TR::DecimalLongDouble)
      {
      generateRRRInstruction(cg, TR::InstOpCode::AXTR, node, tempDEReg, tempDEReg, tempMaxReg);
      uint8_t m3 = 0x0, m4 =0x0;

      tempTgtReg = cg->allocateFPRegisterPair();
      generateRRFInstruction(cg, TR::InstOpCode::LDXTR, node, tempTgtReg, tempDEReg, m3, m4);
      generateRRInstruction(cg, TR::InstOpCode::LDR, node, targetReg, tempTgtReg->getHighOrder());
      }
   else
      generateRRRInstruction(cg, TR::InstOpCode::AXTR, node, targetReg, targetReg, tempMaxReg);

   //clear upper 32bit
   generateRSInstruction(cg, TR::InstOpCode::SRLG, node, tempReg, tempReg, 32);

   cg->stopUsingRegister(tempReg);
   cg->stopUsingRegister(tempMaxReg);
   mrHi->stopUsingMemRefRegister(cg);
   mrLo->stopUsingMemRefRegister(cg);
   if( node->getDataType() != TR::DecimalLongDouble)
      {
      cg->stopUsingRegister(tempDEReg);
      cg->stopUsingRegister(tempTgtReg);
      }

   node->setRegister(targetReg);
   cg->decReferenceCount(firstChild);
   return targetReg;
   }

/**
 * Convert to unsigned long to Decimal float/Double/LongDouble in 64bit mode
 */
inline TR::Register *
lu2dfp64(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * srcReg = cg->evaluate(firstChild);
   TR::Register * tempReg = cg->allocateRegister();
   TR::Register * tempDEReg = NULL;
   TR::Compilation *comp = cg->comp();

   generateRRInstruction(cg, TR::InstOpCode::LGR, node, tempReg, srcReg);
   // subtract (INTMAX + 1) from the upper 32 bit register using x_or operation.
   generateRILInstruction(cg, TR::InstOpCode::XIHF, node, tempReg, 0x80000000);

   TR::Register * targetReg;
   if( node->getDataType() != TR::DecimalLongDouble)
      {
      targetReg = cg->allocateRegister(TR_FPR);
      tempDEReg = cg->allocateFPRegisterPair();
      generateRRInstruction(cg, TR::InstOpCode::CXGTR, node, tempDEReg, tempReg);
      }
   else
      {
      targetReg = cg->allocateFPRegisterPair();
      generateRRInstruction(cg, TR::InstOpCode::CXGTR, node, targetReg, tempReg);
      }

   // add back (INTMAX + 1)
   int64_t value1 = 0x2208000000000000LL;
   int64_t value2 = 0x948DF20DA5CFD42ELL;

   size_t offset1 = cg->fe()->findOrCreateLiteral(comp, &value1, 8);
   size_t offset2 = cg->fe()->findOrCreateLiteral(comp, &value2, 8);

   TR::Register * litReg = cg->allocateRegister();
   generateLoadLiteralPoolAddress(cg, node, litReg);

   TR::MemoryReference * mrHi = new (cg->trHeapMemory()) TR::MemoryReference(litReg, offset1, cg);
   TR::MemoryReference * mrLo = new (cg->trHeapMemory()) TR::MemoryReference(litReg, offset2, cg);

   TR::Register * tempMaxReg = cg->allocateFPRegisterPair();
   generateRXInstruction(cg, TR::InstOpCode::LD, node, tempMaxReg->getHighOrder(), mrHi);
   generateRXInstruction(cg, TR::InstOpCode::LD, node, tempMaxReg->getLowOrder(), mrLo);
   TR::Register * tempTgtReg = NULL;

   if( node->getDataType() != TR::DecimalLongDouble)
      {
      generateRRRInstruction(cg, TR::InstOpCode::AXTR, node, tempDEReg, tempDEReg, tempMaxReg);
      uint8_t m3 = 0x0, m4 =0x0;
      tempTgtReg = cg->allocateFPRegisterPair();
      generateRRFInstruction(cg, TR::InstOpCode::LDXTR, node, tempTgtReg, tempDEReg, m3, m4);
      generateRRInstruction(cg, TR::InstOpCode::LDR, node, targetReg, tempTgtReg->getHighOrder());
      }
   else
      generateRRRInstruction(cg, TR::InstOpCode::AXTR, node, targetReg, targetReg, tempMaxReg);

   cg->stopUsingRegister(tempReg);
   cg->stopUsingRegister(tempMaxReg);
   mrHi->stopUsingMemRefRegister(cg);
   mrLo->stopUsingMemRefRegister(cg);
   if( node->getDataType() != TR::DecimalLongDouble)
      {
      cg->stopUsingRegister(tempDEReg);
      cg->stopUsingRegister(tempTgtReg);
      }

   node->setRegister(targetReg);
   cg->decReferenceCount(firstChild);
   return targetReg;
   }

/************************************************************************************************
Convert Decimal float/Double/LongDouble to fixed number i.e. int,short,byte, or char
Conversion is performed in compliance with what's described in 'zOS XLC V1R10 Language Reference'
  -  Floating-point (binary or decimal) to integer conversion
     The fractional part is discarded (i.e., the value is truncated toward zero).
     If the value of the integral part cannot be represented by the integer type,
     the result is one of the following:
       - If the integer type is unsigned, the result is the largest representable number if the
           floating-point number is positive, or 0 otherwise.
       - If the integer type is signed, the result is the most negative or positive representable
           number according to the sign of the floating-point number
currently tobey follows this rule for DFP to singned/unsigned int, but seems not for short/byte types
     where the upper bits are simple choped off, i think it's just a bug in tobey

     DFP to fixed type conversions are expanded in WCode IlGen phase, so don't need it here anymore
inline TR::Register *
dfpToFixed(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR_ASSERT( 0,"Error: dfpToFixed() -- should not be here ");
   return NULL;
   }

************************************************************************************************/

/**
 * Convert to Decimal Double/LongDouble from fixed number i.e. int,short,byte, or char
 */
inline TR::Register *
fixedToDFP(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * srcRegister = cg->evaluate(firstChild);

   TR::Register * targetRegister;
   TR::Register * lowReg, * highReg;

   TR::InstOpCode::Mnemonic convertOpCode;
   // convert the srcRegister value to appropriate type, if needed
   int32_t nshift = 0;
   bool isSrcUnsigned = false;
   bool isFloatTgt = false;
   if( node->getDataType() != TR::DecimalLongDouble)
      targetRegister = cg->allocateRegister(TR_FPR);
   else
      {
      lowReg = cg->allocateRegister(TR_FPR);
      highReg = cg->allocateRegister(TR_FPR);
      targetRegister = cg->allocateFPRegisterPair(lowReg, highReg);
      }

   TR::Register *tempReg = cg->allocate64bitRegister();
   TR::RegisterDependencyConditions * deps = NULL;
   if (TR::Compiler->target.is32Bit())
      {
      deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 1, cg);
      deps->addPostCondition(tempReg, TR::RealRegister::GPR0);
      }

   switch (node->getOpCodeValue())
     {
     case TR::b2df:
     case TR::b2dd:
     case TR::b2de:
     case TR::s2df:
     case TR::s2dd:
     case TR::s2de:
     case TR::i2df:
     case TR::i2dd:
     case TR::i2de:
         generateRRInstruction(cg, TR::InstOpCode::LGFR, node, tempReg,srcRegister);
         break;
     case TR::bu2df:
     case TR::bu2dd:
     case TR::bu2de:
         nshift = 56;
         break;
     case TR::su2df:
     case TR::su2dd:
     case TR::su2de:
         nshift = 48;
         break;
     case TR::iu2df:
     case TR::iu2dd:
     case TR::iu2de:
         nshift = 32;
         isSrcUnsigned = true;
         generateRSInstruction(cg, TR::InstOpCode::SLLG, node, tempReg, srcRegister, nshift);
         generateRSInstruction(cg, TR::InstOpCode::SRLG, node, tempReg, tempReg, nshift);
         break;
      default:
         TR_ASSERT( 0, "fixedToDFP: unsupported opcode\n");
         break;
      }
   switch (node->getDataType())
      {
      case TR::DecimalDouble  :
         convertOpCode = TR::InstOpCode::CDGTR;
         break;
      case TR::DecimalLongDouble  :
         convertOpCode = TR::InstOpCode::CXGTR;
         break;
      default         :
         TR_ASSERT(false, "should be unreachable");
         return NULL;
      }
   //convert to DFP
   generateRRInstruction(cg, convertOpCode, node, targetRegister, tempReg);
   cg->stopUsingRegister(tempReg);
   node->setRegister(targetRegister);
   cg->decReferenceCount(firstChild);
   return targetRegister;
   }

TR::Register *
J9::Z::TreeEvaluator::i2ddEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return fixedToDFP(node,cg);
   }

TR::Register *
J9::Z::TreeEvaluator::dd2lEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return (TR::Compiler->target.is64Bit() || cg->use64BitRegsOn32Bit()) ? dfp2l64(node,cg) : dfp2l(node,cg);
   }

TR::Register *
J9::Z::TreeEvaluator::dd2luEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return (TR::Compiler->target.is64Bit() || cg->use64BitRegsOn32Bit()) ? dfp2lu64(node,cg) : dfp2lu(node,cg);
   }

TR::Register *
J9::Z::TreeEvaluator::l2ddEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return (TR::Compiler->target.is64Bit() || cg->use64BitRegsOn32Bit()) ? l2dfp64(node,cg) : l2dfp(node,cg);
   }

TR::Register *
J9::Z::TreeEvaluator::lu2ddEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return (TR::Compiler->target.is64Bit() || cg->use64BitRegsOn32Bit()) ? lu2dfp64(node,cg) : lu2dfp(node,cg);
   }

TR::Register *
J9::Z::TreeEvaluator::df2ddEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * targetReg = cg->allocateRegister(TR_FPR);
   TR::Register * srcReg = cg->evaluate(firstChild);

   uint8_t m4 =0x0;
   generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, targetReg, srcReg, m4, false);
   node->setRegister(targetReg);
   cg->decReferenceCount(firstChild);
   cg->stopUsingRegister(srcReg);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::df2deEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * tmpReg = cg->allocateRegister(TR_FPR);
   TR::Register * targetReg = cg->allocateFPRegisterPair();
   TR::Register * srcReg = cg->evaluate(firstChild);
   uint8_t m4 =0x0;
   generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, tmpReg, srcReg, m4, false);
   generateRRFInstruction(cg, TR::InstOpCode::LXDTR, node, targetReg, tmpReg, m4, false);
   cg->stopUsingRegister(srcReg);
   cg->stopUsingRegister(tmpReg);
   cg->decReferenceCount(firstChild);
   node->setRegister(targetReg);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::dd2dfEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * targetReg = cg->allocateRegister(TR_FPR);
   TR::Register * srcReg = cg->evaluate(firstChild);
   uint8_t m3 =0x0, m4 =0x0;
   generateRRFInstruction(cg, TR::InstOpCode::LEDTR, node, targetReg, srcReg, m3, m4);
   node->setRegister(targetReg);
   cg->decReferenceCount(firstChild);
   cg->stopUsingRegister(srcReg);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::dd2deEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * targetReg = cg->allocateFPRegisterPair();
   TR::Register * srcReg = cg->evaluate(firstChild);
   uint8_t m4 =0x0;
   generateRRFInstruction(cg, TR::InstOpCode::LXDTR, node, targetReg, srcReg, m4, false);
   node->setRegister(targetReg);
   cg->decReferenceCount(firstChild);
   cg->stopUsingRegister(srcReg);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::de2dxHelperAndSetRegister(TR::Register *targetReg, TR::Register *srcReg, TR::Node *node, TR::CodeGenerator *cg)
   {
   TR_ASSERT(node->getDataType() == TR::DecimalDouble || node->getDataType() == TR::DecimalFloat,"expecting node %s (%p) dataType to be DecimalDouble or DecimalFloat\n",node->getOpCode().getName(),node);
   uint8_t m3 = 0x0;
   uint8_t m4 = 0x0;
   generateRRFInstruction(cg, TR::InstOpCode::LDXTR, node, targetReg, srcReg, m3, m4);
   if (node->getDataType() == TR::DecimalFloat)
      generateRRFInstruction(cg, TR::InstOpCode::LEDTR, node, targetReg->getHighOrder(), targetReg->getHighOrder(), m3, m4);

   // The converted dd value is in the high order part of targetReg but the low order and the reg pair itself
   // have to be killed -- in order to do this the high is first set on the node and then the low and pair are
   // killed by calling stopUsingRegister.
   TR::Register *newTargetReg = node->setRegister(targetReg->getHighOrder());
   cg->stopUsingRegister(targetReg);
   targetReg = newTargetReg;
   return targetReg;
   }

/**
 * Handles TR::de2dd, TR::de2df
 */
TR::Register *
J9::Z::TreeEvaluator::de2ddEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * srcReg = cg->evaluate(firstChild);
   TR::Register * targetReg = cg->allocateFPRegisterPair();
   targetReg = de2dxHelperAndSetRegister(targetReg, srcReg, node, cg);
   cg->decReferenceCount(firstChild);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::dfaddEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Register* sreg1 = cg->fprClobberEvaluate(node->getFirstChild());
   TR::Register* sreg2 = cg->fprClobberEvaluate(node->getSecondChild());
   TR::Register* treg = cg->allocateRegister(TR_FPR);
   TR::Register* resReg = cg->allocateRegister(TR_FPR);

   generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, sreg1, sreg1, 0, false);
   generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, sreg2, sreg2, 0, false);

   // Extract FPC and save in register
   TR::Register * fpcReg = cg->allocateRegister();
   generateRRInstruction(cg, TR::InstOpCode::EFPC, node, fpcReg, fpcReg);

   generateRSInstruction(cg, TR::InstOpCode::SRL, node, fpcReg, 4);
   generateRILInstruction(cg, TR::InstOpCode::NILF, node, fpcReg, 0x07);

   // set DFP rounding mode before arith op...
   TR::MemoryReference * rmMR = generateS390MemoryReference(0x07, cg);
   generateSInstruction(cg, TR::InstOpCode::SRNMT, node, rmMR);

   generateRRRInstruction(cg, TR::InstOpCode::ADTR, node, treg, sreg1, sreg2);
   generateRSInstruction(cg, TR::InstOpCode::SLL, node, fpcReg, 4);

   TR::Register *tmpReg = cg->allocateRegister();
   generateRRInstruction(cg, TR::InstOpCode::EFPC, node, tmpReg, tmpReg);

   generateRIInstruction(cg, TR::InstOpCode::NILL, node, tmpReg, 0xFF8F);

   generateRRInstruction(cg, TR::InstOpCode::OR, node, fpcReg, tmpReg);
   // reset FPC reg
   generateRRInstruction(cg, TR::InstOpCode::SFPC, node, fpcReg, fpcReg);

   // reround  to 7 digit significance before the double->float conversion
   TR::Register * precReg = cg->allocateRegister();
   generateRIInstruction(cg, TR::InstOpCode::LA, node, precReg, 0x7);

   generateRRFInstruction(cg, TR::InstOpCode::RRDTR, node, resReg, precReg, treg, USE_CURRENT_DFP_ROUNDING_MODE);

   generateRRFInstruction(cg, TR::InstOpCode::LEDTR, node, resReg, resReg, 0, false);

   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());
   cg->stopUsingRegister(sreg1);
   cg->stopUsingRegister(sreg2);
   cg->stopUsingRegister(fpcReg);
   cg->stopUsingRegister(tmpReg);
   cg->stopUsingRegister(treg);
   cg->stopUsingRegister(precReg);
   node->setRegister(resReg);
   return node->getRegister();
   }

TR::Register *
J9::Z::TreeEvaluator::ddaddEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Register* sreg1 = cg->evaluate(node->getFirstChild());
   TR::Register* sreg2 = cg->evaluate(node->getSecondChild());
   TR::Register* treg = cg->allocateRegister(TR_FPR);

   generateRRRInstruction(cg, TR::InstOpCode::ADTR, node, treg, sreg1, sreg2);
   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());
   node->setRegister(treg);
   return node->getRegister();
   }

TR::Register *
J9::Z::TreeEvaluator::deaddEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Register* sreg1 = cg->evaluate(node->getFirstChild());
   TR::Register* sreg2 = cg->evaluate(node->getSecondChild());
   TR::Register* treg = cg->allocateFPRegisterPair();

   generateRRRInstruction(cg, TR::InstOpCode::AXTR, node, treg, sreg1, sreg2);
   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());
   node->setRegister(treg);
   return node->getRegister();
   }

TR::Register *
J9::Z::TreeEvaluator::dfsubEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Register* sreg1 = cg->fprClobberEvaluate(node->getFirstChild());
   TR::Register* sreg2 = cg->fprClobberEvaluate(node->getSecondChild());
   TR::Register* treg = cg->allocateRegister(TR_FPR);

   generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, sreg1, sreg1, 0, false);
   generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, sreg2, sreg2, 0, false);

   generateRRRInstruction(cg, TR::InstOpCode::SDTR, node, treg, sreg1, sreg2);
   generateRRFInstruction(cg, TR::InstOpCode::LEDTR, node, treg, treg, 0, false);
   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());
   cg->stopUsingRegister(sreg1);
   cg->stopUsingRegister(sreg2);
   node->setRegister(treg);
   return node->getRegister();
   }

TR::Register *
J9::Z::TreeEvaluator::ddsubEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Register* sreg1 = cg->evaluate(node->getFirstChild());
   TR::Register* sreg2 = cg->evaluate(node->getSecondChild());
   TR::Register* treg = cg->allocateRegister(TR_FPR);

   generateRRRInstruction(cg, TR::InstOpCode::SDTR, node, treg, sreg1, sreg2);
   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());
   node->setRegister(treg);
   return node->getRegister();
   }

TR::Register *
J9::Z::TreeEvaluator::desubEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Register* sreg1 = cg->evaluate(node->getFirstChild());
   TR::Register* sreg2 = cg->evaluate(node->getSecondChild());
   TR::Register* treg = cg->allocateFPRegisterPair();

   generateRRRInstruction(cg, TR::InstOpCode::SXTR, node, treg, sreg1, sreg2);
   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());
   node->setRegister(treg);
   return node->getRegister();
   }

TR::Register *
J9::Z::TreeEvaluator::dfmulEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Register* sreg1 = cg->fprClobberEvaluate(node->getFirstChild());
   TR::Register* sreg2 = cg->fprClobberEvaluate(node->getSecondChild());
   TR::Register* treg = cg->allocateRegister(TR_FPR);

   generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, sreg1, sreg1, 0, false);
   generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, sreg2, sreg2, 0, false);

   generateRRRInstruction(cg, TR::InstOpCode::MDTR, node, treg, sreg1, sreg2);
   generateRRFInstruction(cg, TR::InstOpCode::LEDTR, node, treg, treg, 0, false);
   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());
   cg->stopUsingRegister(sreg1);
   cg->stopUsingRegister(sreg2);
   node->setRegister(treg);
   return node->getRegister();
   }

TR::Register *
J9::Z::TreeEvaluator::ddmulEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Register* sreg1 = cg->evaluate(node->getFirstChild());
   TR::Register* sreg2 = cg->evaluate(node->getSecondChild());
   TR::Register* treg = cg->allocateRegister(TR_FPR);

   generateRRRInstruction(cg, TR::InstOpCode::MDTR, node, treg, sreg1, sreg2);
   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());
   node->setRegister(treg);
   return node->getRegister();
   }

TR::Register *
J9::Z::TreeEvaluator::demulEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Register* sreg1 = cg->evaluate(node->getFirstChild());
   TR::Register* sreg2 = cg->evaluate(node->getSecondChild());
   TR::Register* treg = cg->allocateFPRegisterPair();

   generateRRRInstruction(cg, TR::InstOpCode::MXTR, node, treg, sreg1, sreg2);
   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());
   node->setRegister(treg);
   return node->getRegister();
   }

TR::Register *
J9::Z::TreeEvaluator::dfdivEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Register* sreg1, *sreg2, *treg;

   // Clobber since we'll need to lengthen to perform 64-bit math
   if (node->getDataType() == TR::DecimalFloat)
      {
      sreg1 = cg->fprClobberEvaluate(node->getFirstChild());
      sreg2 = cg->fprClobberEvaluate(node->getSecondChild());
      }
   else
      {
      sreg1 = cg->evaluate(node->getFirstChild());
      sreg2 = cg->evaluate(node->getSecondChild());
      }

   if (node->getDataType() == TR::DecimalLongDouble)
      treg = cg->allocateFPRegisterPair();
   else
      treg = cg->allocateRegister(TR_FPR);

   // Lengthen to 64 bits
   if (node->getDataType() == TR::DecimalFloat)
      {
      generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, sreg1, sreg1, 0, false);
      generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, sreg2, sreg2, 0, false);
      }

   // RTC 91058: The COBOL runtime was previously setting the IEEE divide-by-zero mask
   // on when it was first brought up, so COBOL programs would terminate with an
   // expection on a divide by zero. In a mixed-language environment, other languages
   // might want to handle the exception instead of terminate. To accommodate this,
   // the runtime will no longer set the divide-by-zero mask. COBOL programs will then
   // need to ensure the mask is on exactly when an exception would be hit.
   //
   // So, we insert code here that compares the divisor to zero, and if it is zero, we
   // turn the mask on before executing the divide.
   TR::Compilation *comp = cg->comp();
   bool checkDivisorForZero = comp->getOption(TR_ForceIEEEDivideByZeroException);
   if (checkDivisorForZero)
      {
      TR::LabelSymbol *oolEntryPoint = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol *oolReturnPoint = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol * cflowRegionStart   = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      TR::LabelSymbol * cflowRegionEnd     = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

      TR::Register *IMzMaskReg = cg->allocate64bitRegister();

      TR::RegisterDependencyConditions *deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 1, cg);
      deps->addPostCondition(IMzMaskReg, TR::RealRegister::AssignAny);

      // Load and test the divisor; branch to the OOL sequence if zero
      if (node->getDataType() == TR::DecimalLongDouble)
         generateRREInstruction(cg, TR::InstOpCode::LTXTR, node, sreg2, sreg2);
      else
         generateRREInstruction(cg, TR::InstOpCode::LTDTR, node, sreg2, sreg2);

      cflowRegionStart->setStartInternalControlFlow();
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, cflowRegionStart, deps);

      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BZ, node, oolEntryPoint);

      // Start OOL sequence
      TR_S390OutOfLineCodeSection *oolHelper = new (cg->trHeapMemory()) TR_S390OutOfLineCodeSection(oolEntryPoint, oolReturnPoint, cg);
      cg->getS390OutOfLineCodeSectionList().push_front(oolHelper);
      oolHelper->swapInstructionListsWithCompilation();
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, oolEntryPoint);

      // Turn on the divide-by-zero exception flag (second bit from the left in the FPC dword)
      int32_t IMzMask = 0x40000000;
      generateRILInstruction(cg, TR::InstOpCode::LGFI, node, IMzMaskReg, IMzMask);
      generateRREInstruction(cg, TR::InstOpCode::SFPC, node, IMzMaskReg, IMzMaskReg);
      cg->stopUsingRegister(IMzMaskReg);

      // End OOL sequence
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BRC, node, oolReturnPoint);
      oolHelper->swapInstructionListsWithCompilation();
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, oolReturnPoint);

      cflowRegionEnd->setEndInternalControlFlow();
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, cflowRegionEnd, deps);
      }

   if (node->getDataType() == TR::DecimalLongDouble)
      generateRRRInstruction(cg, TR::InstOpCode::DXTR, node, treg, sreg1, sreg2);
   else
      generateRRRInstruction(cg, TR::InstOpCode::DDTR, node, treg, sreg1, sreg2);

   // Shorten the result to 32 bits
   if (node->getDataType() == TR::DecimalFloat)
      generateRRFInstruction(cg, TR::InstOpCode::LEDTR, node, treg, treg, 0, false);

   cg->decReferenceCount(node->getFirstChild());
   cg->decReferenceCount(node->getSecondChild());

   if (node->getDataType() == TR::DecimalFloat)
      {
      cg->stopUsingRegister(sreg1);
      cg->stopUsingRegister(sreg2);
      }

   node->setRegister(treg);
   return node->getRegister();
   }

TR::Register *
J9::Z::TreeEvaluator::ifddcmpeqEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBranch(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, TR::InstOpCode::COND_BE, false);
   }

TR::Register *
J9::Z::TreeEvaluator::ifddcmpneEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBranch(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, TR::InstOpCode::COND_BNE, false);
   }

TR::Register *
J9::Z::TreeEvaluator::ifddcmpltEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBranch(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BL, TR::InstOpCode::COND_BH, false);
   }

TR::Register *
J9::Z::TreeEvaluator::ifddcmpgeEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBranch(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNL, TR::InstOpCode::COND_BNH, false);
   }

TR::Register *
J9::Z::TreeEvaluator::ifddcmpgtEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBranch(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BH, TR::InstOpCode::COND_BL, false);
   }

TR::Register *
J9::Z::TreeEvaluator::ifddcmpleEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBranch(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, TR::InstOpCode::COND_BNL, false);
   }

TR::Register *
J9::Z::TreeEvaluator::ifddcmpequEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBranch(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, TR::InstOpCode::COND_BE, true);
   }

TR::Register *
J9::Z::TreeEvaluator::ifddcmpneuEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBranch(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, TR::InstOpCode::COND_BNE, true);
   }

TR::Register *
J9::Z::TreeEvaluator::ifddcmpltuEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBranch(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BL, TR::InstOpCode::COND_BH, true);
   }

TR::Register *
J9::Z::TreeEvaluator::ifddcmpgeuEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBranch(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNL, TR::InstOpCode::COND_BNH, true);
   }

TR::Register *
J9::Z::TreeEvaluator::ifddcmpgtuEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBranch(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BH, TR::InstOpCode::COND_BL, true);
   }

TR::Register *
J9::Z::TreeEvaluator::ifddcmpleuEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBranch(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, TR::InstOpCode::COND_BNL, true);
   }

TR::Register *
J9::Z::TreeEvaluator::ddcmpeqEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, TR::InstOpCode::COND_BE, false);
   }

TR::Register *
J9::Z::TreeEvaluator::ddcmpneEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, TR::InstOpCode::COND_BNE, false);
   }

TR::Register *
J9::Z::TreeEvaluator::ddcmpltEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BL, TR::InstOpCode::COND_BH, false);
   }

TR::Register *
J9::Z::TreeEvaluator::ddcmpgeEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNL, TR::InstOpCode::COND_BNH, false);
   }

TR::Register *
J9::Z::TreeEvaluator::ddcmpgtEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BH, TR::InstOpCode::COND_BL, false);
   }

TR::Register *
J9::Z::TreeEvaluator::ddcmpleEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, TR::InstOpCode::COND_BNL, false);
   }

TR::Register *
J9::Z::TreeEvaluator::ddcmpequEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BE, TR::InstOpCode::COND_BE, true);
   }

TR::Register *
J9::Z::TreeEvaluator::ddcmpneuEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNE, TR::InstOpCode::COND_BNE, true);
   }

TR::Register *
J9::Z::TreeEvaluator::ddcmpltuEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BL, TR::InstOpCode::COND_BH, true);
   }

TR::Register *
J9::Z::TreeEvaluator::ddcmpgeuEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNL, TR::InstOpCode::COND_BNH, true);
   }

TR::Register *
J9::Z::TreeEvaluator::ddcmpgtuEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BH, TR::InstOpCode::COND_BL, true);
   }

TR::Register *
J9::Z::TreeEvaluator::ddcmpleuEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return generateS390CompareBool(node, cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BNH, TR::InstOpCode::COND_BNL, true);
   }


/**
 * ddneg handles all decimal DFP types
 */
TR::Register *
J9::Z::TreeEvaluator::ddnegEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node *firstChild = node->getFirstChild();

   TR::Register *srcReg = cg->evaluate(firstChild);
   TR::Register *targetReg;

   if (node->getDataType()==TR::DecimalLongDouble)
      {
      if (cg->canClobberNodesRegister(firstChild))
         targetReg = srcReg;
      else
         targetReg = cg->allocateFPRegisterPair();
      generateRRInstruction(cg, TR::InstOpCode::LCDFR, node, targetReg->getHighOrder(), srcReg->getHighOrder());

      if (!cg->canClobberNodesRegister(firstChild))
         generateRRInstruction(cg, TR::InstOpCode::LDR, node, targetReg->getLowOrder(), srcReg->getLowOrder());
      }
   else
      {
      if (cg->canClobberNodesRegister(firstChild))
         targetReg = srcReg;
      else
         targetReg = cg->allocateRegister(TR_FPR);
      generateRRInstruction(cg, TR::InstOpCode::LCDFR, node, targetReg, srcReg);
      }

   node->setRegister(targetReg);
   cg->decReferenceCount(firstChild);
   return targetReg;
   }

/**
 * Handles TR::ddInsExp, TR::deInsExp
 */
TR::Register *
J9::Z::TreeEvaluator::ddInsExpEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR_ASSERT(node->getOpCodeValue() == TR::ddInsExp || node->getOpCodeValue() == TR::deInsExp,"expecting op to be ddInsExp or deInsExp and not %d\n",node->getOpCodeValue());

   TR::Node *biasedExpNode = node->getSecondChild();
   TR::Node *srcNode = node->getFirstChild();
   TR::Register *srcReg = cg->evaluate(srcNode);

   TR::Register *targetReg = NULL;
   if(node->getDataType() == TR::DecimalLongDouble)
      targetReg = cg->allocateFPRegisterPair();
   else
      targetReg = cg->allocateRegister(TR_FPR);

   TR::RegisterDependencyConditions *deps = NULL;
   TR::Register *biasedExpReg = NULL;
   if (TR::Compiler->target.is64Bit() || cg->use64BitRegsOn32Bit())
      {
      TR_ASSERT(biasedExpNode->getOpCode().getSize() == 8,"expecting a biasedExpNode of size 8 and not size %d\n",biasedExpNode->getOpCode().getSize());
      biasedExpReg = cg->evaluate(biasedExpNode);
      }
   else
      {
      TR_ASSERT(biasedExpNode->getOpCode().getSize() == 4,"expecting a biasedExpNode of size 4 and not size %d\n",biasedExpNode->getOpCode().getSize());
      // need to ensure biasedExpReg is allocated as a 64 bit register so localRA will spill/reload all 64 bits if needed
      if (biasedExpNode->getOpCode().isLoadConst())
         {
         // manually check for a constant so a single LGHI/LGFI can be used vs LHI+LGFR if evaluate is just called
         int64_t biasedExpValue = biasedExpNode->get64bitIntegralValue();
         if (biasedExpValue >= MIN_IMMEDIATE_VAL && biasedExpValue <= MAX_IMMEDIATE_VAL)
            {
            biasedExpReg = cg->allocate64bitRegister();
            generateRIInstruction(cg, TR::InstOpCode::LGHI, node, biasedExpReg, (int32_t)biasedExpValue);
            }
         else if (biasedExpValue >= GE_MIN_IMMEDIATE_VAL && biasedExpValue <= GE_MAX_IMMEDIATE_VAL)
            {
            biasedExpReg = cg->allocate64bitRegister();
            generateRILInstruction(cg, TR::InstOpCode::LGFI, node, biasedExpReg, (int32_t)biasedExpValue);
            }
         }

      if (biasedExpReg == NULL)
         {
         TR::Register *biasedExpReg32 = cg->evaluate(biasedExpNode);
         biasedExpReg = cg->allocate64bitRegister();
         generateRRInstruction(cg, TR::InstOpCode::LGFR, node, biasedExpReg, biasedExpReg32);
         }
      // the 64 bit registers biasedExpReg is going to be clobbered and R0 is safe to clobber regardless of the hgpr (use64BitRegsOn32Bit) setting
      deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 1, cg);
      deps->addPostCondition(biasedExpReg, TR::RealRegister::GPR0);
      }

   TR::Instruction *inst = generateRRFInstruction(cg, (node->getDataType() == TR::DecimalLongDouble ? TR::InstOpCode::IEXTR : TR::InstOpCode::IEDTR), node, targetReg, biasedExpReg, srcReg);
   if (deps)
      inst->setDependencyConditions(deps);

   cg->decReferenceCount(srcNode);
   cg->decReferenceCount(biasedExpNode);
   node->setRegister(targetReg);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::dffloorEvaluator(TR::Node *node, TR::CodeGenerator * cg)
   {
   TR::Register* srcReg = cg->evaluate(node->getFirstChild());
   TR::Register* trgReg = cg->allocateRegister(TR_FPR);

   generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, trgReg, srcReg, 0, false);
   generateRRFInstruction(cg, TR::InstOpCode::FIDTR, node, trgReg, trgReg, (uint8_t)9, (uint8_t)0); //  mask3=9 round to 0, mask4=0
   generateRRFInstruction(cg, TR::InstOpCode::LEDTR, node, trgReg, trgReg, 0, false);

   cg->decReferenceCount(node->getFirstChild());
   node->setRegister(trgReg);
   return trgReg;
   }

TR::Register *
J9::Z::TreeEvaluator::ddfloorEvaluator(TR::Node *node, TR::CodeGenerator * cg)
   {
   TR::Register* srcReg = cg->evaluate(node->getFirstChild());
   TR::Register* trgReg = cg->allocateRegister(TR_FPR);

   generateRRFInstruction(cg, TR::InstOpCode::FIDTR, node, trgReg, srcReg, (uint8_t)9, (uint8_t)0); //  mask3=9 round to 0, mask4=0

   cg->decReferenceCount(node->getFirstChild());
   node->setRegister(trgReg);
   return trgReg;
   }

TR::Register *
J9::Z::TreeEvaluator::defloorEvaluator(TR::Node *node, TR::CodeGenerator * cg)
   {
   TR::Register* srcReg = cg->evaluate(node->getFirstChild());
   TR::Register * trgReg = cg->allocateFPRegisterPair();

   generateRRFInstruction(cg, TR::InstOpCode::FIXTR, node, trgReg, srcReg, (uint8_t)9, (uint8_t)0); //  mask3=9 round to 0, mask4=0

   cg->decReferenceCount(node->getFirstChild());
   node->setRegister(trgReg);
   return trgReg;
   }

TR::Register *
J9::Z::TreeEvaluator::deconstEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
#ifdef SUPPORT_DFP
   TR::Register * highReg = cg->allocateRegister(TR_FPR);
   TR::Register * lowReg = cg->allocateRegister(TR_FPR);
   TR::Register * targetReg = cg->allocateFPRegisterPair(lowReg, highReg);

   long double value = node->getLongDouble();
   typedef struct
      {
      double dH;
      double dL;
      } twoDblType;
   union
      {
      twoDblType dd;
      long double ldbl;
      } udd;

   udd.ldbl = value;
   generateS390ImmOp(cg, TR::InstOpCode::LD, node, highReg, udd.dd.dH);
   generateS390ImmOp(cg, TR::InstOpCode::LD, node, lowReg, udd.dd.dL);

   node->setRegister(targetReg);
   return targetReg;
#else
   TR_ASSERT_FATAL(false, "No evaulator available for deconst if SUPPORT_DFP is not set");
   return NULL;
#endif
   }

inline TR::Register *
deloadHelper(TR::Node * node, TR::CodeGenerator * cg, TR::MemoryReference * srcMR)
   {
   TR::MemoryReference * loMR = srcMR;
   TR::MemoryReference * hiMR;
   if (loMR == NULL)
      {
      loMR = generateS390MemoryReference(node, cg);
      }
   hiMR = generateS390MemoryReference(*loMR, 8, cg);
   // FP reg pairs for long double: FPR0 & FPR2, FPR4 & FPR6, FPR1 & FPR3, FPR5 & FPR7 etc..
   TR::Register * lowReg = cg->allocateRegister(TR_FPR);
   TR::Register * highReg = cg->allocateRegister(TR_FPR);
   TR::Register * targetReg = cg->allocateFPRegisterPair(lowReg, highReg);

   generateRXInstruction(cg, TR::InstOpCode::LD, node, highReg, loMR);
   loMR->stopUsingMemRefRegister(cg);
   generateRXInstruction(cg, TR::InstOpCode::LD, node, lowReg, hiMR);
   hiMR->stopUsingMemRefRegister(cg);
   node->setRegister(targetReg);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::deloadEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   return deloadHelper(node, cg, NULL);
   }

inline TR::MemoryReference *
destoreHelper(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * valueChild;
   if (node->getOpCode().isIndirect())
      {
      valueChild = node->getSecondChild();
      }
   else
      {
      valueChild = node->getFirstChild();
      }
  // source returns a reg pair, so... TODO
  TR::Register * srcReg = cg->evaluate(valueChild);

   TR::MemoryReference * loMR = generateS390MemoryReference(node, cg);
   TR::MemoryReference * hiMR = generateS390MemoryReference(*loMR, 8, cg);

   generateRXInstruction(cg, TR::InstOpCode::STD, node, srcReg->getHighOrder(), loMR);
   loMR->stopUsingMemRefRegister(cg);
   generateRXInstruction(cg, TR::InstOpCode::STD, node, srcReg->getLowOrder(), hiMR);
   hiMR->stopUsingMemRefRegister(cg);

   cg->decReferenceCount(valueChild);

   return loMR;
   }

TR::Register *
J9::Z::TreeEvaluator::destoreEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   destoreHelper(node, cg);
   return NULL;
   }

TR::Register *
J9::Z::TreeEvaluator::deRegLoadEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Register * globalReg = node->getRegister();

   if (globalReg == NULL)
      {
      TR::Register * lowReg = cg->allocateRegister(TR_FPR);
      TR::Register * highReg = cg->allocateRegister(TR_FPR);
      globalReg = cg->allocateFPRegisterPair(lowReg, highReg);

      node->setRegister(globalReg);
      }
   return globalReg;
   }

TR::Register *
J9::Z::TreeEvaluator::deRegStoreEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node * child = node->getFirstChild();
   TR::Register * globalReg = cg->evaluate(child);
   cg->decReferenceCount(child);
   return globalReg;
   }

/**
 * Handles DFP setNegative ops
 */
TR::Register *
J9::Z::TreeEvaluator::ddSetNegativeEvaluator(TR::Node * node, TR::CodeGenerator * cg)
    {
   TR::Node *firstChild = node->getFirstChild();
   TR::Register * sourceReg = cg->evaluate(firstChild);
   TR::Register * targetReg = NULL;

   if (node->getDataType()==TR::DecimalLongDouble)
      {
      targetReg = cg->allocateFPRegisterPair();
      generateRRInstruction(cg, TR::InstOpCode::LNDFR, node, targetReg->getHighOrder(), sourceReg->getHighOrder());
      generateRRInstruction(cg, TR::InstOpCode::LDR, node, targetReg->getLowOrder(), sourceReg->getLowOrder());
      }
   else
      {
      targetReg = cg->allocateRegister(TR_FPR);
      generateRRInstruction(cg, TR::InstOpCode::LNDFR, node, targetReg, sourceReg);
      }

   node->setRegister(targetReg);
   cg->decReferenceCount(firstChild);
   return node->getRegister();
    }

/**
 * Handles DFP shl ops
 */
TR::Register *
J9::Z::TreeEvaluator::ddshlEvaluator(TR::Node * node, TR::CodeGenerator * cg)
    {
   TR::Node *numNode = node->getChild(0);
   TR::Node *shiftNode = node->getChild(1);

   TR::Register *numReg = cg->evaluate(numNode);
   TR::Register *targetReg;
   unsigned int shift = (int32_t)shiftNode->get64bitIntegralValue();
   cg->decReferenceCount(shiftNode);
   TR::MemoryReference *shiftRef = generateS390MemoryReference(shift, cg);

   // Float to double
    if (node->getDataType() == TR::DecimalFloat)
        generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, numReg, numReg, 0, false);

   if (node->getDataType()==TR::DecimalLongDouble)
    {
    targetReg = cg->allocateFPRegisterPair();
      generateRXFInstruction(cg, TR::InstOpCode::SLXT, node, targetReg, numReg, shiftRef);
    }
    else
    {
      targetReg = cg->allocateRegister(TR_FPR);
      generateRXFInstruction(cg, TR::InstOpCode::SLDT, node, targetReg, numReg, shiftRef);
    }

    // Double to float
    if (node->getDataType() == TR::DecimalFloat)
        generateRRFInstruction(cg, TR::InstOpCode::LEDTR, node, targetReg, targetReg, 0, false);

   node->setRegister(targetReg);
   cg->decReferenceCount(numNode);
   return node->getRegister();
    }

/**
 * Handles DFP shr ops
 */
TR::Register *
J9::Z::TreeEvaluator::ddshrEvaluator(TR::Node * node, TR::CodeGenerator * cg)
    {
   TR::Node *numNode = node->getChild(0);
   TR::Node *shiftNode = node->getChild(1);

   TR::Register *numReg = cg->evaluate(numNode);
   TR::Register *targetReg;
   unsigned int shift = (int32_t)shiftNode->get64bitIntegralValue();
   cg->decReferenceCount(shiftNode);
   TR::MemoryReference *shiftRef = generateS390MemoryReference(shift, cg);

   // Float to double
    if (node->getDataType() == TR::DecimalFloat)
        generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, numReg, numReg, 0, false);

   if (node->getDataType()==TR::DecimalLongDouble)
    {
    targetReg = cg->allocateFPRegisterPair();
      generateRXFInstruction(cg, TR::InstOpCode::SRXT, node, targetReg, numReg, shiftRef);
    }
   else
    {
      targetReg = cg->allocateRegister(TR_FPR);
      generateRXFInstruction(cg, TR::InstOpCode::SRDT, node, targetReg, numReg, shiftRef);
    }

    // Double to float
    if (node->getDataType() == TR::DecimalFloat)
        generateRRFInstruction(cg, TR::InstOpCode::LEDTR, node, targetReg, targetReg, 0, false);

   node->setRegister(targetReg);
   cg->decReferenceCount(numNode);
   return node->getRegister();
    }

/**
 * Handles DFP shr rounded
 */
TR::Register *
J9::Z::TreeEvaluator::ddshrRoundedEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   // This opcode is a replacement for pdshr (with round = 5); a ddshrRounded would get created by converting a pdshr to ddshrRound.
   // The assumption is thus made here that the value is represented with exponent 0. Thus, to get the correct results, we modify the
   // exponent and then use quantize to convert back to a number with exponent 0, rounding in the process.
   // eg. 1234567 (exp=0) shifted right by 2:
   // Set the exponent to -2: 1234567 (exp=-2), or 12345.67
   // Quantize to a value with exponent 0 using the value 1 (exp=0): the 6 causes a round up, so the result is 12346 (exp=0).
   // Using the rounding method "round to nearest with ties away from 0" gives the "round half away from zero" behaviour used
   // in Cobol and works with negative numbers (since the sign bit is separate and not even considered with that rounding
   // mode): -1234567 shifted right two will be -12346.
   TR::Node *numNode = node->getChild(0);
   TR::Node *shiftNode = node->getChild(1);
   TR::Node *roundQuantumNode = node->getChild(2);

   TR::Register *numReg = cg->evaluate(numNode);
   TR::Register *targetReg;

   // Get the shift amount and set the exponent: for shift right of two, the exponent will become -2
   int32_t shift = (int32_t)shiftNode->get64bitIntegralValue();
   if (node->getDataType()==TR::DecimalLongDouble)
      shift = TR_DECIMAL_LONG_DOUBLE_BIAS - shift;
   else
      shift = TR_DECIMAL_DOUBLE_BIAS - shift;

   TR::Register *biasedExpReg = cg->allocate64bitRegister();
   generateRIInstruction(cg, TR::InstOpCode::LGHI, node, biasedExpReg, shift);

   // Float to double
   if (node->getDataType() == TR::DecimalFloat)
      generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, numReg, numReg, 0, false);

   if (node->getDataType()==TR::DecimalLongDouble)
      {
      TR::RegisterDependencyConditions *deps = NULL;
      if (TR::Compiler->target.is32Bit() && !cg->use64BitRegsOn32Bit())
         {
         deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 1, cg);
         deps->addPostCondition(biasedExpReg, TR::RealRegister::GPR0);
         }

      targetReg = cg->allocateFPRegisterPair();
      TR::Instruction *inst = generateRRFInstruction(cg, TR::InstOpCode::IEXTR, node, targetReg, biasedExpReg, numReg);

      if (deps)
         inst->setDependencyConditions(deps);
      }
   else
      {
      targetReg = cg->allocateRegister(TR_FPR);
      generateRRFInstruction(cg, TR::InstOpCode::IEDTR, node, targetReg, biasedExpReg, numReg);
      }

   cg->decReferenceCount(shiftNode);

    // Round, using the quantize instruction
   TR::Register *constReg = cg->evaluate(roundQuantumNode);
   if (node->getDataType() == TR::DecimalLongDouble)
      generateRRFInstruction(cg, TR::InstOpCode::QAXTR, node, targetReg, constReg, targetReg, 0xC);
   else
      generateRRFInstruction(cg, TR::InstOpCode::QADTR, node, targetReg, constReg, targetReg, 0xC);

   cg->decReferenceCount(roundQuantumNode);

   // Double to float
   if (node->getDataType() == TR::DecimalFloat)
      generateRRFInstruction(cg, TR::InstOpCode::LEDTR, node, targetReg, targetReg, 0, false);

   node->setRegister(targetReg);
   cg->stopUsingRegister(biasedExpReg);
   cg->decReferenceCount(numNode);
   return node->getRegister();
   }

/**
 * Handles DFP modify precision ops
 */
TR::Register *
J9::Z::TreeEvaluator::ddModifyPrecisionEvaluator(TR::Node * node, TR::CodeGenerator * cg)
    {
   TR::Node *numNode = node->getChild(0);
   TR::Register *numReg = cg->evaluate(numNode);
   TR::Register *targetReg;

   // To set precision to p, shift left by maximum_precision - p (shifting out all but p digits of the original), then shift right by the same amount
   unsigned int newP = node->getDFPPrecision();
   if (node->getDataType() == TR::DecimalLongDouble)
      newP = TR::DataType::getMaxExtendedDFPPrecision() - newP;
   else
      newP = TR::DataType::getMaxLongDFPPrecision() - newP;
   TR::MemoryReference *shiftRef = generateS390MemoryReference(newP, cg);

   // Float to double
    if (node->getDataType() == TR::DecimalFloat)
        generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, numReg, numReg, 0, false);

   if (node->getDataType()==TR::DecimalLongDouble)
    {
    targetReg = cg->allocateFPRegisterPair();
      generateRXFInstruction(cg, TR::InstOpCode::SLXT, node, targetReg, numReg, shiftRef);
      shiftRef = generateS390MemoryReference(newP, cg);
      generateRXFInstruction(cg, TR::InstOpCode::SRXT, node, targetReg, targetReg, shiftRef);
    }
   else
    {
      targetReg = cg->allocateRegister(TR_FPR);
      generateRXFInstruction(cg, TR::InstOpCode::SLDT, node, targetReg, numReg, shiftRef);
      shiftRef = generateS390MemoryReference(newP, cg);
      generateRXFInstruction(cg, TR::InstOpCode::SRDT, node, targetReg, targetReg, shiftRef);
    }

    // Double to float
    if (node->getDataType() == TR::DecimalFloat)
        generateRRFInstruction(cg, TR::InstOpCode::LEDTR, node, targetReg, targetReg, 0, false);

   node->setRegister(targetReg);
   cg->decReferenceCount(numNode);
   return node->getRegister();
    }

TR::Register *
J9::Z::TreeEvaluator::ddcleanEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR::Register* sreg = cg->evaluate(node->getFirstChild());
   TR::Register* zreg = cg->allocateRegister(TR_FPR);
   TR::Register* treg = cg->allocateRegister(TR_FPR);

   // the below sequence will change a -0 to +0 and leave all other values unchanged
   generateRRRInstruction(cg, TR::InstOpCode::SDTR, node, zreg, sreg, sreg);
   generateRRRInstruction(cg, TR::InstOpCode::ADTR, node, treg, sreg, zreg);

   cg->decReferenceCount(node->getFirstChild());
   cg->stopUsingRegister(zreg);
   node->setRegister(treg);
   return node->getRegister();
   }

TR::Register *
J9::Z::TreeEvaluator::decleanEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR::Register* sreg = cg->evaluate(node->getFirstChild());
   TR::Register* zreg = cg->allocateFPRegisterPair();
   TR::Register* treg = cg->allocateFPRegisterPair();

   // the below sequence will change a -0 to +0 and leave all other values unchanged
   generateRRRInstruction(cg, TR::InstOpCode::SXTR, node, zreg, sreg, sreg);
   generateRRRInstruction(cg, TR::InstOpCode::AXTR, node, treg, sreg, zreg);

   cg->decReferenceCount(node->getFirstChild());
   cg->stopUsingRegister(zreg);
   node->setRegister(treg);
   return node->getRegister();
   }

TR::Register *
J9::Z::TreeEvaluator::dd2iEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR::Node * firstChild = node->getFirstChild();
   TR::Register * srcReg = cg->evaluate(firstChild);
   TR::Register * tempDDReg = NULL;
   TR::Register * targetReg = cg->allocate64bitRegister();

   TR::InstOpCode::Mnemonic convertOpCode;
   switch (firstChild->getDataType())
      {
      case TR::DecimalFloat:
         convertOpCode = TR::InstOpCode::CGDTR;
         tempDDReg = cg->allocateRegister(TR_FPR);
         break;
      case TR::DecimalDouble:
         convertOpCode = TR::InstOpCode::CGDTR;
         tempDDReg = srcReg;
         break;
      case TR::DecimalLongDouble:
         convertOpCode = TR::InstOpCode::CGXTR;
         tempDDReg = srcReg;
         break;
      default:
         TR_ASSERT( 0, "dfpToLong: unsupported opcode\n");
         break;
      }

   // Float to double
    if (firstChild->getDataType() == TR::DecimalFloat)
        generateRRFInstruction(cg, TR::InstOpCode::LDETR, node, tempDDReg, srcReg, 0, false);

   generateRRFInstruction(cg, convertOpCode, node, targetReg, tempDDReg, 0x9, true);

   cg->decReferenceCount(firstChild);
   if (firstChild->getDataType() == TR::DecimalFloat)
     cg->stopUsingRegister(tempDDReg);

   node->setRegister(targetReg);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::pd2iEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pd2i",node);
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "PD-Op/%s", node->getOpCode().getName()),
                            1, TR::DebugCounter::Cheap);
   TR::Register * reg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      reg = generateVectorPackedToBinaryConversion(node, TR::InstOpCode::VCVB, cg);
      }
   else
      {
      reg = generatePackedToBinaryConversion(node, TR::InstOpCode::CVB, cg);
      }

   cg->traceBCDExit("pd2i",node);
   return reg;
   }

TR::Register *
J9::Z::TreeEvaluator::pd2lEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pd2l",node);
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "PD-Op/%s", node->getOpCode().getName()),
                            1, TR::DebugCounter::Cheap);
   TR::Register * reg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      reg = generateVectorPackedToBinaryConversion(node, TR::InstOpCode::VCVBG, cg);
      }
   else
      {
      reg = generatePackedToBinaryConversion(node, TR::InstOpCode::CVBG, cg);
      }

   cg->traceBCDExit("pd2l",node);
   return reg;
   }

/** \brief Reconstruct an address node for byte array packed decimal
 *
 * TODO: Remove duplication.
 * This is a duplicate function of DataAccessAccelerator::constructAddressNode(); and ideally
 * we should restructure variable precision pd2i/pd2l trees to avoid constructing nodes in the codegen.
 * However, this is a potentially large change as decimalPrecision is a TR::Node property and is used by
 * many optimizations such as the simplifier.
*/
TR::Node*
J9::Z::TreeEvaluator::constructDAAAddressPointer(TR::Node* callNode, TR::CodeGenerator* cg)
   {
   TR::Node* base = callNode->getChild(0);
   TR::Node* index = callNode->getChild(1);

   TR::Node * pdBufAddressNode = NULL;
   TR::Node * pdBufPositionNode = NULL;

   if (callNode->getSymbol()->getResolvedMethodSymbol())
      {
      if (callNode->getSymbol()->getResolvedMethodSymbol()->getRecognizedMethod())
         {
         if ((callNode->getSymbol()->getResolvedMethodSymbol()->getRecognizedMethod() == TR::com_ibm_dataaccess_DecimalData_convertPackedDecimalToInteger_ByteBuffer_)
               || (callNode->getSymbol()->getResolvedMethodSymbol()->getRecognizedMethod() == TR::com_ibm_dataaccess_DecimalData_convertPackedDecimalToLong_ByteBuffer_))
            {
            pdBufAddressNode = callNode->getChild(4);
            pdBufPositionNode = callNode->getChild(6);
            return TR::Node::create(TR::l2a, 1, TR::Node::create(TR::ladd, 2, pdBufAddressNode, TR::Node::create(TR::i2l, 1, TR::Node::create(TR::iadd, 2, pdBufPositionNode, index))));
            }
         }
      }

   if (TR::Compiler->target.is64Bit())
      {
      TR::Node* addressBase   = base;
      TR::Node* addressIndex  = TR::Node::create(TR::i2l,    1, index);
      TR::Node* addressHeader = TR::Node::create(TR::lconst, 0, 0);
      TR::Node* addressOffset = TR::Node::create(TR::aladd,  2, addressHeader, addressIndex);

      // Update the address header size
      addressHeader->setLongInt(TR::Compiler->om.contiguousArrayHeaderSizeInBytes());

      // Compute the final address as base + header + index
      return TR::Node::create(TR::aladd, 2, addressBase, addressOffset);
      }
   else
      {
      TR::Node* addressBase   = base;
      TR::Node* addressIndex  = index;
      TR::Node* addressHeader = TR::Node::create(TR::iconst, 0, 0);
      TR::Node* addressOffset = TR::Node::create(TR::aiadd,  2, addressHeader, addressIndex);

      // Update the address header size
      addressHeader->setInt(TR::Compiler->om.contiguousArrayHeaderSizeInBytes());

      // Compute the final address as base + header + index
      return TR::Node::create(TR::aiadd, 2, addressBase, addressOffset);
      }
   }

TR::Register*
J9::Z::TreeEvaluator::pd2lVariableEvaluator(TR::Node* node, TR::CodeGenerator* cg, bool isUseVectorBCD)
   {
   cg->traceBCDEntry("pd2lVariableEvaluator",node);
   cg->generateDebugCounter("PD-Op/pd2l-var", 1, TR::DebugCounter::Cheap);

   TR::Node* pdOpNode      = node->getChild(0);
   TR::Node* pdAddressNode = constructDAAAddressPointer(pdOpNode, cg);
   cg->incReferenceCount(pdAddressNode);

   TR::Compilation *comp = cg->comp();

   // This function handles PD2I and PD2L
   bool PD2I = pdOpNode->getOpCode().getOpCodeValue() == TR::icall;

   TR::Register* returnReg = PD2I ? cg->allocateRegister() : cg->allocate64bitRegister();

   TR::Register* LReg = NULL;
   TR::Register* HReg = NULL;

   TR::RegisterPair* regPair = NULL;

   // We must handle 32 bit registers (only for PD2L)
   bool useRegPair = !PD2I && !(TR::Compiler->target.is64Bit() || cg->use64BitRegsOn32Bit());
   TR::InstOpCode::Mnemonic conversionOp = PD2I ? TR::InstOpCode::VCVB : TR::InstOpCode::VCVBG;

   if (useRegPair)
      {
      LReg = cg->allocateRegister();
      HReg = cg->allocateRegister();

      // A register pair consists of consecutive Low and High registers
      regPair = cg->allocateConsecutiveRegisterPair(LReg, HReg);
      }

   TR::Register* callAddrReg = cg->evaluate(pdAddressNode);
   TR::Register* precisionReg = cg->evaluate(pdOpNode->getChild(2));
   TR::Register* lengthReg = cg->allocateRegister();
   TR_ASSERT(precisionReg && (precisionReg->getKind() == TR_GPR), "precision should be a 32bit GPR");

   // byteLength = precision/2 + 1. Note that the length codes of all instructions are (byteLength-1).
   // Thus, lengthCode = precision/2
   if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z196))
      {
      generateRSInstruction(cg, TR::InstOpCode::SRAK, pdOpNode, lengthReg, precisionReg, 0x1, NULL);
      }
   else
      {
      generateRRInstruction(cg, TR::InstOpCode::LR, pdOpNode, lengthReg, precisionReg);
      generateRSInstruction(cg, TR::InstOpCode::SRA, pdOpNode, lengthReg, 0x1);
      }

   TR::MemoryReference* sourceMR = generateS390MemoryReference(callAddrReg, 0, cg);
   static bool disableTPBeforePD2I = feGetEnv("TR_DisableTPBeforePD2I") != NULL;

   if (isUseVectorBCD)
      {
      // variable length load + vector convert to binary
      TR::Register* vPDReg = cg->allocateRegister(TR_VRF);
      generateVRSdInstruction(cg, TR::InstOpCode::VLRLR, node, lengthReg, vPDReg, sourceMR);

      if (!disableTPBeforePD2I)
         {
         generateVRRgInstruction(cg, TR::InstOpCode::VTP, node, vPDReg);
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC,
                                       TR::InstOpCode::COND_MASK7,
                                       node, cg->getCurrentBCDCHKHandlerLabel());
         }

      generateVRRiInstruction(cg, conversionOp, node, returnReg, vPDReg, 1);      // set CC for overflow
      cg->stopUsingRegister(vPDReg);
      }
   else
      {
      const uint32_t tempSRSize = PD2I ? cg->getPackedToIntegerFixedSize()
                                       : cg->getPackedToLongFixedSize();

      // Allocate space on the stack for the PD to be copied to
      TR_StorageReference* tempSR = TR_StorageReference::createTemporaryBasedStorageReference(tempSRSize, comp);

      tempSR->setTemporaryReferenceCount(1);

      TR::MemoryReference* ZAPtargetMR = generateS390MemRefFromStorageRef(node, tempSR, cg, false, true);
      TR::Register* zapTargetBaseReg = cg->allocateRegister();
      /*
       * Insert an intermediate LA instruction before the ZAP+EX sequence to hold the ZAP target base address
       * value. Intermediate LA instructions are needed for all instructions targeted by EX (or EXRL) and have
       * memory references with unmaterialized base/index registers. This is done so that we are immune to
       * large displacement instruction adjustments.
       *
       * In this particular case, the instruction selection phase emits ZAP+EX. The peephole optimization later
       * replaces the EX with an EXRL and expands to three instructions:
       *
       * BRC [to EXRl]
       * ZAP
       * EXRL [of ZAP]
       *
       * These three instructions work fine if they are all together. If the ZAP is targeting a memory location that's
       * far away down the stack, large displacement instructions will be added in the memory reference binary encoding phase
       * to create the following functionally incorrect instruction sequence:
       *
       * BRC [to EXRL]
       * STG
       * LGHI
       * LA
       * ZAP
       * LG
       * EXRL
       *
       *
       * Having an intermediate LA instruction here prevents the large displacement adjustments on the ZAP instruction and holds
       * the BRC+ZAP+EXRL instructions together.
      */
      generateRXInstruction(cg, TR::InstOpCode::LA, node, zapTargetBaseReg, ZAPtargetMR);

      if (!disableTPBeforePD2I)
         {
         TR::Register* tempLengthForTP = cg->allocateRegister();

         if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z196))
            {
            generateRSInstruction(cg, TR::InstOpCode::SLAK, node, tempLengthForTP, lengthReg, 4);
            }
         else
            {
            generateRRInstruction(cg, TR::InstOpCode::LR, node, tempLengthForTP, lengthReg);
            generateRSInstruction(cg, TR::InstOpCode::SLA, node, tempLengthForTP, 4);
            }

         auto* testPackedInstruction = generateRSLInstruction(cg, TR::InstOpCode::TP, node, 0, generateS390MemoryReference(*sourceMR, 0, cg));

         generateEXDispatch(node, cg, tempLengthForTP, testPackedInstruction);

         // Fallback to the OOL path if anything is wrong with the input packed decimal
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK7, node, cg->getCurrentBCDCHKHandlerLabel());

         cg->stopUsingRegister(tempLengthForTP);
         }

      TR::Instruction* instrZAP = generateSS2Instruction(cg, TR::InstOpCode::ZAP, node,
                                                         tempSRSize - 1,
                                                         generateS390MemoryReference(zapTargetBaseReg, 0, cg),
                                                         0, sourceMR);

      generateEXDispatch(node, cg, lengthReg, instrZAP);

      if (PD2I)
         {
         generateRXInstruction (cg, TR::InstOpCode::CVB, node, returnReg, generateS390MemoryReference(*ZAPtargetMR, 0, cg));
         }
      else
         {
         generateRXYInstruction(cg, TR::InstOpCode::CVBG, node, returnReg, generateS390MemoryReference(*ZAPtargetMR, 0, cg));
         }

      tempSR->setTemporaryReferenceCount(0);
      cg->stopUsingRegister(zapTargetBaseReg);
      }

   if (useRegPair)
      {
      generateRRInstruction(cg, TR::InstOpCode::LR,   node, LReg, returnReg);
      generateRSInstruction(cg, TR::InstOpCode::SRLG, node, HReg, returnReg, 32);

      // The result is now stored in the register pair, so we can discard the old register
      cg->stopUsingRegister(returnReg);

      returnReg = regPair;
      }

   cg->decReferenceCount(pdAddressNode);
   cg->stopUsingRegister(lengthReg);
   pdOpNode->setRegister(returnReg);

   // Create a debug counter to track how often we execute the inline path for variable operations
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(),
                                                               "DAA/variable/inline/(%s)/%p",
                                                               cg->comp()->signature(), node),
                            1, TR::DebugCounter::Undetermined);

   cg->traceBCDExit("pd2lVariableEvaluator",node);

   return returnReg;
   }

TR::Register *
J9::Z::TreeEvaluator::generateVectorPackedToBinaryConversion(TR::Node * node, TR::InstOpCode::Mnemonic op, TR::CodeGenerator * cg)
   {
   TR_ASSERT( op == TR::InstOpCode::VCVB || op == TR::InstOpCode::VCVBG,"unexpected opcode in gen vector pd2i\n");
   bool isPDToLong = (op == TR::InstOpCode::VCVBG);
   bool isUseRegPair = isPDToLong && !(TR::Compiler->target.is64Bit() || cg->use64BitRegsOn32Bit());

   TR::Register *rResultReg = (isPDToLong) ? cg->allocate64bitRegister() : cg->allocateRegister();
   TR::Register *lowReg = NULL;
   TR::Register *highReg = NULL;
   TR::RegisterPair *rResultRegPair = NULL;

   // evaluate pdload
   TR::Node *pdValueNode = node->getFirstChild();
   TR::Register *vPdValueReg = cg->evaluate(pdValueNode);
   TR_ASSERT(vPdValueReg->getKind() == TR_VRF || vPdValueReg->getKind() == TR_FPR, "Vector register expected.");

   static bool disableTPBeforePD2I = feGetEnv("TR_DisableTPBeforePD2I") != NULL;
   if (!disableTPBeforePD2I)
      {
      generateVRRgInstruction(cg, TR::InstOpCode::VTP, node, vPdValueReg);
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC,
                                    TR::InstOpCode::COND_MASK7, node,
                                    cg->getCurrentBCDCHKHandlerLabel());
      }

   // Convert to signed binary of either 32-bit or 64-bit long
   generateVRRiInstruction(cg, op, node, rResultReg, vPdValueReg, 0x1);

   if (isUseRegPair)
      {
      lowReg = cg->allocateRegister();
      highReg = cg->allocateRegister();
      rResultRegPair = cg->allocateConsecutiveRegisterPair(lowReg, highReg);

      generateRRInstruction(cg, TR::InstOpCode::LR, node, lowReg, rResultReg);
      generateRSInstruction(cg, TR::InstOpCode::SRLG, node, highReg, rResultReg, 32);

      cg->stopUsingRegister(rResultReg);
      rResultReg = rResultRegPair;
      }

   cg->decReferenceCount(pdValueNode);
   node->setRegister(rResultReg);
   return rResultReg;
   }

TR::Register *
J9::Z::TreeEvaluator::generatePackedToBinaryConversion(TR::Node * node, TR::InstOpCode::Mnemonic op, TR::CodeGenerator * cg)
   {
   TR_ASSERT( op == TR::InstOpCode::CVB || op == TR::InstOpCode::CVBG,"unexpected opcode in generatePackedToBinaryFixedConversion\n");
   TR::Register *targetReg = (op == TR::InstOpCode::CVBG) ? cg->allocate64bitRegister() : cg->allocateRegister();
   TR::RegisterPair *targetRegPair = NULL;
   TR::Register *lowReg = NULL;
   TR::Register *highReg = NULL;
   bool isUseRegPair = (op == TR::InstOpCode::CVBG && !(TR::Compiler->target.is64Bit() || cg->use64BitRegsOn32Bit()));

   TR::Node *firstChild = node->getFirstChild();
   TR_PseudoRegister *firstReg = cg->evaluateBCDNode(firstChild);
   int32_t requiredSourceSize = op == TR::InstOpCode::CVB ? cg->getPackedToIntegerFixedSize() : cg->getPackedToLongFixedSize();
   TR::MemoryReference *sourceMR = cg->materializeFullBCDValue(firstChild,
                                                                          firstReg,
                                                                          requiredSourceSize,
                                                                          requiredSourceSize,
                                                                          false, // updateStorageReference
                                                                          false); // alwaysEnforceSSLimits -- to be used in CVB

   TR_StorageReference *firstStorageReference = firstReg->getStorageReference();
   sourceMR = reuseS390LeftAlignedMemoryReference(sourceMR, firstChild, firstStorageReference, cg, requiredSourceSize, false); // enforceSSLimits=false for CVB

   static bool disableTPBeforePD2I = feGetEnv("TR_DisableTPBeforePD2I") != NULL;

   if (!disableTPBeforePD2I)
      {
      generateRSLInstruction(cg, TR::InstOpCode::TP, node, firstReg->getSize() - 1, generateS390RightAlignedMemoryReference(*sourceMR, firstChild, 0, cg, false));
      generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_MASK7, node, cg->getCurrentBCDCHKHandlerLabel());
      }

   TR::Instruction *inst = NULL;
   if (op == TR::InstOpCode::CVB)
      inst = generateRXInstruction(cg, op, node, targetReg, sourceMR);
   else
      inst = generateRXYInstruction(cg, op, node, targetReg, sourceMR);

   if (sourceMR->getStorageReference() == firstStorageReference)
      firstReg->setHasKnownValidSignAndData();

   if (isUseRegPair)
      {
      lowReg = cg->allocateRegister();
      highReg = cg->allocateRegister();
      targetRegPair = cg->allocateConsecutiveRegisterPair(lowReg, highReg);

      generateRRInstruction(cg, TR::InstOpCode::LR, node, lowReg, targetReg);
      generateRSInstruction(cg, TR::InstOpCode::SRLG, node, highReg, targetReg, 32);
      cg->stopUsingRegister(targetReg);
      targetReg = targetRegPair;
      }

   // Create a debug counter to track how often we execute the inline path
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "DAA/inline/(%s)/%p", cg->comp()->signature(), node), 1, TR::DebugCounter::Undetermined);

   cg->decReferenceCount(firstChild);
   node->setRegister(targetReg);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::i2pdEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("i2pd",node);
   cg->generateDebugCounter("PD-Op/i2pd", 1, TR::DebugCounter::Cheap);
   TR::Register * reg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      reg = generateVectorBinaryToPackedConversion(node, TR::InstOpCode::VCVD, cg);
      }
   else
      {
      reg = generateBinaryToPackedConversion(node, TR::InstOpCode::CVD, cg);
      }

   cg->traceBCDExit("i2pd",node);
   return reg;
   }

TR::Register *
J9::Z::TreeEvaluator::l2pdEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("l2pd",node);
   cg->generateDebugCounter("PD-Op/l2pd", 1, TR::DebugCounter::Cheap);
   TR::Register * reg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      reg = generateVectorBinaryToPackedConversion(node, TR::InstOpCode::VCVDG, cg);
      }
   else
      {
      reg = generateBinaryToPackedConversion(node, TR::InstOpCode::CVDG, cg);
      }

   cg->traceBCDExit("l2pd",node);
   return reg;
   }

/**
 * \brief This evaluator helper function evaluates i2pd and l2pd conversion nodes
 * using CVD or CVDG instructions.
 *
*/
TR::Register *
J9::Z::TreeEvaluator::generateBinaryToPackedConversion(TR::Node * node,
                                                       TR::InstOpCode::Mnemonic op,
                                                       TR::CodeGenerator * cg)
   {
   TR_ASSERT( op == TR::InstOpCode::CVD || op == TR::InstOpCode::CVDG,
              "unexpected opcode in generateBinaryToPackedConversion\n");

   TR_PseudoRegister *targetReg = cg->allocatePseudoRegister(node->getDataType());
   TR::Compilation *comp = cg->comp();
   bool isI2PD = op == TR::InstOpCode::CVD;
   TR_StorageReference *hint = node->getStorageReferenceHint();
   int32_t cvdSize = isI2PD ? cg->getIntegerToPackedFixedSize() : cg->getLongToPackedFixedSize();
   TR_StorageReference *targetStorageReference = hint ? hint : TR_StorageReference::createTemporaryBasedStorageReference(cvdSize, comp);
   targetReg->setStorageReference(targetStorageReference, node);

   TR::Node *firstChild = node->getFirstChild();
   TR::Register *firstReg = cg->evaluate(firstChild);
   TR::MemoryReference *targetMR = generateS390LeftAlignedMemoryReference(node,
                                                                          targetStorageReference,
                                                                          cg,
                                                                          cvdSize,
                                                                          false); // enforceSSLimits=false for CVD

   bool isUseRegPair = !isI2PD && (firstReg->getRegisterPair() != NULL);

   if (isUseRegPair)
      {
      traceMsg(comp, "Using regPair on l2pd\n");
      TR::Register *tempReg = cg->allocate64bitRegister();
      generateRSInstruction(cg, TR::InstOpCode::SLLG, node, tempReg, firstReg->getRegisterPair()->getHighOrder(), 32);
      generateRRInstruction(cg, TR::InstOpCode::LR, node, tempReg, firstReg->getRegisterPair()->getLowOrder());
      firstReg = tempReg;
      }

   if (isI2PD)
      generateRXInstruction(cg, op, node, firstReg, targetMR);
   else
      generateRXYInstruction(cg, op, node, firstReg, targetMR);

   targetReg->setIsInitialized();

   cg->stopUsingRegister(firstReg);
   cg->decReferenceCount(firstChild);
   node->setRegister(targetReg);
   return targetReg;
   }


TR::Register *
J9::Z::TreeEvaluator::pdnegEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pdneg",node);
   cg->generateDebugCounter("PD-Op/pdneg", 1, TR::DebugCounter::Cheap);

   TR_ASSERT(node->getNumChildren() == 1, "pdneg should only have 1 child");

   TR::Node *srcNode = node->getFirstChild();
   TR_PseudoRegister *srcReg = cg->evaluateBCDNode(srcNode);
   TR::Compilation *comp = cg->comp();

   TR::MemoryReference *sourceMR = generateS390RightAlignedMemoryReference(srcNode, srcReg->getStorageReference(), cg);

   // also do for assumed (PFD) preferred and clean signs?
   int32_t srcSign = srcReg->hasKnownOrAssumedSignCode() ? srcReg->getKnownOrAssumedSignCode() : TR::DataType::getInvalidSignCode();
   bool useRegBasedSequence = cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_z10) && srcReg->hasKnownValidSign();
   bool isSrcSign0xF     = srcSign == 0xf;
   bool isSimpleSignFlip = srcSign == TR::DataType::getPreferredPlusCode() ||
                           srcSign == TR::DataType::getPreferredMinusCode() ||
                           srcReg->hasKnownOrAssumedPreferredSign() ||
                           srcReg->hasKnownOrAssumedCleanSign();
   bool isSimpleSignSet = isSrcSign0xF || isSimpleSignFlip;
   bool needsFullInitialization = !useRegBasedSequence || isSimpleSignSet;
   bool isTruncation = node->getDecimalPrecision() < srcReg->getDecimalPrecision();
   bool isWiden = node->getDecimalPrecision() > srcReg->getDecimalPrecision();

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tpdnegEvaluator: isTruncation=%s, isWiden=%s, srcSign = 0x%x, srcSignIsValid=%s, isSimpleSignSet=%s, useRegBasedSequence=%s, needsFullInitialization=%s (== !useRegBasedSequence || isSimpleSignSet)\n",
         isTruncation ? "yes":"no",
         isWiden ? "yes":"no",
         srcSign,
         srcReg->hasKnownValidSign() ? "yes":"no",
         isSimpleSignSet ? "yes":"no",
         useRegBasedSequence?"yes":"no",
         needsFullInitialization? "yes":"no");


   TR_PseudoRegister *targetReg = evaluateBCDSignModifyingOperand(node,
                                                                  false,      // isEffectiveNop=false
                                                                  false,      // isNondestructiveNop=false
                                                                  needsFullInitialization,
                                                                  sourceMR,
                                                                  cg);
   targetReg->setDecimalPrecision(std::min<int32_t>(node->getDecimalPrecision(), srcReg->getDecimalPrecision()));

   TR::MemoryReference *destMR = generateS390LeftAlignedMemoryReference(node, targetReg->getStorageReference(), cg, targetReg->getSize());

   if (srcReg->hasKnownValidData())
      targetReg->setHasKnownValidData();

   if (!needsFullInitialization && !targetReg->isInitialized() && targetReg->getSize() > 1)
      {
      int32_t mvcSize = targetReg->getSize() - 1;  // do not include the least significant byte as this is done as part of the sign setting below
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\ttargetReg is not init and size %d > 1 so gen MVC with size targetRegSize-1 = %d and leftMostByte %d\n",
            targetReg->getSize(),mvcSize,targetReg->getSize());
      generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                             mvcSize-1,
                             reuseS390LeftAlignedMemoryReference(destMR, node, targetReg->getStorageReference(), cg, targetReg->getSize()),
                             reuseS390LeftAlignedMemoryReference(sourceMR, srcNode, srcReg->getStorageReference(), cg, targetReg->getSize()));
      }

   bool isSignManipulation = false;
   if (isSrcSign0xF)
      {
      cg->genSignCodeSetting(node, targetReg, targetReg->getSize(), destMR, TR::DataType::getPreferredMinusCode(), srcReg, 0, false); // digitsToClear=0, numericNibbleIsZero=false
      if (targetReg->getDataType() == TR::PackedDecimal && targetReg->isEvenPrecision())
         cg->genZeroLeftMostDigitsIfNeeded(node, targetReg, targetReg->getSize(), 1, destMR);
      }
   else if (isSimpleSignFlip)
      {
      isSignManipulation = true;
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tsrcReg has known preferred (%s) or known clean (%s) sign so gen XI 0x1 of sign byte to flip it\n",
            srcReg->hasKnownPreferredSign()?"yes":"no",srcReg->hasKnownCleanSign()?"yes":"no");
      generateSIInstruction(cg, TR::InstOpCode::XI, node, reuseS390LeftAlignedMemoryReference(destMR, node, targetReg->getStorageReference(), cg, 1), 0x01);
      if (targetReg->getDataType() == TR::PackedDecimal && targetReg->isEvenPrecision())
         cg->genZeroLeftMostDigitsIfNeeded(node, targetReg, targetReg->getSize(), 1, destMR);

      }
   else if (useRegBasedSequence)
      {
      isSignManipulation = true;

      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\ttargetReg has unknown but valid sign so generate register based decode sequence\n");

      TR::Register *tempSign = cg->allocateRegister();
      TR::Register *targetSign = cg->allocateRegister();
      TR::Register *targetData = cg->allocate64bitRegister();

      generateRXInstruction(cg, TR::InstOpCode::LB, node, tempSign, reuseS390LeftAlignedMemoryReference(sourceMR, srcNode, srcReg->getStorageReference(), cg, 1));

      generateRRInstruction(cg, TR::InstOpCode::LR, node, targetSign, tempSign);
      generateRRInstruction(cg, TR::InstOpCode::LR, node, targetData, tempSign);

      generateRIInstruction(cg, TR::InstOpCode::AHI, node, tempSign, 1);
      generateRIInstruction(cg, TR::InstOpCode::NILL, node, targetData, 0xF0);

      if (targetReg->getDataType() == TR::PackedDecimal && targetReg->isEvenPrecision())
         cg->genZeroLeftMostDigitsIfNeeded(node, targetReg, targetReg->getSize(), 1, destMR);

      if (cg->getS390ProcessorInfo()->supportsArch(TR_S390ProcessorInfo::TR_zEC12))
         generateRIEInstruction(cg, TR::InstOpCode::RISBGN, node, targetData, tempSign, 63, 63, 64-3);
      else
         generateRIEInstruction(cg, TR::InstOpCode::RISBG, node, targetData, tempSign, 63, 63, 64-3);

      generateRRInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::NGR : TR::InstOpCode::NR, node, targetSign, targetData);
      generateRILInstruction(cg, TR::InstOpCode::XILF, node, targetSign, 13);

      generateRXInstruction(cg, TR::InstOpCode::STC, node, targetSign, reuseS390LeftAlignedMemoryReference(destMR, node, targetReg->getStorageReference(), cg, 1));

      cg->stopUsingRegister(tempSign);
      cg->stopUsingRegister(targetSign);
      cg->stopUsingRegister(targetData);
      }
   else
      {
      isSignManipulation = true;
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\ttargetReg has possibly invalid sign so generate memory based decode sequence\n");

      TR::Register *sourceSign = cg->allocateRegister();
      TR::Register *regMask = NULL;

      generateRXInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::LLGC : TR::InstOpCode::LLC,
           node, sourceSign, reuseS390LeftAlignedMemoryReference(sourceMR, srcNode, srcReg->getStorageReference(), cg, 1));

      uint8_t signCodes[TR_NUM_DECIMAL_CODES];
      for (int32_t i = 0; i < TR_NUM_DECIMAL_CODES; i++)
         {
         TR_BCDSignCode normalizedSign = decimalSignCodeMap[i];
         if (normalizedSign == bcd_invalid_sign)
            signCodes[i] = i;
         else if (normalizedSign == bcd_plus || normalizedSign == bcd_unsigned)
            signCodes[i] = TR::DataType::getPreferredMinusCode();
         else if (normalizedSign == bcd_minus)
            signCodes[i] = TR::DataType::getPreferredPlusCode();
         else
            TR_ASSERT(false,"unexpected normalized sign for raw sign 0x%x\n",i);
         }
      size_t paddingLitPoolOffset = cg->fe()->findOrCreateLiteral(comp, signCodes, TR_NUM_DECIMAL_CODES);
      TR::Register *litPoolBaseReg = NULL;
      if(cg->isLiteralPoolOnDemandOn())
         {
         litPoolBaseReg = cg->allocateRegister();
         generateLoadLiteralPoolAddress(cg, node, litPoolBaseReg);
         }
      else
         {
         litPoolBaseReg = cg->allocateRegister();
         generateRRInstruction(cg, TR::InstOpCode::getLoadRegOpCode(), node, litPoolBaseReg, cg->getLitPoolRealRegister());
         }

      generateRIInstruction(cg, TR::InstOpCode::NILL, node, sourceSign, 0x0F);

      generateRRInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::ALGR : TR::InstOpCode::ALR, node, litPoolBaseReg, sourceSign);

      if (targetReg->getDataType() == TR::PackedDecimal && targetReg->isEvenPrecision())
         cg->genZeroLeftMostDigitsIfNeeded(node, targetReg, targetReg->getSize(), 1, destMR);

      int32_t mvnSize = 1;
      generateSS1Instruction(cg, TR::InstOpCode::MVN, node,
                             mvnSize-1,
                             reuseS390LeftAlignedMemoryReference(destMR, node, targetReg->getStorageReference(), cg, 1),
                             generateS390MemoryReference(litPoolBaseReg, paddingLitPoolOffset, cg));

      cg->stopUsingRegister(sourceSign);
      if (regMask)
         cg->stopUsingRegister(regMask);
      if (litPoolBaseReg)
         cg->stopUsingRegister(litPoolBaseReg);
      }

   if (isSignManipulation)
      {
      if (srcReg->hasKnownPreferredSign())
         targetReg->setHasKnownPreferredSign();
      else if (srcReg->hasAssumedPreferredSign())
         targetReg->setHasAssumedPreferredSign();
      else
         targetReg->setSignStateInitialized();

      if (srcReg->hasKnownValidSign())
         targetReg->setHasKnownValidSign();
      }

   targetReg->transferDataState(srcReg);
   targetReg->setIsInitialized();

   node->setRegister(targetReg);
   cg->decReferenceCount(srcNode);
   cg->traceBCDExit("pdneg",node);
   return targetReg;
   }

TR_PseudoRegister *
J9::Z::TreeEvaluator::evaluateToNewStorageReference(TR::Node * node, TR::MemoryReference *sourceMR, TR::CodeGenerator * cg)
   {
   TR::Compilation *comp = cg->comp();
   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tevaluateToNewStorageReference  %p : op %s\n",node,node->getOpCode().getName());

   TR::Node *srcNode = node->getFirstChild();
   TR_PseudoRegister *srcReg = cg->evaluateBCDNode(srcNode);

   TR_PseudoRegister *targetReg = NULL;

   if (srcReg->isInitialized())
      {
      targetReg = cg->allocatePseudoRegister(node->getDataType());
      // overlapping MVOs are very inefficient so ensure that a new storageRef (either a hint or a new temp is used)
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tsrcReg %s from srcNode %p is initialized : either use a node storageRef hint or allocate a new temp storageRef\n",cg->getDebug()->getName(srcReg),srcNode);
      if (node->getOpCode().canHaveStorageReferenceHint() &&
          node->getStorageReferenceHint() &&
          node->getStorageReferenceHint()->mayOverlapWith(srcReg->getStorageReference()) == false)
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\t\tuse storageRef hint #%d on %s %p\n",
               node->getStorageReferenceHint()->getReferenceNumber(),node->getOpCode().getName(),node);
         targetReg->setStorageReference(node->getStorageReferenceHint(), node);
         }
      else
         {
         int32_t symSize = std::max(node->getStorageReferenceSize(), srcReg->getStorageReference()->getSymbolSize());
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\t\ta^a : allocate a new storageRef of size max(nodeSize,srcStorageRefSize) = max(%d,%d) = %d (node %p)\n",
               node->getStorageReferenceSize(),srcReg->getStorageReference()->getSymbolSize(),symSize,node);
         TR_StorageReference *targetStorageReference = TR_StorageReference::createTemporaryBasedStorageReference(symSize, comp);
         targetReg->setStorageReference(targetStorageReference, node);
         cg->freeUnusedTemporaryBasedHint(node);
         if (srcNode->getReferenceCount() > 1 && !srcReg->getStorageReference()->isTemporaryBased())
            {
            TR_ASSERT(srcReg->getStorageReference()->isNodeBasedHint(),"only node based hints should be initialized\n");
            // This is an unfortunate case as we've started to accumulate a result in a final receiver location but now in order to
            // use a non-overlapping MVO we need one new temp and must copy the value (if child->refCount > 1) to a second new temp
            // These situations are minimized by adding offending node operations to endHintOnBCDOperation
            cg->ssrClobberEvaluate(srcNode, sourceMR);
            }
         }
      node->setRegister(targetReg);
      }
   else
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tsrcReg %s from srcNode %p is not initialized : defer to evaluateBCDValueModifyingOperand\n",cg->getDebug()->getName(srcReg),srcNode);
      targetReg = evaluateBCDValueModifyingOperand(node, false, sourceMR, cg); // initTarget=false
      }
   return targetReg;
   }

TR_PseudoRegister *
J9::Z::TreeEvaluator::evaluateBCDValueModifyingOperand(TR::Node * node,
                                                       bool initTarget,
                                                       TR::MemoryReference *sourceMR,
                                                       TR::CodeGenerator * cg,
                                                       bool trackSignState,
                                                       int32_t sourceSize,
                                                       bool alwaysLegalToCleanSign) // alwaysLegalToCleanSign=true then a ZAP can be used to init/widen if another signMod inst is coming (e.g. AP)
   {
   TR_ASSERT(node->getType().isBCD(),"node %p type %s must be BCD\n",node,node->getDataType().toString());
   TR_OpaquePseudoRegister *reg = evaluateValueModifyingOperand(node, initTarget, sourceMR, cg, trackSignState, sourceSize, alwaysLegalToCleanSign);
   TR_PseudoRegister *pseudoReg = reg->getPseudoRegister();
   TR_ASSERT(pseudoReg,"pseudoReg should be non-NULL for node %p\n",node);
   return pseudoReg;
   }


TR_OpaquePseudoRegister *
J9::Z::TreeEvaluator::evaluateValueModifyingOperand(TR::Node * node,
                                                    bool initTarget,
                                                    TR::MemoryReference *sourceMR,
                                                    TR::CodeGenerator * cg,
                                                    bool trackSignState,
                                                    int32_t sourceSize,
                                                    bool alwaysLegalToCleanSign) // alwaysLegalToCleanSign=true then a ZAP can be used to init/widen if another signMod inst is coming (e.g. AP)
   {
   bool isBCD = node->getType().isBCD();
   bool isAggr = node->getType().isAggregate();
   TR_ASSERT(isBCD || isAggr,"node %p type %s must be BCD or aggregate\n",node,node->getDataType().toString());

   TR_OpaquePseudoRegister *targetReg = isBCD ? cg->allocatePseudoRegister(node->getDataType()) : cg->allocateOpaquePseudoRegister(node->getDataType());
   TR_PseudoRegister *targetBCDReg = targetReg->getPseudoRegister();

   TR::Node *firstChild = node->getFirstChild();
   TR_OpaquePseudoRegister *firstReg = cg->evaluateOPRNode(firstChild);
   TR_PseudoRegister *firstBCDReg = firstReg->getPseudoRegister();
   TR_StorageReference *firstStorageReference = firstReg->getStorageReference();
   TR::Compilation *comp = cg->comp();

   bool isInitialized = firstReg->isInitialized();
   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tevaluateValueModifyingOperand for %s (%p) with targetReg %s and firstReg %s (#%d isInit %s), sourceSize=%d : initTarget=%s, alwaysLegalToCleanSign=%s\n",
         node->getOpCode().getName(),node,cg->getDebug()->getName(targetReg),cg->getDebug()->getName(firstReg),
         firstStorageReference->getReferenceNumber(),isInitialized ? "yes":"no",sourceSize,initTarget ? "yes":"no",alwaysLegalToCleanSign ? "yes":"no");

   if (sourceSize == 0)
      sourceSize = firstReg->getSize();

   bool useZAP = false;

   // to avoid a clobber evaluate in the isInitialized case favour initializing to an available store hint and leave the isInitialized child untouched
   // also force to a new hint even if refCount==1 if there is ZAP widening to be done (and save a later clear)
   bool useNewStoreHint = !comp->getOption(TR_DisableNewStoreHint) &&
                          node->getOpCode().canHaveStorageReferenceHint() &&
                          initTarget && // have to also be initializing here otherwise in caller
                          node->getStorageReferenceHint() &&
                          node->getStorageReferenceHint()->isNodeBasedHint() &&
                          (firstChild->getReferenceCount() > 1 || node->getStorageReferenceSize() > sourceSize) &&
                          node->getStorageReferenceHint() != firstStorageReference;

   if (useNewStoreHint && node->getStorageReferenceHint()->getSymbolSize() < node->getStorageReferenceSize())
      {
      useNewStoreHint = false;
      TR_ASSERT(false,"a storageRef hint should be big enough for the node result (%d is not >= %d)\n",
         node->getStorageReferenceHint()->getSymbolSize(),node->getStorageReferenceSize());
      }

   if (isInitialized && !useNewStoreHint)
      {
      // Save the storage reference dependent state leftAlignedZeroDigits, rightAlignedDeadBytes and the derived liveSymbolSize before
      // the possible call to ssrClobberEvaluate below.
      // If a clobber evaluate is done then the above mentioned state will be reset on firstReg (so subsequent commoned uses of firstReg that now
      // use the newly created temporary storage reference are correct). Cache the values here as this state *will* presist up this tree on the targetReg.
      int32_t savedLiveSymbolSize = firstReg->getLiveSymbolSize();
      int32_t savedLeftAlignedZeroDigits = firstReg->getLeftAlignedZeroDigits();
      int32_t savedRightAlignedDeadBytes = firstReg->getRightAlignedDeadBytes();
      int32_t savedRightAlignedIgnoredBytes = firstReg->getRightAlignedIgnoredBytes();
      bool skipClobberEvaluate = false;
      if (node->getOpCode().isBasicOrSpecialPackedArithmetic())
         {
         // The special case of mul/add/sub/div = op1*op1 does not need a clobber evaluate as there are no uses beyond the current node's operation
         if (node->getNumChildren() > 1 &&   // might be a pddivSelect or pdremSelect node (only one child)
             node->getFirstChild() == node->getSecondChild() &&
             node->getFirstChild()->getReferenceCount() == 2 &&
             firstStorageReference->getOwningRegisterCount() == 1)
            {
            skipClobberEvaluate = true;
            }
         }
      if (!skipClobberEvaluate)
         cg->ssrClobberEvaluate(firstChild, sourceMR);
      int32_t resultSize = node->getStorageReferenceSize();
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tisInitialized==true: liveSymSize %d (symSize %d - firstReg->deadAndIgnoredBytes %d), resultSize = %d (nodeSize %d)\n",
            savedLiveSymbolSize,firstStorageReference->getSymbolSize(),firstReg->getRightAlignedDeadAndIgnoredBytes(),resultSize,node->getSize());
      if (savedLiveSymbolSize < resultSize)
         {
         // In this case the source memory slot has been initialized but it is no longer larger enough to contain the result for the current node.
         // Therefore either the size of the symbol must be increased (for autos) or a new larger, memory slot must be created and initialized (for non-autos)
         if (firstStorageReference->isTemporaryBased())
            {
            if (cg->traceBCDCodeGen())
               {
               traceMsg(comp,"\treg->getLiveSymbolSize() < resultSize (%d < %d) so call increaseTemporarySymbolSize\n",savedLiveSymbolSize,resultSize);
               traceMsg(comp,"\t\t * setting rightAlignedDeadBytes %d from firstReg %s to targetReg %s (valueMod incSize)\n",
                  savedRightAlignedDeadBytes,cg->getDebug()->getName(firstReg),cg->getDebug()->getName(targetReg));
               traceMsg(comp,"\t\t * setting rightAlignedIgnoredBytes %d from firstReg %s to targetReg %s (valueMod incSize)\n",
                  savedRightAlignedIgnoredBytes,cg->getDebug()->getName(firstReg),cg->getDebug()->getName(targetReg));
               }
            targetReg->setStorageReference(firstStorageReference, node);
            targetReg->increaseTemporarySymbolSize(resultSize - savedLiveSymbolSize);
            targetReg->setRightAlignedDeadBytes(savedRightAlignedDeadBytes);
            targetReg->setRightAlignedIgnoredBytes(savedRightAlignedIgnoredBytes);
            }
         else
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\t\tfirstStorageReference is not temporary based and liveSymSize < resultSize (%d < %d) so alloc and init a new temp slot and clear left most bytes\n",
                  savedLiveSymbolSize,resultSize);
            int32_t destLength = resultSize;
            int32_t srcLength = sourceSize;
            // If the firstStorageReference is not a temp or a hint then the recursive dec in setStorageReference() will be wrong.
            // This should always be true because this is the initialized case and it is not legal to initialize a non-temp or non-hint.
            TR_ASSERT( firstStorageReference->isNodeBasedHint(), "expecting the srcStorargeReference to be a node based hint\n");
            bool performExplicitWidening = false;
            cg->initializeNewTemporaryStorageReference(node, targetReg, destLength, firstChild, firstReg, srcLength, sourceMR, performExplicitWidening, alwaysLegalToCleanSign, trackSignState);
            if (targetBCDReg)
               {
               TR_ASSERT(firstBCDReg,"firstBCDReg should be non-NULL when targetBCDReg is non-NULL for node %p\n",firstChild);
               if (performExplicitWidening)
                  targetBCDReg->setDecimalPrecision(node->getDecimalPrecision());
               else
                  targetBCDReg->setDecimalPrecision(firstBCDReg->getDecimalPrecision());
               }
            else
               {
               if (performExplicitWidening)
                  targetReg->setSize(node->getSize());
               else
                  targetReg->setSize(firstReg->getSize());
               }
            }
         }
      else
         {
         if (cg->traceBCDCodeGen())
            {
            traceMsg(comp,"\tliveSymSize >= resultSize (%d >= %d) so can reuse the firstStorageReference #%d for the targetStorageReference\n",
               savedLiveSymbolSize,resultSize,firstStorageReference->getReferenceNumber());
            traceMsg(comp,"\t\t * setting rightAlignedDeadBytes %d from firstReg %s to targetReg %s (valueMod reuse)\n",
               savedRightAlignedDeadBytes,cg->getDebug()->getName(firstReg),cg->getDebug()->getName(targetReg));
            traceMsg(comp,"\t\t * setting rightAlignedIgnoredBytes %d from firstReg %s to targetReg %s (valueMod reuse)\n",
               savedRightAlignedIgnoredBytes,cg->getDebug()->getName(firstReg),cg->getDebug()->getName(targetReg));
            traceMsg(comp,"\t\t * setting savedLeftAlignedZeroDigits %d from firstReg %s to targetReg %s (valueMod reuse)\n",
               savedLeftAlignedZeroDigits,cg->getDebug()->getName(firstReg),cg->getDebug()->getName(targetReg));
            }
         targetReg->setStorageReference(firstStorageReference, node);
         targetReg->setLeftAlignedZeroDigits(savedLeftAlignedZeroDigits);
         targetReg->setRightAlignedDeadBytes(savedRightAlignedDeadBytes);
         targetReg->setRightAlignedIgnoredBytes(savedRightAlignedIgnoredBytes);
         }
      targetReg->setIsInitialized();
      cg->freeUnusedTemporaryBasedHint(node);
      }
   else
      {
      // when initializing the hint storage reference use the symbol size and not the current node size so the same storage reference may be used
      // without further zero initialization for larger node sizes
      TR_StorageReference *targetStorageReference = NULL;
      int32_t destLength = 0;
      if (node->getOpCode().canHaveStorageReferenceHint() && node->getStorageReferenceHint())
         {
         int32_t resultSize = node->getStorageReferenceSize();
         targetStorageReference = node->getStorageReferenceHint();
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tusing storageRefHint #%d on node %p (useNewStoreHintOnInit=%d)\n",targetStorageReference->getReferenceNumber(),node,useNewStoreHint && isInitialized);
         if (targetStorageReference->isTemporaryBased())
            {
            // Consider this scenario (common when a sub-expression is rooted in a load of a large value returned from a runtime routine)
            //
            // store
            //   x      <- size < 10
            //     y    <- current node size=10
            //       z  <- size > 10 and a passThrough operation
            //         load <- size > 10
            //
            // The temporary hint is the size of z but if performExplicitWidening is also set to true below then code will be generated to initialize up
            // to the size of z even though this extra initialized space will be unused for the rest of the operation.
            // Nodes (x,y,z) that share the same hint are tracked and removed when the node is evaluated. At the current node's (y) initializion point
            // only x,y will be in this list and only up to size=10 will be initialized.
            destLength = targetStorageReference->getMaxSharedNodeSize();
            }
         }
      else
         {
         targetStorageReference = TR_StorageReference::createTemporaryBasedStorageReference(node->getStorageReferenceSize(), comp);
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tcreated new targetStorageReference #%d on node %p\n",targetStorageReference->getReferenceNumber(),node);
         }

      if (destLength > 0)
         {
         // update the symSize so in the initTarget=false case a consumer will not do a needlessly large initialization
         targetStorageReference->getTemporarySymbol()->setActiveSize(destLength);
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tsetting destLength and activeSize for initialization based on the smallest remaining node left on the temp based hint #%d : %d\n",
               targetStorageReference->getReferenceNumber(),destLength);
         }
      else if (destLength == 0)
         {
         destLength = targetStorageReference->getSymbolSize();
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tsetting destLength for initialization based on the current storageRef #%d size : %d\n",targetStorageReference->getReferenceNumber(),destLength);
         }
      else
         {
         TR_ASSERT(false,"unexpected negative destLength of %d for node %p\n",destLength,node);
         }

      targetReg->setStorageReference(targetStorageReference, node);
      if (initTarget)
         {
         int32_t srcLength  = sourceSize;
         TR::MemoryReference *destMR = isBCD ?
            generateS390RightAlignedMemoryReference(node, targetStorageReference, cg) :
            generateS390MemRefFromStorageRef(node, targetStorageReference, cg);
         // for packed to packed operations this is likely the start of some (possibly large) computation so *do* perform the explicit widening all at once at
         // the start so later operations do not have to clear.
         bool performExplicitWidening = targetReg->getDataType() == TR::PackedDecimal && firstReg->getDataType() == TR::PackedDecimal;

         int32_t zeroDigits = firstReg->getLeftAlignedZeroDigits();
         if (isBCD &&
             zeroDigits > 0 &&
             zeroDigits > targetReg->getLeftAlignedZeroDigits() &&
             firstReg->getLiveSymbolSize() == targetReg->getLiveSymbolSize() &&
             cg->storageReferencesMatch(targetStorageReference, firstStorageReference))
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\ty^y : transfer leftAlignedZeroDigits %d from firstReg %s to targetReg %s (node %s %p)\n",
                  zeroDigits,cg->getDebug()->getName(firstReg),cg->getDebug()->getName(targetReg),node->getOpCode().getName(),node);
            targetReg->setLeftAlignedZeroDigits(zeroDigits);
            }

         cg->initializeStorageReference(node, targetReg, destMR, destLength, firstChild, firstReg, sourceMR, srcLength, performExplicitWidening, alwaysLegalToCleanSign, trackSignState);
         if (targetBCDReg)
            {
            TR_ASSERT(firstBCDReg,"firstBCDReg should be non-NULL when targetBCDReg is non-NULL for node %p\n",firstChild);
            if (performExplicitWidening)
               targetBCDReg->setDecimalPrecision(node->getDecimalPrecision());
            else
               targetBCDReg->setDecimalPrecision(firstBCDReg->getDecimalPrecision());
            targetBCDReg->transferDataState(firstBCDReg);
            }
         else
            {
            if (performExplicitWidening)
               targetReg->setSize(node->getSize());
            else
               targetReg->setSize(firstReg->getSize());
            }
         targetReg->setIsInitialized();
         }
      }
   if (cg->traceBCDCodeGen() && targetReg->getStorageReference()->isReadOnlyTemporary())
      traceMsg(comp,"reset readOnlyTemp flag on storageRef #%d (%s) (valueMod case)\n",
         targetReg->getStorageReference()->getReferenceNumber(),cg->getDebug()->getName(targetReg->getStorageReference()->getSymbol()));
   targetReg->getStorageReference()->setIsReadOnlyTemporary(false, NULL);
   node->setRegister(targetReg);
   return targetReg;
   }

/**
 * Handles all BCD and aggregate load and const types direct and indirect
 *
 * pdload
 * pdloadi
 *
 * zdload
 * zdloadi
 *
 * zdsleLoad
 * zdsleLoadi
 *
 * zdslsLoad
 * zdslsLoadi
 *
 * zdstsLoad
 * zdstsLoadi
 *
 * udLoad
 * udLoadi
 *
 * udstLoad
 * udstLoadi
 *
 * udslLoad
 * udslLoadi
 */
TR::Register *J9::Z::TreeEvaluator::pdloadEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pdload",node);
   TR::Register* reg = NULL;

   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "PD-Op/%s", node->getOpCode().getName()),
                            1, TR::DebugCounter::Cheap);
   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if((TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv) &&
           (node->getOpCodeValue() == TR::pdload || node->getOpCodeValue() == TR::pdloadi))
      {
      reg = pdloadVectorEvaluatorHelper(node, cg);
      }
   else
      {
      reg = pdloadEvaluatorHelper(node, cg);
      }

   cg->traceBCDExit("pdload",node);
   return reg;
   }


TR::Register *J9::Z::TreeEvaluator::pdloadEvaluatorHelper(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR::Compilation *comp = cg->comp();

   bool isBCD = node->getType().isBCD();

   TR_ASSERT(node->getOpCode().isLoadConst() ||
          (node->getOpCode().hasSymbolReference() && node->getSymbolReference() && !node->getSymbolReference()->isTempVariableSizeSymRef()),
      "load node %p must not be of a tempVariableSizeSymRef\n",node);

   TR_StorageReference *storageRef = TR_StorageReference::createNodeBasedStorageReference(node, node->getReferenceCount(), comp);

   TR_ASSERT(!node->getOpCode().isLoadConst() || node->getNumChildren() == 1,"BCD constant type (%s) should have 1 child and not %d children\n",
      node->getDataType().toString(),node->getNumChildren());
   bool isConstant = node->getOpCode().isLoadConst();
   bool isReadOnlyConstant = false;

   TR_OpaquePseudoRegister *targetReg = NULL;
   if (isBCD)
      {
      targetReg = cg->allocatePseudoRegister(node->getDataType());
      TR_PseudoRegister *targetPseudoReg = targetReg->getPseudoRegister();
      TR_ASSERT(targetPseudoReg,"targetPseudoReg should be non-NULL for node %p\n",node);
      targetPseudoReg->setStorageReference(storageRef, node);
      if (isConstant)
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\t%s (%p) is a constant load so set hasKnownValidSignAndData = true%s\n",
               node->getOpCode().getName(),node,isReadOnlyConstant?" and skip privatizeStorageReference":"");
         targetPseudoReg->setHasKnownValidSignAndData();
         }

      if (node->hasKnownOrAssumedSignCode())
         {
         switch (node->getKnownOrAssumedSignCode())
            {
            case raw_bcd_sign_0xc:
               node->hasKnownSignCode() ? targetPseudoReg->setKnownSignCode(0xc) : targetPseudoReg->setAssumedSignCode(0xc);
               break;
            case raw_bcd_sign_0xd:
               node->hasKnownSignCode() ? targetPseudoReg->setKnownSignCode(0xd) : targetPseudoReg->setAssumedSignCode(0xd);
               break;
            case raw_bcd_sign_0xf:
               if (node->hasKnownOrAssumedCleanSign())
                  {
                  // Something has gone wrong and we've ended up with conflicting sign code properties on the node
                  // This is a bug and should be fixed but in a prod build conservatively reset the clean sign flag and
                  // do transfer the sign to the targetPseudoReg
                  TR_ASSERT(false,"conflicting sign code: sign code 0xf is not clean\n");
                  node->setHasKnownAndAssumedCleanSign(false);
                  }
               else
                  {
                  node->hasKnownSignCode() ? targetPseudoReg->setKnownSignCode(0xf) : targetPseudoReg->setAssumedSignCode(0xf);
                  }
               break;
            case raw_bcd_sign_unknown:
               break;
            default: TR_ASSERT(false,"unexpected node->getKnownOrAssumedSignCode() of %d\n",node->getKnownOrAssumedSignCode());
            }
         }

      if (!node->getOpCode().isSignlessBCDType() && node->hasKnownOrAssumedCleanSign())
         {
         uint32_t preferredPlusSign = TR::DataType::getPreferredPlusSignCode(node->getDataType());
         uint32_t preferredMinusSign = TR::DataType::getPreferredMinusSignCode(node->getDataType());
         if (node->isNonNegative()) // >= 0
            node->hasKnownCleanSign() ? targetPseudoReg->setKnownSignCode(preferredPlusSign) : targetPseudoReg->setAssumedSignCode(preferredPlusSign);
         else if (node->isNonZero() && node->isNonPositive())  // < 0
            node->hasKnownCleanSign() ? targetPseudoReg->setKnownSignCode(preferredMinusSign) : targetPseudoReg->setAssumedSignCode(preferredMinusSign);
         if (cg->traceBCDCodeGen() && targetPseudoReg->hasKnownOrAssumedSignCode())
            traceMsg(comp,"\ttargetPseudoReg has%sSignCode = true and it is 0x%x\n",targetPseudoReg->hasAssumedSignCode()?"Assumed":"Known",targetPseudoReg->getKnownOrAssumedSignCode());
         // call setHasCleanSign() after the set*SignCode() calls so the TR::DataType::getPreferredMinusCode() does not unset
         // the clean flag (as it must conservatively do to account for the unclean case of -0)
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tsetting Has%sCleanSign (due to node flag) on targetPseudoReg %s on %s (%p)\n",
               node->hasKnownCleanSign()?"Known":"Assumed",cg->getDebug()->getName(targetPseudoReg),node->getOpCode().getName(),node);
         node->hasKnownCleanSign() ? targetPseudoReg->setHasKnownCleanSign() : targetPseudoReg->setHasAssumedCleanSign();
         }

      // set decimal precision here so any copy made in privatizeStorageReference is marked with the correct precision
      targetPseudoReg->setDecimalPrecision(node->getDecimalPrecision());

      if (comp->fej9()->assumeLeftMostNibbleIsZero() && targetPseudoReg->isEvenPrecision() && TR::DataType::getDigitSize(node->getDataType()) == HalfByteDigit)
         targetPseudoReg->setLeftMostNibbleClear();

      if (storageRef->isTemporaryBased())
         {
         TR_ASSERT(false,"storageRef for load node %p should not be temp based\n");
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tstorageRef is tempBased so set targetReg %s to isInitialized=true\n",cg->getDebug()->getName(targetPseudoReg));
         targetPseudoReg->setIsInitialized();
         }

      if (cg->traceBCDCodeGen())
         {
         traceMsg(comp,"\tsignState on targetReg %s for %s (%p) :\n",cg->getDebug()->getName(targetPseudoReg),node->getOpCode().getName(),node);
         traceMsg(comp,"\t\tknownCleanSign=%d, knownPrefSign=%d, knownSign=0x%x, assumedCleanSign=%d, assumedPrefSign=%d, assumedSign=0x%x (signStateKnown %d, signStateAssumed %d)\n",
            targetPseudoReg->hasKnownCleanSign(),targetPseudoReg->hasKnownPreferredSign(),targetPseudoReg->hasKnownSignCode()?targetPseudoReg->getKnownSignCode():0,
            targetPseudoReg->hasAssumedCleanSign(),targetPseudoReg->hasAssumedPreferredSign(),targetPseudoReg->hasAssumedSignCode()?targetPseudoReg->getAssumedSignCode():0,
            targetPseudoReg->signStateKnown(),
            targetPseudoReg->signStateAssumed());
         traceMsg(comp,"\t%s (%p) has hasSignStateOnLoad=%d\n",node->getOpCode().getName(),node,node->hasSignStateOnLoad());
         }

      if (!node->hasSignStateOnLoad())
         {
         // even if a particular sign state is not known (i.e. clean,preferred, a particular value) knowing that a load does not have
         // any incoming sign state can help in generating better code (e.g. a ZAP can be used for widening as the side effect of cleaning
         // the sign will not matter vs using a ZAP to widen and illegally modifying a loaded value with an unsigned sign code 0xf->0xc)
         targetPseudoReg->setSignStateInitialized();
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tsetting SignStateInitialized due to hasSignStateOnLoad=false flag on %s (%p)\n",node->getOpCode().getName(),node);
         }
      }
   else
      {
      targetReg = cg->allocateOpaquePseudoRegister(node->getDataType());
      targetReg->setStorageReference(storageRef, node);
      }
   node->setRegister(targetReg);
   if (comp->getOption(TR_ForceBCDInit) || !isReadOnlyConstant)
      cg->privatizeStorageReference(node, targetReg, NULL);
   return targetReg;
   }

/**
 * \brief This helper uses vector instructions to evaluate pdload and pdloadi.
 *
 * Other types of load (zd, ud, etc) can't use vector registers/instructions.
 */
TR::Register*
J9::Z::TreeEvaluator::pdloadVectorEvaluatorHelper(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR_ASSERT(node->getOpCodeValue() == TR::pdload || node->getOpCodeValue() == TR::pdloadi, "vector instructions only support PD load.");
   traceMsg(cg->comp(), "pdload Vector Evaluator, node=%p %d\n", node, __LINE__);

   TR::Register* vTargetReg = vTargetReg = cg->allocateRegister(TR_VRF);
   TR::Node* addressNode = node->getFirstChild();
   TR::Register* addressReg = cg->evaluate(addressNode);
   TR::MemoryReference* sourceMR = generateS390MemoryReference(addressReg, NULL, 0, cg);

   // Index of the first byte to load, counting from the right ranging from 0-15.
   uint8_t indexFromTheRight = TR_VECTOR_REGISTER_SIZE - 1;
   if (node->getDecimalPrecision() > TR_MAX_INPUT_PACKED_DECIMAL_PRECISION)
      {
      // we are loading as many digits as we can starting from the right most digit of the PD in memory
      // Need to calculate offset in order to load this way
      sourceMR->addToOffset(node->getSize() - TR_VECTOR_REGISTER_SIZE);
      }
   else
      {
      indexFromTheRight = node->getSize() - 1;
      }

   TR_ASSERT(indexFromTheRight >= 0 && indexFromTheRight <= 15, "Load length too large for VLRL instruction");
   if(cg->traceBCDCodeGen())
      {
      traceMsg(cg->comp(),"\tGen VLRL for %s node->size=%d\n",
               node->getOpCode().getName(),
               node->getSize());
      }
   generateVSIInstruction(cg, TR::InstOpCode::VLRL, node, vTargetReg, sourceMR, indexFromTheRight);

   node->setRegister(vTargetReg);
   cg->decReferenceCount(addressNode);
   return vTargetReg;
   }

/**
 * A ZAP with an overlapping dest (1st operand) and source (2nd operand) are allowed if the rightmost byte
 * of the 1st operand is coincident with or to the right of the rightmost byte of the second operand
 * Check for this special case here to allow it.
 *
 * pdstorei <mustClean> s=8 bytes
 *    aiadd
 *       aload
 *       iconst 386
 *    pdloadi s=5 bytes
 *       aiadd
 *          aload
 *          iconst 388
 *
 * In this example the store is from 386->394 and the load from 388->393 so the rightmost byte (393->394) of the 1st operand (store) of the ZAP
 * is to the right of the rightmost byte of the 2nd operand (load) at 392->393
 */
bool
isLegalOverlappingZAP(TR::Node *store, TR::CodeGenerator *cg)
   {
   TR::Compilation *comp = cg->comp();

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tisLegalOverlappingZAP check : store %s (%p), valueChild %s (%p)\n",
         store->getOpCode().getName(),store,store->getValueChild()->getOpCode().getName(),store->getValueChild());

   if (!store->getOpCode().isStoreIndirect())
      return false;

   TR::Node *load = store->getValueChild();
   if (!load->getOpCode().isLoadIndirect())
      return false;

   if (load->getRegister())
      return false;

   if (load->hasKnownOrAssumedCleanSign()) // won't need a ZAP anyway so don't bother going further
      return false;

   TR::Node *storeAddr = store->getFirstChild();
   TR::Node *loadVarAddr = load->getFirstChild();

   if (!cg->isSupportedAdd(storeAddr))
      return false;

   if (!cg->isSupportedAdd(loadVarAddr))
      return false;

   if (!cg->nodeMatches(storeAddr->getFirstChild(), loadVarAddr->getFirstChild()))
      return false;

   if (!storeAddr->getSecondChild()->getOpCode().isIntegralConst())
      return false;

   if (!loadVarAddr->getSecondChild()->getOpCode().isIntegralConst())
      return false;

   int64_t storeSize = store->getSize();
   int64_t loadSize = load->getSize();

   int64_t storeAddrOffset = storeAddr->getSecondChild()->get64bitIntegralValue() + store->getSymbolReference()->getOffset();
   int64_t loadAddrOffset = loadVarAddr->getSecondChild()->get64bitIntegralValue() + load->getSymbolReference()->getOffset();

   int64_t storeStart = storeAddrOffset;
   int64_t storeEnd   = storeStart + storeSize;

   int64_t loadStart = loadAddrOffset;
   int64_t loadEnd   = loadStart + loadSize;

   if (cg->traceBCDCodeGen())
      {
      int64_t overlapStart = std::max(storeStart, loadStart);
      int64_t overlapEnd = std::min(storeEnd, loadEnd);
      traceMsg(comp,"\tstoreRange %lld->%lld vs loadRange %lld->%lld --> overlap range %lld -> %lld\n",
         storeStart,storeEnd,loadStart,loadEnd,overlapStart,overlapEnd);
      }

   if (storeEnd >= loadEnd)
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\t\tstoreEnd %lld >= loadEnd %lld : overlap ZAP is legal\n",storeEnd, loadEnd);
      return true;
      }
   else
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\t\tstoreEnd %lld < loadEnd %lld : overlap ZAP is NOT legal\n",storeEnd, loadEnd);
      return false;
      }
   }

/**
  * This evaluator handles the following packed (pd) and unpacked (zd, ud)
  * direct/indirect store operations
  *
  * pdstore
  * pdstorei
  *
  * zdstore
  * zdstorei
  *
  * zdsleStore
  * zdsleStorei
  *
  * zdslsStore
  * zdslsStorei
  *
  * zdstsStore
  * zdstsStorei
  *
  * udStore
  * udStorei
  *
  * udstStore
  * udstStorei
  *
  * udslStore
  * udslStorei
  */
TR::Register*
J9::Z::TreeEvaluator::pdstoreEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pdstore",node);
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "PD-Op/%s", node->getOpCode().getName()),
                            1, TR::DebugCounter::Cheap);
   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if((TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() &&
       !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) ||
       isVectorBCDEnv) &&
           (node->getOpCodeValue() == TR::pdstore || node->getOpCodeValue() == TR::pdstorei))
      {
      pdstoreVectorEvaluatorHelper(node, cg);
      }
   else
      {
      pdstoreEvaluatorHelper(node, cg);
      }

   cg->traceBCDExit("pdstore",node);
   return NULL;
   }

TR::Register* J9::Z::TreeEvaluator::pdstoreEvaluatorHelper(TR::Node *node, TR::CodeGenerator *cg)
   {
   bool isBCD = node->getType().isBCD();
   bool isAggr = node->getType().isAggregate();

   TR::Node * valueChild = node->getValueChild();
   bool isPacked = node->getType().isAnyPacked();
   bool isIndirect = node->getOpCode().isIndirect();
   TR::Compilation *comp = cg->comp();

   bool evaluatedPaddingAnchor = false; // store nodes may contain an extra node giving an address of padding bytes (e.g. 0xF0F0..F0 for zoned)
   bool useZAP = isPacked && node->mustCleanSignInPDStoreEvaluator();

   TR_ASSERT(isBCD || (node->getSize() == valueChild->getSize()),"nodeSize %d != srcSize %d for node %p\n",node->getSize(),valueChild->getSize(),node);

   // If a temp copy may be needed for a child load or passthrough operations (such as a redundant pdclean) but the pdstore location
   // will live on (skipCopyOnStore=true) then force the use of the pdstore result location for the child value (and do not generate a temp copy)
   // Note: that size check below isn't quite the same as the isByteTruncation one below (when setting isLegalToChangeCommonedChildAddress)
   // as this first one uses valueChild nodeSize instead of the valueChild regSize.
   // However in cases where the flag will be checked then the valueReg will be uninitialized so the valueChild->getSize() will equal the valueReg->getSize().
   //
   // useStoreAsAnAccumulator check is needed below as it indicates no overlap between the store and any ancestor. If there is possible overlap then setting the skipCopyOnLoad
   // flag is incorrect as commoned references will use the updated value (updated by this store) instead of the correct value from the first reference point
   // pdstore "a1" // a1 and a2 overlap in some way
   //    pdload "a2"
   //...
   //   =>pdload "a2"  // this commoned node needs the value at first reference and not the updated value after the pdstore to "a1"
   //                  // if skipCopyOnLoad is set then "a2" will be loaded again at the commoned point and get the wrong value.
   bool uninitializedSourceLocationMayBeKilled = false;
   bool mustUseZAP = false;
   bool overlapZAPIsAllowed = false;
   if (valueChild->getSize() <= node->getSize() &&
       !valueChild->skipCopyOnLoad() &&
       valueChild->getReferenceCount() > 1 &&
       node->skipCopyOnStore())
      {
      bool canForceSkipCopyOnLoad = false;
      if (node->useStoreAsAnAccumulator()) // see comment above
         {
         canForceSkipCopyOnLoad = true;
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tsetting valueChild (%s) %p setSkipCopyOnLoad=true due to store with skipCopyOnStore=true (storeAccumCase)\n",valueChild->getOpCode().getName(),valueChild);
         }
      else if (useZAP && isLegalOverlappingZAP(node, cg))
         {
         canForceSkipCopyOnLoad = true;
         mustUseZAP = true; // the overlap check and forcing of skipCopyOnLoad is only valid if we do actually end up generating a ZAP (vs an MVC for example) so make sure this happens
         overlapZAPIsAllowed = true;
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tsetting valueChild %s (%p) setSkipCopyOnLoad=true due to store with skipCopyOnStore=true (legalOverlappingZAPCase)\n",valueChild->getOpCode().getName(),valueChild);
         }
      if (canForceSkipCopyOnLoad)
         {
         valueChild->setSkipCopyOnLoad(true);
         uninitializedSourceLocationMayBeKilled = true;
         }
      }

   if (useZAP && valueChild->getOpCode().isPackedLeftShift())
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tsetting valueChild %p cleanSignDuringPackedLeftShift=true due to store that needs a ZAP\n",valueChild);
      valueChild->setCleanSignDuringPackedLeftShift(true);
      }

   TR_OpaquePseudoRegister *valueReg = cg->evaluateOPRNode(valueChild);

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\t%s (%p) : isInMemoryCopyProp=%s\n",node->getOpCode().getName(),node,node->isInMemoryCopyProp()?"yes":"no");
   // NOTE: if a temp copy is generated below then valueStorageReference and valueReg are reset to point to the temp copies
   TR_StorageReference *valueStorageReference = valueReg->getStorageReference();
   TR::MemoryReference *sourceMR = NULL;
   TR_StorageReference *tempStorageReference = NULL;
   bool nodeAndValueRegSizeMatch = node->getSize() == valueReg->getSize();
   bool allSizesMatch = false;
   if (valueStorageReference->isNonConstantNodeBased())
      {
      allSizesMatch = nodeAndValueRegSizeMatch &&
                      valueReg->getSize() == valueStorageReference->getNode()->getSize();
      }
   else
      {
      allSizesMatch = nodeAndValueRegSizeMatch;
      }

   if (valueStorageReference->isNonConstantNodeBased() &&
       comp->getOption(TR_PrivatizeOverlaps) &&
       !overlapZAPIsAllowed &&
       !(node->useStoreAsAnAccumulator() || valueReg->isInitialized()))
      {
      // In addition to when the isInMemoryCopyProp flag is set on the store there are two other cases when an temp copy is needed for overlap
      // 1) isUsingStorageRefFromAnotherStore : even with CSE commoning (so not subject to isInMemoryCopyProp flag as the IL itself is safe)
      //    can result in an overlap if 'b' is updated to point to 'c' storageRef and 'd' overlap
      //    This is a lazy fixup -- could also pro-actively not set skipCopyOnStore for 'c' in the first place if the stores for any of the commoned 'b' nodes
      //    are in memory types (BCD/Aggr) that also overlap with 'c' (e.g. 'd' in this case)
      //
      // c
      //   b
      //
      // d
      //   =>b   (was just 'b' before CSE) but could  be 'c' after 'c' is evaluated
      //
      TR::Node *storageRefNode = valueStorageReference->getNode();
      bool isUsingStorageRefFromAnotherStore = storageRefNode->getOpCode().isStore() && storageRefNode != node;

      // 2) The valueRegHasDeadOrIgnoredBytes check is for when a ZAP could be generated for an overlapping copy where the rightmost
      // bytes are not coincident (due to the deadOrIgnoredBytes) so go through a temp in this case too
      //
      // This also handles the case like the below (so do not bother checking useZAP along with valueRegHasDeadOrIgnoredBytes)
      // The copy is not redundant when the valueReg has some dead or ignored bytes as the right most bytes of the source
      // and target will not be coincident in this case even if the addresses exactly match
      // izdstore p = 6 "A"
      //    addr1
      //    zdshrSetSign p = 1  --> valueReg has 5 ignored bytes
      //       izdload "A" p = 6
      //          =>addr1
      //       iconst 5    // shift
      ///      iconst 15   // setSign
      //
      // In this case have to move from offset +0 to offset +5 and then clear the top 5 bytes (starting at offset +0)
      // If copyIsRedundant is incorrectly set to true then only the clear of the top 5 bytes happens and the one surviving
      // digit from the zdshrSetSign is clobbered
      // MVC +0(base,L=1),+5(base)   move surviving digit first
      // MVC +0(base,L-5),(constant) complete widening by setting top 5 bytes to 0xF0
      bool valueRegHasDeadOrIgnoredBytes = valueReg->getRightAlignedIgnoredBytes() > 0;

      // 3) if there is any size mismatch between the sizes of node, valueReg and storageRefNode
      //
      // if nodeSize != storageRefNodeSize then this could be a truncating copy where the data needs to be moved back a number of bytes
      // "a" and "a_alias" start at the same address (so loadOrStoreAddressesMatch will return true) but "a" is 10 bytes and "a_alias" is 13 bytes
      // The meaning of the IL below is to move the low (addr+3) 10 bytes of "a_alias" back (to the left) 3 bytes.
      // This is actual needed data movement so a copy must be done (TODO : going through a temp here but this particular size mismatch case could
      // be done with an MVC as this direction of copy is non-destructive.
      // ipdstore "a" s=10
      //    addr
      //    ipdload "a_alias" s=13     // valueChild may not be a simple load but some commoned pdX operation that has the ipdload as its storageRefNode
      //       =>addr

      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tisInMemoryCopyProp=%s, isUsingStorageRefFromAnotherStore=%s, valueRegHasDeadOrIgnoredBytes=%s : node %s (%p), valueReg %s, storageRefNode %s (%p)\n",
            node->isInMemoryCopyProp() ? "yes":"no",
            isUsingStorageRefFromAnotherStore ? "yes":"no",
            valueRegHasDeadOrIgnoredBytes ? "yes":"no",
            node->getOpCode().getName(),node,
            cg->getDebug()->getName(valueReg),
            storageRefNode->getOpCode().getName(),storageRefNode);

      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tallSizesMatch=%s (nodeSize=%d, valueRegSize=%d, storageRefNodeSize=%d)\n",
            allSizesMatch ? "yes":"no",node->getSize(),valueReg->getSize(),storageRefNode->getSize());

      if (node->isInMemoryCopyProp() || isUsingStorageRefFromAnotherStore || valueRegHasDeadOrIgnoredBytes || !allSizesMatch)
         {
         // a redundant copy is an MVC with exact matching target and source. This is a nop but a very expensive nop as the hardware treats it
         // as any other overlap copy (i.e. very slowly)
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tnode %s (%p) and source %s (%p) may overlap but first check if copy would be redundant\n",
               node->getOpCode().getName(),node,valueChild->getOpCode().getName(),valueChild);

         bool copyIsRedundant = !valueRegHasDeadOrIgnoredBytes && allSizesMatch && cg->loadOrStoreAddressesMatch(node, valueStorageReference->getNode());

         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tgot copyIsRedundant=%s from first test\n",copyIsRedundant?"yes":"no");

         //Further check if there is potential destructive overlap based on storage info
         if (isAggr && !copyIsRedundant && !valueRegHasDeadOrIgnoredBytes && allSizesMatch)
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tperform test for definitelyNoDestructive overlap\n");

            if (cg->getStorageDestructiveOverlapInfo(valueStorageReference->getNode(), valueReg->getSize(), node, node->getSize()) == TR_DefinitelyNoDestructiveOverlap)
               {
               copyIsRedundant = true;
               if (cg->traceBCDCodeGen())
                  traceMsg(comp,"\t\tset copyIsRedundant=true : overlap check between node %s (%p) size=%d and valueStorageRefNode %s (%p) valueRegSize %d returns TR_DefinitelyNoDestructiveOverlap\n",
                     node->getOpCode().getName(),node,node->getSize(),
                     valueStorageReference->getNode()->getOpCode().getName(),valueStorageReference->getNode(),valueReg->getSize());
               }
            }

         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\t\tcopyIsRedundant=%s\n",copyIsRedundant?"yes":"no");

         if (!copyIsRedundant)
            {
            // i.e. a simple load/store BUT load and store memory may overlap so must use a temp so MVC doesn't destructively overlap and lose some source bytes
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tnode %s (%p) and source %s (%p) (uninitialized valueReg %s) may overlap -- must privatize valueReg\n",
                  node->getOpCode().getName(),node,valueChild->getOpCode().getName(),valueChild,cg->getDebug()->getName(valueReg));

            int32_t privatizedSize = valueReg->getSize();
            int32_t storageRefNodeSize = storageRefNode->getSize();
            if (!valueReg->isInitialized() &&
                storageRefNodeSize != privatizedSize)
               {
               // may need to increase the size of the memcpy so it captures all of the source value -- this is important for the example above of moving 10 bytes starting at addr_1+3
               // back 3 bytes to addr_1
               // This 13 byte copy will copy the entire original field and then the store generated by the usual pdstoreEvaluator will be MVC addr_1(10,br),addr_1+3(10,br)
               privatizedSize = storageRefNodeSize;
               if (cg->traceBCDCodeGen())
                  traceMsg(comp,"\tset privatizedSize to storageRefNodeSize %d for uninit valueReg %s with mismatched storageRefNodeSize %d and valueRegSize %d\n",
                    privatizedSize,cg->getDebug()->getName(valueReg),storageRefNodeSize,valueReg->getSize());

               if (valueRegHasDeadOrIgnoredBytes)
                  {
                  // below IL comes from statements like : DIVIDE powerOfTenLit into var  where var is an unsigned zoned type
                  // zdstore           s=15
                  //    addr
                  //    zdshrSetSign   s=12  <- passThrough with 3 rightAligned deadBytes
                  //       izdload      s=15
                  //          =>addr
                  //       iconst 3       // shift
                  //       iconst 0xf     // sign
                  //
                  // in this case using an overridden size of 15 from the zdload is incorrect as there are only 12 valid bytes after the passThru zdshrSetSign
                  // If the offset on the addr is less then the shift then the final offset will be < 0 and the binary encoding time assume will be hit
                  // For larger offsets no compile time problem is hit but the temp copy reaches back to read bytes from before it's field (but the these bytes
                  // are not actually examined so everything ends up 'working' (delta any access exceptions if this were the first field in storage)
                  if (cg->traceBCDCodeGen())
                     traceMsg(comp,"\t\tgetRightAlignedIgnoredBytes %d > 0 so reduce privatizedSize %d -> %d\n",
                        valueReg->getRightAlignedIgnoredBytes(), privatizedSize,  privatizedSize - valueReg->getRightAlignedIgnoredBytes());
                  privatizedSize = privatizedSize - valueReg->getRightAlignedIgnoredBytes();
                  }
               }
            TR_OpaquePseudoRegister *tempRegister = cg->privatizePseudoRegister(valueChild, valueReg, valueStorageReference, privatizedSize);
            tempStorageReference = tempRegister->getStorageReference();

            if (cg->traceBCDCodeGen())
               {
               if (node->isInMemoryCopyProp())
                  traceMsg(comp,"\ta^a : privatize needed due to isInMemoryCopyProp node %s (%p) on line_no=%d (storeCase)\n",
                     node->getOpCode().getName(),node,comp->getLineNumber(node));
               if (isUsingStorageRefFromAnotherStore)
                  traceMsg(comp,"\ta^a : privatize needed due to isUsingStorageRefFromAnotherStore storageRefNode %s (%p) on line_no=%d (storeCase)\n",
                     storageRefNode->getOpCode().getName(),storageRefNode,comp->getLineNumber(node));
               if (valueRegHasDeadOrIgnoredBytes)
                  traceMsg(comp,"\ta^a : privatize needed due to valueRegHasDeadOrIgnoredBytes valueReg %s valueChild %s (%p) on line_no=%d (storeCase)\n",
                     cg->getDebug()->getName(valueReg),valueChild->getOpCode().getName(),valueChild,comp->getLineNumber(node));
               }

            TR_ASSERT(!comp->getOption(TR_EnablePerfAsserts),"gen overlap copy on node %s (%p) on line_no=%d (storeCase)\n",
               node->getOpCode().getName(),node,comp->getLineNumber(node));

            if (isBCD)
               sourceMR = generateS390RightAlignedMemoryReference(valueChild, tempStorageReference, cg);
            else
               sourceMR = generateS390MemRefFromStorageRef(valueChild, tempStorageReference, cg);

            valueReg = tempRegister;
            valueStorageReference = tempStorageReference;

            TR_ASSERT(!isBCD || valueReg->getPseudoRegister(),"valueReg must be a pseudoRegister on node %s (%p)\n",valueChild->getOpCode().getName(),valueChild);
            }
         }
      else
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"y^y : temp copy saved isInMemoryCopyProp = false on %s (%p) (storeCase)\n",node->getOpCode().getName(),node);
         }
      }

   TR_PseudoRegister *bcdValueReg = NULL;
   if (valueReg->getPseudoRegister())
      {
      bcdValueReg = valueReg->getPseudoRegister();
      }

   int32_t destSize = node->getSize();
   int32_t sourceSize = valueReg->getSize();

   TR_ASSERT(isBCD || (destSize == sourceSize),"destSize %d != sourceSize %d for node %p\n",destSize,sourceSize,node);

   bool isByteTruncation = sourceSize > destSize;
   bool isByteWidening = destSize > sourceSize;

   bool isLeadingSignByteWidening = isByteWidening && node->getType().isLeadingSign();

   useZAP =  useZAP && bcdValueReg && (!bcdValueReg->hasKnownOrAssumedCleanSign() || mustUseZAP);
   //useZAP = useZAP || (isPacked && isByteTruncation); // truncating packed stores that need oveflow exception should be using pdshlOverflow

   bool preserveSrcSign = bcdValueReg && !bcdValueReg->isLegalToCleanSign();

   bool savePreZappedValue = false;
   if (useZAP &&
       valueChild->getReferenceCount() > 1 &&
       preserveSrcSign)
      {
      savePreZappedValue = true;
      if (cg->traceBCDCodeGen())
         {
         traceMsg(comp,"\tsetting savePreZappedValue=true because valueReg (from valueChild %p with refCount %d > 1) ",valueChild,valueChild->getReferenceCount());
         if (!bcdValueReg->signStateInitialized())
            traceMsg(comp,"has an uninitialized sign state and a ZAP is to be used for the store\n");
         else
            traceMsg(comp,"has signCode 0x%x and a ZAP is to be used for the store\n", bcdValueReg->getKnownOrAssumedSignCode());
         }
      }

   bool childContainsAccumulatedResult = valueStorageReference->isNodeBased() &&
                                         valueStorageReference->isNodeBasedHint() &&
                                         (valueStorageReference->getNode() == node);

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tisPacked=%s, useZAP=%s, valueReg->signStateInit()=%s, valueReg->hasKnownOrAssumedCleanSign()=%s, isByteTruncation=%s, isByteWidening=%s, destSize=%d, sourceSize=%d\n",
         isPacked?"true":"false",
         useZAP?"true":"false",
         bcdValueReg && bcdValueReg->signStateInitialized()?"true":"false",
         bcdValueReg && bcdValueReg->hasKnownOrAssumedCleanSign()?"true":"false",
         isByteTruncation?"true":"false",
         isByteWidening?"true":"false",
         destSize,
         sourceSize);

   TR::Node *sourceNode = NULL;
   bool changeCommonedChildAddress = false;
   bool isLegalToChangeCommonedChildAddress = false;

   TR_ASSERT( !childContainsAccumulatedResult || valueReg->isInitialized(),"an accumulated result should also be initialized\n");

   if (!isByteTruncation &&
       !isLeadingSignByteWidening &&
       !savePreZappedValue &&
       tempStorageReference == NULL && // valueReg->setStorageReference() will not work in this case as the valueReg is pointing to the copy (tempRef count underflow)
       valueChild->getReferenceCount() > 1 &&
       node->skipCopyOnStore())
      {
      isLegalToChangeCommonedChildAddress = true;
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tsetting isLegalToChangeCommonedChildAddress=true for valueChild %s (%p) because isByteTruncation=false, isLeadingSignByteWidening=false, refCount %d > 1, skipCopyOnStore=true and savePreZappedValue=false\n",
            valueChild->getOpCode().getName(),
            valueChild,
            valueChild->getReferenceCount());
      }

   if (!valueStorageReference->isTemporaryBased() &&
       valueStorageReference->getNode() != node)
      {
      TR_ASSERT(!valueReg->isInitialized(),"expecting valueReg to not be initialized for valueChild %p\n",valueChild);
      TR_ASSERT(valueReg->getStorageReference()->isNodeBased(),"expecting valueReg storageRef to be nodeBased on valueChild %p\n",valueChild);
      if (valueStorageReference->getNode()->getOpCode().isStore())
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"found uninit storageRef node based STORE case valueChild %s (%p) and storageRefNode %s (%p)\n",
               valueChild->getOpCode().getName(),
               valueChild,
               valueStorageReference->getNode()->getOpCode().getName(),
               valueStorageReference->getNode());
         }
      else if (valueStorageReference->getNode()->getOpCode().isLoad())
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"found uninit storageRef node based LOAD case valueChild %s (%p) and storageRefNode %s (%p), skipCopyOnLoad storageRefNode is %s\n",
               valueChild->getOpCode().getName(),
               valueChild,
               valueStorageReference->getNode()->getOpCode().getName(),
               valueStorageReference->getNode(),
               valueStorageReference->getNode()->skipCopyOnLoad()?"yes":"no");
         }
      else
         {
         TR_ASSERT(false,"storageRefNode %p should be a load or a store node %p (%s)\n",valueStorageReference->getNode(),cg->getDebug()->getName(valueStorageReference->getNode()));
         }
      }

   if (valueStorageReference->isTemporaryBased() || (valueStorageReference->getNode() != node))
      {
      if (cg->traceBCDCodeGen() && valueStorageReference->isTemporaryBased())
         traceMsg(comp,"\tvalueStorageReference->isTemporaryBased() case so see if changeCommonedChildAddress should be set to true\n");
      else if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tvalueStorageReference->getNode() != node (%p != %p) case so see if changeCommonedChildAddress should be set to true\n",
            valueStorageReference->getNode(),node);

      sourceNode = valueChild;
      if (isLegalToChangeCommonedChildAddress)
         {
         if (useZAP)
            {
            changeCommonedChildAddress = true;
            if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tset changeCommonedChildAddress = true due to ZAP\n");
            }
         else if (isByteWidening)
            {
            changeCommonedChildAddress = true;
            if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tset changeCommonedChildAddress = true due to byteWidening\n");
            }
/* // disable this case, not a good enough reason for potential operand store compare
         else if (!isIndirect && valueChild->getOpCode().isIndirect())    // addressability is cheaper
            {
            changeCommonedChildAddress = true;
            if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tset changeCommonedChildAddress = true due to cheaper addressability\n");
            }
*/
         else if (uninitializedSourceLocationMayBeKilled &&
                  !valueStorageReference->isTemporaryBased() &&            // last two conditions are true when source location is uninitialized (passThrough operations or just a load child)
                  (valueStorageReference->getNode()->getOpCode().isLoadVar() || valueStorageReference->getNode()->getOpCode().isStore()))
            {
            changeCommonedChildAddress = true;
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\t\tset changeCommonedChildAddress = true due to uninitialized storageRefNode %p with skipCopyOnLoad that was forced to true\n",valueStorageReference->getNode());
            }
         else
            {
            if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tleave changeCommonedChildAddress = false\n");
            }
         }
      else
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\t\tisLegalToChangeCommonedChildAddress = false so do not attempt to look for cases to set changeCommonedChildAddress to true\n");
         }
      }
   else
      {
      TR_ASSERT( childContainsAccumulatedResult, "expecting the pdstore child node to contain the accumulated result\n");
      // If there is any byte truncation and we are in the accumulator case then this means some leftmost child of the store
      // may have written data outside the bounds of the current store and this would be (horribly) incorrect.
      // This case should never occur as hints should only be assigned when the pdstore memory location is large enough
      // to contain any leftmost result value.
      TR_ASSERT( !isByteTruncation,"byte truncation should not occur when using the pdstore as an accumulator\n");
      changeCommonedChildAddress = true;
      if (cg->traceBCDCodeGen()) traceMsg(comp,"\taccumulated hint case so unconditionally set changeCommonedChildAddress = true\n");
      }

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tbef legality check: changeCommonedChildAddress = %s and isLegalToChangeCommonedChildAddress=%s so final changeCommonedChildAddress=%s\n",
         changeCommonedChildAddress?"true":"false",
         isLegalToChangeCommonedChildAddress?"true":"false",
         (changeCommonedChildAddress && isLegalToChangeCommonedChildAddress)?"true":"false");

   changeCommonedChildAddress = changeCommonedChildAddress && isLegalToChangeCommonedChildAddress;

   // well this is unfortunate -- the valueChild has skipCopyOnLoad set on it but for some reason (likely some corner case savePreZappedValue)
   // isLegalToChangeCommonedChildAddress is false.
   // This means that it is not safe to keep using the storageRef on the valueChild past this store point so must force it to a temp
   bool mustPrivatizeValueChild = tempStorageReference == NULL && !valueReg->isInitialized() && uninitializedSourceLocationMayBeKilled && !changeCommonedChildAddress;
   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tmustPrivatizeValueChild=%s\n",mustPrivatizeValueChild?"yes":"no");

   TR_StorageReference *targetStorageReference =
         TR_StorageReference::createNodeBasedStorageReference(node,
                                                              changeCommonedChildAddress ? valueChild->getReferenceCount() : 1,
                                                              comp);

   rcount_t origValueChildRefCount = valueChild->getReferenceCount();

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tcreate node based targetStorageReference #%d from %s (%p) and nodeRefCount %d (%s)\n",
         targetStorageReference->getReferenceNumber(),
         node->getOpCode().getName(),
         node,
         targetStorageReference->getNodeReferenceCount(),
         changeCommonedChildAddress?"from valueChild":"fixed at 1");

   TR::MemoryReference *targetMR = NULL;
   if (useZAP)
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tuseZAP=true so gen ZAP but first determine the zapDestSize, initial size is destSize=%d\n",destSize);
      int32_t zapDestSize = destSize;
      targetMR = generateS390RightAlignedMemoryReference(node, targetStorageReference, cg);
      TR::Node *sourceNodeForZAP = sourceNode;
      if (sourceNode)
         {
         if (sourceMR == NULL)
            sourceMR = generateS390RightAlignedMemoryReference(sourceNode, valueStorageReference, cg);
         cg->correctBadSign(sourceNode, bcdValueReg, sourceSize, sourceMR);
         }
      else
         {
         // when zapping a field against itself then we may be able to reduce the destSize if some of the upper bytes are already clear
         if (isByteWidening)
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\t\tdestSize > sourceSize (%d > %d) so check valueReg->getLiveSymbolSize() %d against destSize %d before checking if the upper bytes are clear\n",
                  destSize,sourceSize,valueReg->getLiveSymbolSize(),destSize);
            if (valueReg->getBytesToClear(sourceSize, destSize) == 0)
               {
               zapDestSize=sourceSize;
               if (cg->traceBCDCodeGen())
                  traceMsg(comp,"\t\tvalueReg bytes sourceSize->destSize (%d->%d) are already clear so set zapDestSize=sourceSize=%d\n",sourceSize,destSize,sourceSize);
               }
            }
         cg->correctBadSign(node, bcdValueReg, zapDestSize, targetMR);
         // save the dead/ignored bytes here as it will be reset to 0 if savePreZappedValue is true as part of the setStorageReference call below
         int32_t savedRightAlignedDeadAndIgnoredBytes = valueReg->getRightAlignedDeadAndIgnoredBytes();
         if (savePreZappedValue)
            {
            TR_StorageReference *valueStorageReferenceCopy = TR_StorageReference::createTemporaryBasedStorageReference(sourceSize, comp);
            // when tempStorageReference != NULL then the valueReg->setStorageReference call below will not work as the temp ref count will underflow
            // valueReg in this case is actually pointing to the tempRegister created when copyMR was initialized
            // shouldn't reach here in this case as tempStorageReference is only used for the uninit and non-hint cases and this is an init path
            TR_ASSERT(tempStorageReference == NULL,"tempStorageReference == NULL should be null for node %p\n",node);
            valueReg->setStorageReference(valueStorageReferenceCopy, valueChild);
            valueReg->setIsInitialized();
            valueStorageReference = valueStorageReferenceCopy;
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tsavePreZappedValue=true so gen MVC with sourceSize %d to copy #%d on pdstore for valueChild %p with refCnt %d\n",
                  sourceSize,valueStorageReferenceCopy->getReferenceNumber(),valueChild,valueChild->getReferenceCount());
            TR::MemoryReference *targetCopyMR = generateS390RightAlignedMemoryReference(*targetMR, node, 0, cg);
            if (savedRightAlignedDeadAndIgnoredBytes > 0)
               {
               if (cg->traceBCDCodeGen())
                  traceMsg(comp,"\tadd -savedRightAlignedDeadAndIgnoredBytes = -%d to sourceMR for savePreZappedValue copy\n",savedRightAlignedDeadAndIgnoredBytes);
               targetCopyMR->addToTemporaryNegativeOffset(node, -savedRightAlignedDeadAndIgnoredBytes, cg);
               }
            generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                                   sourceSize-1,
                                   generateS390RightAlignedMemoryReference(valueChild, valueStorageReferenceCopy, cg),
                                   targetCopyMR);

            }
         sourceMR = generateS390RightAlignedMemoryReference(*targetMR, node, 0, cg);   // ensure sourceMR and targetMR are the same when used for the ZAP below

         if (savedRightAlignedDeadAndIgnoredBytes > 0)
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tadd -savedRightAlignedDeadAndIgnoredBytes = -%d to sourceMR for final ZAP\n",savedRightAlignedDeadAndIgnoredBytes);
            sourceMR->addToTemporaryNegativeOffset(node, -savedRightAlignedDeadAndIgnoredBytes, cg);
            }

         sourceNodeForZAP = node; // so a NULL sourceNode is not passed in for the ZAP sourceMR reuse below
         }

      if (isByteTruncation)
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tisByteTruncating ZAP so reduce sourceSize %d->%d\n",sourceSize,zapDestSize);
         sourceSize = zapDestSize;
         }

      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tgen ZAP with zapDestSize=%d,sourceSize=%d\n",zapDestSize,sourceSize);
      generateSS2Instruction(cg, TR::InstOpCode::ZAP, node,
                             zapDestSize-1,
                             reuseS390RightAlignedMemoryReference(targetMR, node, targetStorageReference, cg),
                             sourceSize-1,
                             reuseS390RightAlignedMemoryReference(sourceMR, sourceNodeForZAP, valueStorageReference, cg));
      }
   else
      {
      if (sourceNode)
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tuseZAP=false and sourceNode %s (%p) is non-NULL so gen MVC but first determine the mvcSize\n",
               sourceNode->getOpCode().getName(),sourceNode);
         int32_t mvcSize = sourceSize;
         if (isByteTruncation)
            {
            mvcSize = destSize;
            }
         bool needsClear = false;
         if (isByteWidening)
            {
            needsClear = true;
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\t\tdestSize > sourceSize (%d > %d) so try to reduce mvcSize by checking if the upper bytes are clear\n",
                  destSize,sourceSize,valueReg->getLiveSymbolSize(),destSize);
            if (valueReg->getBytesToClear(sourceSize, destSize) == 0)
               {
               needsClear=false;
               mvcSize=destSize;
               if (cg->traceBCDCodeGen())
                  traceMsg(comp,"\t\tvalueReg bytes sourceSize->destSize (%d->%d) are already clear so set mvcSize=destSize=%d\n",sourceSize,destSize,mvcSize);
               }
            }

         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tsourceNode %s (%p) is non-NULL so gen MVC/memcpy with size %d to store (isByteTruncation=%s)\n",
               sourceNode->getOpCode().getName(),sourceNode,mvcSize,isByteTruncation?"yes":"no");

         if (isBCD)
            {
            targetMR = generateS390RightAlignedMemoryReference(node, targetStorageReference, cg);
            if (sourceMR == NULL)
               sourceMR = generateS390RightAlignedMemoryReference(sourceNode, valueStorageReference, cg);
            }
         else
            {
            targetMR = generateS390MemRefFromStorageRef(node, targetStorageReference, cg);
            if (sourceMR == NULL)
               sourceMR = generateS390MemRefFromStorageRef(sourceNode, valueStorageReference, cg);
            }

         // if getRightAlignedIgnoredBytes > - then the rightmost bytes will not be coincident so the addressesMatch check is not sufficient
         // to detect if the copyIsRedundant
         //
         // Similarly if the node and storageRefNode sizes do not match (!allSizesMatch) then different offset bumps will be applied even if their starting addresses
         // are coincident (i.e. loadOrStoreAddressesMatch would return true)
         bool copyIsRedundant = valueReg->getRightAlignedIgnoredBytes() == 0 &&
                                allSizesMatch &&
                                valueStorageReference->isNonConstantNodeBased() &&
                                cg->loadOrStoreAddressesMatch(node, valueStorageReference->getNode());
         if (cg->traceBCDCodeGen() && copyIsRedundant)
            traceMsg(comp,"\t\tcopyIsRedundant=yes so skip memcpy\n");
         if (!copyIsRedundant)
            cg->genMemCpy(targetMR, node, sourceMR, sourceNode, mvcSize);

         if (needsClear)
            {
            cg->widenBCDValue(node, NULL, valueReg->getSize(), node->getSize(), targetMR);
            evaluatedPaddingAnchor = true;
            }
         }
      else if (isByteWidening)
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tuseZAP=false and sourceNode is NULL so just check if upper bytes need to be cleared\n");
         targetMR = generateS390RightAlignedMemoryReference(node, targetStorageReference, cg);
         cg->widenBCDValueIfNeeded(node, bcdValueReg, sourceSize, node->getSize(), targetMR);
         evaluatedPaddingAnchor = true;
         }
      }

   if (valueChild->getReferenceCount() > 1)
      {
      if (changeCommonedChildAddress)
         {
         int32_t savedLeftAlignedZeroDigits = valueReg->getLeftAlignedZeroDigits();
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tchangeCommonedChildAddress=true so update storage reference on valueReg %s (leftAlignedZeroDigits=%d) and reset isInit to false\n",
               cg->getDebug()->getName(valueReg),savedLeftAlignedZeroDigits);

         valueReg->setStorageReference(targetStorageReference, valueChild); // also resets leftAlignedZeroDigits

         // Reset isInit to false for correctness so the commoned reference does not clobber a user variable location
         // This reset is also done during addStorageReferenceHints but there is no guarantee this pass will be done for every
         // IL pattern
         if (!targetStorageReference->isTemporaryBased())
            valueReg->setIsInitialized(false);

         if (isByteWidening)
            {
            bcdValueReg->addRangeOfZeroBytes(sourceSize, destSize);
            }
         else if (savedLeftAlignedZeroDigits > 0)
            {
            // TODO: is the size check below needed? -- isByteWidening is checked in the if above and isByteTruncation would never happen for an accum case
            if (childContainsAccumulatedResult &&
                valueReg->getSize() == node->getSize())
               {
               if (cg->traceBCDCodeGen())
                  traceMsg(comp,"\tset leftAlignedZeroDigits to %d on %s after setStorageReference\n",savedLeftAlignedZeroDigits,cg->getDebug()->getName(valueReg));
               valueReg->setLeftAlignedZeroDigits(savedLeftAlignedZeroDigits);
               }
            else
               {
               // could also probably transfer savedLeftAlignedZeroDigits in some non-accum cases too but need to see a motivating case first
               if (cg->traceBCDCodeGen())
                  traceMsg(comp,"z^z : missed transferring zeroDigits %d to valueChild %s (%p) (accum=%s, valueRegSize %d, nodeSize %d\n",
                     savedLeftAlignedZeroDigits,valueChild->getOpCode().getName(),valueChild,childContainsAccumulatedResult?"yes":"no",valueReg->getSize(),node->getSize());
               }
            }

         if (useZAP)
            {
            bcdValueReg->setHasKnownValidSignAndData();
            bcdValueReg->setHasKnownCleanSign();
            TR_ASSERT(!bcdValueReg->hasKnownOrAssumedSignCode() || bcdValueReg->getKnownOrAssumedSignCode() != 0xf,"inconsistent sign code of 0xf found for node %p\n",valueChild);
            if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tsetting HasKnownCleanSign (due to ZAP) on valueReg %s on valueChild %p\n",cg->getDebug()->getName(bcdValueReg),valueChild);
            }
         }
      else if (mustPrivatizeValueChild ||
               (!valueStorageReference->isTemporaryBased() &&                                                 // comment1 below
                childContainsAccumulatedResult &&                                                            // comment2 below
                (!node->skipCopyOnStore() || isLeadingSignByteWidening)))                                    // comments 2 and 3 below
         {
         // comment1 (explains the first case where a temp copy is *not* needed)
         // do not generate another temp copy if storing a temp that is already attached to a commoned load or pass thru node
         //    pdstore
         //       =>ipdload (in temp1), skipSSCopy=false  <- temp1 will have the correct ref count for all its commoned uses
         //
         // comment2 (explains the second case where a temp copy is *not* needed)
         // pdstore
         //    =>pdshr
         // here the pdshr storageReference is store based as the result of the initial (an earlier) store of the same pdshr node being marked with skipCopyOnStore.
         // In this case all commoned references of pdshr can use the store based storageReference as this flag guarantees the store symbol is
         // not killed before the last reference to the pdshr is seen.
         // comment3
         // skipCopyOnStore does not consider kills of the value that happen during the store itself. When storing a value
         // with a leading sign, if we have to widen that value, we move the sign code. This causes later uses of the value
         // child to see the wrong result unless we make a copy, so we ignore skipCopyOnStore if isLeadingSignByteWidening.

         TR_StorageReference *valueStorageReferenceCopy = TR_StorageReference::createTemporaryBasedStorageReference(sourceSize, comp);
         // when tempStorageReference != NULL then the valueReg->setStorageReference call below will not work as the temp ref count will underflow
         // valueReg in this case is actually pointing to the tempRegister created when copyMR was initialized
         // shouldn't reach here in this case as tempStorageReference is only used for the uninit and non-hint cases and this is hint path
         TR_ASSERT(tempStorageReference == NULL,"tempStorageReference == NULL should be null for node %p\n",node);
         valueReg->setIsInitialized();

         // do not clean sign for the BCD copy as the commoned use may not be a final use (so the sign cleaning may be premature)
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tlate pdstore privatization of valueChild : so gen MVC/memcpy with sourceSize %d to copy #%d (%s) on %s for child %s (%p) with refCnt %d (mustPrivatizeValueChild %s)\n",
               sourceSize,valueStorageReferenceCopy->getReferenceNumber(),cg->getDebug()->getName(valueStorageReferenceCopy->getSymbol()),
               node->getOpCode().getName(),valueChild->getOpCode().getName(),valueChild,valueChild->getReferenceCount(),
               mustPrivatizeValueChild?"yes":"no");

         bool useSourceMR = sourceMR && !overlapZAPIsAllowed;

         TR::Node *copySourceNode = useSourceMR ? valueChild : node;
         TR::MemoryReference *copySourceMR = useSourceMR ? sourceMR : targetMR;
         TR_StorageReference *copySourceStorageRef = useSourceMR ? valueStorageReference : targetStorageReference;

         TR::MemoryReference *copyTargetMR = NULL;
         if (isBCD)
            {
            copySourceMR = reuseS390RightAlignedMemoryReference(copySourceMR, copySourceNode, copySourceStorageRef, cg);
            valueReg->setStorageReference(valueStorageReferenceCopy, valueChild);
            copyTargetMR = generateS390RightAlignedMemoryReference(valueChild, valueStorageReferenceCopy, cg);
            }
         else
            {
            copySourceMR = reuseS390MemRefFromStorageRef(copySourceMR, 0, copySourceNode, copySourceStorageRef, cg);
            valueReg->setStorageReference(valueStorageReferenceCopy, valueChild);
            copyTargetMR = generateS390MemRefFromStorageRef(valueChild, valueStorageReferenceCopy, cg);
            }

         cg->genMemCpy(copyTargetMR, node, copySourceMR, copySourceNode, sourceSize);

         if (useSourceMR)
            sourceMR = copySourceMR;
         else
            targetMR = copySourceMR;

         // If we are accumulating a leading sign type, then the above copy will include the
         // byte widening that we did before storing. The long-term fix is to rewrite this evaluator
         // to make the copy before we do any modification of the stored value.
         // The short term fix is to copy the widened sign back into this copy.
         if (childContainsAccumulatedResult && isLeadingSignByteWidening)
            {
            uint16_t signSize = 0;
            TR::InstOpCode::Mnemonic signCopyOp = TR::InstOpCode::BAD;

            switch (node->getType().getDataType())
               {
               case TR::ZonedDecimalSignLeadingEmbedded:
                  signSize = 1;
                  signCopyOp = TR::InstOpCode::MVZ;
                  break;
               case TR::ZonedDecimalSignLeadingSeparate:
                  signSize = 1;
                  signCopyOp = TR::InstOpCode::MVC;
                  break;
               case TR::UnicodeDecimalSignLeading:
                  signSize = 2;
                  signCopyOp = TR::InstOpCode::MVC;
                  break;
               default:
                  TR_ASSERT(0, "unknown leading sign type in pdStoreEvaluator");
               }

            TR::MemoryReference *originalSignCodeMR =
               reuseS390LeftAlignedMemoryReference(targetMR, node, targetStorageReference, cg, node->getSize());

            TR::MemoryReference *copyMR =
               reuseS390LeftAlignedMemoryReference(copyTargetMR, valueChild, valueStorageReferenceCopy, cg, sourceSize);

            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tAccumulating a leading sign type: have to restore the sign code for the copy: signSize %d, signCopyOp %s\n",
                        signSize,  TR::InstOpCode::opCodeToNameMap[signCopyOp]);


            generateSS1Instruction(cg, signCopyOp, node,
                                   signSize-1,
                                   copyMR,
                                   originalSignCodeMR);

            }
         }
      }

   rcount_t finalValueChildRefCount = valueChild->getReferenceCount();
   if (changeCommonedChildAddress &&
       finalValueChildRefCount != origValueChildRefCount)
      {
      // In this case the addressChild and the valueChild share a commoned node.
      // This will cause the addressChild evaluation (done as part of getting targetMR) to be an impliedMemoryReference and
      // the aiadd will be incremented by one (in anticipation of the valueChild using the targetStorageRef going forward)
      // In the trivial case where this future use is only under the current store ( == 1 check below) then have to take care to do the final
      // recDec of the addressChild to remove the extra increment done when forming the targetMR.
      //
      // izdstore
      //    aiadd
      //       ...
      //          zdload
      //    =>zdload
      //
      TR_ASSERT(finalValueChildRefCount > 0 && finalValueChildRefCount < origValueChildRefCount,
         "finalValueChildRefCount %d must be > 0 and less than origValueChildRefCount %d on store %p\n",finalValueChildRefCount,origValueChildRefCount,node);
      // the only way the refCounts can be not equal is if we evaluated a targetMR
      TR_ASSERT(targetMR,"finalValueChildRefCount %d must be equal to origValueChildRefCount %d if targetMR is non-NULL on store %p\n",finalValueChildRefCount,origValueChildRefCount,node);
      if (isIndirect && finalValueChildRefCount == 1)
         {
         // only remaining use is as the valueChild of this very store so must do the final recDec of the addressChild
         // a recDec is safe here as the targetMR would have already privatized any loads in the address child to registers
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tfinalValueChildRefCount < origValueChildRefCount (%d < %d) and is 1 so recursively dec addrChild %s (%p) %d->%d\n",
               finalValueChildRefCount,origValueChildRefCount,
               node->getFirstChild()->getOpCode().getName(),
               node->getFirstChild(),
               node->getFirstChild()->getReferenceCount(),node->getFirstChild()->getReferenceCount()-1);
         cg->recursivelyDecReferenceCount(node->getFirstChild());
         }
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tfinalValueChildRefCount < origValueChildRefCount (%d < %d) decrement the targetStorageReference nodeRefCount by the difference %d->%d\n",
            finalValueChildRefCount,origValueChildRefCount,
            targetStorageReference->getNodeReferenceCount(),targetStorageReference->getNodeReferenceCount()-(origValueChildRefCount-finalValueChildRefCount));
      // the valueChild may be commoned more than once under the addressChild of the store so dec by the difference of the before and after refCounts
      targetStorageReference->decrementNodeReferenceCount(origValueChildRefCount-finalValueChildRefCount);
      }

   if (targetMR == NULL)
      {
      if (isIndirect)
         {
         // if changeCommonedChildAddress=true then we must not decrement the addressChild as it will be needed for future commoned references
         // to the valueChild
         // a recDec is safe here as the only way no store can be done (targetMR==NULL case) is when valueChildren have already privatized
         // any loads in the address child to registers when accumulating to the final store location
         if (!changeCommonedChildAddress)
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tno explicit store inst and changeCommonedChildAddress=false so recursively dec addrChild %p %d->%d\n",
                  node->getFirstChild(),node->getFirstChild()->getReferenceCount(),node->getFirstChild()->getReferenceCount()-1);
            cg->recursivelyDecReferenceCount(node->getFirstChild());
            }
         else
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tno explicit store inst and changeCommonedChildAddress=true so do NOT recursively dec addrChild %p (refCount stays at %d)\n",
                  node->getFirstChild(),node->getFirstChild()->getReferenceCount());
            }
         }
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tno explicit store inst so decrement the targetStorageReference nodeRefCount %d->%d\n",
            targetStorageReference->getNodeReferenceCount(),targetStorageReference->getNodeReferenceCount()-1);
      targetStorageReference->decrementNodeReferenceCount();
      }

   if (!evaluatedPaddingAnchor)
      cg->processUnusedNodeDuringEvaluation(NULL);

   cg->decReferenceCount(valueChild);
   return NULL;
   }

/**
 * This only handles pdstore and pdstorei.
 * Other types of stores (zd, ud) can't use vector instructions.
*/
TR::Register*
J9::Z::TreeEvaluator::pdstoreVectorEvaluatorHelper(TR::Node *node, TR::CodeGenerator *cg)
   {
   traceMsg(cg->comp(), "DAA: Entering pdstoreVectorEvaluator %d\n", __LINE__);
   TR::Compilation *comp = cg->comp();
   TR::Node * valueChild = node->getValueChild();
   TR::Node* addressNode = node->getChild(0);
   // evalute valueChild (which is assumed by the OMR layer to be the second child) to Vector register.
   // for this "pdStore" we assume if we evaluate value node we get Vector Register
   TR::Register* addressReg = cg->evaluate(addressNode);
   TR::Register* pdValueReg = cg->evaluate(valueChild);

   TR_ASSERT((pdValueReg->getKind() == TR_FPR || pdValueReg->getKind() == TR_VRF),
             "vectorized pdstore is expecting its value in a vector register.");

   if (cg->traceBCDCodeGen())
      {
      traceMsg(comp,"generating VSTRL for pdstore node->size = %d.\n", node->getSize());
      }

   TR::MemoryReference * targetMR = generateS390MemoryReference(addressReg, NULL, 0, cg);

   // 0 we store 1 byte, 15 we store 16 bytes
   uint8_t lengthToStore = TR_VECTOR_REGISTER_SIZE - 1;
   if (node->getDecimalPrecision() > TR_MAX_INPUT_PACKED_DECIMAL_PRECISION )
      {
      targetMR->addToOffset(node->getSize() - TR_VECTOR_REGISTER_SIZE);
      }
   else
      {
      lengthToStore = node->getSize() - 1;
      }

   generateVSIInstruction(cg, TR::InstOpCode::VSTRL, node, pdValueReg, targetMR, lengthToStore);
   cg->decReferenceCount(valueChild);
   cg->decReferenceCount(addressNode);

   traceMsg(cg->comp(), "DAA: Exiting pdstoreVectorEvaluator %d\n", __LINE__);
   return NULL;
   }

TR_PseudoRegister * J9::Z::TreeEvaluator::evaluateBCDSignModifyingOperand(TR::Node *node,
                                                                              bool isEffectiveNop,
                                                                              bool isNondestructiveNop,
                                                                              bool initTarget,
                                                                              TR::MemoryReference *sourceMR,
                                                                              TR::CodeGenerator *cg)
   {
   TR_ASSERT(node->getType().isBCD(),"node %p type %s must be BCD\n",node,node->getDataType().toString());
   TR_OpaquePseudoRegister *reg = evaluateSignModifyingOperand(node, isEffectiveNop, isNondestructiveNop, initTarget, sourceMR, cg);
   TR_PseudoRegister *pseudoReg = reg->getPseudoRegister();
   TR_ASSERT(pseudoReg,"pseudoReg should be non-NULL for node %p\n",node);
   return pseudoReg;
   }


TR_OpaquePseudoRegister * J9::Z::TreeEvaluator::evaluateSignModifyingOperand(TR::Node *node,
                                                                                 bool isEffectiveNop,
                                                                                 bool isNondestructiveNop,
                                                                                 bool initTarget,
                                                                                 TR::MemoryReference *sourceMR,
                                                                                 TR::CodeGenerator *cg)
   {
   bool isBCD = node->getType().isBCD();
   TR::Node *child = node->getFirstChild();
   TR_OpaquePseudoRegister *firstReg = cg->evaluateOPRNode(child);
   TR::Compilation *comp = cg->comp();

   if (isBCD)
      TR_ASSERT(firstReg->getPseudoRegister(),"firstReg->getPseudoRegister() is null in evaluateSignModifyingOperand for BCD node %p\n",child);

   if (cg->traceBCDCodeGen())
      {
      if (isBCD)
         traceMsg(comp,"\tevaluateSignModOperand %s (%p) : firstReg %s firstReg->getPseudoRegister()->prec %d (isInit %s, isLegalToCleanSign %s, isEffectiveNop %s, initTarget %s)\n",
            node->getOpCode().getName(),node,cg->getDebug()->getName(firstReg),firstReg->getPseudoRegister()->getDecimalPrecision(),
            firstReg->isInitialized() ? "yes":"no",firstReg->getPseudoRegister()->isLegalToCleanSign()? "yes":"no",isEffectiveNop ? "yes":"no",initTarget ? "yes":"no");
      else
         traceMsg(comp,"\tevaluateSignModOperand for aggr type %s (%p) : firstReg %s (isInit %s, isEffectiveNop %s, initTarget %s)\n",
            node->getOpCode().getName(),node,cg->getDebug()->getName(firstReg),
            firstReg->isInitialized() ? "yes":"no",isEffectiveNop ? "yes":"no",initTarget ? "yes":"no");
      }

   TR_OpaquePseudoRegister *targetReg = NULL;

   // Note that a clobber evaluate must be done for any initialized firstReg -- even in the effectiveNop case:
   // 2  pdclean  <- (isEffectiveNop=true) (temp1)
   // 1     pdremSelect <- node (isEffectiveNop=true) (temp1)
   // 2        pddivrem <- child (temp1)
   // ...
   //    pdshr (clobbers temp1)
   //       =>pddivrem (temp1)
   // ...
   //    =>pdclean (uses invalid clobbered temp1 - wrong)
   // if a clobber evaluate is *not* done and temp1 is used for the pdremSelect and the pdclean then the parent of the second reference to the pddivrem node
   // will clobber temp1 and subsequent references to pdclean (and pdremSelect if any) will use the incorrectly clobbered temp1.
   // The clobber evaluate will copy the pddivrem result in temp1 to temp2 and the commoned pdclean will use the (now unclobbered) temp1
   // TODO: an alternative fix would be to *not* clobber evaluate for the isEffectiveNop=true case but to instead allocate and mark a new register as read-only
   // for the commoned pddivrem but clobberable for the pdremSelect and pdclean (basically do a clobber evaluate but don't generate an MVC to copy the value).
   // Doing the MVC copy lazily by any later consumer (the pdshr) would likely be better in some cases.
   // UPDATE: the above TODO is complete as part of ReadOnlyTemporary sets done below
   bool resetReadOnly = true;
   if (isEffectiveNop)
      {
      resetReadOnly = false;
      targetReg = isBCD? cg->allocatePseudoRegister(firstReg->getPseudoRegister()) : cg->allocateOpaquePseudoRegister(firstReg);

      if (isBCD && (node->getDecimalPrecision() < firstReg->getPseudoRegister()->getDecimalPrecision()) &&
          (!firstReg->getPseudoRegister()->hasKnownOrAssumedSignCode() || (firstReg->getPseudoRegister()->getKnownOrAssumedSignCode() != TR::DataType::getPreferredPlusCode())))
         {
         // on a truncation of a value with an unknown or negative sign code then conservatively set clean to false as negative zero (unclean) may be produced
         targetReg->getPseudoRegister()->resetCleanSign();
         }
      TR_StorageReference *firstStorageReference = firstReg->getStorageReference();
      // transfer the zeroDigits/deadBytes and cache the firstReg->getStorageReference() *before* calling ssrClobberEvaluate in case
      // a new storage reference set on firstReg causes these values to be reset
      targetReg->setLeftAlignedZeroDigits(firstReg->getLeftAlignedZeroDigits());
      targetReg->setRightAlignedDeadBytes(firstReg->getRightAlignedDeadBytes());
      targetReg->setRightAlignedIgnoredBytes(firstReg->getRightAlignedIgnoredBytes());
      if (cg->traceBCDCodeGen())
         {
         traceMsg(comp,"\t * setting rightAlignedDeadBytes %d from firstReg %s to targetReg %s (signMod nop)\n",
            firstReg->getRightAlignedDeadBytes(),cg->getDebug()->getName(firstReg),cg->getDebug()->getName(targetReg));
         traceMsg(comp,"\t * setting rightAlignedIgnoredBytes %d from firstReg %s to targetReg %s (signMod nop)\n",
            firstReg->getRightAlignedIgnoredBytes(),cg->getDebug()->getName(firstReg),cg->getDebug()->getName(targetReg));
         if (isBCD)
            traceMsg(comp,"\t * setting savedLeftAlignedZeroDigits %d from firstReg %s to targetReg %s (signMod nop)\n",
               firstReg->getLeftAlignedZeroDigits(),cg->getDebug()->getName(firstReg),cg->getDebug()->getName(targetReg));
         }

      if (firstReg->isInitialized())
         {
         // The extra work to allow this for non-temp based is to expand the skipCopyOnStore check to all nodes (i.e. do not restrict this flag to those directly under a store node).
         // This skipCopyOnStore analysis will then guarantee that the underlying non-temp variable is not killed before its next use(s).
         if (!comp->getOption(TR_DisableRefinedBCDClobberEval) && firstStorageReference->isTemporaryBased() && isNondestructiveNop)
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"%sskipping ssrClobberEvaluate for %s (%p) with child %s (%p) refCount %d %s 1 owningRegisterCount %d %s 1-- %s mark #%d (%s) as readOnlyTemp (nondestructive nop case)\n",
                        child->getReferenceCount() > 1 ? "y^y : ":"",
                        node->getOpCode().getName(),node,child->getOpCode().getName(),child,
                        child->getReferenceCount(),child->getReferenceCount() > 1 ? ">":"<=",
                        firstStorageReference->getOwningRegisterCount(), firstStorageReference->getOwningRegisterCount() > 1 ? ">" : "<=",
                        child->getReferenceCount() > 1 ? "do":"do not",firstStorageReference->getReferenceNumber(),
                  cg->getDebug()->getName(firstStorageReference->getSymbol()));

            if (child->getReferenceCount() > 1 || firstStorageReference->getOwningRegisterCount() > 1)
               {
               firstStorageReference->setIsReadOnlyTemporary(true, child);
               }
            resetReadOnly = false;
            }
         else
            {
            cg->ssrClobberEvaluate(child, sourceMR);
            }
         }

      // transfer the storageRef *after* calling ssrClobberEvaluate so the referenceCounts of the temporaries are set correctly
      TR_StorageReference *targetStorageReference = firstStorageReference;
      targetReg->setStorageReference(targetStorageReference, node);
      if (!firstReg->isInitialized() && targetStorageReference->isNodeBased())
         {
         // NodeReferenceCounts are not used for node based hints and this path should never be reached for these hints
         // as this type of storage reference is only used when it has been initialized
         TR_ASSERT( !targetStorageReference->isNodeBasedHint(),"a node based hint should have been initialized\n");
         // This is the case where the firstChild is likely an ipdload (or a pdclean of ipdload etc)
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tisEffectiveNop=yes and firstReg->isInit=false case so increment the targetStorageReference nodeRefCount by (node->refCount() - 1) = %d : %d->%d\n",
               node->getReferenceCount()-1,
               targetStorageReference->getNodeReferenceCount(),
               targetStorageReference->getNodeReferenceCount()+(node->getReferenceCount()-1));
         targetStorageReference->incrementNodeReferenceCount(node->getReferenceCount()-1);
         cg->privatizeStorageReference(node, targetReg, NULL);
         }
      }
   else if (firstReg->isInitialized())
      {
      TR_ASSERT( isBCD, "this path should only be taken for BCD nodes (unless we extend support for aggr types)\n");
      TR_StorageReference *firstStorageReference = firstReg->getStorageReference();
      // An initialized reg cannot have a non-hint node based storage reference as these would come from an ipdload node and pdload's never initialize a register
      TR_ASSERT( firstStorageReference->isTemporaryBased() || firstStorageReference->isNodeBasedHint(),"expecting the initalized firstReg to be either a temp or a node based hint\n");
      targetReg = cg->allocatePseudoRegister(node->getDataType());
      // transfer the zeroDigits/deadBytes and cache the firstReg->getStorageReference() *before* calling ssrClobberEvaluate in case
      // a new storage reference set on firstReg causes these values to be reset
      targetReg->setLeftAlignedZeroDigits(firstReg->getLeftAlignedZeroDigits());
      targetReg->setRightAlignedDeadBytes(firstReg->getRightAlignedDeadBytes());
      targetReg->setRightAlignedIgnoredBytes(firstReg->getRightAlignedIgnoredBytes());
      targetReg->getPseudoRegister()->transferDataState(firstReg->getPseudoRegister());
      if (cg->traceBCDCodeGen())
         {
         traceMsg(comp,"\t * setting rightAlignedDeadBytes %d from firstReg %s to targetReg %s (signMod isInit)\n",
            firstReg->getRightAlignedDeadBytes(),cg->getDebug()->getName(firstReg),cg->getDebug()->getName(targetReg));
         traceMsg(comp,"\t * setting rightAlignedIgnoredBytes %d from firstReg %s to targetReg %s (signMod isInit)\n",
            firstReg->getRightAlignedIgnoredBytes(),cg->getDebug()->getName(firstReg),cg->getDebug()->getName(targetReg));
         traceMsg(comp,"\t * setting savedLeftAlignedZeroDigits %d from firstReg %s to targetReg %s (signMod isInit)\n",
            firstReg->getLeftAlignedZeroDigits(),cg->getDebug()->getName(firstReg),cg->getDebug()->getName(targetReg));

         }

      if (!comp->getOption(TR_DisableRefinedBCDClobberEval) && firstReg->canBeConservativelyClobberedBy(node))
         {
         //    pdclean
         // 3    pdadd
         //
         //    AP    t1,t2
         //    ZAP   t1,t1 // this ZAP is a conservative clobber as it will not modify the value in pdadd and there are no special sign codes to be preserved
         //
         //    the t1 storageReference will be marked as readOnly and pdadd added to nodeToUpdateOnClobber list so if/when t1 is actually clobbered the commoned
         //    register/node can have its storageRef updated to point to the saved value.
         //
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"%sskipping ssrClobberEvaluate for %s (%p) with child %s (%p) refCount %d %s 1 owningRegisterCount %d %s 1-- %s mark #%d (%s) as readOnlyTemp (isInit case)\n",
                     child->getReferenceCount() > 1 ? "y^y : ":"",
                     node->getOpCode().getName(),node,child->getOpCode().getName(),child,
                     child->getReferenceCount(),child->getReferenceCount() > 1 ? ">":"<=",
                     firstStorageReference->getOwningRegisterCount(), firstStorageReference->getOwningRegisterCount() > 1 ? ">" : "<=",
                     child->getReferenceCount() > 1 ? "do":"do not",firstStorageReference->getReferenceNumber(),
                     cg->getDebug()->getName(firstStorageReference->getSymbol()));

         if (child->getReferenceCount() > 1 || firstStorageReference->getOwningRegisterCount() > 1)
            {
            firstStorageReference->setIsReadOnlyTemporary(true, child);
            }
         resetReadOnly = false;
         }
      else
         {
         cg->ssrClobberEvaluate(child, sourceMR);
         }

      // transfer the storageRef *after* calling ssrClobberEvaluate so the referenceCounts of the temporaries are set correctly
      targetReg->setStorageReference(firstStorageReference, node);
      targetReg->setIsInitialized();
      }
   else
      {
      TR_ASSERT( isBCD, "this path should only be taken for BCD nodes (unless we extend support for aggr types)\n");
      targetReg = cg->allocatePseudoRegister(node->getDataType());
      TR_StorageReference *targetStorageReference = NULL;
      if (node->getOpCode().canHaveStorageReferenceHint() && node->getStorageReferenceHint())
         targetStorageReference = node->getStorageReferenceHint();
      else
         targetStorageReference = TR_StorageReference::createTemporaryBasedStorageReference(node->getStorageReferenceSize(), comp);
      targetReg->setStorageReference(targetStorageReference, node);
      if (initTarget)
         {
         int32_t srcLiveSymbolSize = firstReg->getLiveSymbolSize();
         int32_t targetLiveSymbolSize = targetReg->getLiveSymbolSize();
         int32_t mvcSize = node->getSize();
         bool isTruncation = node->getSize() < firstReg->getSize();
         // if there are some left aligned zero digits in the source then increase the mvcSize to capture these in the initializing MVC
         if (firstReg->trackZeroDigits() &&
             (targetLiveSymbolSize == srcLiveSymbolSize) &&
             (srcLiveSymbolSize > mvcSize) &&
             (firstReg->getBytesToClear(mvcSize, srcLiveSymbolSize) == 0))
            {
            // increasing the mvcSize to include already zero'd bytes is illegal if targetLiveSymbolSize < srcLiveSymbolSize and
            // legal if targetLiveSymbolSize>=srcLiveSymbolSize but pointless if targetLiveSymbolSize > srcLiveSymbolSize as the extra
            // zero bytes will not be tracked on the targetReg so only do this when targetLiveSymbolSize == srcLiveSymbolSize
            //
            // In this case the source register has some zero bytes above its register size so increase the MVC size to include these zero bytes
            // e.g. if targetReg->getSize()=6 but the childLiveSymbolSize=9 then increase the mvcSize by 3 to 9
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tupper %d bytes on srcReg %s are already clear so set mvcSize=%d\n", srcLiveSymbolSize-mvcSize,cg->getDebug()->getName(firstReg),srcLiveSymbolSize);
            targetReg->addRangeOfZeroBytes(mvcSize,srcLiveSymbolSize);
            mvcSize = srcLiveSymbolSize;
            }
         else if (!isTruncation)   // on a widening only initialize up to the source size
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tfirstReg->getSize() <= node->getSize() (%d <= %d) so reduce mvcSize\n",firstReg->getSize(),node->getSize());
            mvcSize = firstReg->getSize();
            }

         if (isTruncation && node->getType().isSeparateSign())
            {
            mvcSize -= node->getDataType().separateSignSize();
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tnode %s is a truncating separateSign type so reduce mvcSize by sign size (%d->%d)\n",
                  node->getOpCode().getName(),mvcSize+node->getDataType().separateSignSize(),mvcSize);
            }

         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tfirstReg->isInitialized()==false so gen MVC to init with mvcSize %d\n", mvcSize);
         TR_ASSERT( sourceMR,"source memory reference should have been created by caller\n");
         generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                                mvcSize-1,
                                generateS390RightAlignedMemoryReference(node, targetStorageReference, cg),
                                generateS390RightAlignedMemoryReference(*sourceMR, node, 0, cg));
         targetReg->getPseudoRegister()->transferDataState(firstReg->getPseudoRegister());
         targetReg->setIsInitialized();
         }
      }

   if (isEffectiveNop || firstReg->isInitialized())
      cg->freeUnusedTemporaryBasedHint(node);

   if (firstReg->getSize() < node->getSize())
      {
      TR_ASSERT( isBCD, "this path should only be taken for BCD nodes (unless we extend support for aggr types)\n");
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\twidening: firstRegSize < nodeSize (%d < %d) so set targetReg->getPseudoRegister()->prec to firstReg->prec (%d)\n",firstReg->getSize(), node->getSize(),firstReg->getPseudoRegister()->getDecimalPrecision());
      targetReg->getPseudoRegister()->setDecimalPrecision(firstReg->getPseudoRegister()->getDecimalPrecision());
      }

   if (cg->traceBCDCodeGen() && targetReg->getStorageReference()->isReadOnlyTemporary())
      traceMsg(comp,"%sreset readOnlyTemp flag on storageRef #%d (%s) (signMod case)\n",
         resetReadOnly?"":"do not ",targetReg->getStorageReference()->getReferenceNumber(),cg->getDebug()->getName(targetReg->getStorageReference()->getSymbol()));

   if (resetReadOnly)
      targetReg->getStorageReference()->setIsReadOnlyTemporary(false, NULL);

   node->setRegister(targetReg);
   return targetReg;
   }

TR::Register *J9::Z::TreeEvaluator::pdSetSignHelper(TR::Node *node, int32_t sign, TR::CodeGenerator *cg)
   {
   TR::Node *srcNode = node->getFirstChild();
   TR_PseudoRegister *srcReg = cg->evaluateBCDNode(srcNode);
   TR_PseudoRegister *targetReg = NULL;

   if (node->getType().isAnyPacked())
      {
      targetReg = simpleWideningOrTruncation(node, srcReg, true, sign, cg);  // setSign=true
      }
   else if (node->getDataType() == TR::ZonedDecimal)
      {
      bool isEffectiveNop = (sign == TR::DataType::getIgnoredSignCode()) || srcReg->knownOrAssumedSignCodeIs(sign);
      TR::MemoryReference *sourceMR = NULL;
      if (!srcReg->isInitialized() && !isEffectiveNop)
         sourceMR = generateS390RightAlignedMemoryReference(srcNode, srcReg->getStorageReference(), cg);
      targetReg = evaluateBCDSignModifyingOperand(node, isEffectiveNop, isEffectiveNop, true, sourceMR, cg); // initTarget=true
      bool isTruncation = srcReg->getDecimalPrecision() > node->getDecimalPrecision();
      if (isTruncation)
         targetReg->setDecimalPrecision(node->getDecimalPrecision());
      else
         targetReg->setDecimalPrecision(srcReg->getDecimalPrecision());
      if (!isEffectiveNop)
         {
         TR_StorageReference *targetStorageReference = targetReg->getStorageReference();
         TR_StorageReference *firstStorageReference = srcReg->getStorageReference();
         TR::MemoryReference *destMR = generateS390RightAlignedMemoryReference(node, targetStorageReference, cg);
         int32_t destLength = targetReg->getSize();
         cg->genSignCodeSetting(node, targetReg, destLength, destMR, sign, srcReg, 0, false); // digitsToClear=0, numericNibbleIsZero=false
         }
      }
   else
      {
      TR_ASSERT(false,"unexpected datatype %s in pdSetSignHelper\n",node->getDataType().toString());
      }

   node->setRegister(targetReg);
   cg->decReferenceCount(srcNode);
   return targetReg;
   }

/**
 * \brief Evaluator function to evaluate pdSetSign opCode
*/
TR::Register*
J9::Z::TreeEvaluator::pdSetSignEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pdSetSign",node);
   cg->generateDebugCounter("PD-Op/pdsetsign", 1, TR::DebugCounter::Cheap);

   TR::Register *targetReg = NULL;
   TR::Node *signNode = node->getSecondChild();

   TR_ASSERT(signNode->getOpCode().isLoadConst() && signNode->getOpCode().getSize() <= 4,
             "expecting a <= 4 size integral constant set sign amount\n");
   TR_ASSERT(node->getFirstChild()->getType().isAnyPacked(), "expecting setSign's first child of PD data type");

   int32_t sign = (int32_t)signNode->get64bitIntegralValue();
   cg->decReferenceCount(signNode);

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      targetReg = vectorPerformSignOperationHelper(node,
                                                   cg,
                                                   false,       // change precision
                                                   0,
                                                   node->hasKnownOrAssumedCleanSign(),
                                                   SignOperationType::setSign,
                                                   false,       // signValidityCheck
                                                   sign);
      }
   else
      {
      targetReg = pdSetSignHelper(node, sign, cg);
      }

   cg->traceBCDExit("pdSetSign",node);
   return targetReg;
   }


/**
 * TR::pdclear
 * TR::pdclearSetSign
 * current limitation for this is that leftMostDigit must equal digitsToClear (i.e. clearing right most digits)
 */
TR::Register *J9::Z::TreeEvaluator::pdclearEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pdclear",node);
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "PD-Op/%s", node->getOpCode().getName()),
                            1, TR::DebugCounter::Cheap);
   TR_ASSERT(!node->getOpCode().isSetSign(),"isSetSign on child not supported for node %s (%p)\n",node->getOpCode().getName(),node);
   bool isSetSign = node->getOpCode().isSetSignOnNode();
   TR_RawBCDSignCode setSignValue = isSetSign ? node->getSetSign() : raw_bcd_sign_unknown;
   int32_t sign = TR::DataType::getValue(setSignValue);
   TR::Compilation *comp = cg->comp();

   TR_ASSERT(!isSetSign || setSignValue != raw_bcd_sign_unknown,"setSignValue must be on the node for %p\n",node);

   TR::Node *srcNode = node->getChild(0);
   TR::Node *leftMostDigitNode = node->getChild(1);
   TR::Node *digitsToClearNode = node->getChild(2);
   TR::Node *literalAddrNode = (isSetSign && node->getNumChildren() > 3) ? node->getChild(3) : NULL;

   TR_ASSERT(leftMostDigitNode->getOpCode().isLoadConst() && leftMostDigitNode->getSize() <= 4,
      "leftMostDigitNode %p must be a <= 4 size const\n",leftMostDigitNode);
   TR_ASSERT(digitsToClearNode->getOpCode().isLoadConst() && digitsToClearNode->getSize() <= 4,
      "digitsToClearNode %p must be a <= 4 size const\n",digitsToClearNode);

   int32_t leftMostDigit = leftMostDigitNode->get32bitIntegralValue();
   int32_t leftMostByte = TR::DataType::packedDecimalPrecisionToByteLength(leftMostDigit);
   int32_t digitsToClear = digitsToClearNode->get32bitIntegralValue();
   int32_t rightMostDigit = leftMostDigit - digitsToClear;

   TR_ASSERT(leftMostDigit == digitsToClear,"leftMostDigit %d must equal digitsToClear for node %p\n",leftMostDigit,digitsToClear,node);

   TR_PseudoRegister *srcReg = cg->evaluateBCDNode(srcNode);
   bool isInitialized = srcReg->isInitialized();
   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\t%s (%p) : srcNode %s (%p) isInit=%s, digitClearRange %d->%d (leftMostByte=%d), digitsToClear = %d (isSetSign %s, sign 0x%x)\n",
         node->getOpCode().getName(),node,
         srcNode->getOpCode().getName(),srcNode,
         isInitialized ? "yes":"no",
         leftMostDigit,rightMostDigit,leftMostByte,digitsToClear,isSetSign?"yes":"no",sign);
   TR_StorageReference *srcStorageReference = srcReg->getStorageReference();
   TR::MemoryReference *sourceMR = generateS390RightAlignedMemoryReference(srcNode, srcStorageReference, cg);

   TR_PseudoRegister *targetReg = evaluateBCDValueModifyingOperand(node, true, sourceMR, cg); // initTarget=true
   TR::MemoryReference *destMR = generateS390RightAlignedMemoryReference(node, targetReg->getStorageReference(), cg);

   bool isTruncation = srcReg->getDecimalPrecision() > node->getDecimalPrecision();
   if (isTruncation)
      targetReg->setDecimalPrecision(node->getDecimalPrecision());
   else
      targetReg->setDecimalPrecision(srcReg->getDecimalPrecision());

   int32_t targetRegPrec = targetReg->getDecimalPrecision();

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tset targetReg prec to %d (isTrucation %s)\n",targetRegPrec,isTruncation?"yes":"no");

   bool truncatedIntoClearedDigits = false;
   if (targetRegPrec < leftMostDigit)
      {
      truncatedIntoClearedDigits = true;
      int32_t precDelta = leftMostDigit - targetRegPrec;
      leftMostDigit -= precDelta;
      leftMostByte = TR::DataType::packedDecimalPrecisionToByteLength(leftMostDigit);
      digitsToClear -= precDelta;
      rightMostDigit = leftMostDigit - digitsToClear;
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\ttargetRegPrec %d < leftMostDigit %d : update leftMostDigit %d->%d, leftMostByte = %d, digitsToClear %d->%d, rightMostDigit = %d\n",
            targetRegPrec,leftMostDigit+precDelta,leftMostDigit+precDelta,leftMostDigit,leftMostByte,digitsToClear+precDelta,digitsToClear,rightMostDigit);
      }

   // do not bother checking !node->canSkipPadByteClearing() below because being able to clear the full byte generally results in better codegen
   // coincidentEvenDigitCorrection is true when leftMostNibble == targetRegPrec so instead of generating separate NI 0xF0 and then NI 0x0F on the same byte
   // just inc digitsToClear below so this full byte clearing can be done in one instruction
   // e.g. p4v0 = (p15v0 / 10000) * 10000
   int32_t leftMostByteForClear = leftMostByte;
   bool needsEvenDigitCorrection = !truncatedIntoClearedDigits && isTruncation && targetReg->isEvenPrecision();
   bool coincidentEvenDigitCorrection = needsEvenDigitCorrection && (leftMostByteForClear == targetReg->getSize());
   if (isEven(leftMostDigit))
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tleftMostDigit %d isEven : isInit=%s, truncatedIntoClearedDigits=%s, coincidentEvenDigitCorrection=%s -- adjust the leftMostNibble to preserve or clear the leftMostByte\n",
            leftMostDigit,isInitialized?"yes":"no",truncatedIntoClearedDigits?"yes":"no",needsEvenDigitCorrection?"yes":"no");

      if (isInitialized && !truncatedIntoClearedDigits && !coincidentEvenDigitCorrection) // full byte will be cleared if truncatedIntoClearedDigits or coincidentEvenDigitCorrection are true
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\t\tisInit=yes,truncatedIntoClearedDigits=no,coincidentEvenDigitCorrection=no so dec %d->%d to preserve initialized leftMostNibble\n",digitsToClear,digitsToClear-1);
         digitsToClear--; // must preserve the top byte and then clear just the top digit after the clearAndSetSign
         leftMostByteForClear--;
         }
      else
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\t\tisInit=no or truncatedIntoClearedDigits=yes or coincidentEvenDigitCorrection=yes so inc %d->%d to clear initialized leftMostNibble\n",digitsToClear,digitsToClear+1);
         digitsToClear++; // clear a larger even # of digits and put back
         }
      }

   if (!isTruncation && srcReg->isEvenPrecision() && srcReg->isLeftMostNibbleClear())
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\twidening with even srcRegPrec %d update targetReg with zero range for leftMostNibble %d->%d\n",
            srcReg->getDecimalPrecision(),srcReg->getDecimalPrecision(),srcReg->getDecimalPrecision()+1);
      targetReg->addRangeOfZeroDigits(srcReg->getDecimalPrecision(),srcReg->getDecimalPrecision()+1);
      }

   // clearAndSetSign will be clearing full bytes so half byte values or signs will be put back afterwards
   clearAndSetSign(node, targetReg, leftMostByteForClear, digitsToClear, destMR, srcReg, sourceMR, isSetSign, sign, isInitialized, cg); // isSignInitialized=isInitialized

   if (!(truncatedIntoClearedDigits || coincidentEvenDigitCorrection))
      {
      if (isEven(leftMostDigit))
         {
         if (isInitialized)
            {
               {
               if (cg->traceBCDCodeGen())
                  traceMsg(comp,"\tisInit=yes : gen NI to clear right most nibble at byte %d\n",leftMostByte);
               generateSIInstruction(cg, TR::InstOpCode::NI, node,
                                     reuseS390LeftAlignedMemoryReference(destMR, node, targetReg->getStorageReference(), cg, leftMostByte),
                                     0xF0);
               }
            }
         else
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tisInit=no : gen MVZ to restore left most nibble at byte %d\n",leftMostByte);
            int32_t mvzSize = 1;
            generateSS1Instruction(cg, TR::InstOpCode::MVZ, node,
                                   mvzSize-1,
                                   reuseS390LeftAlignedMemoryReference(destMR, node, targetReg->getStorageReference(), cg, leftMostByte),
                                   reuseS390LeftAlignedMemoryReference(sourceMR, srcNode, srcStorageReference, cg, leftMostByte));
            }
         }

      if (needsEvenDigitCorrection && !node->canSkipPadByteClearing())
         cg->genZeroLeftMostPackedDigits(node, targetReg, targetReg->getSize(), 1, destMR);
      }

   cg->decReferenceCount(srcNode);
   cg->decReferenceCount(leftMostDigitNode);
   cg->decReferenceCount(digitsToClearNode);
   cg->processUnusedNodeDuringEvaluation(literalAddrNode);
   cg->traceBCDExit("pdclear",node);
   return targetReg;
   }

TR::Register *J9::Z::TreeEvaluator::pdchkEvaluator(TR::Node *node, TR::CodeGenerator *cg)
   {
   TR::Register *chkResultReg  = cg->allocateRegister(TR_GPR);
   generateRRInstruction(cg, TR::Compiler->target.is64Bit() ? TR::InstOpCode::XGR : TR::InstOpCode::XR, node, chkResultReg, chkResultReg);

   TR::Node * pdloadNode = node->getFirstChild();
   TR::Register* pdReg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() &&
           !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) ||
           isVectorBCDEnv)
      {
      pdReg = cg->evaluate(pdloadNode);
      generateVRRgInstruction(cg, TR::InstOpCode::VTP, node, pdReg);
      }
   else
      {
      pdReg = cg->evaluateBCDNode(pdloadNode);
      TR_StorageReference *pdStorageReference = static_cast<TR_PseudoRegister*>(pdReg)->getStorageReference();
      TR::MemoryReference *tempMR = generateS390RightAlignedMemoryReference(pdloadNode, pdStorageReference, cg);
      generateRSLInstruction(cg, TR::InstOpCode::TP, pdloadNode, static_cast<TR_PseudoRegister*>(pdReg)->getSize()-1, tempMR);
      }

   generateRRInstruction(cg, TR::InstOpCode::IPM, node, chkResultReg, chkResultReg);

   if(TR::Compiler->target.is64Bit())
      {
      generateRRInstruction(cg, TR::InstOpCode::LLGTR, node, chkResultReg, chkResultReg);
      generateRSInstruction(cg, TR::InstOpCode::SRLG, node, chkResultReg, chkResultReg, 28);
      }
   else
      {
      generateRSInstruction(cg, TR::InstOpCode::SRL, node, chkResultReg, 28);
      }

   node->setRegister(chkResultReg);
   cg->decReferenceCount(pdloadNode);
   return chkResultReg;
   }

/**
 * pd<op>Evaluator - various binary packed decimal evaluators
 */
void
J9::Z::TreeEvaluator::correctPackedArithmeticPrecision(TR::Node *node, int32_t op1EncodingSize, TR_PseudoRegister *targetReg, int32_t computedResultPrecision, TR::CodeGenerator * cg)
   {
   int32_t computedResultSize = TR::DataType::packedDecimalPrecisionToByteLength(computedResultPrecision);
   if (op1EncodingSize >= computedResultSize)
      targetReg->removeRangeOfZeroDigits(0, computedResultPrecision);
   else
      targetReg->removeRangeOfZeroBytes(0, op1EncodingSize);

   int32_t resultPrecision = std::min<int32_t>(computedResultPrecision, node->getDecimalPrecision());
   targetReg->setDecimalPrecision(resultPrecision);
   if (cg->traceBCDCodeGen())
      traceMsg(cg->comp(),"\tset targetRegPrec to min(computedResultPrecision, nodePrec) = min(%d, %d) = %d (targetRegSize = %d)\n",
         computedResultPrecision,node->getDecimalPrecision(),resultPrecision,targetReg->getSize());
   }

TR::Register *
J9::Z::TreeEvaluator::pdaddEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pdadd",node);
   cg->generateDebugCounter("PD-Op/pdadd", 1, TR::DebugCounter::Cheap);

   TR::Register * reg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      reg = pdArithmeticVectorEvaluatorHelper(node, TR::InstOpCode::VAP, cg);
      }
   else
      {
      reg = pdaddsubEvaluatorHelper(node, TR::InstOpCode::AP, cg);
      }

   cg->traceBCDExit("pdadd",node);
   return reg;
   }

TR::Register *
J9::Z::TreeEvaluator::pdsubEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pdsub",node);
   cg->generateDebugCounter("PD-Op/pdsub", 1, TR::DebugCounter::Cheap);

   TR::Register * reg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      reg = pdArithmeticVectorEvaluatorHelper(node, TR::InstOpCode::VSP, cg);
      }
   else
      {
      reg = pdaddsubEvaluatorHelper(node, TR::InstOpCode::SP, cg);
      }

   cg->traceBCDExit("pdsub",node);
   return reg;
   }

int32_t getAddSubComputedResultPrecision(TR::Node *node, TR::CodeGenerator * cg)
   {
   TR::Node *firstChild = node->getFirstChild();
   TR::Node *secondChild = node->getSecondChild();

   TR_PseudoRegister *firstReg = firstChild->getPseudoRegister();
   if (firstReg == NULL)
      firstReg = cg->evaluateBCDNode(firstChild);

   TR_PseudoRegister *secondReg = secondChild->getPseudoRegister();
   if (secondReg == NULL)
      secondReg = cg->evaluateBCDNode(secondChild);

   int32_t precBump = (firstChild->isZero() || secondChild->isZero()) ? 0 : 1;
   int32_t computedResultPrecision = std::max(firstReg->getDecimalPrecision(), secondReg->getDecimalPrecision())+precBump;

   return computedResultPrecision;
   }

/**
 * This evaluator helper function uses BCD vector instructions for PD arithmetic operations:
 *
 * -- pdadd
 * -- pdsub
 * -- pdmul
 * -- pddiv
 *
 * whose corresponding BCD vector instructrions are of VRI-f format.
 */
TR::Register *
J9::Z::TreeEvaluator::pdArithmeticVectorEvaluatorHelper(TR::Node * node, TR::InstOpCode::Mnemonic op, TR::CodeGenerator * cg)
   {
   TR_ASSERT(node->getType().isAnyPacked(), "pd Arithmetic is only valid for Packed types");
   //for VSDP/VMSP immediate field is shift amount.
   //for VAP/VDP/VMP/VSP immediate field is precisioninformation,
   int32_t immediateValue = 0;

   switch (op)
      {
      case TR::InstOpCode::VAP:
      case TR::InstOpCode::VSP:
      case TR::InstOpCode::VDP:
      case TR::InstOpCode::VMP:
      case TR::InstOpCode::VRP:
         immediateValue = node->getDecimalPrecision();
         break;
      case TR::InstOpCode::VSDP:
         immediateValue = node->getDecimalAdjust();
         break;
      case TR::InstOpCode::VMSP:
         immediateValue = node->getDecimalAdjust() * -1;
         break;
      default:
         TR_ASSERT(0,"Invalid Decimal arithmetic OpCode.");
         break;
      }

   TR_ASSERT((immediateValue >> 8) == 0, "Decimal precision or adjustment value exceeds 1 byte");

   TR::Node* firstChild = node->getFirstChild();
   TR::Node* secondChild = node->getSecondChild();

   // dec before evaluating the second child to avoid an unneeded clobber evaluate
   TR::Register* firstChildReg = cg->evaluate(firstChild);
   TR::Register* secondChildReg = cg->evaluate(secondChild);

   // For simple PD Decimal Operations, let's set the mask to 0: no force positive nor set CC
   TR::Register* targetReg = cg->allocateRegister(TR_VRF);
   generateVRIfInstruction(cg, op, node, targetReg, firstChildReg, secondChildReg, immediateValue, 0x1);
   node->setRegister(targetReg);

   cg->decReferenceCount(firstChild);
   cg->decReferenceCount(secondChild);

   return targetReg;
   }

/**
 * Handles pdadd,pdsub
 */
TR::Register *
J9::Z::TreeEvaluator::pdaddsubEvaluatorHelper(TR::Node * node, TR::InstOpCode::Mnemonic op, TR::CodeGenerator * cg)
   {
   bool produceOverflowMessage = node->getOpCode().isPackedArithmeticOverflowMessage();
   bool isAdd = (op == TR::InstOpCode::AP);
   TR::Node *firstChild = node->getFirstChild();
   TR::Node *secondChild = node->getSecondChild();
   TR::Compilation *comp = cg->comp();

   TR_PseudoRegister *firstReg = cg->evaluateBCDNode(firstChild);
   bool trackSignState=false;
   bool alwaysLegalToCleanSign=true; // ok to use ZAP (and clobber srcSign) to init as there is an AP/SP coming
   TR_PseudoRegister *targetReg = evaluateBCDValueModifyingOperand(node, true, NULL, cg, trackSignState, 0, alwaysLegalToCleanSign); // initTarget=true, sourceMR=NULL, srcSize=0
   cg->decReferenceCount(firstChild); // dec bef evaluating the second child to avoid an unneeded clobber evaluate
   TR_PseudoRegister *secondReg = cg->evaluateBCDNode(secondChild);
   TR_StorageReference *targetStorageReference = targetReg->getStorageReference();
   TR::MemoryReference *destMR = generateS390RightAlignedMemoryReference(node, targetStorageReference, cg);
   TR::MemoryReference *secondMR = generateS390RightAlignedMemoryReference(secondChild, secondReg->getStorageReference(), cg);


   int32_t op1EncodingPrecision = cg->getPDAddSubEncodedPrecision(node, firstReg);
   int32_t op1EncodingSize = cg->getPDAddSubEncodedSize(node, firstReg);
   // The preparatory clearing operations need a length set so base it on the op1EncodingSize but the final returned precision will be set after the AP/SP instruction has been generated
   targetReg->setDecimalPrecision(op1EncodingPrecision);

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\t%s: produceOverflowMessage=%s, node->getSize()=%d, firstReg->getSize()=%d, secondReg->getSize()=%d, op1EncodingPrec=%d, op1EncodingSize=%d\n",
         node->getOpCode().getName(),produceOverflowMessage?"yes":"no", node->getSize(), firstReg->getSize(), secondReg->getSize(),op1EncodingPrecision, targetReg->getSize());

   if (op1EncodingSize > firstReg->getSize())
      cg->clearByteRangeIfNeeded(node, targetReg, generateS390RightAlignedMemoryReference(*destMR, node, 0, cg), firstReg->getSize(), op1EncodingSize, true); // widenOnLeft=true

   // endByte=firstReg->getSize but for types like packed where the sign is right aligned this endByte setting does not matter
   // as the leftMostByte for the sign is always known (== 1)
   cg->correctBadSign(firstChild, firstReg, firstReg->getSize(), destMR);
   cg->correctBadSign(secondChild, secondReg, secondReg->getSize(), secondMR);

   int32_t computedResultPrecision = getAddSubComputedResultPrecision(node, cg);
   bool mayOverflow = computedResultPrecision > node->getDecimalPrecision();
   correctPackedArithmeticPrecision(node, op1EncodingSize, targetReg, computedResultPrecision, cg);

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tcomputedResultPrecision %s nodePrec (%d %s %d) -- mayOverflow = %s\n",
         mayOverflow?">":"<=",computedResultPrecision,mayOverflow?">":"<=",node->getDecimalPrecision(),mayOverflow?"yes":"no");

   TR::LabelSymbol * cflowRegionStart = NULL;
   TR::LabelSymbol * cflowRegionEnd = NULL;
   TR::RegisterDependencyConditions * deps = NULL;
   if (mayOverflow && produceOverflowMessage)
      {
      cflowRegionStart   = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      cflowRegionEnd     = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
      deps = new (cg->trHeapMemory()) TR::RegisterDependencyConditions(0, 4, cg);

      if (destMR->getIndexRegister())
         deps->addPostConditionIfNotAlreadyInserted(destMR->getIndexRegister(), TR::RealRegister::AssignAny);
      if (destMR->getBaseRegister())
         deps->addPostConditionIfNotAlreadyInserted(destMR->getBaseRegister(), TR::RealRegister::AssignAny);
      if (secondMR->getIndexRegister())
         deps->addPostConditionIfNotAlreadyInserted(secondMR->getIndexRegister(), TR::RealRegister::AssignAny);
      if (secondMR->getBaseRegister())
         deps->addPostConditionIfNotAlreadyInserted(secondMR->getBaseRegister(), TR::RealRegister::AssignAny);

      cflowRegionStart->setStartInternalControlFlow();
      generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, cflowRegionStart, deps);
      }

   TR::Instruction * cursor =
      generateSS2Instruction(cg, op, node,
                             op1EncodingSize-1,
                             generateS390RightAlignedMemoryReference(*destMR, node, 0, cg),
                             secondReg->getSize()-1,
                             generateS390RightAlignedMemoryReference(*secondMR, node, 0, cg));

   targetReg->setHasKnownValidSignAndData();

   if (mayOverflow)
      {
      if (targetReg->isEvenPrecision() && !node->canSkipPadByteClearing())
         {
         cg->genZeroLeftMostPackedDigits(node, targetReg, targetReg->getSize(), 1, generateS390RightAlignedMemoryReference(*destMR, node, 0, cg));
         }
      targetReg->setHasKnownPreferredSign();
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\toverflow may occur so set HasKnownPreferredSign = true on reg %s\n",cg->getDebug()->getName(targetReg));
      if (produceOverflowMessage)
         {
         // The only overflow message handled is overflow into the next byte (i.e. not 'even' to 'odd' precision 'overflow').
         // This is also an important restriction as no NI for the top nibble is done here and if it were to be done then this
         // would also overwrite the condition code in the isFoldedIf=true case
         TR_ASSERT(targetReg->isOddPrecision(),"expecting targetPrecision to be odd and not %d for addsubOverflowMessage\n",targetReg->getDecimalPrecision());

         TR::LabelSymbol *oolEntryPoint = TR::LabelSymbol::create(cg->trHeapMemory(),cg);
         TR::LabelSymbol *oolReturnPoint = TR::LabelSymbol::create(cg->trHeapMemory(),cg);

         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, TR::InstOpCode::COND_BO, node, oolEntryPoint);

         cflowRegionEnd->setEndInternalControlFlow();
         generateS390LabelInstruction(cg, TR::InstOpCode::LABEL, node, cflowRegionEnd, deps);
         }
      }
   else
      {
      targetReg->setHasKnownCleanSign();
      if (cg->traceBCDCodeGen())
         {
         if (firstChild->isZero() || secondChild->isZero())
            traceMsg(comp,"\t%s firstChild %p isZero=%s or secondChild %p isZero=%s so nibble clearing is NOT required and set HasKnownCleanSign = true on reg %s\n",
                        isAdd?"add":"sub",firstChild,firstChild->isZero()?"yes":"no",secondChild,secondChild->isZero()?"yes":"no",cg->getDebug()->getName(targetReg));
         else
            traceMsg(comp,"\t%s result prec %d is > both reg1 prec %d and reg2 prec %d so nibble clearing is NOT required and set HasKnownCleanSign = true on reg %s\n",
                        isAdd?"add":"sub",node->getDecimalPrecision(),firstReg->getDecimalPrecision(),secondReg->getDecimalPrecision(),cg->getDebug()->getName(targetReg));
         }
      // An NI to clear the top nibble is never required in this case:
      //    If the largest source is even (eg prec 4) then biggest the result can be is odd (i.e. +1 largest source -- prec 5)
      //    and on an odd result no clearing is needed
      //    If the largest source is odd (eg prec 5) then the biggest the result can be is even (i.e. +1 largest source -- prec 6)
      //    and the top nibble must already be clear as the whole byte must be clear before the operation
      }


   if (isAdd &&
       firstReg->hasKnownOrAssumedPositiveSignCode() &&
       secondReg->hasKnownOrAssumedPositiveSignCode())
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp, "\tfirstReg and secondReg have positive sign codes so set targetReg sign code to the preferred positive sign 0x%x\n", TR::DataType::getPreferredPlusCode());
      // positive+positive=positive and then AP will clean the positive sign to 0xc
      targetReg->setKnownSignCode(TR::DataType::getPreferredPlusCode());
      }

   node->setRegister(targetReg);
   cg->decReferenceCount(secondChild);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::inlineIfpdaddsubOverflowDetectEvaluator(TR::Node *node, TR::InstOpCode::Mnemonic op, TR::InstOpCode::S390BranchCondition brCond, TR::CodeGenerator *cg)
   {
   TR::Node *thirdChild = NULL;
   TR::RegisterDependencyConditions *deps = NULL;
   TR::LabelSymbol *targetLabel = node->getBranchDestination()->getNode()->getLabel();
   if (node->getNumChildren() == 3)
      {
      thirdChild = node->getThirdChild();
      TR_ASSERT( thirdChild->getOpCodeValue() == TR::GlRegDeps,
         "The third child of a compare is assumed to be a TR::GlRegDeps, but wasn't");

      cg->evaluate(thirdChild);
      deps = generateRegisterDependencyConditions(cg, thirdChild, 0);
      cg->decReferenceCount(thirdChild);
      }

   TR::Node *arithNode = node->getFirstChild();
   TR::Register *targetReg = pdaddsubOverflowDetectEvaluator(arithNode, op, true, brCond, targetLabel, deps, cg); // isFoldedIf=true
   TR_ASSERT( targetReg == NULL,"should not evaluate a folded if pdaddsubOverflowDetect node to a register\n");
   cg->decReferenceCount(arithNode);
   return NULL;
   }

bool
J9::Z::TreeEvaluator::isAddressAliasedToStorageRef(TR::Node *address, size_t sizePointedToByAddress, TR_StorageReference *storageRef, TR::CodeGenerator *cg)
   {
   if (cg->traceBCDCodeGen())
      traceMsg(cg->comp(),"\tisAddressAliasedToStorageRef : address %s (%p) size=%d  vs storageRef #%d %s (%p)\n",
         address->getOpCode().getName(),address,sizePointedToByAddress,
         storageRef->getSymbolReference()?storageRef->getSymbolReference()->getReferenceNumber():-1,
         storageRef->isNodeBased()?storageRef->getNode()->getOpCode().getName():"temp_based",
         storageRef->isNodeBased()?storageRef->getNode():NULL);

   if (storageRef->isConstantNodeBased())
      {
      if (cg->traceBCDCodeGen())
         traceMsg(cg->comp(), "\t\tstorageRef (node %s %p) isConstantNodeBased set isAliased = false\n",
            storageRef->getNode()->getOpCode().getName(),storageRef->getNode());
      return false;
      }

   bool isAliased = true;
   if (address->getOpCodeValue() == TR::loadaddr) // only handling simple loadaddrs now as this is the expected pattern for initial use in pdaddsubOverflowDetectEvaluator
      {
      TR::Compilation *comp = cg->comp();
      TR::SymbolReference *addressSymRef = address->getSymbolReference();
      TR::SymbolReference *storageRefSymRef = storageRef->getSymbolReference();
      // check for null storageRefSymRef -- isConstantNodeBased tested above so this should only be temp based or node based and both have a symRef
      TR_ASSERT(storageRefSymRef,"storageRefSymRef should be set for storageRef\n");
      if (1)
         {
         TR_UseDefAliasSetInterface aliases1 = addressSymRef->getUseDefAliases();
         if (aliases1.contains(storageRefSymRef, comp))
            {

            isAliased = true;
            if (cg->traceBCDCodeGen())
               traceMsg(comp, "\t\ttargetSymRef #%d and storageRefSymRef #%d are aliased so set isAliased = true\n",
                  addressSymRef->getReferenceNumber(),storageRefSymRef->getReferenceNumber());
            }
         else
            {
            isAliased = false;
            if (cg->traceBCDCodeGen())
               traceMsg(comp, "\t\taddressSymRef #%d and storageRefSymRef #%d are NOT aliased so set isAliased = false\n",
                  addressSymRef->getReferenceNumber(),storageRefSymRef->getReferenceNumber());
            }
         }
      }
   else
      {
      isAliased = true;
      if (cg->traceBCDCodeGen())
         traceMsg(cg->comp(),"\t\tunhandled address opcode %s (%p) set isAliased = true\n",address->getOpCode().getName(),address);
      }

   if (cg->traceBCDCodeGen())
      traceMsg(cg->comp(),"\tisAddressAliasedToStorageRef = %s\n",isAliased?"true":"false");

   return isAliased;
   }

TR::Register *
J9::Z::TreeEvaluator::pdaddsubOverflowDetectEvaluator(TR::Node *node,
                                                          TR::InstOpCode::Mnemonic op,
                                                          bool isFoldedIf,
                                                          TR::InstOpCode::S390BranchCondition brCond,
                                                          TR::LabelSymbol *targetLabel,
                                                          TR::RegisterDependencyConditions *deps,
                                                          TR::CodeGenerator *cg)
   {
   cg->traceBCDEntry("pdaddsubOverflowDetect",node);
   TR_ASSERT( op == TR::InstOpCode::AP || op == TR::InstOpCode::SP,"pdaddsubOverflowDetectEvaluator only valid for AP and SP opcodes\n");
   bool isAdd = (op == TR::InstOpCode::AP);
   TR::Node *firstChild = node->getFirstChild();
   TR::Node *secondChild = node->getSecondChild();
   TR::Node *targetAddress = node->getThirdChild();
   TR::Node *targetPrecisionNode = node->getChild(3);
   TR_PseudoRegister *firstReg = cg->evaluateBCDNode(firstChild);
   TR_PseudoRegister *secondReg = cg->evaluateBCDNode(secondChild);
   TR::Compilation *comp = cg->comp();

   TR_ASSERT( targetPrecisionNode->getOpCode().isLoadConst() && targetPrecisionNode->getOpCode().getSize() <= 4 ,
      "excepting targetPrecision on pdaddsubOverflowDetect to be a <= 4 size constant\n");
   int32_t targetPrecision = (int32_t)targetPrecisionNode->get64bitIntegralValue();
   int32_t targetSize = TR::DataType::packedDecimalPrecisionToByteLength(targetPrecision);

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\t%s: isFoldedIf %s, firstReg->getSize() %d, secondReg->getSize() %d, targetPrec %d\n",
         node->getOpCode().getName(),isFoldedIf?"yes":"no", firstReg->getSize(), secondReg->getSize(), targetPrecision);

   TR::MemoryReference *firstMR = generateS390RightAlignedMemoryReference(firstChild, firstReg->getStorageReference(), cg);
   TR::MemoryReference *secondMR = generateS390RightAlignedMemoryReference(secondChild, secondReg->getStorageReference(), cg);

   cg->correctBadSign(firstChild, firstReg, firstReg->getSize(), firstMR);
   cg->correctBadSign(secondChild, secondReg, secondReg->getSize(), secondMR);

   //TR_ASSERT(targetPrecision == TR::DataType::getMaxPackedDecimalPrecision(), "expecting targetPrecision to be 31 and not %d for addsubOverflowDetect\n",targetPrecision);
   // The only overflow handled is overflow into the next byte (i.e. not 'even' to 'odd' precision 'overflow').
   // This is also an important restriction as no NI for the top nibble is done here and if it were to be done then this
   // would also overwrite the condition code in the isFoldedIf=true case
   TR_ASSERT((targetPrecision&0x1)==1,"expecting targetPrecision to be odd and not %d for addsubOverflowDetect\n",targetPrecision);

   TR_ASSERT(targetSize >= firstReg->getSize(),
         "byte truncations should not be performed as part of an add or subtract overflow detect operation\n");

   int32_t computedResultPrecision = getAddSubComputedResultPrecision(node, cg);

   bool mayOverflow = computedResultPrecision > targetPrecision;
   if (!mayOverflow && cg->traceBCDCodeGen())
      traceMsg(comp,"\tno overflow possible because targetPrecision >= computedResultPrecision (%d >= %d) -- due to first or second op being zero (%s)\n",
         targetPrecision, computedResultPrecision, (firstChild->isZero() || secondChild->isZero()) ? "yes":"no");

   TR_StorageReference *firstStorageRef = firstReg->getStorageReference();
   bool needsInit = true;
   if (firstStorageRef->isNodeBasedHint())
      {
      TR_ASSERT( firstStorageRef->getNode() && (firstStorageRef->getNode()->getOpCode().isLoad() || firstStorageRef->getNode()->getOpCode().isStore()),
         "the storageRef node hint must be a load or store\n");
      if (targetAddress->getOpCodeValue() == TR::loadaddr &&
          !firstStorageRef->getNode()->getOpCode().isIndirect() &&
          (firstStorageRef->getSymbolReference() == targetAddress->getSymbolReference()))
         {
         needsInit = false;
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tset needsInit=false: using accumulated hint (firstStorageRef=targetAddrRef=#%d) so no initializing MVC required\n",firstStorageRef->getReferenceNumber());
         }
      }

   if (needsInit &&
       firstStorageRef->isNonConstantNodeBased() &&
       firstStorageRef->getNode() &&
       firstStorageRef->getNode()->getOpCode().isLoadVarOrStore() &&
       firstStorageRef->getNode()->getOpCode().isIndirect() &&
       firstStorageRef->getNode()->getSymbolReference()->getOffset() == 0 &&
       firstStorageRef->getNode()->getSize() == targetSize &&
       cg->addressesMatch(firstStorageRef->getNode()->getFirstChild(), targetAddress, true))
      {
      needsInit = false;
      if (cg->traceBCDCodeGen())
         traceMsg(comp, "\tset needsInit=false : targetAddress %s (%p) and firstStorageRef address %s (%p) are equal, so no initializing MVC required\n",
            targetAddress->getOpCode().getName(),targetAddress,firstStorageRef->getNode()->getFirstChild()->getOpCode().getName(),firstStorageRef->getNode()->getFirstChild());
      }

   TR::MemoryReference *finalTargetMR = generateS390MemoryReference(cg, node, targetAddress, 0, true); // forSS=true
   int32_t firstSize = firstReg->getSize();
   TR::MemoryReference *targetMR = NULL;
   bool canUseFinalTargetMR = false;
   if (needsInit)
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tneedsInit = true : check for overlap between targetAddress %s (%p) and second op %s (%p) before setting canUseFinalTargetMR to true\n",
            targetAddress->getOpCode().getName(),targetAddress,secondChild->getOpCode().getName(),secondChild);
      // before the initialization to the targetMR have to ensure it is ok to overwrite the targetAddress in case this initialization may overwrite the 2nd operand location
      TR_StorageReference *secondStorageRef = secondReg->getStorageReference();
      if (isAddressAliasedToStorageRef(targetAddress, targetSize, secondStorageRef, cg))
         {
         canUseFinalTargetMR = false;
         // target and operand2 are aliased so cannot initialize directly to the target address as this may overwrite the 2nd operand before it can be used
         // a = b + a
         // so if an initializing
         //    MVC a,b
         // is done then 'a' will be overwritten before use in the AP/SP
         //    AP  a,a (but the 2nd operand 'a' has already been overwritten by 'b')
         //
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tset canUseFinalTargetMR to false as targetAddress and secondStorageRef are aliased\n");
         }
      else
         {
         canUseFinalTargetMR = true;
         // target and operand2 are not aliased so no danger of over-writing operand2 location when initializing directly to target address
         // a = b + c
         // so if an initializing
         //    MVC a,b
         // is done then 'c' will not be overwritten before use in the AP/SP as 'a' and 'c' are not aliased to each other
         //    AP  a,c
         //
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tset canUseFinalTargetMR to true as targetAddress and secondStorageRef are NOT aliased\n");
         }

      int32_t mvcSize = firstSize;
      int32_t targetOffset = targetSize-mvcSize;
      if (canUseFinalTargetMR)
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tcanUseFinalTargetMR = true : initialize directly to the targetMR\n");
         if (firstReg->isInitialized() &&
             isAddressAliasedToStorageRef(targetAddress, targetSize, firstStorageRef, cg))
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\t\tfirstReg is initialized and is also aliased to targetAddress so call clobberEval\n");
            // if the targetAddress and first operand are aliased then initializing directly to the targetMR
            // is not safe as the MVC below may clobber the first operand before subsequent commoned uses
            cg->ssrClobberEvaluate(firstChild, firstMR);
            }
         targetMR = finalTargetMR;
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tgen MVC with size %d and targetOffset %d to store to initialize the targetMR\n",mvcSize,targetOffset);
         // TODO: look at the firstReg cleared bytes to see if the mvcSize can be increased to include these
         // already cleared bytes -- when done then can remove the !needsInit check below
         generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                                mvcSize-1,
                                generateS390MemoryReference(*targetMR, targetOffset, cg),
                                generateS390RightAlignedMemoryReference(*firstMR, node, 0, cg));
         }
      else
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tcanUseFinalTargetMR = false : create a new temp storageRef\n");
         TR_StorageReference *tempStorageReference = TR_StorageReference::createTemporaryBasedStorageReference(targetSize, comp);
         tempStorageReference->setIsSingleUseTemporary();
         TR::MemoryReference *tempMR = generateS390MemRefFromStorageRef(node, tempStorageReference, cg);
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tgen MVC size=%d, targetOffset %d to initialize the tempMR\n",mvcSize,targetOffset);
         generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                                mvcSize-1,
                                generateS390MemoryReference(*tempMR, targetOffset, cg),
                                generateS390RightAlignedMemoryReference(*firstMR, node, 0, cg));
         targetMR = tempMR;
         }
      }
   else
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tneedsInit = false : set canUseFinalTargetMR to true and targetMR to finalTargetMR\n");
      // definitely overwriting the first operand with the AP/SP below so need to do a clobberEvaluate
      // so original first operand value is preserved for any commoned uses
      if (firstReg->isInitialized())
         cg->ssrClobberEvaluate(firstChild, firstMR);
      canUseFinalTargetMR = true;
      targetMR = finalTargetMR;
      }

   int32_t bytesToClear = targetSize - firstSize;
   if (bytesToClear)
      {
      if (!needsInit &&
          firstReg->getLiveSymbolSize() >= targetSize &&
          firstReg->getBytesToClear(firstSize, targetSize) == 0)
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tupper bytes from %d->%d are already clear\n",firstSize,targetSize);
         }
      else
         {
         if (bytesToClear == 1)
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tgen MVI 0x0 to clear the upper byte\n");
            generateSIInstruction(cg, TR::InstOpCode::MVI, node, generateS390MemoryReference(*targetMR, 0, cg), 0);
            }
         else
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tgen XC with size %d to store to clear the upper bytes\n",bytesToClear);
            generateSS1Instruction(cg, TR::InstOpCode::XC, node,
                                   bytesToClear-1,
                                   generateS390MemoryReference(*targetMR, 0, cg),
                                   generateS390MemoryReference(*targetMR, 0, cg));
            }
         }
      }

   generateSS2Instruction(cg, op, node,
                          targetSize-1,
                          generateS390MemoryReference(*targetMR, 0, cg),
                          secondReg->getSize()-1,
                          generateS390RightAlignedMemoryReference(*secondMR, node, 0, cg));

   if (!canUseFinalTargetMR)
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tcanUseFinalTargetMR = false - gen MVC size=%d to store result to finalTargetMR\n",targetSize);
      generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                             targetSize-1,
                             generateS390MemoryReference(*finalTargetMR, 0, cg),
                             generateS390MemoryReference(*targetMR, 0, cg));
      }

   TR::Register *targetReg = NULL;
   if (isFoldedIf)
      {
      if (mayOverflow)
         generateS390BranchInstruction(cg, TR::InstOpCode::BRC, brCond, node, targetLabel, deps);
      }
   else
      {
      targetReg = cg->allocateRegister();
      if (mayOverflow)
         {
         generateRRInstruction(cg, TR::InstOpCode::IPM, node, targetReg, targetReg); // cc1|cc2 at bits 34|35
         generateRSInstruction(cg, TR::InstOpCode::SRL, node, targetReg, 63 - 35);   // move cc1|cc2 to bit 62|63 -- 00,01,10,11
         }
      else
         {
         generateLoad32BitConstant(cg, node, 0, targetReg, true);
         }
      }

   node->setRegister(targetReg);
   cg->decReferenceCount(firstChild);
   cg->decReferenceCount(secondChild);
   cg->decReferenceCount(targetPrecisionNode);

   cg->traceBCDExit("pdaddsubOverflowDetect",node);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::pdmulEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pdmul",node);
   cg->generateDebugCounter("PD-Op/pdmul", 1, TR::DebugCounter::Cheap);

   TR::Register * reg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() &&
           !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) ||
           isVectorBCDEnv)
      {
      reg = pdArithmeticVectorEvaluatorHelper(node, TR::InstOpCode::VMP, cg);
      }
   else
      {
      reg = pdmulEvaluatorHelper(node, cg);
      }

   cg->traceBCDExit("pdmul",node);
   return reg;
   }

TR::Register *
J9::Z::TreeEvaluator::pdmulEvaluatorHelper(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Node *firstChild = node->getFirstChild();
   TR::Node *secondChild = node->getSecondChild();
   TR::Compilation *comp = cg->comp();

   TR_PseudoRegister *firstReg = cg->evaluateBCDNode(firstChild);
   bool trackSignState=false;
   bool alwaysLegalToCleanSign=true; // ok to use ZAP (and clobber srcSign) to init as there is an MP coming
   TR_PseudoRegister *targetReg = evaluateBCDValueModifyingOperand(node, true, NULL, cg, trackSignState, 0, alwaysLegalToCleanSign); // initTarget=true, sourceMR=NULL, srcSize=0
   cg->decReferenceCount(firstChild);
   TR_PseudoRegister *secondReg = cg->evaluateBCDNode(secondChild);
   TR_StorageReference *targetStorageReference = targetReg->getStorageReference();
   TR::MemoryReference *destMR = generateS390RightAlignedMemoryReference(node, targetStorageReference, cg);
   TR::MemoryReference *secondMR = generateS390RightAlignedMemoryReference(secondChild, secondReg->getStorageReference(), cg);

   int32_t op1EncodingPrecision = cg->getPDMulEncodedPrecision(node, firstReg, secondReg);
   int32_t op1EncodingSize = cg->getPDMulEncodedSize(node, firstReg, secondReg);
   // The preparatory clearing operations need a length set so base it on the op1EncodingSize but the final precision will be set after the MP instruction has been generated
   targetReg->setDecimalPrecision(op1EncodingPrecision);

   TR_ASSERT( targetReg->getSize() >= firstReg->getSize() + secondReg->getSize(),"MP may result in a data exception\n");
   TR_ASSERT( secondReg->getSize() <= 8, "MP will result in a spec exception\n");

   cg->clearByteRangeIfNeeded(node, targetReg, generateS390RightAlignedMemoryReference(*destMR, node, 0, cg), firstReg->getSize(), op1EncodingSize, true); // widenOnLeft=true

   cg->correctBadSign(firstChild, firstReg, firstReg->getSize(), destMR);
   cg->correctBadSign(secondChild, secondReg, secondReg->getSize(), secondMR);

   TR::Instruction * cursor =
      generateSS2Instruction(cg, TR::InstOpCode::MP, node,
                             op1EncodingSize-1,
                             generateS390RightAlignedMemoryReference(*destMR, node, 0, cg),
                             secondReg->getSize()-1,
                             generateS390RightAlignedMemoryReference(*secondMR, node, 0, cg));

   targetReg->setHasKnownValidSignAndData();

   int32_t computedResultPrecision = firstReg->getDecimalPrecision() + secondReg->getDecimalPrecision();
   correctPackedArithmeticPrecision(node, op1EncodingSize, targetReg, computedResultPrecision, cg);

   if (targetReg->getDecimalPrecision() < computedResultPrecision)
      {
      if (!node->canSkipPadByteClearing() && targetReg->isEvenPrecision())
         cg->genZeroLeftMostPackedDigits(node, targetReg, targetReg->getSize(), 1, generateS390RightAlignedMemoryReference(*destMR, node, 0, cg));
      }
   else if (cg->traceBCDCodeGen())
      {
      traceMsg(comp,"TR::InstOpCode::MP node %p targetRegPrec %d >= computedResultPrecision %d (firstRegPrec %d + secondRegPrec %d) so skip nibble clearing\n",
         node,targetReg->getDecimalPrecision(),computedResultPrecision,firstReg->getDecimalPrecision(),secondReg->getDecimalPrecision());
      }

   // Even with no overflow MP can produce a negative zero as the sign of the result is determinted from the rules
   // of algebra *even when one or both of the operands are zero*. So 0 * -1 = -0 (0x0c * 0x1d = 0x0d -- not clean result)
   // MP will always produce a result with a preferred sign however.
   if (firstReg->hasKnownOrAssumedPositiveSignCode() &&
       secondReg->hasKnownOrAssumedPositiveSignCode())
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp, "\tfirstReg and secondReg have positive sign codes so set targetReg sign code to the preferred positive sign 0x%x\n", TR::DataType::getPreferredPlusCode());
      // positive*positive=positive and then MP will clean the positive sign to 0xc
      targetReg->setKnownSignCode(TR::DataType::getPreferredPlusCode());
      }
   else
      {
      targetReg->setHasKnownPreferredSign();
      }

   cg->decReferenceCount(secondChild);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::pddivSelectEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pddivSelect",node);
   cg->generateDebugCounter("PD-Op/pddivSel", 1, TR::DebugCounter::Cheap);

   TR::Compilation *comp = cg->comp();
   TR::Node *child = node->getFirstChild();
   TR_ASSERT(child->getOpCodeValue() == TR::pddivrem || (child->getOpCode().isLoadVar() && child->getDataType() == TR::PackedDecimal),
      "pddivSelect child should be a pddivrem or a pdload and not op %d\n",child->getOpCodeValue());

   int32_t divisorPrecision = node->getSelectDivisorPrecision();
   int32_t computedDivisorPrecision = divisorPrecision;
   int32_t computedDivisorSize = TR::DataType::packedDecimalPrecisionToByteLength(divisorPrecision);
   int32_t deadBytes = computedDivisorSize;

   int32_t dividendPrecision = node->getSelectDividendPrecision();
   // the dividend precision used in the DP instruction must be large enough to contain the operands,two sign codes and a possible pad digit
   int32_t computedDividendPrecision = cg->getPDDivEncodedPrecisionCommon(node, dividendPrecision, divisorPrecision, (divisorPrecision&0x1)==0);
   int32_t computedDividendSize = TR::DataType::packedDecimalPrecisionToByteLength(computedDividendPrecision);

   int32_t computedQuotientPrecision = TR::DataType::byteLengthToPackedDecimalPrecisionCeiling(computedDividendSize - computedDivisorSize);

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tdividendPrecision=%d,computedDividendPrecision=%d,divisorPrecision=%d,deadBytes=%d,computedQuotientPrecision=%d\n",
         dividendPrecision,computedDividendPrecision,divisorPrecision,deadBytes,computedQuotientPrecision);

   if ((dividendPrecision&0x1)==0)
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\t\tdividendPrecision (%d) isEven=true so reduce computedQuotientPrecision %d->%d\n",dividendPrecision,computedQuotientPrecision,computedQuotientPrecision-1);
      computedQuotientPrecision--;
      }

   int32_t resultQuotientPrecision = std::min<int32_t>(computedQuotientPrecision, node->getDecimalPrecision());

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tsetting targetRegPrec to min(computedQuotientPrecision, nodePrec) = min(%d,%d) = %d and deadBytes to %d\n",
         computedQuotientPrecision,node->getDecimalPrecision(),resultQuotientPrecision,deadBytes);

   TR_PseudoRegister *targetReg = NULL;
   if (!node->canSkipPadByteClearing() &&
       ((resultQuotientPrecision&0x1) == 0))
      {
      TR::Node *src = node->getFirstChild();
      TR_PseudoRegister *srcReg = cg->evaluateBCDNode(src);
      TR::MemoryReference *sourceMR = generateS390RightAlignedMemoryReference(src, srcReg->getStorageReference(), cg);
      targetReg = evaluateBCDValueModifyingOperand(node, false /* initTarget */, sourceMR, cg);
      targetReg->setDecimalPrecision(resultQuotientPrecision);
      TR::MemoryReference *destMR = generateS390RightAlignedMemoryReference(node, targetReg->getStorageReference(), cg);
      if (targetReg->isInitialized())
         {
         destMR->addToTemporaryNegativeOffset(node, -deadBytes, cg);
         targetReg->addToRightAlignedDeadBytes(deadBytes);
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tisInitialized=true (pddivSelect) : increment targetReg %s deadBytes %d -> %d (by the computedDivisorSize)\n",
               cg->getDebug()->getName(targetReg),targetReg->getRightAlignedDeadBytes()-deadBytes,targetReg->getRightAlignedDeadBytes());
         }
      else
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tisInit=false case: gen MVC of size %d to init quotient before top nibble clearing (sourceMR offset=-deadBytes=%d\n",targetReg->getSize(),-deadBytes);
         int32_t mvcSize = targetReg->getSize();
         generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                                mvcSize-1,
                                generateS390RightAlignedMemoryReference(*destMR, node, 0, cg),
                                generateS390RightAlignedMemoryReference(*sourceMR, node, -deadBytes, cg));
         }
      cg->genZeroLeftMostPackedDigits(node, targetReg, targetReg->getSize(), 1, generateS390RightAlignedMemoryReference(*destMR, node, 0, cg));
      }
   else
      {
      targetReg = evaluateBCDSignModifyingOperand(node, true, false, false, NULL, cg); // isEffectiveNop=true, isNondestructiveNop=false,initTarget=false
      targetReg->setDecimalPrecision(resultQuotientPrecision);
      targetReg->addToRightAlignedDeadBytes(deadBytes);
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tisEffectiveNop=true (pddivSelect) : increment targetReg %s deadBytes %d -> %d (by the computedDivisorSize)\n",
            cg->getDebug()->getName(targetReg),targetReg->getRightAlignedDeadBytes()-deadBytes,targetReg->getRightAlignedDeadBytes());
      }

   cg->decReferenceCount(child);
   cg->traceBCDExit("pddivSelect",node);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::pdremSelectEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pdremSelect",node);
   cg->generateDebugCounter("PD-Op/pdremSel", 1, TR::DebugCounter::Cheap);

   TR::Node *child = node->getFirstChild();
   TR::Compilation *comp = cg->comp();
   TR_ASSERT(child->getOpCodeValue() == TR::pddivrem ||
             (child->getOpCode().isLoadVar() && child->getDataType() == TR::PackedDecimal),
             "pddivSelect child should be a pddivrem or a pdload and not op %d\n",child->getOpCodeValue());

   int32_t computedRemainderPrecision = std::min<int32_t>(node->getSelectDivisorPrecision(), node->getDecimalPrecision());

   if (cg->traceBCDCodeGen())
      {
      traceMsg(comp,"\tsetting targetRegPrec to computedRemainderPrecision = min(node->getSelectDivisorPrecision(), node->getDecimalPrecision()) = min(%d,%d) = %d\n",
         node->getSelectDivisorPrecision(),node->getDecimalPrecision(),computedRemainderPrecision);
      }

   TR_PseudoRegister *targetReg = NULL;
   if (!node->canSkipPadByteClearing() &&
       ((computedRemainderPrecision&0x1) == 0))
      {
      TR::Node *src = node->getFirstChild();
      TR_PseudoRegister *srcReg = cg->evaluateBCDNode(src);
      TR::MemoryReference *sourceMR = generateS390RightAlignedMemoryReference(src, srcReg->getStorageReference(), cg);
      targetReg = evaluateBCDValueModifyingOperand(node, false /* initTarget */, sourceMR, cg);
      targetReg->setLeftAlignedZeroDigits(0);
      targetReg->setDecimalPrecision(computedRemainderPrecision);
      TR::MemoryReference *destMR = generateS390RightAlignedMemoryReference(node, targetReg->getStorageReference(), cg);
      if (!targetReg->isInitialized())
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tisInit=false case: gen MVC of size %d to init remainder before top nibble clearing\n",targetReg->getSize());
         int32_t mvcSize = targetReg->getSize();
         generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                                mvcSize-1,
                                generateS390RightAlignedMemoryReference(*destMR, node, 0, cg),
                                generateS390RightAlignedMemoryReference(*sourceMR, node, 0, cg));
         }
      cg->genZeroLeftMostPackedDigits(node, targetReg, targetReg->getSize(), 1, generateS390RightAlignedMemoryReference(*destMR, node, 0, cg));
      }
   else
      {
      targetReg = evaluateBCDSignModifyingOperand(node, true /*isEffectiveNop*/, false /*isNondestructiveNop*/, false /* !initTarget*/, NULL, cg);
      targetReg->setLeftAlignedZeroDigits(0);
      targetReg->setDecimalPrecision(computedRemainderPrecision);
      }
   cg->decReferenceCount(child);
   cg->traceBCDExit("pdremSelect",node);
   return targetReg;
   }

/**
 * Handles pddiv, pdrem and pddivrem.
 */
TR::Register *
J9::Z::TreeEvaluator::pddivremEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pddivrem",node);
   cg->generateDebugCounter(TR::DebugCounter::debugCounterName(cg->comp(), "PD-Op/%s", node->getOpCode().getName()),
                            1, TR::DebugCounter::Cheap);
   TR::Register * reg = NULL;

   static char* isVectorBCDEnv = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() && !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) || isVectorBCDEnv)
      {
      reg = pddivremVectorEvaluatorHelper(node, cg);
      }
   else
      {
      reg = pddivremEvaluatorHelper(node, cg);
      }

   cg->traceBCDExit("pddivrem",node);
   return reg;
   }

/**
 * Handles pddiv, pdrem and pddivrem. This is the vector evaluator helper function.
 */
TR::Register *
J9::Z::TreeEvaluator::pddivremVectorEvaluatorHelper(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR::Register* vTargetReg = NULL;
   TR::InstOpCode::Mnemonic opCode;
   switch(node->getOpCodeValue())
      {
      case TR::pddiv:
         opCode = TR::InstOpCode::VDP;
         break;
      case TR::pdrem:
         opCode = TR::InstOpCode::VRP;
         break;
      case TR::pddivrem:
         // TR::divrem is not generated from DAA opetimization
         TR_ASSERT(0, "Unexpected divrem opcode in pddivremVectorEvaluatorHelper");
         break;
      default:
         TR_ASSERT(0, "Unexpected opcode in pddivremVectorEvaluatorHelper");
         break;
      }

   vTargetReg = pdArithmeticVectorEvaluatorHelper(node, opCode, cg);
   return vTargetReg;
   }

/**
 * Handles pddiv, pdrem and pddivrem. This is the non-vector evaluator helper function.
 */
TR::Register *
J9::Z::TreeEvaluator::pddivremEvaluatorHelper(TR::Node * node, TR::CodeGenerator * cg)
   {
   TR_ASSERT( node->getOpCodeValue() == TR::pddiv || node->getOpCodeValue() == TR::pdrem || node->getOpCodeValue() == TR::pddivrem,"pddivEvaluator only valid for pddiv/pdrem/pddivrem\n");

   bool isFused = (node->getOpCodeValue() == TR::pddivrem);
   TR::Node *firstChild = node->getFirstChild();
   TR::Node *secondChild = node->getSecondChild();
   TR::Compilation *comp = cg->comp();

   TR_PseudoRegister *firstReg = cg->evaluateBCDNode(firstChild);
   bool trackSignState=false;
   bool alwaysLegalToCleanSign=true; // ok to use ZAP (and clobber srcSign) to init as there is a DP coming
   TR_PseudoRegister *targetReg = evaluateBCDValueModifyingOperand(node, true, NULL, cg, trackSignState, 0, alwaysLegalToCleanSign); // initTarget=true, sourceMR=NULL, srcSize=0
   cg->decReferenceCount(firstChild);
   TR_PseudoRegister *secondReg = cg->evaluateBCDNode(secondChild);
   TR_StorageReference *targetStorageReference = targetReg->getStorageReference();
   TR::MemoryReference *destMR = generateS390RightAlignedMemoryReference(node, targetStorageReference, cg);

   if (secondReg->getDecimalPrecision() > secondChild->getDecimalPrecision())
      {
      TR_ASSERT( false,"the secondRegPrec has grown so using an inline DP may not be legal\n"); // TODO: for now disallow this completely but the below fix is also correct.
      TR_ASSERT(secondReg->getSize() == secondChild->getSize(),
         "the secondRegSize (regSize %d != nodeSize %d) has grown so using an inline DP may not be legal\n",secondReg->getSize(),secondChild->getSize());
      // The register precision may have been conservatively adjusted from an even precision to the next odd precision so in these
      // cases set it back to the even precision so the inline divide will still be legal. This extra nibble of precision will be zero so this is safe.
      secondReg->setDecimalPrecision(secondReg->getDecimalPrecision()-1);
      }

   int32_t dividendPrecision = 0;
   int32_t divisorSize = 0;
   int32_t dividendSizeBumpForClear = 0;
   TR::MemoryReference *divisorMR = NULL;
   if (isFused)
      {
      if (firstChild->getSize() > firstReg->getSize())
         {
         // if the first child is a pass through widening op then have to clear this range as well
         dividendSizeBumpForClear = firstChild->getSize() - firstReg->getSize();
         if (cg->traceBCDCodeGen())
            traceMsg(cg->comp(),"\tfirstChildSize %d > firstRegSize %d in fused case : set dividendSizeBumpForClear = firstChildSize - firstRegSize = %d\n",
               firstChild->getSize(),firstReg->getSize(),dividendSizeBumpForClear);
         }
      divisorMR = cg->materializeFullBCDValue(secondChild, secondReg, secondChild->getSize());
      dividendPrecision = cg->getPDDivEncodedPrecision(node);
      divisorSize = secondChild->getSize();
      }
   else
      {
      divisorMR = generateS390RightAlignedMemoryReference(secondChild, secondReg->getStorageReference(), cg);
      dividendPrecision = cg->getPDDivEncodedPrecision(node, firstReg, secondReg);
      divisorSize = secondReg->getSize();
      }
   targetReg->setDecimalPrecision(dividendPrecision);
   int32_t dividendSize = targetReg->getSize();
   TR_ASSERT( dividendSize <= node->getStorageReferenceSize(),"allocated symbol for pddiv/pdrem is too small\n");
   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\t%s: gen DP dividendSize = %d, secondOpSize = secondRegSize = %d, targetRegSize = %d (firstRegPrec %d, secondRegPrec %d)\n",
         node->getOpCode().getName(),dividendSize,secondReg->getSize(),targetReg->getSize(),firstReg->getDecimalPrecision(),secondReg->getDecimalPrecision());

   cg->clearByteRangeIfNeeded(node, targetReg, generateS390RightAlignedMemoryReference(*destMR, node, 0, cg), dividendSize-divisorSize-dividendSizeBumpForClear, dividendSize, true); // widenOnLeft=true

   cg->correctBadSign(firstChild, firstReg, targetReg->getSize(), destMR);
   cg->correctBadSign(secondChild, secondReg, secondReg->getSize(), divisorMR);

   TR::Instruction * cursor =
      generateSS2Instruction(cg, TR::InstOpCode::DP, node,
                             dividendSize-1,
                             generateS390RightAlignedMemoryReference(*destMR, node, 0, cg),
                             divisorSize-1,
                             generateS390RightAlignedMemoryReference(*divisorMR, node, 0, cg));

   targetReg->setHasKnownValidSignAndData();

   if (isFused)
      {
      int32_t resultPrecision = TR::DataType::byteLengthToPackedDecimalPrecisionCeiling(dividendSize);
      if (firstReg->isEvenPrecision())
         {
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tfirstRegPrec (%d) isEven=true so reduce resultPrecision %d->%d\n",firstReg->getDecimalPrecision(),resultPrecision,resultPrecision-1);
         resultPrecision--;
         }
      targetReg->removeRangeOfZeroDigits(0, resultPrecision);
      }
   else
      {
      bool isRem = node->getOpCodeValue() == TR::pdrem;
      int32_t deadBytes = 0;
      bool isTruncation = false;
      if (isRem)
         {
         targetReg->setDecimalPrecision(secondReg->getDecimalPrecision());
         isTruncation = node->getDecimalPrecision() < targetReg->getDecimalPrecision();
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\tpdrem: setting targetReg prec to divisor prec %d (node prec is %d), isTruncation=%s\n",
               secondReg->getDecimalPrecision(),node->getDecimalPrecision(),isTruncation?"yes":"no");
         targetReg->removeRangeOfZeroDigits(0, TR::DataType::byteLengthToPackedDecimalPrecisionCeiling(dividendSize));
         }
      else
         {
         deadBytes = divisorSize;
         // computedQuotientPrecision is the size of the quotient as computed by the DP instruction.
         // The actual returned node precision may be less.
         int32_t computedQuotientPrecision = TR::DataType::byteLengthToPackedDecimalPrecisionCeiling(dividendSize - deadBytes);
         if (firstReg->isEvenPrecision())
            {
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tfirstRegPrec (%d) isEven=true so reduce computedQuotientPrecision %d->%d\n",firstReg->getDecimalPrecision(),computedQuotientPrecision,computedQuotientPrecision-1);
            computedQuotientPrecision--;
            }
         isTruncation = node->getDecimalPrecision() < computedQuotientPrecision;
         int32_t resultQuotientPrecision = std::min<int32_t>(computedQuotientPrecision, node->getDecimalPrecision());
         targetReg->setDecimalPrecision(resultQuotientPrecision);
         targetReg->addToRightAlignedDeadBytes(deadBytes);
         if (cg->traceBCDCodeGen())
            {
            traceMsg(comp,"\tisDiv=true (pddivrem) : increment targetReg %s deadBytes %d -> %d (by the divisorSize)\n",
               cg->getDebug()->getName(targetReg),targetReg->getRightAlignedDeadBytes()-deadBytes,targetReg->getRightAlignedDeadBytes());
            traceMsg(comp,"\tsetting targetReg prec to min(computedQuotPrec, nodePrec) = min(%d, %d) = %d (size %d), isTruncation=%s\n",
               computedQuotientPrecision,node->getDecimalPrecision(),resultQuotientPrecision,targetReg->getSize(),isTruncation?"yes":"no");
            }
         targetReg->removeRangeOfZeroDigits(0, computedQuotientPrecision);
         }

      if (!node->canSkipPadByteClearing() && targetReg->isEvenPrecision() && isTruncation)
         {
         TR_ASSERT( node->getStorageReferenceSize() >= dividendSize,"operand size should only shrink from original size\n");
         int32_t leftMostByte = targetReg->getSize();
         if (cg->traceBCDCodeGen())
            traceMsg(comp,"\t%s: generating NI to clear top nibble with leftMostByte = targetReg->getSize() = %d\n",isRem ? "pdrem":"pddiv",targetReg->getSize());
         cg->genZeroLeftMostPackedDigits(node, targetReg, leftMostByte, 1, generateS390RightAlignedMemoryReference(*destMR, node, -deadBytes, cg));
         }

      targetReg->setHasKnownPreferredSign();
      if (isRem)
         {
         // sign of the remainder is the same as the sign of dividend (and then set to the preferred sign by the DP instruction)
         if (firstReg->hasKnownOrAssumedSignCode())
            {
            targetReg->setKnownSignCode(firstReg->hasKnownOrAssumedPositiveSignCode() ? TR::DataType::getPreferredPlusCode() : TR::DataType::getPreferredMinusCode());
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tpdrem: firstReg has the knownSignCode 0x%x so set targetReg sign code to the preferred sign 0x%x\n",
                  firstReg->getKnownOrAssumedSignCode(),targetReg->getKnownOrAssumedSignCode());
            }
         }
      else
         {
         // when the sign of the divisor and divident are different then the quotient sign is negative otherwise if the signs are the same then the
         // quotient sign is positive
         if (firstReg->hasKnownOrAssumedSignCode() && secondReg->hasKnownOrAssumedSignCode())
            {
            bool dividendSignIsPositive = firstReg->hasKnownOrAssumedPositiveSignCode();
            bool dividendSignIsNegative = !dividendSignIsPositive;
            bool divisorSignIsPositive = secondReg->hasKnownOrAssumedPositiveSignCode();
            bool divisorSignIsNegative = !divisorSignIsPositive;

            if ((dividendSignIsPositive && divisorSignIsPositive) ||
                (dividendSignIsNegative && divisorSignIsNegative))
               {
               targetReg->setKnownSignCode(TR::DataType::getPreferredPlusCode());
               if (cg->traceBCDCodeGen())
                  traceMsg(comp,"\tpddiv: dividendSign matches the divisorSign so set targetReg sign code to the preferred sign 0x%x\n", TR::DataType::getPreferredPlusCode());
               }
            else
               {
               targetReg->setKnownSignCode(TR::DataType::getPreferredMinusCode());
               if (cg->traceBCDCodeGen())
                  traceMsg(comp,"\tpddiv: dividendSign does not match the divisorSign so set targetReg sign code to the preferred sign 0x%x\n", TR::DataType::getPreferredMinusCode());
               }
            }
         }
      }

   cg->decReferenceCount(secondChild);
   return targetReg;
   }

/**
 * Handles pdshr
 */
TR::Register *
J9::Z::TreeEvaluator::pdshrEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pdshr",node);
   cg->generateDebugCounter("PD-Op/pdshr", 1, TR::DebugCounter::Cheap);

   TR::Register* targetReg = NULL;

   static char* isEnableVectorBCD = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() &&
           !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) ||
           isEnableVectorBCD)
      {
      targetReg = pdshrVectorEvaluatorHelper(node, cg);
      }
   else
      {
      targetReg = pdshiftEvaluatorHelper(node, cg, true);
      }

   cg->traceBCDExit("pdshr",node);
   return targetReg;
   }

void
J9::Z::TreeEvaluator::clearAndSetSign(TR::Node *node,
                                          TR_PseudoRegister *targetReg,
                                          int32_t leftMostByteForClear,
                                          int32_t digitsToClear,
                                          TR::MemoryReference *destMR,
                                          TR_PseudoRegister *srcReg,
                                          TR::MemoryReference *sourceMR,
                                          bool isSetSign,
                                          int32_t sign,
                                          bool signCodeIsInitialized,
                                          TR::CodeGenerator *cg)
   {
   TR::Compilation *comp = cg->comp();

   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tclearAndSetSign: digitsToClear %d, leftMostByte %d (isSetSign=%s, sign 0x%x)\n",digitsToClear,leftMostByteForClear,isSetSign?"yes":"no",sign);
   bool clearingNeeded = digitsToClear > 0;
   if (isSetSign)
      {
      // a better sign code setting maybe possible if a current setting is known
      TR_PseudoRegister *signReg = signCodeIsInitialized ? targetReg : NULL;
      int32_t digitsCleared = cg->genSignCodeSetting(node, targetReg, node->getSize(), generateS390RightAlignedMemoryReference(*destMR, node, 0, cg), sign, signReg, digitsToClear, !clearingNeeded);
      if (clearingNeeded)
         {
         digitsToClear-=digitsCleared;
         if (digitsToClear > 0 && (digitsToClear&0x1) && sign == TR::DataType::getIgnoredSignCode())
            {
            digitsToClear++;  // when digitsToClear is odd for the ignore sign code case then bump up to the next even amount (and clear the sign too) as this is easier to clear
            targetReg->setHasKnownBadSignCode();
            if (cg->traceBCDCodeGen())
               traceMsg(comp,"\tignored setSign case so inc digitsToClear %d->%d and setHasKnownBadSignCode=true on targetReg %s\n",
                  digitsToClear-1,digitsToClear,cg->getDebug()->getName(targetReg));
            }
         }
      signCodeIsInitialized = true;
      if (cg->traceBCDCodeGen())
         {
         if (clearingNeeded)
            traceMsg(comp,"\t\tisSetSign case (clearingNeeded==true): sign setting cleared %d digits so adjust digitsToClear %d->%d\n",
               digitsCleared,digitsToClear+digitsCleared,digitsToClear);
          traceMsg(comp,"\t\tisSetSign case: set signCode of 0x%x on targetReg %s\n",sign,cg->getDebug()->getName(targetReg));
         }
      }
   else if (!signCodeIsInitialized)
      {
      /* if (digitsToClear == 1) // MVN done later is better then MVC/NI as the latter suffers from an OSC
         {
         int32_t mvcSize = 1;
         generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                                mvcSize-1,
                                generateS390RightAlignedMemoryReference(*destMR, node, 0, cg),
                                generateS390RightAlignedMemoryReference(*sourceMR, node, 0, cg));
         targetReg->transferSignState(srcReg, true); // digitsLost=true -- a clear always loses digits
         signCodeIsInitialized = true;    // no longer clear the sign code in the code below for if (needLateClear)
         if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tdigitsToClear==1 case: gen MVC to initialize sign code\n");
         }
      else */
      if (clearingNeeded)
         {
         digitsToClear++;         // clear the sign code too and then MVN in the new sign code
         if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\t init=false && isSetSign=false case : bump digitsToClear %d->%d to clear entire field\n",digitsToClear,digitsToClear+1);
         }
      }
   TR_ASSERT(digitsToClear >= 0,"digitsToClear %d should be >= 0\n",digitsToClear);
   if (digitsToClear > 0)
      {
      if (cg->traceBCDCodeGen()) traceMsg(comp,"\t\tdigitsToClear %d > 0 so call genClearLeftMostDigitsIfNeeded\n",digitsToClear);
      cg->genZeroLeftMostDigitsIfNeeded(node, targetReg, leftMostByteForClear, digitsToClear, generateS390RightAlignedMemoryReference(*destMR, node, 0, cg));
      }

   if (!signCodeIsInitialized)
      {
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\t\tsignCodeIsInitialized=false after clearing of %d digits : init the sign now with an MVN of size 1\n",digitsToClear,isSetSign?"yes":"no");
      // Move the sign code over from the source location. The top nibble has already been cleared above.
      int32_t mvnSize = 1;
      generateSS1Instruction(cg, TR::InstOpCode::MVN, node,
                             mvnSize-1,
                             generateS390RightAlignedMemoryReference(*destMR, node, 0, cg),
                             generateS390RightAlignedMemoryReference(*sourceMR, node, 0, cg));
      targetReg->transferSignState(srcReg, true); // digitsLost=true -- a clear always loses digits
      }
   }

TR_PseudoRegister *
J9::Z::TreeEvaluator::simpleWideningOrTruncation(TR::Node *node,
                                                     TR_PseudoRegister *srcReg,
                                                     bool isSetSign,
                                                     int32_t sign,
                                                     TR::CodeGenerator *cg)
   {
   TR::Compilation *comp = cg->comp();
   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tsimple widening or truncating shift: srcRegPrecision %d, isSetSign=%s, sign 0x%x\n",srcReg->getDecimalPrecision(),isSetSign?"yes":"no",sign);
   bool isDigitTruncation = false;
   bool needsTopNibbleClearing = false;
   int32_t srcPrecision = srcReg->getDecimalPrecision();
   if (srcReg->getDecimalPrecision() > node->getDecimalPrecision())
      {
      srcPrecision = node->getDecimalPrecision();
      isDigitTruncation = true;
      if (!node->canSkipPadByteClearing() && node->isEvenPrecision() && srcReg->getDigitsToClear(srcPrecision,srcPrecision+1) != 0)
         needsTopNibbleClearing = true;
      }

   int32_t targetPrecision = node->getDecimalPrecision();

   if (!isDigitTruncation && srcReg->isEvenPrecision() && !srcReg->isLeftMostNibbleClear())
      {
      if (targetPrecision != srcPrecision) // in case this routine starts doing explicit widenings at some point then !canSkipPadByteClearing alone is not valid
         {
         needsTopNibbleClearing = true;
         }
      else if (!node->canSkipPadByteClearing())
         {
         needsTopNibbleClearing = true;
         if (cg->traceBCDCodeGen()) traceMsg(comp,"z^z : new clear : simpleWide %p\n",node);
         }
      }

   bool isPassThrough = false;
   bool initTargetAndSign = (isSetSign && !isPassThrough); // try to get a ZAP generated here for a widening as this can simplify the coming setSign operation
   bool isNondestructiveNop = isPassThrough && !isDigitTruncation;
   TR_PseudoRegister *targetReg = NULL;
   TR::MemoryReference *sourceMR = NULL;
   if (cg->traceBCDCodeGen())
      traceMsg(comp,"\tisDigitTruncation=%s, srcPrecision=%d, isPassThrough=%s, needsTopNibbleClearing=%s, initTargetAndSign=%s\n",
         isDigitTruncation?"true":"false",srcPrecision,isPassThrough?"true":"false",needsTopNibbleClearing?"true":"false",initTargetAndSign?"yes":"no");
   if (!isPassThrough)
      sourceMR =  generateS390RightAlignedMemoryReference(node->getFirstChild(), srcReg->getStorageReference(), cg);
   if (initTargetAndSign || needsTopNibbleClearing)
      targetReg = evaluateBCDValueModifyingOperand(node, initTargetAndSign, sourceMR, cg, initTargetAndSign);
   else
      targetReg = evaluateBCDSignModifyingOperand(node, isPassThrough, isNondestructiveNop, false, sourceMR, cg); // initTarget=false

   bool isInitialized = targetReg->isInitialized();
   TR::MemoryReference *destMR = NULL;
   if (!isPassThrough)
      destMR = generateS390RightAlignedMemoryReference(node, targetReg->getStorageReference(), cg);
   if (!isInitialized && !isPassThrough)
      {
      int32_t srcSize = TR::DataType::packedDecimalPrecisionToByteLength(srcPrecision);
      if (cg->traceBCDCodeGen())
         traceMsg(comp,"\tisInit=false and isPassThru=false so gen initializing MVC with size %d. Do not clear after MVC just set targetReg->prec to srcPrecision %d\n",srcSize,srcPrecision);
      generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                             srcSize-1,
                             generateS390RightAlignedMemoryReference(*destMR, node, 0, cg),
                             generateS390RightAlignedMemoryReference(*sourceMR, node, 0, cg));
      }
   else if (cg->traceBCDCodeGen())
      {
      traceMsg(comp,"\tisInit=true (%s) or isPassThru=true (%s): no move needed just set targetReg->prec to srcPrecision %d\n",isInitialized?"yes":"no",isPassThrough?"yes":"no",srcPrecision);
      }

   // a ZAP may have been generated when initializing targetReg so in this case do not transfer the srcReg sign
   if (!targetReg->signStateInitialized() || !initTargetAndSign)
      targetReg->transferSignState(srcReg, isDigitTruncation);

   targetReg->setDecimalPrecision(targetPrecision);

   if (isSetSign && !isPassThrough)
      cg->genSignCodeSetting(node, targetReg, targetReg->getSize(), generateS390RightAlignedMemoryReference(*destMR, node, 0, cg), sign, targetReg, 0, false /* !topNibbleIsZero */);
   else
      targetReg->transferSignState(srcReg, isDigitTruncation);

   targetReg->transferDataState(srcReg);

   if (needsTopNibbleClearing)
      {
      if (cg->traceBCDCodeGen()) traceMsg(comp,"\tisDigitTruncation=true and targetReg->isEvenPrecision() (%d) so clear top nibble\n",targetReg->isEvenPrecision());
      int32_t leftMostByteForClear = TR::DataType::packedDecimalPrecisionToByteLength(srcPrecision);
      cg->genZeroLeftMostPackedDigits(node, targetReg, leftMostByteForClear, 1, generateS390RightAlignedMemoryReference(*destMR, node, 0, cg));
      }

   if (!isPassThrough)
      targetReg->setIsInitialized();

   return targetReg;
   }

/*
 * \brief
 * Generate non-exception throwing intructions for pdModifyPrecision node to narrow or widen packed decimals.
 * The generated instruction sequence does not validate the source packed decimals. Any invalid packed
 * decimals will be loaded as is and modified as if their digits and signs were valid.
*/
TR::Register *
J9::Z::TreeEvaluator::pdModifyPrecisionEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pdModifyPrecision",node);
   cg->generateDebugCounter("PD-Op/pdmodifyPrec", 1, TR::DebugCounter::Cheap);

   TR::Register* targetReg = NULL;

   static char* isEnableVectorBCD = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() &&
           !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD)
           || isEnableVectorBCD)
      {
      int32_t targetPrec = node->getDecimalPrecision();
      targetReg = cg->allocateRegister(TR_VRF);

      int32_t imm = 0x0FFFF >> (TR_VECTOR_REGISTER_SIZE - TR::DataType::packedDecimalPrecisionToByteLength(targetPrec));
      TR::Register* pdReg = cg->evaluate(node->getFirstChild());
      TR::Register* maskReg = cg->allocateRegister(TR_VRF);
      generateVRIaInstruction(cg, TR::InstOpCode::VGBM, node, maskReg, imm, 0);

      if (targetPrec % 2 == 0)
         {
         TR::Register* shiftAmountReg = cg->allocateRegister(TR_VRF);
         generateVRIaInstruction(cg, TR::InstOpCode::VREPI, node, shiftAmountReg, 4, 0);
         generateVRRcInstruction(cg, TR::InstOpCode::VSRL, node, maskReg, maskReg, shiftAmountReg, 0, 0, 0);
         cg->stopUsingRegister(shiftAmountReg);
         }

      generateVRRcInstruction(cg, TR::InstOpCode::VN, node, targetReg, pdReg, maskReg, 0, 0, 0);

      cg->stopUsingRegister(maskReg);
      cg->decReferenceCount(node->getFirstChild());
      }
   else
      {
      TR::Node *srcNode = node->getChild(0);
      TR_PseudoRegister *srcReg = cg->evaluateBCDNode(srcNode);
      targetReg = simpleWideningOrTruncation(node, srcReg, false, 0, cg);
      cg->decReferenceCount(srcNode);
      node->setRegister(targetReg);
      }

   cg->traceBCDExit("pdModifyPrecision",node);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::pdshlEvaluator(TR::Node * node, TR::CodeGenerator * cg)
   {
   cg->traceBCDEntry("pdshl",node);
   cg->generateDebugCounter("PD-Op/pdshl", 1, TR::DebugCounter::Cheap);

   TR::Register* targetReg = NULL;

   static char* isEnableVectorBCD = feGetEnv("TR_enableVectorBCD");
   if(TR::Compiler->target.cpu.getS390SupportsVectorPackedDecimalFacility() &&
           !TR::Options::getCmdLineOptions()->getOption(TR_DisableVectorBCD) ||
           isEnableVectorBCD)
      {
      targetReg = pdshlVectorEvaluatorHelper(node, cg);
      }
   else
      {
      targetReg = pdshiftEvaluatorHelper(node, cg, false);
      }

   cg->traceBCDExit("pdshl",node);
   return targetReg;
   }

/**
 * \brief This is a helper function that handles pdshl, pdshr, and pdshlOverflow nodes.
 *
 * pdshl is currently not used and replaced by pdshlOverflow.
*/
TR::Register *
J9::Z::TreeEvaluator::pdshiftEvaluatorHelper(TR::Node *node, TR::CodeGenerator *cg, bool isRightShift)
   {
   TR::Node* srcNode         = node->getChild(0);
   TR::Node* shiftAmountNode = node->getChild(1);
   TR::Compilation *comp     = cg->comp();
   int32_t roundAmount = 0;
   int32_t shiftAmount = 0;

   TR_ASSERT(shiftAmountNode, "expecting a shiftAmountNode\n");
   TR_ASSERT(shiftAmountNode->getOpCode().isLoadConst() &&
             shiftAmountNode->getOpCode().getSize() <= 4,
             "expecting a <= 4 size integral constant PD shift amount\n");
   shiftAmount = (int32_t)shiftAmountNode->get64bitIntegralValue();
   TR_ASSERT(shiftAmount >= 0, "unexpected PD shift amount of %d\n", shiftAmount);

   if(isRightShift)
      {
      shiftAmount *= -1;
      TR::Node* roundAmountNode = node->getChild(2);
      TR_ASSERT(roundAmountNode, "round amount node should not be null\n");
      roundAmount = roundAmountNode->get32bitIntegralValue();
      TR_ASSERT(roundAmount == 0 || roundAmount == 5, "unexpected round amount of %d\n", roundAmount);
      cg->decReferenceCount(roundAmountNode);
      }

   TR_PseudoRegister *srcReg = cg->evaluateBCDNode(srcNode);

   uint32_t srcPrecision = srcNode->getDecimalPrecision();
   uint32_t resultPrecision = node->getDecimalPrecision();
   uint32_t resultSize = TR::DataType::packedDecimalPrecisionToByteLength(resultPrecision);
   uint32_t sourceSize = TR::DataType::packedDecimalPrecisionToByteLength(srcPrecision);

   TR_StorageReference* targetStorageRef = TR_StorageReference::createTemporaryBasedStorageReference(resultSize, comp);
   TR_PseudoRegister* targetReg = cg->allocatePseudoRegister(node->getDataType());
   targetReg->setIsInitialized(true);
   targetReg->setSize(resultSize);
   targetReg->setStorageReference(targetStorageRef, node);

   TR::MemoryReference* targetMR = generateS390RightAlignedMemoryReference(node, targetReg->getStorageReference(), cg);
   TR::MemoryReference* sourceMR = generateS390RightAlignedMemoryReference(srcNode, srcReg->getStorageReference(), cg);

   bool isNeedExtraShift = false;
   bool isSimpleCopy = false;

   if(resultPrecision < srcPrecision)
      {
      if(resultPrecision % 2 == 0)
         {
         // MVC + SRP + ZAP + SRP
         isNeedExtraShift = true;
         shiftAmount += 1;
         }
      else
         {
         if(shiftAmount == 0)
            {
            // ZAP
            isSimpleCopy = true;
            }
         else
            {
            // MVC + SRP + ZAP
            }
         }
      }
   else
      {
      if(shiftAmount == 0)
         {
         // ZAP
         isSimpleCopy = true;
         }
      else
         {
         if(resultPrecision % 2 == 0)
            {
            // MVC + SRP + ZAP + SRP
            isNeedExtraShift = true;
            shiftAmount += 1;
            }
         else
            {
            // MVC + SRP + ZAP
            }
         }
      }

   if(isSimpleCopy)
      {
      generateSS2Instruction(cg, TR::InstOpCode::ZAP, node,
                             resultSize - 1,
                             generateS390RightAlignedMemoryReference(*targetMR, node, 0, cg),
                             sourceSize - 1,
                             generateS390RightAlignedMemoryReference(*sourceMR, node, 0, cg));
      }
   else
      {
      if (cg->traceBCDCodeGen())
         {
         traceMsg(comp,"\tGen MVC + SRP + ZAP for shift: %s %p : shift by %d, roundAmount=%d, \
                                                                isNeedExtraShift=%d \
                                                                result Size=%d, precision %d, \
                                                                sourceSize=%d, precision %d\n",
                  node->getOpCode().getName(),
                  node,
                  shiftAmount,
                  roundAmount,
                  isNeedExtraShift,
                  resultSize,
                  resultPrecision,
                  sourceSize,
                  srcNode->getDecimalPrecision());
         }

      TR_StorageReference* tmpStorageRef = TR_StorageReference::createTemporaryBasedStorageReference(sourceSize, comp);
      TR_PseudoRegister* tmpReg = cg->allocatePseudoRegister(node->getDataType());
      tmpReg->setIsInitialized(true);
      tmpReg->setSize(sourceSize);
      tmpReg->setStorageReference(tmpStorageRef, node);
      TR::MemoryReference* tmpMR = generateS390RightAlignedMemoryReference(node, tmpReg->getStorageReference(), cg);

      generateSS1Instruction(cg, TR::InstOpCode::MVC, node,
                              sourceSize - 1,
                              generateS390RightAlignedMemoryReference(*tmpMR, node, 0, cg),
                              sourceMR);

      generateSS3Instruction(cg, TR::InstOpCode::SRP, node,
                             sourceSize - 1,
                             generateS390RightAlignedMemoryReference(*tmpMR, node, 0, cg),
                             shiftAmount, roundAmount);

      generateSS2Instruction(cg, TR::InstOpCode::ZAP, node,
                             resultSize - 1,
                             generateS390RightAlignedMemoryReference(*targetMR, node, 0, cg),
                             sourceSize - 1,
                             generateS390RightAlignedMemoryReference(*tmpMR, node, 0, cg));

      cg->stopUsingRegister(tmpReg);

      if(isNeedExtraShift)
         {
         generateSS3Instruction(cg, TR::InstOpCode::SRP, node,
                                resultSize - 1,
                                generateS390RightAlignedMemoryReference(*targetMR, node, 0, cg),
                                -1, 0);
         }
      }

   cg->decReferenceCount(srcNode);
   cg->decReferenceCount(shiftAmountNode);
   node->setRegister(targetReg);
   return targetReg;
   }

/**
 * Helper to create VPSOP instruction.
 *
 * @param setPrecision true if the VPSOP will set precision.
 * @param signedStatus true if this is this node is signed false if unsigned (0xF)
 * @param soType see enum SignOperationType
 * @param signValidityCheck checks if originalSignCode is a valid sign
 * @param sign sign to set to. (0xA,0xC positive) (0xB,0xD negative) (0xF unsigned)
 * @param setConditionCode determines if this instruction sets ConditionCode or not. (by default this is false)
 */
TR::Register*
J9::Z::TreeEvaluator::vectorPerformSignOperationHelper(TR::Node *node,
                                                       TR::CodeGenerator *cg,
                                                       bool setPrecision,
                                                       uint32_t precision,
                                                       bool signedStatus,
                                                       SignOperationType signOpType,
                                                       bool signValidityCheck,
                                                       int32_t sign,
                                                       bool setConditionCode)
   {
   TR::Register *targetReg = NULL;
   TR::Node *pdNode = node->getFirstChild();

   TR::Register *childReg = cg->evaluate(pdNode);
   targetReg = cg->allocateRegister(TR_VRF);

   int32_t numPrecisionDigits = setPrecision ? precision : TR_MAX_INPUT_PACKED_DECIMAL_PRECISION;
   if(numPrecisionDigits > TR_MAX_INPUT_PACKED_DECIMAL_PRECISION)
      {
      numPrecisionDigits = TR_MAX_INPUT_PACKED_DECIMAL_PRECISION;
      }

   uint8_t constImm4 = signOpType << 2; //bit 4-5 Sign Operation, 6 Positive Sign code, 7 Sign validation on V2

   if(signOpType == SignOperationType::setSign)
      {
      switch(sign)
         {
         case TR_PREFERRED_PLUS_CODE:
         case TR_ALTERNATE_PLUS_CODE:
         case TR_ZONED_PLUS:
            constImm4 |= 0x1;
            break;
         case TR_PREFERRED_MINUS_CODE:
         case TR_ALTERNATE_MINUS_CODE:
            break;
         default:
            TR_ASSERT(0, "Sign code 0x%x is invalid", sign);
            break;
         }
      }

   constImm4 |= (signedStatus ? 0x0 : 0x2 ); //if signedStatus is true it means signed so use 0xC instead of 0xF
   constImm4 |= (signValidityCheck ? 0x1 : 0x0);
   //current use of pdclean does not want to modifyprecision or set condition code.
   //todo: we can probably come up with more complex optimization that will collapse modify precision and setsign/pdclean to one instruction.
   generateVRIgInstruction(cg, TR::InstOpCode::VPSOP, node, targetReg, childReg, numPrecisionDigits, constImm4, setConditionCode);
   node->setRegister(targetReg);
   cg->decReferenceCount(pdNode);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::generateVectorBinaryToPackedConversion(TR::Node * node, TR::InstOpCode::Mnemonic op, TR::CodeGenerator * cg)
   {
   TR_ASSERT(op == TR::InstOpCode::VCVD || op == TR::InstOpCode::VCVDG,
              "unexpected opcode in gen vector i2pd\n");

   TR::Register *vTargetReg = cg->allocateRegister(TR_VRF);
   TR::Node * firstChild = node->getFirstChild();
   TR::Register *sourceReg = cg->evaluate(firstChild);
   bool isUseRegPair = (op == TR::InstOpCode::VCVDG && sourceReg->getRegisterPair());

   if (isUseRegPair)
      {
      TR::Register *tempReg = cg->allocate64bitRegister();
      generateRSInstruction(cg, TR::InstOpCode::SLLG, node, tempReg, sourceReg->getRegisterPair()->getHighOrder(), 32);
      generateRRInstruction(cg, TR::InstOpCode::LR, node, tempReg, sourceReg->getRegisterPair()->getLowOrder());
      sourceReg = tempReg;
      }

   uint8_t precision = node->getDecimalPrecision();
   generateVRIiInstruction(cg, op, node, vTargetReg, sourceReg, precision, 0x1);

   if (isUseRegPair)
      {
      cg->stopUsingRegister(sourceReg);
      }

   cg->decReferenceCount(firstChild);
   node->setRegister(vTargetReg);
   return vTargetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::pdshlVectorEvaluatorHelper(TR::Node *node, TR::CodeGenerator * cg)
   {
   TR::Register * targetReg = NULL;
   TR::Node *firstChild = node->getChild(0);
   TR::Node *shiftAmountNode = node->getNumChildren() > 1 ? node->getSecondChild() : NULL;
   TR_ASSERT(shiftAmountNode, "shift amount node should not be null");
   TR_ASSERT(shiftAmountNode->getOpCode().isLoadConst() && shiftAmountNode->getOpCode().getSize() <= 4,
               "expecting a <= 4 size integral constant PD shift amount\n");

   // If this is a pdshlOverflow with i2pd under it, the i2pd vector instruction (VCVD/VCVDG) will
   // truncate the resulting PD by the amount specified by 'decimalPrecision'. Therefore, we can
   // skip the shift and just return i2pd results.
   bool isSkipShift = node->getOpCodeValue() == TR::pdshlOverflow &&
           (firstChild->getOpCodeValue() == TR::i2pd ||
            firstChild->getOpCodeValue() == TR::l2pd) &&
           firstChild->isSingleRefUnevaluated();

   int32_t shiftAmount = (int32_t)shiftAmountNode->get64bitIntegralValue();
   uint8_t decimalPrecision = node->getDecimalPrecision();

   if(isSkipShift)
      {
      firstChild->setDecimalPrecision(decimalPrecision);
      }

   TR::Register * sourceReg = cg->evaluate(firstChild);

   if(isSkipShift)
      {
      // Passthrough. Assign register to node before decrementing refCount of the firstChild
      // to avoid killing this live register
      targetReg = sourceReg;
      }
   else
      {
      TR_ASSERT((shiftAmount >= -32 && shiftAmount <= 31),"TR::pdshl/r shift amount %d not in range [-32, 31]\n", shiftAmount);

      // VSRP mask 5: bit 0, force source positive (P2).
      //              bit 1, no used, set to 0
      //              bit 2, force target positive (P1) use alternative positive sign 0xF (Unsigned)
      //              bit 3, set condition code
      //
      // Default mask5 to 0x1 to set condition code
      uint8_t mask5 = 0x1;

      targetReg = cg->allocateRegister(TR_VRF);
      generateVRIgInstruction(cg, TR::InstOpCode::VSRP, node, targetReg, sourceReg, decimalPrecision, shiftAmount, mask5);
      }

   node->setRegister(targetReg);
   cg->decReferenceCount(firstChild);
   cg->decReferenceCount(shiftAmountNode);
   return targetReg;
   }

TR::Register *
J9::Z::TreeEvaluator::pdshrVectorEvaluatorHelper(TR::Node *node, TR::CodeGenerator * cg)
   {
   TR::Node *srcNode = node->getChild(0);
   TR::Node *shiftAmountNode = node->getNumChildren() > 1 ? node->getChild(1) : NULL;
   TR_ASSERT(shiftAmountNode != NULL, "pdshrVectorEvaluatorHelper is expecting a shiftAmountNode as child-1\n");
   TR_ASSERT(shiftAmountNode->getOpCode().isLoadConst() && shiftAmountNode->getOpCode().getSize() <= 4,
              "expecting a <= 4 size integral constant PD shift amount\n");

   int32_t shiftAmount = (int32_t)shiftAmountNode->get32bitIntegralValue();
   TR_ASSERT((shiftAmount >=0 || shiftAmount <= 31),"unexpected TR::pdshr shift amount of %d\n",shiftAmount);

   //set shift amount and round amount
   shiftAmount *= -1;                 // right shift is negative
   shiftAmount &= 0x0000007F;         // clear off top bits

   TR::Node *roundAmountNode = node->getChild(2);
   TR_ASSERT( roundAmountNode->getOpCode().isLoadConst(),"excepting pdshr round amount to be a const\n");
   int32_t roundAmount = roundAmountNode->get32bitIntegralValue();
   TR_ASSERT(roundAmount == 0 || roundAmount == 5, "round amount should be 0 or 5 and not %d\n",roundAmount);
   if (roundAmount)
      {
      shiftAmount |= 0x80;       //set the round bit in the shift amount. (immediate3 field in VRIg)
      }

   // Get PD value
   TR::Register * pdValueReg = cg->evaluate(srcNode);
   TR::Register* targetReg = cg->allocateRegister(TR_VRF);

   // Perform shift and set condition code on overflows
   generateVRIgInstruction(cg, TR::InstOpCode::VSRP, node,
                           targetReg, pdValueReg,
                           node->getDecimalPrecision(),
                           shiftAmount, 0x1);

   node->setRegister(targetReg);

   cg->decReferenceCount(srcNode);
   cg->decReferenceCount(shiftAmountNode);
   cg->decReferenceCount(roundAmountNode);

   return targetReg;
   }
