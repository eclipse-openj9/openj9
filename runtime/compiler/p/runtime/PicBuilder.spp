!! Copyright (c) 2000, 2019 IBM Corp. and others
!!
!! This program and the accompanying materials are made available under
!! the terms of the Eclipse Public License 2.0 which accompanies this
!! distribution and is available at https://www.eclipse.org/legal/epl-2.0/
!! or the Apache License, Version 2.0 which accompanies this distribution and
!! is available at https://www.apache.org/licenses/LICENSE-2.0.
!!
!! This Source Code may also be made available under the following
!! Secondary Licenses when the conditions for such availability set
!! forth in the Eclipse Public License, v. 2.0 are satisfied: GNU
!! General Public License, version 2 with the GNU Classpath
!! Exception [1] and GNU General Public License, version 2 with the
!! OpenJDK Assembly Exception [2].
!!
!! [1] https://www.gnu.org/software/classpath/license.html
!! [2] http://openjdk.java.net/legal/assembly-exception.html
!!
!! SPDX-License-Identifier: EPL-2.0 OR Apache-2.0 OR GPL-2.0 WITH Classpath-exception-2.0 OR LicenseRef-GPL-2.0 WITH Assembly-exception

#include "j9cfg.h"
#include "jilconsts.inc"
#include "p/runtime/ppcasmdefines.inc"

	.file "PicBuilder.s"

	.set LOCKED_VALUE,               0x0001
	.set SNIPPET_COMPLETION,         0x0002
	.set Partially_Resolved,         0x0004
	.set IS_SyncSeq,                 0x2000
	.set IS_SpecialDouble,           0x4000
	.set IS_IndexedForm,             0x1000
	.set IS_PsuedoTOC,               0x8000
        .set IS_32BitLong,               0x0800

	.set blr_high,                   0x4e80                 ! Encode the instruction blr
	.set blr_low,                    0x0020
	.set isync_high,                 0x4c00                 ! Encoding for isync instruction
	.set isync_low,                  0x012c
	.set sync_high,                  0x7c00                 ! Encoding for sync instruction
	.set sync_low,                   0x04ac
	.set lwsync_high,                0x7c20                 ! Encoding for lwsync instruction
	.set lwsync_low,                 0x04ac
	.set nop_high,                   0x6000                 ! Encoding for nop
	.set addi_r3_high,               0x386b                 ! Encoding for addi r3,r11,0
	.set add_r3_high,		 0x7c60	                ! Encoding for add r3, ra, rb
	.set add_r3_low,		 0x0214
	.set lwz_r3_high,                0x806b                 ! Encoding for lwz r3,0(r11)
	.set lwz_r4_high,                0x808b                 ! Encoding for lwz r4,0(r11)
	.set stw_r4_high,                0x908b                 ! Encoding for stw r4,0(r11)
	.set stw_r5_high,                0x90ab                 ! Encoding for stw r5,0(r11)

	.set in_clinit,                  0x0001	                ! Indicates if <clinit> is being executed

#define SETVAL(A,B) .set A, B
#include "runtime/Helpers.inc"
#undef SETVAL

#include "p/runtime/PPCAsmUtil.inc"

#ifdef TR_TARGET_64BIT
#define maskVFT(reg)    rldicr reg, reg, 0, 63-J9TR_RequiredClassAlignmentInBits
#else
#define maskVFT(reg)    rlwinm reg, reg, 0, 0, 31-J9TR_RequiredClassAlignmentInBits
#endif

#if defined(TR_HOST_64BIT) && defined(OMR_GC_COMPRESSED_POINTERS)
/* extract isolated field address in TenantDataxxx
   MT_ComputeIsolatedFieldAddress(32/64/obj, element_shift size 2/3)
   assume
   1. r3 has isolated index address
   2. r7 contains RA in snippet
   3. r6 contains return address in mainline
   4. r4, r5 is free
   output
   1. r3 contains col offset in TenantData array
   2. r5 contains row address, owning object
   3. r6, r7 remain unchanged

   sample code to compute TenantData32
    clrrdi r3, r3, 2                                ! clear bits
    ld r4, J9TR_VMThread_tenantData32(r15)          ! TenantData32 base address
    ld r3, 0(r3)                                    ! isolated field index in r3
    sradi  r5, r3, 16                               ! r5 contains row index
    rlwinm r5, r5, 2, 2, 31         				! r5 = row_index << 2
    addi   r5, r5, 8                                ! r5 = row_index*4 + 8
    lwzx   r5, r5, r4                               ! r5 contains row address
    lwz    r4, 20(r7)                               ! r4 contains compressed pointer shift size
    sld    r5, r5, r4                               ! decompress row address
    rlwinm	r3, r3,0, 16, 31        	            ! Masking off high 16 bits, r3 has col index
    rlwinm r3, r3, 2, 2, 31         				! r3 = col_index << 2
    addi   r3, r3, 8                                ! r3 = col_index*4 + 8
 */
#define MT_ComputeStaticFieldAddress(TenantData, elem_shift_size) \
    clrrdi r3, r3, 2 ;                              \
    ld r4, TenantData(r15) ;                        \
    ld r3, 0(r3);                                   \
    sradi  r5, r3, 16 ;                             \
    rlwinm r5, r5, 2, 2, 31 ;                       \
    addi   r5, r5, 8 ;                              \
    lwzx   r5, r5, r4 ;                             \
    lwz    r4, 20(r7) ;                             \
    sld    r5, r5, r4 ;                             \
    rlwinm	r3, r3,0, 16, 31 ;                      \
    rlwinm r3, r3, elem_shift_size, elem_shift_size, 31 ;                       \
    addi   r3, r3, 8        ;

/*
 * load jitResolveStaticField helper address into r8
 * call jitResolveStaticField
 * r7 contains RA in snippet
 * mtspr   CTR, r8					    !move helper address to CTR
    laddr	r3, 1*ALen+4(r7)			! load cp address	                \
    lwz	r29,1*ALen(r7)					! Load cp index for this field
    laddr	r5, 0(r7)					! Load code cache RA
    rlwinm	r4, r29,0, 5, 31				! Masking off flag bits
    bcctrl  BO_ALWAYS, CR0_LT				! Call to resolve: RTOC, r7
 */

#define MT_CallHelper                                       \
    mtspr   CTR, r8;				                        \
    laddr	r3, 1*ALen+4(r7);   			                \
    lwz	r29,1*ALen(r7);					                    \
    laddr	r5, 0(r7);					                    \
    rlwinm	r4, r29,0, 5, 31;				                \
    bcctrl  BO_ALWAYS, CR0_LT

#ifdef AIXPPC
#define MT_ResovleStaticField                               \
    ld      RTOC, J9TR_VMThread_jitTOC(J9VM_STRUCT);        \
    laddr	r8, TOCjitResolveStaticField(RTOC);	            \
    laddr	r8, 0(r8);					                    \
    MT_CallHelper

#define MT_ResovleStaticFieldSetter                         \
    ld      RTOC, J9TR_VMThread_jitTOC(J9VM_STRUCT);        \
    laddr	r8, TOCjitResolveStaticFieldSetter(RTOC);	    \
    laddr	r8, 0(r8);					                    \
    MT_CallHelper

#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
#define MT_ResovleStaticField                               \
    ld      RTOC, J9TR_VMThread_jitTOC(J9VM_STRUCT);        \
    laddr	r8, TOCjitResolveStaticField@toc(RTOC);         \
    MT_CallHelper

#define MT_ResovleStaticFieldSetter                         \
    ld      RTOC, J9TR_VMThread_jitTOC(J9VM_STRUCT);        \
    laddr	r8, TOCjitResolveStaticFieldSetter@toc(RTOC);   \
    MT_CallHelper
#else
#define MT_ResovleStaticField                               \
    ld      RTOC, J9TR_VMThread_jitTOC(J9VM_STRUCT);        \
    laddr	r8, TOCjitResolveStaticField@toc(RTOC);         \
    laddr	r8, 0(r8);                                      \
    MT_CallHelper

#define MT_ResovleStaticFieldSetter                         \
    ld      RTOC, J9TR_VMThread_jitTOC(J9VM_STRUCT);        \
    laddr	r8, TOCjitResolveStaticFieldSetter@toc(RTOC);   \
    laddr	r8, 0(r8);                                      \
    MT_CallHelper
#endif
#else
#define MT_ResovleStaticField                               \
    laddr	r8, jitResolveStaticField@got(RTOC);            \
    MT_CallHelper

#define MT_ResovleStaticFieldSetter                               \
    laddr	r8, jitResolveStaticFieldSetter@got(RTOC);            \
    MT_CallHelper
#endif

#endif

#ifdef AIXPPC
	.lglobl   .__common_lock_check
	.lglobl   .__common_lock_update
	.lglobl   .__spin_for_update
	.lglobl   .__picRegistration
	.lglobl   PicBuilder_DATA{RW}
	.lglobl   __staticGlueTable
	.globl    __j9_smp_flag{RW}
	.globl	.__refreshHelper
	.globl	__refreshHelper{DS}
    .globl    ._interpreterUnresolvedInstanceDataGlue
	.globl    _interpreterUnresolvedInstanceDataGlue{DS}
	.globl	  ._interpreterUnresolvedInstanceDataStoreGlue
	.globl	  _interpreterUnresolvedInstanceDataStoreGlue{DS}
	.globl    ._interpreterUnresolvedClassGlue
	.globl    _interpreterUnresolvedClassGlue{DS}
	.globl    ._interpreterUnresolvedClassGlue2
	.globl    _interpreterUnresolvedClassGlue2{DS}
	.globl    ._interpreterUnresolvedStringGlue
	.globl    _interpreterUnresolvedStringGlue{DS}
	.globl    ._interpreterUnresolvedConstantDynamicGlue
	.globl    _interpreterUnresolvedConstantDynamicGlue{DS}
	.globl    ._interpreterUnresolvedMethodTypeGlue
	.globl    _interpreterUnresolvedMethodTypeGlue{DS}
	.globl    ._interpreterUnresolvedMethodHandleGlue
	.globl    _interpreterUnresolvedMethodHandleGlue{DS}
	.globl    ._interpreterUnresolvedCallSiteTableEntryGlue
	.globl    _interpreterUnresolvedCallSiteTableEntryGlue{DS}
	.globl    ._interpreterUnresolvedMethodTypeTableEntryGlue
	.globl    _interpreterUnresolvedMethodTypeTableEntryGlue{DS}
	.globl    ._interpreterUnresolvedStaticDataGlue
	.globl    .MTUnresolvedInt32Load
	.globl    MTUnresolvedInt32Load{DS}
	.globl    .MTUnresolvedInt64Load
	.globl    MTUnresolvedInt64Load{DS}
	.globl    .MTUnresolvedFloatLoad
	.globl    MTUnresolvedFloatLoad{DS}
	.globl    .MTUnresolvedDoubleLoad
	.globl    MTUnresolvedDoubleLoad{DS}
	.globl    .MTUnresolvedAddressLoad
	.globl    MTUnresolvedIAddressLoad{DS}
	.globl    .MTUnresolvedInt32Store
	.globl    MTUnresolvedInt32Store{DS}
	.globl    .MTUnresolvedInt64Store
	.globl    MTUnresolvedInt64Store{DS}
	.globl    .MTUnresolvedIntFloatStore
	.globl    MTUnresolvedFloatStore{DS}
	.globl    .MTUnresolvedDoubleStore
	.globl    MTUnresolvedDoubleLoad{DS}
	.globl    .MTUnresolvedAddressStore
	.globl    MTUnresolvedIAddressStore{DS}
	.globl    _interpreterUnresolvedStaticDataGlue{DS}
	.globl	  ._interpreterUnresolvedStaticDataStoreGlue
	.globl	  _interpreterUnresolvedStaticDataStoreGlue{DS}
	.globl    ._interpreterVoidStaticGlue
	.globl    _interpreterVoidStaticGlue{DS}
	.globl    ._interpreterSyncVoidStaticGlue
	.globl    _interpreterSyncVoidStaticGlue{DS}
	.globl    ._interpreterGPR3StaticGlue
	.globl    _interpreterGPR3StaticGlue{DS}
	.globl    ._interpreterSyncGPR3StaticGlue
	.globl    _interpreterSyncGPR3StaticGlue{DS}
	.globl    ._interpreterGPR3GPR4StaticGlue
	.globl    _interpreterGPR3GPR4StaticGlue{DS}
	.globl    ._interpreterSyncGPR3GPR4StaticGlue
	.globl    _interpreterSyncGPR3GPR4StaticGlue{DS}
	.globl    ._interpreterFPR0FStaticGlue
	.globl    _interpreterFPR0FStaticGlue{DS}
	.globl    ._interpreterSyncFPR0FStaticGlue
	.globl    _interpreterSyncFPR0FStaticGlue{DS}
	.globl    ._interpreterFPR0DStaticGlue
	.globl    _interpreterFPR0DStaticGlue{DS}
	.globl    ._interpreterSyncFPR0DStaticGlue
	.globl    _interpreterSyncFPR0DStaticGlue{DS}
	.globl    ._nativeStaticHelperForUnresolvedGlue
	.globl    _nativeStaticHelperForUnresolvedGlue
	.globl    ._nativeStaticHelper
	.globl    _nativeStaticHelper
	.globl    ._interpreterUnresolvedStaticGlue
	.globl    _interpreterUnresolvedStaticGlue{DS}
	.globl    ._interpreterUnresolvedSpecialGlue
	.globl    _interpreterUnresolvedSpecialGlue{DS}
	.globl    ._interpreterUnresolvedDirectVirtualGlue
	.globl    _interpreterUnresolvedDirectVirtualGlue{DS}
	.globl    ._virtualUnresolvedHelper
	.globl    _virtualUnresolvedHelper{DS}
	.globl    ._interfaceCallHelper
	.globl    _interfaceCallHelper{DS}
	.globl    ._interfaceCompeteSlot2
	.globl    _interfaceCompeteSlot2{DS}
	.globl    ._interfaceSlotsUnavailable
	.globl    _interfaceSlotsUnavailable{DS}

#elif defined(LINUXPPC64)
	.globl FUNC_LABEL(__refreshHelper)
	.type  FUNC_LABEL(__refreshHelper),@function
	.globl FUNC_LABEL(_interfaceCallHelper)
	.type  FUNC_LABEL(_interfaceCallHelper),@function
	.globl FUNC_LABEL(_interfaceCompeteSlot2)
	.type  FUNC_LABEL(_interfaceCompeteSlot2),@function
	.globl FUNC_LABEL(_interfaceSlotsUnavailable)
	.type  FUNC_LABEL(_interfaceSlotsUnavailable),@function
	.globl FUNC_LABEL(_interpreterFPR0DStaticGlue)
	.type  FUNC_LABEL(_interpreterFPR0DStaticGlue),@function
	.globl FUNC_LABEL(_interpreterFPR0FStaticGlue)
	.type  FUNC_LABEL(_interpreterFPR0FStaticGlue),@function
	.globl FUNC_LABEL(_interpreterGPR3GPR4StaticGlue)
	.type  FUNC_LABEL(_interpreterGPR3GPR4StaticGlue),@function
	.globl FUNC_LABEL(_interpreterGPR3StaticGlue)
	.type  FUNC_LABEL(_interpreterGPR3StaticGlue),@function
	.globl FUNC_LABEL(_interpreterSyncFPR0DStaticGlue)
	.type  FUNC_LABEL(_interpreterSyncFPR0DStaticGlue),@function
	.globl FUNC_LABEL(_interpreterSyncFPR0FStaticGlue)
	.type  FUNC_LABEL(_interpreterSyncFPR0FStaticGlue),@function
	.globl FUNC_LABEL(_interpreterSyncGPR3GPR4StaticGlue)
	.type  FUNC_LABEL(_interpreterSyncGPR3GPR4StaticGlue),@function
	.globl FUNC_LABEL(_interpreterSyncGPR3StaticGlue)
	.type  FUNC_LABEL(_interpreterSyncGPR3StaticGlue),@function
	.globl FUNC_LABEL(_interpreterSyncVoidStaticGlue)
	.type  FUNC_LABEL(_interpreterSyncVoidStaticGlue),@function
    .globl FUNC_LABEL(_interpreterUnresolvedClassGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedClassGlue),@function
	.globl FUNC_LABEL(_interpreterUnresolvedClassGlue2)
	.type  FUNC_LABEL(_interpreterUnresolvedClassGlue2),@function
	.globl FUNC_LABEL(_interpreterUnresolvedDirectVirtualGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedDirectVirtualGlue),@function
	.globl FUNC_LABEL(_interpreterUnresolvedInstanceDataGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedInstanceDataGlue),@function
	.globl FUNC_LABEL(_interpreterUnresolvedInstanceDataStoreGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedInstanceDataStoreGlue),@function
	.globl FUNC_LABEL(_interpreterUnresolvedSpecialGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedSpecialGlue),@function
	.globl FUNC_LABEL(MTUnresolvedInt32Load)
	.type  FUNC_LABEL(MTUnresolvedInt32Load),@function
	.globl FUNC_LABEL(MTUnresolvedInt64Load)
	.type  FUNC_LABEL(MTUnresolvedInt64Load),@function
	.globl FUNC_LABEL(MTUnresolvedFloatLoad)
	.type  FUNC_LABEL(MTUnresolvedFloatLoad),@function
	.globl FUNC_LABEL(MTUnresolvedDoubleLoad)
	.type  FUNC_LABEL(MTUnresolvedDoubleLoad),@function
	.globl FUNC_LABEL(MTUnresolvedAddressLoad)
	.type  FUNC_LABEL(MTUnresolvedAddressLoad),@function
	.globl FUNC_LABEL(MTUnresolvedInt32Store)
	.type  FUNC_LABEL(MTUnresolvedInt32Store),@function
	.globl FUNC_LABEL(MTUnresolvedInt64Store)
	.type  FUNC_LABEL(MTUnresolvedInt64Store),@function
	.globl FUNC_LABEL(MTUnresolvedFloatStore)
	.type  FUNC_LABEL(MTUnresolvedFloatStore),@function
	.globl FUNC_LABEL(MTUnresolvedDoubleStore)
	.type  FUNC_LABEL(MTUnresolvedDoubleStore),@function
	.globl FUNC_LABEL(MTUnresolvedAddressStore)
	.type  FUNC_LABEL(MTUnresolvedAddressStore),@function
	.globl FUNC_LABEL(_interpreterUnresolvedStaticDataGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedStaticDataGlue),@function
	.globl FUNC_LABEL(_interpreterUnresolvedStaticDataStoreGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedStaticDataStoreGlue),@function
	.globl FUNC_LABEL(_interpreterUnresolvedStaticGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedStaticGlue),@function
	.globl FUNC_LABEL(_interpreterUnresolvedStringGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedStringGlue),@function
	.globl FUNC_LABEL(_interpreterUnresolvedConstantDynamicGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedConstantDynamicGlue),@function
	.globl FUNC_LABEL(_interpreterUnresolvedMethodTypeGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedMethodTypeGlue),@function
	.globl FUNC_LABEL(_interpreterUnresolvedMethodHandleGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedMethodHandleGlue),@function
	.globl FUNC_LABEL(_interpreterUnresolvedCallSiteTableEntryGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedCallSiteTableEntryGlue),@function
	.globl FUNC_LABEL(_interpreterUnresolvedMethodTypeTableEntryGlue)
	.type  FUNC_LABEL(_interpreterUnresolvedMethodTypeTableEntryGlue),@function
	.globl FUNC_LABEL(_interpreterVoidStaticGlue)
	.type  FUNC_LABEL(_interpreterVoidStaticGlue),@function
	.globl FUNC_LABEL(_nativeStaticHelperForUnresolvedGlue)
	.type  FUNC_LABEL(_nativeStaticHelperForUnresolvedGlue),@function
	.globl FUNC_LABEL(_nativeStaticHelper)
	.type  FUNC_LABEL(_nativeStaticHelper),@function
	.globl FUNC_LABEL(_virtualUnresolvedHelper)
	.type  FUNC_LABEL(_virtualUnresolvedHelper),@function
#if defined(__LITTLE_ENDIAN__)
	.globl trJitGOT
	.type  trJitGOT,@function
#endif

#elif defined(LINUX)
	.globl __refreshHelper
	.globl _interfaceCallHelper
	.globl _interfaceCompeteSlot2
	.globl _interfaceSlotsUnavailable
	.globl _interpreterFPR0DStaticGlue
	.globl _interpreterFPR0FStaticGlue
	.globl _interpreterGPR3GPR4StaticGlue
	.globl _interpreterGPR3StaticGlue
	.globl _interpreterSyncFPR0DStaticGlue
	.globl _interpreterSyncFPR0FStaticGlue
	.globl _interpreterSyncGPR3GPR4StaticGlue
	.globl _interpreterSyncGPR3StaticGlue
	.globl _interpreterSyncVoidStaticGlue
    .globl _interpreterUnresolvedClassGlue
	.globl _interpreterUnresolvedClassGlue2
	.globl _interpreterUnresolvedDirectVirtualGlue
	.globl _interpreterUnresolvedInstanceDataGlue
	.globl _interpreterUnresolvedInstanceDataStoreGlue
	.globl _interpreterUnresolvedSpecialGlue
	.globl MTUnresolvedInt32Load
	.globl MTUnresolvedInt64Load
	.globl MTUnresolvedFloatLoad
	.globl MTUnresolvedDoubleLoad
	.globl MTUnresolvedAddressLoad
	.globl MTUnresolvedInt32Store
	.globl MTUnresolvedInt64Store
	.globl MTUnresolvedFloatStore
	.globl MTUnresolvedDoubleStore
	.globl MTUnresolvedAddressStore
	.globl _interpreterUnresolvedStaticDataGlue
	.globl _interpreterUnresolvedStaticDataStoreGlue
	.globl _interpreterUnresolvedStaticGlue
	.globl _interpreterUnresolvedStringGlue
	.globl _interpreterUnresolvedConstantDynamicGlue
	.globl _interpreterUnresolvedMethodTypeGlue
	.globl _interpreterUnresolvedMethodHandleGlue
	.globl _interpreterUnresolvedCallSiteTableEntryGlue
	.globl _interpreterUnresolvedMethodTypeTableEntryGlue
	.globl _interpreterVoidStaticGlue
	.globl _nativeStaticHelperForUnresolvedGlue
	.globl _nativeStaticHelper
	.globl _virtualUnresolvedHelper
#if defined(LINUX)
	.globl trJitGOT
#endif

#endif

	.extern   jitResolveField
	.extern   jitResolveFieldSetter
	.extern   jitResolveClass
	.extern   jitResolveClassFromStaticField
	.extern   jitResolveString
	.extern   jitResolveConstantDynamic
	.extern   jitResolveMethodType
	.extern   jitResolveMethodHandle
	.extern   jitResolveInvokeDynamic
	.extern   jitResolveHandleMethod
	.extern   jitResolveStaticField
	.extern   jitResolvedFieldIsVolatile
	.extern   jitResolveStaticFieldSetter
	.extern   jitResolveStaticMethod
	.extern   jitResolveSpecialMethod
	.extern   jitMethodIsSync
	.extern   jitMethodIsNative
	.extern	  j2iTransition
	.extern   icallVMprJavaSendNativeStatic
	.extern   icallVMprJavaSendStatic0
	.extern   icallVMprJavaSendStatic1
	.extern   icallVMprJavaSendStaticJ
	.extern   icallVMprJavaSendStaticF
	.extern   icallVMprJavaSendStaticD
	.extern   icallVMprJavaSendStaticSync0
	.extern   icallVMprJavaSendStaticSync1
	.extern   icallVMprJavaSendStaticSyncJ
	.extern   icallVMprJavaSendStaticSyncF
	.extern   icallVMprJavaSendStaticSyncD
	.extern   jitResolveVirtualMethod
	.extern   jitThrowException
	.extern   jitResolveInterfaceMethod
	.extern   jitLookupInterfaceMethod
	.extern   jitAddPicToPatchOnClassUnload
	.extern   jitCallCFunction
	.extern   jitInstanceOf
	.extern   mcc_reservationAdjustment_unwrapper
	.extern   mcc_callPointPatching_unwrapper
	.extern   mcc_lookupHelperTrampoline_unwrapper

#ifdef AIXPPC
! .text section
	.csect    PicBuilder_TEXT{PR}
#elif defined(LINUXPPC64)
	.section  ".text"
	.align    2
#endif

#ifdef AIXPPC
.__common_lock_check:
	.function .__common_lock_check,startproc.__common_lock_check,16,0,(endproc.__common_lock_check-startproc.__common_lock_check)
	startproc.__common_lock_check:
	laddr  r8, TOC__j9_smp_flag(RTOC)      ! Load flag address
	lwz    r0, 0(r8)                       ! Load flag
#elif defined(LINUXPPC64)
.__common_lock_check:
	startproc.__common_lock_check:
	laddr  r8, TOC__j9_smp_flag@toc(RTOC)  ! Load flag address
	lwz    r0, 0(r8)                       ! Load flag
#else
__common_lock_check:
.__common_lock_check:
	lwz     r0, __j9_smp_flag@got(RTOC) ! Load flag
#endif
	or.     r0, r0, r0                      ! Is it 0?
	bc      BO_IF, CR0_EQ,.__uni_lock_check
	b       .__smp_lock_check
	endproc.__common_lock_check:

#ifdef AIXPPC
.__common_lock_update:
	.function .__common_lock_update,startproc.__common_lock_update,16,0,(endproc.__common_lock_update-startproc.__common_lock_update)
	startproc.__common_lock_update:
	laddr  r8, TOC__j9_smp_flag(RTOC)      ! Load flag address
	lwz    r0, 0(r8)                       ! Load flag
#elif defined(LINUXPPC64)
.__common_lock_update:
	startproc.__common_lock_update:
	laddr  r8, TOC__j9_smp_flag@toc(RTOC)  ! Load flag address
	lwz    r0, 0(r8)                       ! Load flag
#else
__common_lock_update:
.__common_lock_update:
	lwz     r0, __j9_smp_flag@got(RTOC) ! Load flag
#endif
	or.     r0, r0, r0                      ! Is it 0?
	bc      BO_IF, CR0_EQ,.__uni_lock_update
	b       .__smp_lock_update
	endproc.__common_lock_update:

#ifdef AIXPPC
.__spin_for_update:
	.function .__spin_for_update,startproc.__spin_for_update,16,0,(endproc.__spin_for_update-startproc.__spin_for_update)
#elif defined(LINUXPPC64)
.__spin_for_update:
#else
__spin_for_update:
.__spin_for_update:
#endif
	startproc.__spin_for_update:
	lwz     r8, 0(r10)                           ! Load lock word value
	andi.   r8, r8, SNIPPET_COMPLETION           ! Check for completion
	bc      BO_IF,CR0_EQ,.__spin_for_update      ! Return, if completed
	isync
	blr
	endproc.__spin_for_update:

#if defined(LINUX)
! Return the GOT/TOC address in r3.
#if !defined(LINUXPPC64)
trJitGOT:
	startproc.trJitGOT:
	mflr	r0
	lis		r3,_GLOBAL_OFFSET_TABLE_-4@ha
	addi	r3,r3,_GLOBAL_OFFSET_TABLE_-4@l
	mtctr	r3
	bctrl
	mflr	r3
	mtlr	r0
	blr
	endproc.trJitGOT:
#elif defined(LINUXPPC64) && defined(__LITTLE_ENDIAN__)
trJitGOT:
	startproc.trJitGOT:
	mr	r3, r2
	blr
	endproc.trJitGOT:
#endif
#endif

#ifdef AIXPPC
._interpreterUnresolvedInstanceDataGlue:
	.function ._interpreterUnresolvedInstanceDataGlue,startproc._interpreterUnresolvedInstanceDataGlue,16,0,(endproc._interpreterUnresolvedInstanceDataGlue-startproc._interpreterUnresolvedInstanceDataGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedInstanceDataGlue):
#else
_interpreterUnresolvedInstanceDataGlue:
#endif
	startproc._interpreterUnresolvedInstanceDataGlue:
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)				! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR					! Get the RA in snippet
	laddr  RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)	! Restore RTOC
#ifdef AIXPPC
	laddr  r8, TOCjitResolveField(RTOC)			! Load descriptor pointer
	laddr  r8, 0(r8)					! Load the callee address
#elif defined(LINUXPPC64)
	laddr  r8, TOCjitResolveField@toc(RTOC)		! Load descriptor pointer
#if !defined(__LITTLE_ENDIAN__)
	laddr  r8, 0(r8)					! Load the callee address
#endif
#else
	laddr  r8, jitResolveField@got(RTOC)			! Load the callee address
#endif
	li      r27, 0					! This is instance field resolution
	li	r28, 0					! This is a load/loadaddr
.L10.common_code:
	li      r26, 0					! r26 will be set once its found the memory reference really is volatile
	mtspr   CTR, r8					! Move callee address to CTR
	laddr	r3, 1*ALen+4(r7)				! Load constant pool literal
	lwz	r29,1*ALen(r7)					! Load cp index for this field
	laddr	r5, 0(r7)					! Load code cache RA
	rlwinm	r4, r29,0, 5, 31				! Masking off flag bits
	addi	r5, r5, 1					! Increment for EX search
	bcctrl  BO_ALWAYS, CR0_LT				! Call to resolve: RTOC, r7
	lis     r4, IS_SyncSeq | IS_32BitLong
	and.	r4, r29, r4				        ! Is it a volatile sync, or a long volatile 32-bit OS sequence?
	beq	cr0, .L11.common_code				! No, continue normal patching
	ori     r30, r3, 0                                      ! Save resolved field address
#ifdef AIXPPC
	laddr   r8, TOCjitResolvedFieldIsVolatile(RTOC)         ! Load descriptor pointer
	laddr   r8, 0(r8)                                       ! Load the callee address
#elif defined(LINUXPPC64)
        laddr   r8, TOCjitResolvedFieldIsVolatile@toc(RTOC)       ! Load descriptor pointer
#if !defined(__LITTLE_ENDIAN__)
        laddr   r8, 0(r8)                                         ! Load the callee address
#endif
#else
        laddr   r8, jitResolvedFieldIsVolatile@got(RTOC)             ! Load the callee address
#endif
	mtspr   CTR, r8                                         ! Move callee address to CTR
	laddr   r3, 1*ALen+4(r7)                                ! Load constant pool literal
	rlwinm	r4, r29, 0, 5, 31				! Get the cpIndex
	mr      r5, r27                                         ! is Static
	bcctrl  BO_ALWAYS, CR0_LT                               ! Call to ask if the field is volatile
	cmpi	cr0, CmpAddr, r3, 0
	bne     cr0, .L10.it_is_volatile
	andis.  r4, r29, IS_32BitLong                           ! was it a potentially volatile long, 32-bit OS sequence?
	bne     cr0, .L.normal_patching
	andis.	r4, r29, IS_SpecialDouble			! check the special double flag
	bne	cr0, .L.yankTheCall
	andis.	r4, r29, IS_PsuedoTOC				! 64bit TOC sequence?
	li	r5, -4
	beq	cr0, .L.prevIOffset
	lwz	r8, 2*ALen+4(r7)				! Load TOC offset
	cmpi	cr0, 0, r8, 0
	li	r5, 20						! TOC overflow offset
	beq	cr0, .L.prevIOffset
	srawi.	r8, r8, 15
	li	r5, 4
	beq	cr0, .L.prevIOffset
	cmpi	cr0, 0, r8, -1
	beq	cr0, .L.prevIOffset
	li	r5, 8
.L.prevIOffset:
	laddr	r6, 0(r7)					! Load codeCache RA
	cmpi	cr0, 0, r28, 0					! Is it a load seq?
	lis	r3, nop_high
	beq	cr0, .L.isyncPatching
	add	r9, r6, r5
	stw	r3, 0(r9)					! patch the lwsync
	bl	.__code_synchronization
	andis.	r4, r29, IS_PsuedoTOC
	addi	r9, r9, 8
	bne	cr0, .L.syncPatching
	andis.	r4, r29, IS_IndexedForm
	addi	r9, r9, 4
	beq	cr0, .L.syncPatching
	addi	r9, r9, 4
.L.syncPatching:
	stw	r3, 0(r9)
	bl	.__code_synchronization
	b	.L.normal_patching
.L.isyncPatching:
	andis.	r4, r29, IS_PsuedoTOC
	add	r9, r6, r5
	addi	r9, r9, 4
	bne	cr0, .L.doIsyncPatching
	andis.	r4, r29, IS_IndexedForm
	addi	r9, r9, 8
	beq	cr0, .L.doIsyncPatching
	addi	r9, r9, 4
.L.doIsyncPatching:
	stw	r3, 0(r9)
	bl	.__code_synchronization
	b	.L.normal_patching
.L.yankTheCall:
	laddr	r6, 0(r7)					! Load codeCache RA
	lis	r3, nop_high
	addi	r9, r6, 8
	andis.	r4, r29, IS_IndexedForm				! Is the original instruction indexed
	beq	cr0, .L.nopingTheCall
	addi	r9, r9, 4
.L.nopingTheCall:
	stw	r3, 0(r9)
	bl	.__code_synchronization
	b	.L.normal_patching

.L10.it_is_volatile:
        lis     r26, IS_32BitLong                               ! Mark that the memory reference really is volatile,
	                                                        ! using IS_32BitLong to simplify later condition checking
	andis.	r4, r29, IS_SpecialDouble			! check the special double flag
	beq     cr0, .L.normal_patching
	laddr	r6, 0(r7)					! Load codeCache RA
	lis	r3, addi_r3_high
	andis.	r4, r29, IS_IndexedForm				! Is the original instruction indexed
	lwz	r4, 2*ALen+4(r7)				! Load offset to be merged
	add	r4, r30, r4
	addi	r9, r6, 4
	rlwimi	r3, r4, 0, 16, 31				! Important: eliminate possible race cond.
	beq	cr0, .L.setUpAddressing
	lwz	r4, 8(r6)					! the indexed instruction
	lis	r3, add_r3_high
	addi	r3, r3, add_r3_low
	addi	r9, r6, 8
	rlwimi	r3, r4, 0, 11, 20				! add r3, ra, rb
.L.setUpAddressing:
	stw     r3, 0(r9)                                       ! replace isync with noop
	bl      .__code_synchronization
.L.normal_patching:
	ori     r3, r30, 0                                      ! restore resolved field addre
.L11.common_code:						!   not modified, r3 is result
	laddr	r6, 0(r7)					! Load code cache RA
	rlwinm  r17, r3, 0, 31, 31                              ! keep in r17 if r3 last bit is set: <clinit> is being executed
#ifdef TR_HOST_64BIT
	clrrdi r3, r3, 1                                        ! <clinit> clear up the last bit, which must be zero
#else
	rlwinm  r3, r3, 0, 0xfffffffe                           ! <clinit> clear up the last bit, which must be zero
#endif
	cmpi	cr0, 0, r17, in_clinit				! <clinit> is being executed
	bc	BO_IF, CR0_EQ, .L_update			! If in <clinit>
	addi    r10, r7, 2*ALen+12				! Calculate lock address
	addi    r9, 0, LOCKED_VALUE
	bl      .__common_lock_check				! Try to lock
	or.     r8, r8, r8					! Result in r8
	bc      BO_IF,CR0_EQ,.L_update				! Grab the lock successfully?
	bl      .__spin_for_update				! r10 containing lock address
	b       .L_restore_and_return
.L_update:
	lwz	r29, 1*ALen(r7)					! Load cp index
	andis.	r4, r29, 0x8000					! Test the pTOC bit
	lwz	r4, 2*ALen+4(r7)				! Load offset to be merged
#ifdef TR_HOST_64BIT
	extsw	r4, r4
#endif
	bc	BO_IF_NOT, CR0_EQ, .L_pTOC_update		! Is pTOC case?
	lwz     r9, 4(r6)                                       ! load the second instr from memory reference sequence in the code cache
	andis.  r29, r29, IS_32BitLong                          ! Mask off all bits but the IS_32BitLong bit
	andc.   r8, r29, r26                                    ! if IS_32BitLong and it is not really a volatile then
	beq     .L_LoadTemplateInstruction                      ! dont branch,
	cmpi    cr0, 0, r28, 0                                  ! and check if we are in a load sequence.
        lis     r9, lwz_r3_high                                 ! if so then use lwz r3,0(r11)
	beq     .L_LoadTemplateInstruction                      !
	lis     r9, stw_r4_high                                 ! else else use stw r4,0(r11)
.L_LoadTemplateInstruction:
	lwz	r8, 2*ALen+8(r7)				! Load the template instruction
	add	r3, r3, r4					! Add to the returned result
.L_patch_dword_load:
	! r8 contains the template instruction, r9 the next instruction
	rlwinm	r0, r3, 17, 0x00000001				! Put r3{16} in r0
	srawi   r4, r3, 16					! Put r3{0:15} in r4
	add	r4, r4, r0					! r4 contains the upper value
	rlwimi	r8, r4, 0, 0x0000ffff				! r8 to override bl instruction
	rlwimi	r9, r3, 0, 0x0000ffff				! r9 contains the second instr
	stw	r9, 4(r6)					! Override the second instr
	addi	r9, r6, 4					! Modified instruction address must be in r9
	bl	.__code_synchronization				! r9: the sync-ed instruction address

        lwz     r9,1*ALen(r7)                                   ! Load cp index for this field
	andis.  r9, r9, IS_32BitLong                            ! Mask off all bits but the IS_32BitLong bit
        andc.   r9, r9, r26                                     ! if IS_32BitLong and it is not really a volatile then
        beq     .L_Skip2ndMemRefInstruction                     ! dont branch,
        cmpi    cr0, 0, r28, 0                                  ! and check if we are in a load sequence.
        lis     r9, lwz_r4_high                                 ! if so then use lwz r4,0(r11)
        beq     .L_lwz                                          !
        lis     r9, stw_r5_high                                 ! else else use stw r5,0(r11)
.L_lwz:
        addi    r3, r3, 4                                       ! prepare immediate offset of upper word of long mem ref
        rlwimi  r9, r3, 0, 0x0000ffff                           ! r9 contains the instruction for upper word of long mem ref
        stw     r9, 8(r6)                                       ! Override the second instr
	addi    r9, r6, 8                                       ! Modified instruction address must be in r9
	bl      .__code_synchronization                         ! r9: the sync-ed instruction address
.L_Skip2ndMemRefInstruction:
								! Handle <clinit> case
	cmpi	cr0, 0, r17, in_clinit				! <clinit> is being executed
	bc	BO_IF_NOT, CR0_EQ, .L_no_clinit			! If not in <clinit>
	addi	r9, r7, 2*ALen+16				! Get the address of the snippet instr
	stw	r8, 0(r9)					! Override the snippet instr
	mr	r6, r9						! r6 is the return target
	bl	.__code_synchronization				! r9: the sync-ed address
	b	.L_restore_and_return

.L_no_clinit:
	stw	r8, 0(r6)					! Override the first instr
	or	r9, r6, r6					! Move r6 to r9
	bl	.__code_synchronization				! r9: the sync-ed address
	addi	r9, 0, SNIPPET_COMPLETION			! Release lock and marking
	bl	.__common_lock_update				! r10: lock word address
	b	.L_restore_and_return

.L_pTOC_update:
	or.	r4, r4, r4
	bc	BO_IF, CR0_EQ, .L_pTOC_full
	laddrx	r5, J9_TOC, r4					! Load the TOC entry
	or.	r5, r5, r5
	bc	BO_IF_NOT, CR0_EQ, .L_entryUpdated		! Entry != 0
	staddrx	r3, J9_TOC, r4					! Store result into entry
	sync							! Ensure order
.L_entryUpdated:
	cmpi	cr0, 0, r4, 0x00007fff				! This is a word value

	addi	r9, r6, 4					! Set up value on r9 for both paths below

	bc	BO_IF, CR0_GT, .L_twoSlots
	cmpi	cr0, 0, r4, -0x8000
	bc	BO_IF_NOT, CR0_LT, .L_oneSlot
.L_twoSlots:
	lwz	r8, 4(r6)
	rlwimi	r8, r4, 0, 16, 31
	stw	r8, 0(r9)
	bl	.__code_synchronization				! r9 is the sync-ed addr
	rlwinm	r0, r4, 17, 31, 31
	srawi	r4, r4, 16
	add	r4, r4, r0					! Upper value in r4
.L_oneSlot:
	lwz	r8, 2*ALen+8(r7)				! Load the template
	rlwimi	r8, r4, 0, 16, 31

.L_modifyFirst:							! Handle <clinit> case
	cmpi	cr0, 0, r17, in_clinit				! <clinit> is being executed
	bc	BO_IF_NOT, CR0_EQ, .L_pTOC_no_clinit		! If not in <clinit>
	addi	r9, r7, 2*ALen+16				! Get the address of the snippet instr
	stw	r8, 0(r9)					! Override the snippet instr
	mr	r6, r9						! r6 is the return target
	bl	.__code_synchronization				! r9 is the sync-ed addr
	b	.L_restore_and_return

.L_pTOC_no_clinit:
	stw	r8, 0(r6)					! Override the first instr
	or	r9, r6, r6
	bl	.__code_synchronization				! r9 is the sync-ed addr
	addi	r9, 0, SNIPPET_COMPLETION			! Release lock and marking
	bl	.__common_lock_update				! r10 is lock word addr

.L_restore_and_return:

	mtspr	CTR, r6						! Move the return addr to CTR
	lwz     r0, 33*ALen-4(J9SP)
	mtcrf   0xff, r0					! Restore CR

#include "p/runtime/RestoreGPRs.inc"
	bcctr	BO_ALWAYS, CR0_LT				! Return

.L_pTOC_full:
	lwz	r8, 4(r6)
#ifdef TR_HOST_64BIT
	rldicl	r4, r3, 32, 48					! bits 16-31
#else
	ori	r4, r4, 0					! nop
#endif
	addi	r9, r6, 4
	or	r8, r8, r4
	stw	r8, 4(r6)
	bl	.__code_synchronization                         ! second instr
	lwz	r8, 12(r6)
#ifdef TR_HOST_64BIT
	rldicl	r4, r3, 48, 48					! bits 32-47
#else
	ori	r4, r4, 0					! nop
#endif
	addi	r9, r6, 12
	or	r8, r8, r4
	stw	r8, 12(r6)
	bl	.__code_synchronization				! fourth instr
	lwz	r8, 16(r6)
#ifdef TR_HOST_64BIT
	rldicl	r4, r3, 0, 48					! bits 48-63
#else
	ori	r4, r4, 0					! nop
#endif
	addi	r9, r6, 16
	or	r8, r8, r4
	stw	r8, 16(r6)
	bl	.__code_synchronization				! fifth instr
	lwz	r8, 2*ALen+8(r7)				! load the template
#ifdef TR_HOST_64BIT
	rldicl	r4, r3, 16, 48					! bits 0-15
#else
	ori	r4, r4, 0					! nop
#endif
	addi	r9, r6, 4					! Set up r9 for return addr manipulation
	or	r8, r8, r4
	b	.L_modifyFirst
	endproc._interpreterUnresolvedInstanceDataGlue:


#ifdef AIXPPC
._interpreterUnresolvedInstanceDataStoreGlue:
	.function ._interpreterUnresolvedInstanceDataStoreGlue,startproc._interpreterUnresolvedInstanceDataStoreGlue,16,0,(endproc._interpreterUnresolvedInstanceDataStoreGlue-startproc._interpreterUnresolvedInstanceDataStoreGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedInstanceDataStoreGlue):
#else
_interpreterUnresolvedInstanceDataStoreGlue:
._interpreterUnresolvedInstanceDataStoreGlue:
#endif
	startproc._interpreterUnresolvedInstanceDataStoreGlue:
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)	! Restore RTOC
#ifdef AIXPPC
	laddr	r8, TOCjitResolveFieldSetter(RTOC)		! Load descriptor pointer
	laddr	r8, 0(r8)					! Load the callee address
#elif defined(LINUXPPC64)
	laddr	r8, TOCjitResolveFieldSetter@toc(RTOC)		! Load descriptor pointer
#if !defined(__LITTLE_ENDIAN__)
	laddr	r8, 0(r8)					! Load the callee address
#endif
#else
	laddr	r8, jitResolveFieldSetter@got(RTOC)		! Load the callee address
#endif
	li      r27, 0
	li	r28, 1						! This is a store
	b	.L10.common_code
	endproc._interpreterUnresolvedInstanceDataStoreGlue:


#ifdef AIXPPC
._interpreterUnresolvedClassGlue:
	.function ._interpreterUnresolvedClassGlue,startproc._interpreterUnresolvedClassGlue,16,0,(endproc._interpreterUnresolvedClassGlue-startproc._interpreterUnresolvedClassGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedClassGlue):
#else
_interpreterUnresolvedClassGlue:
._interpreterUnresolvedClassGlue:
#endif
	startproc._interpreterUnresolvedClassGlue:
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)	! Restore RTOC
#ifdef AIXPPC
	laddr	r8, TOCjitResolveClass(RTOC)			! Load descriptor pointer
	laddr	r8, 0(r8)					! Load the callee address
#elif defined(LINUXPPC64)
	laddr	r8, TOCjitResolveClass@toc(RTOC)			! Load descriptor pointer
#if !defined(__LITTLE_ENDIAN__)
	laddr	r8, 0(r8)					! Load the callee address
#endif
#else
	laddr	r8, jitResolveClass@got(RTOC)			! Load the callee address
#endif
	laddr	r3, 1*ALen+4(r7)				! Load constant pool literal
	lwz	r4, 1*ALen(r7)					! Load cp index for this field
	laddr	r5, 0(r7)					! Load code cache RA
	rlwinm	r4, r4, 0, 5, 31				! Masking off the flag bits
	addi	r5, r5, 1					! Increment for EX search
	mtspr   CTR, r8						! Move callee address to CTR
	bcctrl  BO_ALWAYS, CR0_LT				! Call to resolve: RTOC, r7
	b       .L11.common_code				! not modified, r3: result
	endproc._interpreterUnresolvedClassGlue:

#ifdef AIXPPC
._interpreterUnresolvedClassGlue2:
      .function ._interpreterUnresolvedClassGlue2,startproc._interpreterUnresolvedClassGlue2,16,0,(endproc._interpreterUnresolvedClassGlue2-startproc._interpreterUnresolvedClassGlue2)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedClassGlue2):
#else
_interpreterUnresolvedClassGlue2:
._interpreterUnresolvedClassGlue2:
#endif
      startproc._interpreterUnresolvedClassGlue2:
#include "p/runtime/SaveGPRs.inc"
      mfcr    r0
      stw     r0,-4(J9SP)                                     ! Save CR also
      addi    J9SP,J9SP,-(33*ALen)
      mfspr   r7, LR                                          ! Get the RA in snippet
      laddr   RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)      ! Restore RTOC
#ifdef AIXPPC
      laddr   r8, TOCjitResolveClassFromStaticField(RTOC)     ! Load descriptor pointer
      laddr   r8, 0(r8)                                       ! Load the callee address
#elif defined(LINUXPPC64)
      laddr   r8, TOCjitResolveClassFromStaticField@toc(RTOC) ! Load descriptor pointer
#if !defined(__LITTLE_ENDIAN__)
      laddr   r8, 0(r8)                                       ! Load the callee address
#endif
#else
      laddr   r8, jitResolveClassFromStaticField@got(RTOC)    ! Load the callee address
#endif
      laddr   r3, 1*ALen+4(r7)                                ! Load constant pool literal
      lwz     r4, 1*ALen(r7)                                  ! Load cp index for this field
      laddr   r5, 0(r7)                                       ! Load code cache RA
      rlwinm  r4, r4, 0, 5, 31                                ! Masking off the flag bits
      addi    r5, r5, 1                                       ! Increment for EX search
      mtspr   CTR, r8                                         ! Move callee address to CTR
      bcctrl  BO_ALWAYS, CR0_LT                               ! Call to resolve: RTOC, r7
      b       .L11.common_code                                ! not modified, r3: result
      endproc._interpreterUnresolvedClassGlue2:

#ifdef AIXPPC
._interpreterUnresolvedStringGlue:
	.function ._interpreterUnresolvedStringGlue,startproc._interpreterUnresolvedStringGlue,16,0,(endproc._interpreterUnresolvedStringGlue-startproc._interpreterUnresolvedStringGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedStringGlue):
#else
_interpreterUnresolvedStringGlue:
._interpreterUnresolvedStringGlue:
#endif
	startproc._interpreterUnresolvedStringGlue:
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr	r7, LR						! Get the RA in snippet
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)	! Restore RTOC
#ifdef AIXPPC
	laddr	r8, TOCjitResolveString(RTOC)			! Load descriptor pointer
	laddr	r8, 0(r8)					! Load the callee address
#elif defined(LINUXPPC64)
	laddr	r8, TOCjitResolveString@toc(RTOC)			! Load descriptor pointer
#if !defined(__LITTLE_ENDIAN__)
	laddr	r8, 0(r8)					! Load the callee address
#endif
#else
	laddr	r8, jitResolveString@got(RTOC)			! Load the callee address
#endif
	laddr	r3, 1*ALen+4(r7)				! Load constant pool literal
	lwz	r4, 1*ALen(r7)					! Load cp index for this field
	laddr	r5, 0(r7)					! Load code cache RA
	rlwinm	r4, r4, 0, 5, 31				! Masking off the flag bits
	addi	r5, r5, 1					! Increment for EX search
	mtspr	CTR, r8						! Move callee address to CTR
	bcctrl	BO_ALWAYS, CR0_LT				! Call to resolve: RTOC, r7
	laddr	r6, 0(r7)					! Load code cache RA
	rlwinm  r17, r3, 0, 31, 31				! keep in r17 if r3 last bit is set: <clinit> is being executed
#ifdef TR_HOST_64BIT
	clrrdi r3, r3, 1                                        ! <clinit> clear up the last bit, which must be zero
#else
	rlwinm  r3, r3, 0, 0xfffffffe                           ! <clinit> clear up the last bit, which must be zero
#endif
	cmpi	cr0, 0, r17, in_clinit				! <clinit> is being executed
	bc	BO_IF, CR0_EQ, .L_string_update			! If in <clinit>
	addi	r10, r7, 2*ALen+12				! Calculate lock address
	addi	r9, 0, LOCKED_VALUE
	bl	.__common_lock_check				! Try to lock
	or.	r8, r8, r8					! Result in r8
	bc	BO_IF,CR0_EQ,.L_string_update			! Grab the lock successfully?
	bl	.__spin_for_update				! r10 containing lock address
	b	.L_restore_and_return
.L_string_update:
	lwz	r4, 1*ALen(r7)					! Load cp index
	andis.	r4, r4, 0x8000					! Test the pTOC bit
	lwz	r4, 2*ALen+4(r7)				! Load offset to be merged
#ifdef TR_HOST_64BIT
	extsw	r4, r4
#endif
	bc	BO_IF_NOT, CR0_EQ, .L_pTOC_update		! Is pTOC case?
	or	r3, r4, r4					! Not pTOC case -- 32bit
	lwz	r9, 4(r6)					! Load the second instr
	lwz	r8, 2*ALen+8(r7)				! Load the template instruction
	b	.L_patch_dword_load
	endproc._interpreterUnresolvedStringGlue:

#ifdef AIXPPC
._interpreterUnresolvedConstantDynamicGlue:
   .function ._interpreterUnresolvedConstantDynamicGlue,startproc._interpreterUnresolvedConstantDynamicGlue,16,0,(endproc._interpreterUnresolvedConstantDynamicGlue-startproc._interpreterUnresolvedConstantDynamicGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedConstantDynamicGlue):
#else
_interpreterUnresolvedConstantDynamicGlue:
._interpreterUnresolvedConstantDynamicGlue:
#endif
        startproc._interpreterUnresolvedConstantDynamicGlue:
#include "p/runtime/SaveGPRs.inc"
        mfcr    r0
        stw     r0,-4(J9SP)                                     ! Save CR also
        addi    J9SP,J9SP,-(33*ALen)
        mfspr   r7, LR                                          ! Get the RA in snippet
        laddr   RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)      ! Restore RTOC
#ifdef AIXPPC
        laddr   r8, TOCjitResolveConstantDynamic(RTOC)          ! Load descriptor pointer
        laddr   r8, 0(r8)                                       ! Load the callee address
#elif defined(LINUXPPC64)
        laddr   r8, TOCjitResolveConstantDynamic@toc(RTOC)      ! Load descriptor pointer
#if !defined(__LITTLE_ENDIAN__)
        laddr   r8, 0(r8)                                       ! Load the callee address
#endif
#else
        laddr   r8, jitResolveConstantDynamic@got(RTOC)         ! Load the callee address
#endif
        laddr   r3, 1*ALen+4(r7)                                ! Load constant pool literal
        lwz     r4, 1*ALen(r7)                                  ! Load cp index for this field
        laddr   r5, 0(r7)                                       ! Load code cache RA
        rlwinm  r4, r4, 0, 5, 31                                ! Masking off the flag bits
        addi    r5, r5, 1                                       ! Increment for EX search
        mtspr   CTR, r8                                         ! Move callee address to CTR
        bcctrl  BO_ALWAYS, CR0_LT                               ! Call to resolve: RTOC, r7
        laddr   r6, 0(r7)                                       ! Load code cache RA
        rlwinm  r17, r3, 0, 31, 31                              ! keep in r17 if r3 last bit is set: <clinit> is being executed
#ifdef TR_HOST_64BIT
        clrrdi r3, r3, 1                                        ! <clinit> clear up the last bit, which must be zero
#else
        rlwinm  r3, r3, 0, 0xfffffffe                           ! <clinit> clear up the last bit, which must be zero
#endif
        cmpi    cr0, 0, r17, in_clinit                          ! <clinit> is being executed
        bc      BO_IF, CR0_EQ, .L_condy_update                  ! If in <clinit>
        addi    r10, r7, 2*ALen+12                              ! Calculate lock address
        addi    r9, 0, LOCKED_VALUE
        bl      .__common_lock_check                            ! Try to lock
        or.     r8, r8, r8                                      ! Result in r8
        bc      BO_IF,CR0_EQ,.L_condy_update                    ! Grab the lock successfully?
        bl      .__spin_for_update                              ! r10 containing lock address
        b       .L_restore_and_return
.L_condy_update:
        lwz     r4, 1*ALen(r7)                                  ! Load cp index
        andis.  r4, r4, 0x8000                                  ! Test the pTOC bit
        lwz     r4, 2*ALen+4(r7)                                ! Load offset to be merged
#ifdef TR_HOST_64BIT
        extsw   r4, r4
#endif
        bc      BO_IF_NOT, CR0_EQ, .L_pTOC_update               ! Is pTOC case?
        or      r3, r4, r4                                      ! Not pTOC case -- 32bit
        lwz     r9, 4(r6)                                       ! Load the second instr
        lwz     r8, 2*ALen+8(r7)                                ! Load the template instruction
        b       .L_patch_dword_load
        endproc._interpreterUnresolvedConstantDynamicGlue:

#ifdef AIXPPC
._interpreterUnresolvedMethodTypeGlue:
	.function ._interpreterUnresolvedMethodTypeGlue,startproc._interpreterUnresolvedMethodTypeGlue,16,0,(endproc._interpreterUnresolvedMethodTypeGlue-startproc._interpreterUnresolvedMethodTypeGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedMethodTypeGlue):
#else
_interpreterUnresolvedMethodTypeGlue:
._interpreterUnresolvedMethodTypeGlue:
#endif
	startproc._interpreterUnresolvedMethodTypeGlue:
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr	r7, LR						! Get the RA in snippet
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)	! Restore RTOC
#ifdef AIXPPC
	laddr	r8, TOCjitResolveMethodType(RTOC)			! Load descriptor pointer
	laddr	r8, 0(r8)					! Load the callee address
#elif defined(LINUXPPC64)
	laddr	r8, TOCjitResolveMethodType@toc(RTOC)			! Load descriptor pointer
#if !defined(__LITTLE_ENDIAN__)
	laddr	r8, 0(r8)					! Load the callee address
#endif
#else
	laddr	r8, jitResolveMethodType@got(RTOC)			! Load the callee address
#endif
	laddr	r3, 1*ALen+4(r7)				! Load constant pool literal
	lwz	r4, 1*ALen(r7)					! Load cp index for this field
	laddr	r5, 0(r7)					! Load code cache RA
	rlwinm	r4, r4, 0, 5, 31				! Masking off the flag bits
	addi	r5, r5, 1					! Increment for EX search
	mtspr	CTR, r8						! Move callee address to CTR
	bcctrl	BO_ALWAYS, CR0_LT				! Call to resolve: RTOC, r7
	laddr	r6, 0(r7)					! Load code cache RA
	rlwinm  r17, r3, 0, 31, 31				! keep in r17 if r3 last bit is set: <clinit> is being executed
#ifdef TR_HOST_64BIT
	clrrdi r3, r3, 1                                        ! <clinit> clear up the last bit, which must be zero
#else
	rlwinm  r3, r3, 0, 0xfffffffe                           ! <clinit> clear up the last bit, which must be zero
#endif
	cmpi	cr0, 0, r17, in_clinit				! <clinit> is being executed
	bc	BO_IF, CR0_EQ, .L_MethodType_update			! If in <clinit>
	addi	r10, r7, 2*ALen+12				! Calculate lock address
	addi	r9, 0, LOCKED_VALUE
	bl	.__common_lock_check				! Try to lock
	or.	r8, r8, r8					! Result in r8
	bc	BO_IF,CR0_EQ,.L_MethodType_update			! Grab the lock successfully?
	bl	.__spin_for_update				! r10 containing lock address
	b	.L_restore_and_return
.L_MethodType_update:
	lwz	r4, 1*ALen(r7)					! Load cp index
	andis.	r4, r4, 0x8000					! Test the pTOC bit
	lwz	r4, 2*ALen+4(r7)				! Load offset to be merged
#ifdef TR_HOST_64BIT
	extsw	r4, r4
#endif
	bc	BO_IF_NOT, CR0_EQ, .L_pTOC_update		! Is pTOC case?
	or	r3, r4, r4					! Not pTOC case -- 32bit
	lwz	r9, 4(r6)					! Load the second instr
	lwz	r8, 2*ALen+8(r7)				! Load the template instruction
	b	.L_patch_dword_load
	endproc._interpreterUnresolvedMethodTypeGlue:

#ifdef AIXPPC
._interpreterUnresolvedMethodHandleGlue:
	.function ._interpreterUnresolvedMethodHandleGlue,startproc._interpreterUnresolvedMethodHandleGlue,16,0,(endproc._interpreterUnresolvedMethodHandleGlue-startproc._interpreterUnresolvedMethodHandleGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedMethodHandleGlue):
#else
_interpreterUnresolvedMethodHandleGlue:
._interpreterUnresolvedMethodHandleGlue:
#endif
	startproc._interpreterUnresolvedMethodHandleGlue:
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr	r7, LR						! Get the RA in snippet
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)	! Restore RTOC
#ifdef AIXPPC
	laddr	r8, TOCjitResolveMethodHandle(RTOC)			! Load descriptor pointer
	laddr	r8, 0(r8)					! Load the callee address
#elif defined(LINUXPPC64)
	laddr	r8, TOCjitResolveMethodHandle@toc(RTOC)			! Load descriptor pointer
#if !defined(__LITTLE_ENDIAN__)
	laddr	r8, 0(r8)					! Load the callee address
#endif
#else
	laddr	r8, jitResolveMethodHandle@got(RTOC)			! Load the callee address
#endif
	laddr	r3, 1*ALen+4(r7)				! Load constant pool literal
	lwz	r4, 1*ALen(r7)					! Load cp index for this field
	laddr	r5, 0(r7)					! Load code cache RA
	rlwinm	r4, r4, 0, 5, 31				! Masking off the flag bits
	addi	r5, r5, 1					! Increment for EX search
	mtspr	CTR, r8						! Move callee address to CTR
	bcctrl	BO_ALWAYS, CR0_LT				! Call to resolve: RTOC, r7
	laddr	r6, 0(r7)					! Load code cache RA
	rlwinm  r17, r3, 0, 31, 31				! keep in r17 if r3 last bit is set: <clinit> is being executed
#ifdef TR_HOST_64BIT
	clrrdi r3, r3, 1                                        ! <clinit> clear up the last bit, which must be zero
#else
	rlwinm  r3, r3, 0, 0xfffffffe                           ! <clinit> clear up the last bit, which must be zero
#endif
	cmpi	cr0, 0, r17, in_clinit				! <clinit> is being executed
	bc	BO_IF, CR0_EQ, .L_MethodHandle_update			! If in <clinit>
	addi	r10, r7, 2*ALen+12				! Calculate lock address
	addi	r9, 0, LOCKED_VALUE
	bl	.__common_lock_check				! Try to lock
	or.	r8, r8, r8					! Result in r8
	bc	BO_IF,CR0_EQ,.L_MethodHandle_update			! Grab the lock successfully?
	bl	.__spin_for_update				! r10 containing lock address
	b	.L_restore_and_return
.L_MethodHandle_update:
	lwz	r4, 1*ALen(r7)					! Load cp index
	andis.	r4, r4, 0x8000					! Test the pTOC bit
	lwz	r4, 2*ALen+4(r7)				! Load offset to be merged
#ifdef TR_HOST_64BIT
	extsw	r4, r4
#endif
	bc	BO_IF_NOT, CR0_EQ, .L_pTOC_update		! Is pTOC case?
	or	r3, r4, r4					! Not pTOC case -- 32bit
	lwz	r9, 4(r6)					! Load the second instr
	lwz	r8, 2*ALen+8(r7)				! Load the template instruction
	b	.L_patch_dword_load
	endproc._interpreterUnresolvedMethodHandleGlue:

#ifdef AIXPPC
._interpreterUnresolvedCallSiteTableEntryGlue:
	.function ._interpreterUnresolvedCallSiteTableEntryGlue,startproc._interpreterUnresolvedCallSiteTableEntryGlue,16,0,(endproc._interpreterUnresolvedCallSiteTableEntryGlue-startproc._interpreterUnresolvedCallSiteTableEntryGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedCallSiteTableEntryGlue):
#else
_interpreterUnresolvedCallSiteTableEntryGlue:
._interpreterUnresolvedCallSiteTableEntryGlue:
#endif
	startproc._interpreterUnresolvedCallSiteTableEntryGlue:
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr	r7, LR						! Get the RA in snippet
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)	! Restore RTOC
#ifdef AIXPPC
	laddr	r8, TOCjitResolveInvokeDynamic(RTOC)			! Load descriptor pointer
	laddr	r8, 0(r8)					! Load the callee address
#elif defined(LINUXPPC64)
	laddr	r8, TOCjitResolveInvokeDynamic@toc(RTOC)			! Load descriptor pointer
#if !defined(__LITTLE_ENDIAN__)
	laddr	r8, 0(r8)					! Load the callee address
#endif
#else
	laddr	r8, jitResolveInvokeDynamic@got(RTOC)			! Load the callee address
#endif
	laddr	r3, 1*ALen+4(r7)				! Load constant pool literal
	lwz	r4, 1*ALen(r7)					! Load cp index for this field
	laddr	r5, 0(r7)					! Load code cache RA
	rlwinm	r4, r4, 0, 5, 31				! Masking off the flag bits
	addi	r5, r5, 1					! Increment for EX search
	mtspr	CTR, r8						! Move callee address to CTR
	bcctrl	BO_ALWAYS, CR0_LT				! Call to resolve: RTOC, r7
	laddr	r6, 0(r7)					! Load code cache RA
	rlwinm  r17, r3, 0, 31, 31				! keep in r17 if r3 last bit is set: <clinit> is being executed
#ifdef TR_HOST_64BIT
	clrrdi r3, r3, 1                                        ! <clinit> clear up the last bit, which must be zero
#else
	rlwinm  r3, r3, 0, 0xfffffffe                           ! <clinit> clear up the last bit, which must be zero
#endif
	cmpi	cr0, 0, r17, in_clinit				! <clinit> is being executed
	bc	BO_IF, CR0_EQ, .L_CallSiteTableEntry_update			! If in <clinit>
	addi	r10, r7, 2*ALen+12				! Calculate lock address
	addi	r9, 0, LOCKED_VALUE
	bl	.__common_lock_check				! Try to lock
	or.	r8, r8, r8					! Result in r8
	bc	BO_IF,CR0_EQ,.L_CallSiteTableEntry_update			! Grab the lock successfully?
	bl	.__spin_for_update				! r10 containing lock address
	b	.L_restore_and_return
.L_CallSiteTableEntry_update:
	lwz	r4, 1*ALen(r7)					! Load cp index
	andis.	r4, r4, 0x8000					! Test the pTOC bit
	lwz	r4, 2*ALen+4(r7)				! Load offset to be merged
#ifdef TR_HOST_64BIT
	extsw	r4, r4
#endif
	bc	BO_IF_NOT, CR0_EQ, .L_pTOC_update		! Is pTOC case?
	lwz	r9, 4(r6)					! Load the second instr
	lwz	r8, 2*ALen+8(r7)				! Load the template instruction
	b	.L_patch_dword_load
	endproc._interpreterUnresolvedCallSiteTableEntryGlue:

#ifdef AIXPPC
._interpreterUnresolvedMethodTypeTableEntryGlue:
	.function ._interpreterUnresolvedMethodTypeTableEntryGlue,startproc._interpreterUnresolvedMethodTypeTableEntryGlue,16,0,(endproc._interpreterUnresolvedMethodTypeTableEntryGlue-startproc._interpreterUnresolvedMethodTypeTableEntryGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedMethodTypeTableEntryGlue):
#else
_interpreterUnresolvedMethodTypeTableEntryGlue:
._interpreterUnresolvedMethodTypeTableEntryGlue:
#endif
	startproc._interpreterUnresolvedMethodTypeTableEntryGlue:
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr	r7, LR						! Get the RA in snippet
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)	! Restore RTOC
#ifdef AIXPPC
	laddr	r8, TOCjitResolveHandleMethod(RTOC)			! Load descriptor pointer
	laddr	r8, 0(r8)					! Load the callee address
#elif defined(LINUXPPC64)
	laddr	r8, TOCjitResolveHandleMethod@toc(RTOC)			! Load descriptor pointer
#if !defined(__LITTLE_ENDIAN__)
	laddr	r8, 0(r8)					! Load the callee address
#endif
#else
	laddr	r8, jitResolveHandleMethod@got(RTOC)			! Load the callee address
#endif
	laddr	r3, 1*ALen+4(r7)				! Load constant pool literal
	lwz	r4, 1*ALen(r7)					! Load cp index for this field
	laddr	r5, 0(r7)					! Load code cache RA
	rlwinm	r4, r4, 0, 5, 31				! Masking off the flag bits
	addi	r5, r5, 1					! Increment for EX search
	mtspr	CTR, r8						! Move callee address to CTR
	bcctrl	BO_ALWAYS, CR0_LT				! Call to resolve: RTOC, r7
	laddr	r6, 0(r7)					! Load code cache RA
	rlwinm  r17, r3, 0, 31, 31				! keep in r17 if r3 last bit is set: <clinit> is being executed
#ifdef TR_HOST_64BIT
	clrrdi r3, r3, 1                                        ! <clinit> clear up the last bit, which must be zero
#else
	rlwinm  r3, r3, 0, 0xfffffffe                           ! <clinit> clear up the last bit, which must be zero
#endif
	cmpi	cr0, 0, r17, in_clinit				! <clinit> is being executed
	bc	BO_IF, CR0_EQ, .L_MethodTypeTableEntry_update			! If in <clinit>
	addi	r10, r7, 2*ALen+12				! Calculate lock address
	addi	r9, 0, LOCKED_VALUE
	bl	.__common_lock_check				! Try to lock
	or.	r8, r8, r8					! Result in r8
	bc	BO_IF,CR0_EQ,.L_MethodTypeTableEntry_update			! Grab the lock successfully?
	bl	.__spin_for_update				! r10 containing lock address
	b	.L_restore_and_return
.L_MethodTypeTableEntry_update:
	lwz	r4, 1*ALen(r7)					! Load cp index
	andis.	r4, r4, 0x8000					! Test the pTOC bit
	lwz	r4, 2*ALen+4(r7)				! Load offset to be merged
#ifdef TR_HOST_64BIT
	extsw	r4, r4
#endif
	bc	BO_IF_NOT, CR0_EQ, .L_pTOC_update		! Is pTOC case?
	lwz	r9, 4(r6)					! Load the second instr
	lwz	r8, 2*ALen+8(r7)				! Load the template instruction
	b	.L_patch_dword_load
	endproc._interpreterUnresolvedMethodTypeTableEntryGlue:

#ifdef AIXPPC
._interpreterUnresolvedStaticDataGlue:
	.function ._interpreterUnresolvedStaticDataGlue,startproc._interpreterUnresolvedStaticDataGlue,16,0,(endproc._interpreterUnresolvedStaticDataGlue-startproc._interpreterUnresolvedStaticDataGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedStaticDataGlue):
#else
_interpreterUnresolvedStaticDataGlue:
._interpreterUnresolvedStaticDataGlue:
#endif
	startproc._interpreterUnresolvedStaticDataGlue:
!     Expected code patterns to be patched
!
!1) Atomic read
!     bl  snippet
!     load   anyreg, 0(gr11)
!
!
!2) Non-atomic load long
!     bl snippet
!     addi   r3, r3, 0
!     bl     jitVolatileReadLong
!
!
!3) Non-atomic load double (bit 1 of cp index flags this case)
!      bl snippet
!      lfd   fp0, 0(r3)
!      bl  jitVolatileReadDouble
!
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)	! Restore RTOC
#ifdef AIXPPC
	laddr	r8, TOCjitResolveStaticField(RTOC)		! Load descriptor pointer
	laddr	r8, 0(r8)					! Load the callee address
#elif defined(LINUXPPC64)
	laddr	r8, TOCjitResolveStaticField@toc(RTOC)		! Load descriptor pointer
#if !defined(__LITTLE_ENDIAN__)
	laddr	r8, 0(r8)					! Load the callee address
#endif
#else
	laddr	r8, jitResolveStaticField@got(RTOC)		! Load the callee address
#endif
	li      r27, 1                                          ! is Static=true
	li	r28, 0						! This is a load/loadaddr
	b       .L10.common_code
	endproc._interpreterUnresolvedStaticDataGlue:

#ifdef AIXPPC
.MTUnresolvedInt32Load:
	.function .MTUnresolvedInt32Load,startproc.MTUnresolvedInt32Load,16,0,(endproc.MTUnresolvedInt32Load-startproc.MTUnresolvedInt32Load)
#elif defined(LINUXPPC64)
FUNC_LABEL(MTUnresolvedInt32Load):
#else
MTUnresolvedInt32Load:
.MTUnresolvedInt32Load:
#endif
	startproc.MTUnresolvedInt32Load:
#if defined(TR_HOST_64BIT) && defined(OMR_GC_COMPRESSED_POINTERS) && defined(J9VM_OPT_TENANT)
	#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet

    MT_ResovleStaticField               ! call jitResovleStaticField

    laddr	r6, 0(r7)					! Load code cache RA
    clrrdi r3, r3, 1                    ! <clinit> clear up the last bit, which must be zero

    andi. r4, r3, 0x2                   ! check r3 if r3 is isolated field
    cmpi  cr0, CmpAddr, r4, 2
    bne	cr0, .MTUnresolvedInt32LoadNoneIsolated		! Not isolated, branch to none isolated case

    MT_ComputeStaticFieldAddress(J9TR_VMThread_tenantData32, 2) ! extract address from isolate field index
    lwzx   r3, r3, r5                               ! load result to r3, input r3 has col offset, r5 has row base
    isync
    b .MTUnresolvedInt32LoadRestore
.MTUnresolvedInt32LoadNoneIsolated:
    lwz    r3, 0(r3)                               ! r3 contains load result
    isync
.MTUnresolvedInt32LoadRestore:
    std     r3, 24(J9SP)                    ! store r3 value into r3 slot
    b .L_restore_and_return
#endif
	endproc.MTUnresolvedInt32Load:

#ifdef AIXPPC
.MTUnresolvedInt64Load:
	.function .MTUnresolvedInt64Load,startproc.MTUnresolvedInt64Load,16,0,(endproc.MTUnresolvedInt64Load-startproc.MTUnresolvedInt64Load)
#elif defined(LINUXPPC64)
FUNC_LABEL(MTUnresolvedInt64Load):
#else
MTUnresolvedInt64Load:
.MTUnresolvedInt64Load:
#endif
	startproc.MTUnresolvedInt64Load:
#if defined(TR_HOST_64BIT) && defined(OMR_GC_COMPRESSED_POINTERS) && defined(J9VM_OPT_TENANT)
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet

    MT_ResovleStaticField

    laddr	r6, 0(r7)					! Load code cache RA
    clrrdi r3, r3, 1           ! <clinit> clear up the last bit, which must be zero

    andi. r4, r3, 0x2
    cmpi  cr0, CmpAddr, r4, 2
    bne	cr0, .MTUnresolvedInt64LoadNoneIsolated		! Not isolated, branch to none isolated case

    MT_ComputeStaticFieldAddress(J9TR_VMThread_tenantData64, 3)
    ldx r3, r3, r5                               ! r3 contains load result
    isync
    b .MTUnresolvedInt64LoadRestore
.MTUnresolvedInt64LoadNoneIsolated:
    ld    r3, 0(r3)                               ! r3 contains load result
    isync
.MTUnresolvedInt64LoadRestore:
    std     r3, 24(J9SP)                          ! store r3 value into r3 slot
    b .L_restore_and_return
#endif
	endproc.MTUnresolvedInt64Load:

#ifdef AIXPPC
.MTUnresolvedFloatLoad:
	.function .MTUnresolvedFloatLoad,startproc.MTUnresolvedFloatLoad,16,0,(endproc.MTUnresolvedFloatLoad-startproc.MTUnresolvedFloatLoad)
#elif defined(LINUXPPC64)
FUNC_LABEL(MTUnresolvedFloatLoad):
#else
MTUnresolvedFloatLoad:
.MTUnresolvedFloatLoad:
#endif
	startproc.MTUnresolvedFloatLoad:
#if defined(TR_HOST_64BIT) && defined(OMR_GC_COMPRESSED_POINTERS) && defined(J9VM_OPT_TENANT)
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet

    MT_ResovleStaticField

    laddr	r6, 0(r7)					! Load code cache RA
    clrrdi r3, r3, 1                   ! <clinit> clear up the last bit, which must be zero

    andi. r4, r3, 0x2                               ! check r3 if r3 is isolated field
    cmpi  cr0, CmpAddr, r4, 2
    bne	cr0, .MTUnresolvedFloatLoadNoneIsolated		! Not isolated, branch to none isolated case

    MT_ComputeStaticFieldAddress(J9TR_VMThread_tenantData32, 2)
    lfsx fp0, r3, r5                               ! r3 contains load result
    isync
    b .MTUnresolvedFloatLoadRestore
.MTUnresolvedFloatLoadNoneIsolated:
    lfs    fp0, 0(r3)                               ! r3 contains load result
    isync
.MTUnresolvedFloatLoadRestore:

    b .L_restore_and_return
#endif
	endproc.MTUnresolvedFloatLoad:

#ifdef AIXPPC
.MTUnresolvedDoubleLoad:
	.function .MTUnresolvedDoubleLoad,startproc.MTUnresolvedDoubleLoad,16,0,(endproc.MTUnresolvedDoubleLoad-startproc.MTUnresolvedDoubleLoad)
#elif defined(LINUXPPC64)
FUNC_LABEL(MTUnresolvedDoubleLoad):
#else
MTUnresolvedDoubleLoad:
.MTUnresolvedDoubleLoad:
#endif
	startproc.MTUnresolvedDoubleLoad:
#if defined(TR_HOST_64BIT) && defined(OMR_GC_COMPRESSED_POINTERS) && defined(J9VM_OPT_TENANT)
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet

    MT_ResovleStaticField

    laddr	r6, 0(r7)					! Load code cache RA
    clrrdi r3, r3, 1                ! <clinit> clear up the last bit, which must be zero

    andi. r4, r3, 0x2               ! check r3 if r3 is isolated field
    cmpi  cr0, CmpAddr, r4, 2
    bne	cr0, .MTUnresolvedDoubleLoadNoneIsolated		! Not isolated, branch to none isolated case

    MT_ComputeStaticFieldAddress(J9TR_VMThread_tenantData64, 3)
    lfdx fp0, r3, r5                               ! r3 contains load result
    isync
    b .MTUnresolvedDoubleLoadRestore
.MTUnresolvedDoubleLoadNoneIsolated:
    lfd    fp0, 0(r3)                               ! r3 contains load result
    isync
.MTUnresolvedDoubleLoadRestore:
    b .L_restore_and_return
#endif
	endproc.MTUnresolvedDoubleLoad:

#ifdef AIXPPC
.MTUnresolvedAddressLoad:
	.function .MTUnresolvedAddressLoad,startproc.MTUnresolvedAddressLoad,16,0,(endproc.MTUnresolvedAddressLoad-startproc.MTUnresolvedAddressLoad)
#elif defined(LINUXPPC64)
FUNC_LABEL(MTUnresolvedAddressLoad):
#else
MTUnresolvedAddressLoad:
.MTUnresolvedAddressLoad:
#endif
	startproc.MTUnresolvedAddressLoad:
#if defined(TR_HOST_64BIT) && defined(OMR_GC_COMPRESSED_POINTERS) && defined(J9VM_OPT_TENANT)
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet

    MT_ResovleStaticField

    laddr	r6, 0(r7)					! Load code cache RA
    clrrdi r3, r3, 1          ! <clinit> clear up the last bit, which must be zero

    andi. r4, r3, 0x2                   ! check r3 if r3 is isolated field
    cmpi  cr0, CmpAddr, r4, 2
    bne	cr0, .MTUnresolvedObjLoadNoneIsolated		! Not isolated, branch to none isolated case

    MT_ComputeStaticFieldAddress(J9TR_VMThread_tenantDataObj, 2)
    lwzx r3, r3, r5                               ! r3 contains load result
    isync
    lwz    r4, 20(r7)                              ! get compressed shift size
    sld    r3, r3, r4                              ! decompress pointer
    b .MTUnresolvedObjLoadRestore
.MTUnresolvedObjLoadNoneIsolated:
    ld    r3, 0(r3)                               ! r3 contains load result
    isync
.MTUnresolvedObjLoadRestore:
    std     r3, 24(J9SP)                    ! store r3 value into r3 slot
    b .L_restore_and_return
#endif
	endproc.MTUnresolvedAddressLoad:

#ifdef AIXPPC
.MTUnresolvedInt32Store:
	.function .MTUnresolvedInt32Store,startproc.MTUnresolvedInt32Store,16,0,(endproc.MTUnresolvedInt32Store-startproc.MTUnresolvedInt32Store)
#elif defined(LINUXPPC64)
FUNC_LABEL(MTUnresolvedInt32Store):
#else
MTUnresolvedInt32Store:
.MTUnresolvedInt32Store:
#endif
	startproc.MTUnresolvedInt32Store:
#if defined(TR_HOST_64BIT) && defined(OMR_GC_COMPRESSED_POINTERS) && defined(J9VM_OPT_TENANT)
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet

    MT_ResovleStaticFieldSetter         ! call jitResovleStaticFieldSetter

    laddr	r6, 0(r7)					! Load code cache RA
    clrrdi r3, r3, 1                    ! <clinit> clear up the last bit, which must be zero
    ld r29, 24(J9SP)                    ! load store value into r29

    andi. r4, r3, 0x2                   ! check r3 if r3 is isolated field
    cmpi  cr0, CmpAddr, r4, 2
    bne	cr0, .MTUnresolvedInt32StoreNoneIsolated		! Not isolated, branch to none isolated case

    MT_ComputeStaticFieldAddress(J9TR_VMThread_tenantData32, 2)
    lwsync
    stwx   r29, r3, r5                               ! r29 contains store value
    sync
    b .MTUnresolvedInt32StoreRestore
.MTUnresolvedInt32StoreNoneIsolated:
    lwsync
    stw    r29, 0(r3)                               ! r29 contains store value
    sync
.MTUnresolvedInt32StoreRestore:
    b .L_restore_and_return
#endif
	endproc.MTUnresolvedInt32Store:

#ifdef AIXPPC
.MTUnresolvedInt64Store:
	.function .MTUnresolvedInt64Store,startproc.MTUnresolvedInt64Store,16,0,(endproc.MTUnresolvedInt64Store-startproc.MTUnresolvedInt64Store)
#elif defined(LINUXPPC64)
FUNC_LABEL(MTUnresolvedInt64Store):
#else
MTUnresolvedInt64Store:
.MTUnresolvedInt64Store:
#endif
	startproc.MTUnresolvedInt64Store:
#if defined(TR_HOST_64BIT) && defined(OMR_GC_COMPRESSED_POINTERS) && defined(J9VM_OPT_TENANT)
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet

    MT_ResovleStaticFieldSetter

    laddr	r6, 0(r7)					! Load code cache RA
    clrrdi r3, r3, 1                   ! <clinit> clear up the last bit, which must be zero
    ld r29, 24(J9SP)                   ! load store value into r29

    andi. r4, r3, 0x2                           ! check r3 if r3 is isolated field
    cmpi  cr0, CmpAddr, r4, 2
    bne	cr0, .MTUnresolvedInt64StoreNoneIsolated		! Not isolated, branch to none isolated case

    MT_ComputeStaticFieldAddress(J9TR_VMThread_tenantData64, 3)
    lwsync
    stdx   r29, r3, r5                               ! r29 contains store value
    sync
    b .MTUnresolvedInt64StoreRestore
.MTUnresolvedInt64StoreNoneIsolated:
    lwsync
    std    r29, 0(r3)                               ! r29 contains store value
    sync
.MTUnresolvedInt64StoreRestore:
    b .L_restore_and_return
#endif
	endproc.MTUnresolvedInt64Store:

#ifdef AIXPPC
.MTUnresolvedFloatStore:
	.function .MTUnresolvedFloatStore,startproc.MTUnresolvedFloatStore,16,0,(endproc.MTUnresolvedFloatStore-startproc.MTUnresolvedFloatStore)
#elif defined(LINUXPPC64)
FUNC_LABEL(MTUnresolvedFloatStore):
#else
MTUnresolvedFloatStore:
.MTUnresolvedFloatStore:
#endif
	startproc.MTUnresolvedFloatStore:
#if defined(TR_HOST_64BIT) && defined(OMR_GC_COMPRESSED_POINTERS) && defined(J9VM_OPT_TENANT)
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet

    MT_ResovleStaticFieldSetter

    laddr	r6, 0(r7)					! Load code cache RA
    clrrdi r3, r3, 1                    ! <clinit> clear up the last bit, which must be zero

    ! check r3 if r3 is isolated field
    andi. r4, r3, 0x2
    cmpi  cr0, CmpAddr, r4, 2
    bne	cr0, .MTUnresolvedFloatStoreNoneIsolated		! Not isolated, branch to none isolated case

    MT_ComputeStaticFieldAddress(J9TR_VMThread_tenantData32, 2)
    lwsync
    stfsx   fp0, r3, r5                               ! fp0 contains store value
    sync
    b .MTUnresolvedFloatStoreRestore
.MTUnresolvedFloatStoreNoneIsolated:
    lwsync
    stfs   fp0, 0(r3)                               ! fp0 contains store value
    sync
.MTUnresolvedFloatStoreRestore:
    b .L_restore_and_return
#endif
	endproc.MTUnresolvedFloatStore:

#ifdef AIXPPC
.MTUnresolvedDoubleStore:
	.function .MTUnresolvedDoubleStore,startproc.MTUnresolvedDoubleStore,16,0,(endproc.MTUnresolvedDoubleStore-startproc.MTUnresolvedDoubleStore)
#elif defined(LINUXPPC64)
FUNC_LABEL(MTUnresolvedDoubleStore):
#else
MTUnresolvedDoubleStore:
.MTUnresolvedDoubleStore:
#endif
	startproc.MTUnresolvedDoubleStore:
#if defined(TR_HOST_64BIT) && defined(OMR_GC_COMPRESSED_POINTERS) && defined(J9VM_OPT_TENANT)
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet

    MT_ResovleStaticFieldSetter

    laddr	r6, 0(r7)					! Load code cache RA
    clrrdi r3, r3, 1                    ! <clinit> clear up the last bit, which must be zero

    andi. r4, r3, 0x2
    cmpi  cr0, CmpAddr, r4, 2
    bne	cr0, .MTUnresolvedDoubleStoreNoneIsolated		! Not isolated, branch to none isolated case

    MT_ComputeStaticFieldAddress(J9TR_VMThread_tenantData64, 3)
    lwsync
    stfdx   fp0, r3, r5                               ! fp0 contains store value
    sync
    b .MTUnresolvedDoubleStoreRestore
.MTUnresolvedDoubleStoreNoneIsolated:
    lwsync
    stfd   fp0, 0(r3)                               ! fp0 contains store value
    sync
.MTUnresolvedDoubleStoreRestore:
    b .L_restore_and_return
#endif
	endproc.MTUnresolvedDoubleStore:

#ifdef AIXPPC
.MTUnresolvedAddressStore:
	.function .MTUnresolvedAddressStore,startproc.MTUnresolvedAddressStore,16,0,(endproc.MTUnresolvedAddressStore-startproc.MTUnresolvedAddressStore)
#elif defined(LINUXPPC64)
FUNC_LABEL(MTUnresolvedAddressStore):
#else
MTUnresolvedAddressStore:
.MTUnresolvedAddressStore:
#endif
	startproc.MTUnresolvedAddressStore:
#if defined(TR_HOST_64BIT) && defined(OMR_GC_COMPRESSED_POINTERS) && defined(J9VM_OPT_TENANT)
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet

	MT_ResovleStaticFieldSetter

    laddr	r6, 0(r7)					! Load code cache RA
    clrrdi r3, r3, 1                    ! <clinit> clear up the last bit, which must be zero
    ld r29, 24(J9SP)                ! load store value into r29

    andi. r4, r3, 0x2               ! check r3 if r3 is isolated field
    cmpi  cr0, CmpAddr, r4, 2
    bne	cr0, .MTUnresolvedObjStoreNoneIsolated		! Not isolated, branch to none isolated case

    MT_ComputeStaticFieldAddress(J9TR_VMThread_tenantDataObj, 2)
    ! compress store value
    lwz    r4, 20(r7)                              ! get compressed shift size
    srd    r29, r29, r4                              ! compress pointer

    lwsync
    stwx   r29, r3, r5                               ! r29 contains store value
    sync
    std r5, 32(J9SP)                            ! update owning object, overwrite r4 slot
    b .MTUnresolvedObjStoreRestore
.MTUnresolvedObjStoreNoneIsolated:
    lwsync
    std    r29, 0(r3)                               ! r29 contains store value, in ramstatic its not compressed
    sync
.MTUnresolvedObjStoreRestore:
    b .L_restore_and_return
#endif
	endproc.MTUnresolvedAddressStore:

#ifdef AIXPPC
._interpreterUnresolvedStaticDataStoreGlue:
	.function ._interpreterUnresolvedStaticDataStoreGlue,startproc._interpreterUnresolvedStaticDataStoreGlue,16,0,(endproc._interpreterUnresolvedStaticDataStoreGlue-startproc._interpreterUnresolvedStaticDataStoreGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedStaticDataStoreGlue):
#else
_interpreterUnresolvedStaticDataStoreGlue:
._interpreterUnresolvedStaticDataStoreGlue:
#endif
	startproc._interpreterUnresolvedStaticDataStoreGlue:
!     Expected code patterns to be patched
!
!1) Atomic store
!     bl      snippet
!     store  anyreg, 0(gr11)
!
!
!2) Non-atomic store long
!     bl     snippet
!     addi   r3, r3, 0
!     bl     jitVolatileWriteLong
!
!
!3) Non-atomic store double (bit 1 of cp index flags this case)
!      bl     snippet
!      stfd   fp0, 0(r3)
!      bl     jitVolatileWriteDouble
!
#include "p/runtime/SaveGPRs.inc"
	mfcr    r0
	stw     r0,-4(J9SP)					! Save CR also
	addi    J9SP,J9SP,-(33*ALen)
	mfspr   r7, LR						! Get the RA in snippet
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)	! Restore RTOC
#ifdef AIXPPC
	laddr	r8, TOCjitResolveStaticFieldSetter(RTOC)	! Load descriptor pointer
	laddr	r8, 0(r8)					! Load the callee address
#elif defined(LINUXPPC64)
	laddr	r8, TOCjitResolveStaticFieldSetter@toc(RTOC)	! Load descriptor pointer
#if !defined(__LITTLE_ENDIAN__)
	laddr	r8, 0(r8)					! Load the callee address
#endif
#else
	laddr	r8, jitResolveStaticFieldSetter@got(RTOC)	! Load the callee address
#endif
	li      r27, 1						! This is a static
	li	r28, 1						! This is a store
	b       .L10.common_code
	endproc._interpreterUnresolvedStaticDataStoreGlue:

#ifdef AIXPPC
! This helper expects the code cache RA to be pointed to by LR
._nativeStaticHelperForUnresolvedGlue:
	.function ._nativeStaticHelperForUnresolvedGlue,startproc._nativeStaticHelperForUnresolvedGlue,16,0,(endproc._nativeStaticHelperForUnresolvedGlue-startproc._nativeStaticHelperForUnresolvedGlue)
	startproc._nativeStaticHelperForUnresolvedGlue:
	mfspr	r11, LR						! Preserve snippet RA
#elif defined(LINUXPPC64)
FUNC_LABEL(_nativeStaticHelperForUnresolvedGlue):
	startproc._nativeStaticHelperForUnresolvedGlue:
	mfspr	r11, LR						! Preserve snippet RA
#else
_nativeStaticHelperForUnresolvedGlue:
	mfspr   r11, LR						! Preserve snippet RA
#endif
	laddr	r4, 0(r11)					! Load code cache RA
	b	._nativeStaticHelper.common
	endproc._nativeStaticHelperForUnresolvedGlue:

#ifdef AIXPPC
! This helper expects the code cache RA to be LR
! The common portion expects the code cache RA to be in r4
._nativeStaticHelper:
	.function ._nativeStaticHelper,startproc._nativeStaticHelper,16,0,(endproc._nativeStaticHelper-startproc._nativeStaticHelper)
	startproc._nativeStaticHelper:
	mfspr	r11, LR						! Preserve snippet RA
	mr	r4, r11						! Load code cache RA
._nativeStaticHelper.common:
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)	! Restore RTOC
	laddr	r5, TOCicallVMprJavaSendNativeStatic(RTOC)
	laddr	r0, 0(r5)					! Load the callee address
#elif defined(LINUXPPC64)
FUNC_LABEL(_nativeStaticHelper):
	startproc._nativeStaticHelper:
	mfspr	r11, LR						! Preserve snippet RA
	mr      r4, r11
._nativeStaticHelper.common:
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)	! Restore RTOC
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCicallVMprJavaSendNativeStatic@toc(RTOC)
#else
	laddr	r5, TOCicallVMprJavaSendNativeStatic@toc(RTOC)
	laddr	r0, 0(r5)					! Load the callee address
#endif
#else
_nativeStaticHelper:
	mfspr   r11, LR						! Preserve snippet RA
	mr      r4, r11
._nativeStaticHelper.common:
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)	! Restore RTOC
	laddr	r0, icallVMprJavaSendNativeStatic@got(RTOC)	! Load the callee address
#endif
	laddr	r3, 1*ALen(r11)					! Load the method pointer
	mtspr   LR, r4						! Set up to return
	mtspr   CTR, r0						! Set up to call
	bcctr   BO_ALWAYS, CR0_LT				! Dispatch
	endproc._nativeStaticHelper:

#ifdef AIXPPC
._interpreterVoidStaticGlue:
	.function ._interpreterVoidStaticGlue,startproc._interpreterVoidStaticGlue,16,0,(endproc._interpreterVoidStaticGlue-startproc._interpreterVoidStaticGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterVoidStaticGlue):
#else
_interpreterVoidStaticGlue:
._interpreterVoidStaticGlue:
#endif
	startproc._interpreterVoidStaticGlue:
	mfspr   r11, LR						! Preserve snippet RA
	bl      .L.StaticGlueCallFixer				! Call to fix code cache
								! RTOC, r3 and r4 set up
	mtspr   LR, r4						! Set up to return
#ifdef AIXPPC
	laddr	r5, TOCicallVMprJavaSendStatic0(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCicallVMprJavaSendStatic0@toc(RTOC)
#else
	laddr	r5, TOCicallVMprJavaSendStatic0@toc(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#endif
#else
	laddr	r0, icallVMprJavaSendStatic0@got(RTOC)		! Load the callee address
#endif
	mtspr   CTR, r0						! Set up to call
	bcctr   BO_ALWAYS, CR0_LT				! Dispatch
	endproc._interpreterVoidStaticGlue:

#ifdef AIXPPC
._interpreterSyncVoidStaticGlue:
	.function ._interpreterSyncVoidStaticGlue,startproc._interpreterSyncVoidStaticGlue,16,0,(endproc._interpreterSyncVoidStaticGlue-startproc._interpreterSyncVoidStaticGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterSyncVoidStaticGlue):
#else
_interpreterSyncVoidStaticGlue:
._interpreterSyncVoidStaticGlue:
#endif
	startproc._interpreterSyncVoidStaticGlue:
	mfspr   r11, LR						! Preserve snippet RA
	bl      .L.StaticGlueCallFixer				! Call to fix code cache
								! RTOC, r3, and r4 set up
	mtspr   LR, r4						! Set up to return
#ifdef AIXPPC
	laddr	r5, TOCicallVMprJavaSendStaticSync0(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCicallVMprJavaSendStaticSync0@toc(RTOC)
#else
	laddr	r5, TOCicallVMprJavaSendStaticSync0@toc(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#endif
#else
	laddr	r0, icallVMprJavaSendStaticSync0@got(RTOC)	! Load the callee address
#endif
	mtspr   CTR, r0						! Set up to call
	bcctr   BO_ALWAYS, CR0_LT				! Dispatch
	endproc._interpreterSyncVoidStaticGlue:

#ifdef AIXPPC
._interpreterGPR3StaticGlue:
	.function ._interpreterGPR3StaticGlue,startproc._interpreterGPR3StaticGlue,16,0,(endproc._interpreterGPR3StaticGlue-startproc._interpreterGPR3StaticGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterGPR3StaticGlue):
#else
_interpreterGPR3StaticGlue:
._interpreterGPR3StaticGlue:
#endif
	startproc._interpreterGPR3StaticGlue:
	mfspr   r11, LR						! Preserve snippet RA
	bl      .L.StaticGlueCallFixer				! Call to fix code cache
								! RTOC, r3, and r4 set up
	mtspr   LR, r4						! Set up to return
#ifdef AIXPPC
	laddr	r5, TOCicallVMprJavaSendStatic1(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCicallVMprJavaSendStatic1@toc(RTOC)
#else
	laddr	r5, TOCicallVMprJavaSendStatic1@toc(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#endif
#else
	laddr  r0, icallVMprJavaSendStatic1@got(RTOC)		! Load the callee address
#endif
	mtspr   CTR, r0						! Set up to call
	bcctr   BO_ALWAYS, CR0_LT				! Dispatch
	endproc._interpreterGPR3StaticGlue:

#ifdef AIXPPC
._interpreterSyncGPR3StaticGlue:
	.function ._interpreterSyncGPR3StaticGlue,startproc._interpreterSyncGPR3StaticGlue,16,0,(endproc._interpreterSyncGPR3StaticGlue-startproc._interpreterSyncGPR3StaticGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterSyncGPR3StaticGlue):
#else
_interpreterSyncGPR3StaticGlue:
._interpreterSyncGPR3StaticGlue:
#endif
	startproc._interpreterSyncGPR3StaticGlue:
	mfspr   r11, LR						! Preserve snippet RA
	bl      .L.StaticGlueCallFixer				! Call to fix code cache
								! RTOC, r3, and r4 set up
	mtspr   LR, r4						! Set up to return
#ifdef AIXPPC
	laddr	r5, TOCicallVMprJavaSendStaticSync1(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCicallVMprJavaSendStaticSync1@toc(RTOC)
#else
	laddr	r5, TOCicallVMprJavaSendStaticSync1@toc(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#endif
#else
	laddr	r0, icallVMprJavaSendStaticSync1@got(RTOC)	! Load the callee address
#endif
	mtspr   CTR, r0						! Set up to call
	bcctr   BO_ALWAYS, CR0_LT				! Dispatch
	endproc._interpreterSyncGPR3StaticGlue:

#ifdef AIXPPC
._interpreterGPR3GPR4StaticGlue:
	.function ._interpreterGPR3GPR4StaticGlue,startproc._interpreterGPR3GPR4StaticGlue,16,0,(endproc._interpreterGPR3GPR4StaticGlue-startproc._interpreterGPR3GPR4StaticGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterGPR3GPR4StaticGlue):
#else
_interpreterGPR3GPR4StaticGlue:
._interpreterGPR3GPR4StaticGlue:
#endif
	startproc._interpreterGPR3GPR4StaticGlue:
	mfspr   r11, LR						! Preserve snippet RA
	bl      .L.StaticGlueCallFixer				! Call to fix code cache
								! RTOC, r3, and r4 set up
	mtspr   LR, r4						! Set up to return
#ifdef AIXPPC
	laddr	r5, TOCicallVMprJavaSendStaticJ(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCicallVMprJavaSendStaticJ@toc(RTOC)
#else
	laddr	r5, TOCicallVMprJavaSendStaticJ@toc(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#endif
#else
	laddr	r0, icallVMprJavaSendStaticJ@got(RTOC)		! Load the callee address
#endif
	mtspr   CTR, r0						! Set up to call
	bcctr   BO_ALWAYS, CR0_LT				! Dispatch
	endproc._interpreterGPR3GPR4StaticGlue:

#ifdef AIXPPC
._interpreterSyncGPR3GPR4StaticGlue:
	.function ._interpreterSyncGPR3GPR4StaticGlue,startproc._interpreterSyncGPR3GPR4StaticGlue,16,0,(endproc._interpreterSyncGPR3GPR4StaticGlue-startproc._interpreterSyncGPR3GPR4StaticGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterSyncGPR3GPR4StaticGlue):
#else
_interpreterSyncGPR3GPR4StaticGlue:
._interpreterSyncGPR3GPR4StaticGlue:
#endif
	startproc._interpreterSyncGPR3GPR4StaticGlue:
	mfspr   r11, LR						! Preserve snippet RA
	bl      .L.StaticGlueCallFixer				! Call to fix code cache
								! RTOC, r3, and r4 set up
	mtspr   LR, r4						! Set up to return
#ifdef AIXPPC
	laddr	r5, TOCicallVMprJavaSendStaticSyncJ(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCicallVMprJavaSendStaticSyncJ@toc(RTOC)
#else
	laddr	r5, TOCicallVMprJavaSendStaticSyncJ@toc(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#endif
#else
	laddr	r0, icallVMprJavaSendStaticSyncJ@got(RTOC)	! Load the callee address
#endif
	mtspr   CTR, r0						! Set up to call
	bcctr   BO_ALWAYS, CR0_LT				! Dispatch
	endproc._interpreterSyncGPR3GPR4StaticGlue:

#ifdef AIXPPC
._interpreterFPR0FStaticGlue:
	.function ._interpreterFPR0FStaticGlue,startproc._interpreterFPR0FStaticGlue,16,0,(endproc._interpreterFPR0FStaticGlue-startproc._interpreterFPR0FStaticGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterFPR0FStaticGlue):
#else
_interpreterFPR0FStaticGlue:
._interpreterFPR0FStaticGlue:
#endif
	startproc._interpreterFPR0FStaticGlue:
	mfspr   r11, LR						! Preserve snippet RA
	bl      .L.StaticGlueCallFixer				! Call to fix code cache
								! RTOC, r3, and r4 set up
	mtspr   LR, r4						! Set up to return
#ifdef AIXPPC
	laddr	r5, TOCicallVMprJavaSendStaticF(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCicallVMprJavaSendStaticF@toc(RTOC)
#else
	laddr	r5, TOCicallVMprJavaSendStaticF@toc(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#endif
#else
	laddr	r0, icallVMprJavaSendStaticF@got(RTOC)		! Load the callee address
#endif
	mtspr   CTR, r0						! Set up to call
	bcctr   BO_ALWAYS, CR0_LT				! Dispatch
	endproc._interpreterFPR0FStaticGlue:

#ifdef AIXPPC
._interpreterSyncFPR0FStaticGlue:
	.function ._interpreterSyncFPR0FStaticGlue,startproc._interpreterSyncFPR0FStaticGlue,16,0,(endproc._interpreterSyncFPR0FStaticGlue-startproc._interpreterSyncFPR0FStaticGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterSyncFPR0FStaticGlue):
#else
_interpreterSyncFPR0FStaticGlue:
._interpreterSyncFPR0FStaticGlue:
#endif
	startproc._interpreterSyncFPR0FStaticGlue:
	mfspr   r11, LR						! Preserve snippet RA
	bl      .L.StaticGlueCallFixer				! Call to fix code cache
								! RTOC, r3, and r4 set up
	mtspr   LR, r4						! Set up to return
#ifdef AIXPPC
	laddr	r5, TOCicallVMprJavaSendStaticSyncF(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCicallVMprJavaSendStaticSyncF@toc(RTOC)
#else
	laddr	r5, TOCicallVMprJavaSendStaticSyncF@toc(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#endif
#else
	laddr	r0, icallVMprJavaSendStaticSyncF@got(RTOC)	! Load the callee address
#endif
	mtspr   CTR, r0						! Set up to call
	bcctr   BO_ALWAYS, CR0_LT				! Dispatch
	endproc._interpreterSyncFPR0FStaticGlue:

#ifdef AIXPPC
._interpreterFPR0DStaticGlue:
	.function ._interpreterFPR0DStaticGlue,startproc._interpreterFPR0DStaticGlue,16,0,(endproc._interpreterFPR0DStaticGlue-startproc._interpreterFPR0DStaticGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterFPR0DStaticGlue):
#else
_interpreterFPR0DStaticGlue:
._interpreterFPR0DStaticGlue:
#endif
	startproc._interpreterFPR0DStaticGlue:
	mfspr   r11, LR						! Preserve snippet RA
	bl      .L.StaticGlueCallFixer				! Call to fix code cache
								! RTOC, r3, and r4 set up
	mtspr   LR, r4						! Set up to return
#ifdef AIXPPC
	laddr	r5, TOCicallVMprJavaSendStaticD(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCicallVMprJavaSendStaticD@toc(RTOC)
#else
	laddr	r5, TOCicallVMprJavaSendStaticD@toc(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#endif
#else
	laddr	r0, icallVMprJavaSendStaticD@got(RTOC)		! Load the callee address
#endif
	mtspr   CTR, r0						! Set up to call
	bcctr   BO_ALWAYS, CR0_LT				! Dispatch
	endproc._interpreterFPR0DStaticGlue:

#ifdef AIXPPC
._interpreterSyncFPR0DStaticGlue:
	.function ._interpreterSyncFPR0DStaticGlue,startproc._interpreterSyncFPR0DStaticGlue,16,0,(endproc._interpreterSyncFPR0DStaticGlue-startproc._interpreterSyncFPR0DStaticGlue)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterSyncFPR0DStaticGlue):
#else
_interpreterSyncFPR0DStaticGlue:
._interpreterSyncFPR0DStaticGlue:
#endif
	startproc._interpreterSyncFPR0DStaticGlue:
	mfspr   r11, LR						! Preserve snippet RA
	bl      .L.StaticGlueCallFixer				! Call to fix code cache
								! RTOC, r3, and r4 set up
	mtspr   LR, r4						! Set up to return
#ifdef AIXPPC
	laddr	r5, TOCicallVMprJavaSendStaticSyncD(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCicallVMprJavaSendStaticSyncD@toc(RTOC)
#else
	laddr	r5, TOCicallVMprJavaSendStaticSyncD@toc(RTOC)
	laddr	r0, 0(r5)					! Load the helper addr
#endif
#else
	laddr	r0, icallVMprJavaSendStaticSyncD@got(RTOC)	! Load the callee address
#endif
	mtspr   CTR, r0						! Set up to call
	bcctr   BO_ALWAYS, CR0_LT				! Dispatch

.L.StaticGlueCallFixer:
      laddr   r3, 1*ALen(r11)                                 ! Load method pointer
      laddr   r4, 0(r11)                                      ! Load code cache RA
      laddr   r0, J9TR_MethodPCStartOffset(r3)                ! Load filed containing startPC
      laddr   RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)      ! Restore TOC
      andi.   r0, r0, J9TR_MethodNotCompiledBit
      bclr    BO_IF_NOT, CR0_EQ                               ! Return to call interpreter
      addi    r10, r11, 2*ALen                                ! Lock address for compilation
      addi    r9, 0, LOCKED_VALUE
      bl      .__common_lock_check                            ! Try to lock
      or.     r8, r8, r8                                      ! Grab the lock successfully?
      laddr   r10, J9TR_MethodPCStartOffset(r3)
      bc      BO_IF_NOT, CR0_EQ, .L.exec_jitted_code
      staddr  r3, -4*ALen(J9SP)                               ! Replaced staddru r3, -4*ALen(J9SP) for P6 perf
      addi    J9SP, J9SP, -4*ALen                             !	Performs update of replaced staddru
#if defined(AIXPPC)
      laddr   r5, TOCjitCallCFunction(RTOC)
      laddr   r3, TOCmcc_callPointPatching_unwrapper(RTOC)
      laddr   r5, 0(r5)
#elif defined(LINUXPPC64)
      laddr   r5, TOCjitCallCFunction@toc(RTOC)
      laddr   r3, TOCmcc_callPointPatching_unwrapper@toc(RTOC)
#if !defined(__LITTLE_ENDIAN__)
      laddr   r5, 0(r5)
#endif
#else
      laddr   r5, jitCallCFunction@got(RTOC)
      laddr   r3, mcc_callPointPatching_unwrapper@got(RTOC)
#endif
      addi    r6, r4, -4
      staddr  r10, 2*ALen(J9SP)
      staddr  r6, ALen(J9SP)
      li      r6, 0
      staddr  r6, 3*ALen(J9SP)
      mtctr   r5
      mr      r4, J9SP
      mr      r5, J9SP
      bctrl
      laddr   r4, 0(r11)
      addi    J9SP, J9SP, 4*ALen
.L.exec_jitted_code:
      mtspr   LR, r4                                                  ! Jitted code expects this RA
      mtspr   CTR, r10                                                ! Set up CTR to jump
      bcctr   BO_ALWAYS, CR0_LT                                       ! Jump to the jitted code
	endproc._interpreterSyncFPR0DStaticGlue:

#ifdef AIXPPC
._interpreterUnresolvedStaticGlue:
	.function ._interpreterUnresolvedStaticGlue,startproc._interpreterUnresolvedStaticGlue,16,0,(endproc._interpreterUnresolvedStaticGlue-startproc._interpreterUnresolvedStaticGlue)
	startproc._interpreterUnresolvedStaticGlue:
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
	laddr	r6, TOCjitResolveStaticMethod(RTOC)
	laddr	r0, 0(r6)						! Load the callee address
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedStaticGlue):
	startproc._interpreterUnresolvedStaticGlue:
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCjitResolveStaticMethod@toc(RTOC)
#else
	laddr	r6, TOCjitResolveStaticMethod@toc(RTOC)
	laddr	r0, 0(r6)						! Load the callee address
#endif
#else
_interpreterUnresolvedStaticGlue:
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
	laddr	r0, jitResolveStaticMethod@got(RTOC)			! Load the callee address
#endif
	mfspr   r7, LR							! Preserve the snippet RA
	laddr	r3, 0(r7)						! Load code cache RA
	laddr	r4, 2*ALen+8(r7)					! Load constant pool literal
	lwz	r5, 2*ALen+4(r7)					! Load cp index
	mtspr   CTR, r0							! Move callee address to CTR
	rlwinm  r6, r5, 8, 0x000000ff					! Table offset in r6
	rlwinm  r5, r5, 0, 0x007fffff					! Mask off the offset
	bcctrl  BO_ALWAYS, CR0_LT					! Call to resolve: r3-5 can
	andi.   r11, r3, in_clinit                                      ! Extract clinit tag from j9method returned
	bc      BO_IF, CR0_EQ, .L22.common_code    						! If clinit is set then make call the method without patching
#ifdef TR_HOST_64BIT
	clrrdi r3, r3, 1                                                ! <clinit> clear up the last bit, which must be zero
#else
	rlwinm  r3, r3, 0, 0xfffffffe                                   ! <clinit> clear up the last bit, which must be zero
#endif
	laddr	r4, 0(r7)												! Load RA
	mtspr   LR, r4                                                  ! Load RA into LR
	laddr   r10, J9TR_MethodPCStartOffset(r3)                        ! Grab the J9Method extra/StartPC
	andi.   r0, r10, J9TR_MethodNotCompiledBit                       ! Check if the method is jit compiled
	bc      BO_IF_NOT, CR0_EQ, .L.IntCall    						! Call Interpreter if method is not jit compiled yet
	mtspr   CTR, r10                                                ! Set up CTR to jump to jitted method
	bcctr BO_ALWAYS, CR0_LT 										! Jump to the jitted code
.L.IntCall:
#ifdef AIXPPC
	laddr   r11, TOCj2iTransition(RTOC)							! Load The j2iTransition Helper Addr
	laddr 	r0, 0(r11)
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr 	r0, TOCj2iTransition@toc(RTOC)
#else
	laddr 	r11, TOCj2iTransition@toc(RTOC)
	laddr 	r0, 0(r11)
#endif
#else
	laddr 	r0, j2iTransition@got(RTOC)
#endif
	mtspr 	CTR, r0  											! Set up to call
	bcctr BO_ALWAYS, CR0_LT 									! Dispatch 
.L22.common_code:							!   be modified, r3 is result.
#ifdef TR_HOST_64BIT
        clrrdi r3, r3, 1                                                ! <clinit> clear up the last bit, which must be zero
#else
        rlwinm  r3, r3, 0, 0xfffffffe                                   ! <clinit> clear up the last bit, which must be zero
#endif
	or      r5, r3, r3						! Preserve r3
#ifdef AIXPPC
	laddr	r11, TOCjitMethodIsNative(RTOC)
	laddr	r0, 0(r11)						! Addr of jitMethodIsNative
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCjitMethodIsNative@toc(RTOC)
#else
	laddr	r11, TOCjitMethodIsNative@toc(RTOC)
	laddr	r0, 0(r11)						! Addr of jitMethodIsNative
#endif
#else
	laddr	r0, jitMethodIsNative@got(RTOC)				! Load the callee address
#endif
	mtspr	CTR, r0
	bcctrl	BO_ALWAYS, CR0_LT					! Call to test Native
	or.	r3, r3, r3						! r3==0 --> not Native
	bc	BO_IF, CR0_EQ, .L.not_Native
#ifdef AIXPPC
	laddr	r11, TOC_nativeStaticHelperForUnresolvedGlue(RTOC)
	laddr	r4, 0(r11)						! Helper code in r4
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r4, TOC_nativeStaticHelperForUnresolvedGlue@toc(RTOC)
#else
	laddr	r11, TOC_nativeStaticHelperForUnresolvedGlue@toc(RTOC)
	laddr	r4, 0(r11)						! Helper code in r4
#endif
#else
	laddr	r4, _nativeStaticHelperForUnresolvedGlue@got(RTOC)	! Load the callee address
#endif
	li	r3, TR_PPCnativeStaticHelperForUnresolvedGlue
	b       .L33
.L.not_Native:
#ifdef AIXPPC
	laddr	r11, TOCjitMethodIsSync(RTOC)
	laddr	r0, 0(r11)						! Addr of jitMethodIsSync
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCjitMethodIsSync@toc(RTOC)
#else
	laddr	r11, TOCjitMethodIsSync@toc(RTOC)
	laddr	r0, 0(r11)						! Addr of jitMethodIsSync
#endif
#else
	laddr	r0, jitMethodIsSync@got(RTOC)				! Load the callee address
#endif
	mtspr   CTR, r0
	or      r3, r5, r5						! Restore the method pointer
	bcctrl  BO_ALWAYS, CR0_LT					! Call to test Sync
	or.     r3, r3, r3						! r3==0 --> not Sync
#ifdef AIXPPC
	laddr	r11, TOC__staticGlueTable(RTOC)
#elif defined(LINUXPPC64)
	laddr	r11, TOC__staticGlueTable@toc(RTOC)
#else
	laddr	r11, staticGlueTable@got(RTOC)				! Load the callee address
#endif
	srawi	r3, r6, ALen/4
	addi	r3, r3, TR_PPCinterpreterVoidStaticGlue
	bc      BO_IF, CR0_EQ, .L.not_Sync
	addi    r11, r11, 5*ALen					! Offset to Sync helpers
	addi	r3, r3, 1
.L.not_Sync:
	laddrx	r4, r11, r6						! Load helper address to r4
.L33:
	addi    r10, r7, 3*ALen+8					! Cal resolve lock address
	addi    r9, 0, LOCKED_VALUE
	bl      .__common_lock_check					! Try to lock
	or.     r8, r8, r8						! Grab the lock successfully?
	bc      BO_IF, CR0_EQ, .L.target_mod				! Yes, go to modify the target
	bl      .__spin_for_update					! No, wait for completion
	b       .L.to_call_static_glue
.L.target_mod:
	addi	J9SP, J9SP, -6*ALen
	staddr	r3, 4*ALen(J9SP)
	staddr	r5, 5*ALen(J9SP)
	lwz	r8, 2*ALen+4(r7)					! CP index
	laddr	r3, 0(r7)						! code cache RA
	laddr	r6, 2*ALen+8(r7)					! constant pool
	rlwinm  r8, r8, 0, 0x007fffff					! Mask off the offset
	staddr	r3, 0(J9SP)
	staddr	r5, ALen(J9SP)
	staddr	r6, 2*ALen(J9SP)
	staddr	r8, 3*ALen(J9SP)					! Set up argument record
#if defined(AIXPPC)
	laddr	r8, TOCjitCallCFunction(RTOC)
	laddr	r3, TOCmcc_reservationAdjustment_unwrapper(RTOC)
	laddr	r8, 0(r8)
#elif defined(LINUXPPC64)
	laddr	r8, TOCjitCallCFunction@toc(RTOC)
	laddr	r3, TOCmcc_reservationAdjustment_unwrapper@toc(RTOC)
#if !defined(__LITTLE_ENDIAN__)
	laddr	r8, 0(r8)
#endif
#else
	laddr	r8, jitCallCFunction@got(RTOC)
	laddr	r3, mcc_reservationAdjustment_unwrapper@got(RTOC)
#endif
	mr	r6, r4							! Save r4 by moving it
	mr	r4, J9SP
	mr	r5, J9SP
	mtctr	r8
	bctrl
	laddr	r3, 4*ALen(J9SP)
	laddr	r5, 5*ALen(J9SP)
	addi	J9SP, J9SP, 6*ALen
	mr	r4, r6
	staddr	r5, 1*ALen(r7)						! Store method pointer
	sync
	addi	r5, r7, -4						! Location of bl instruction
#if defined(LINUXPPC64)
	bl	FUNC_LABEL(__refreshHelper)
#else
	bl	.__refreshHelper					! save:	RTOC, r4, r7, r10
#endif
	addi    r9, 0, SNIPPET_COMPLETION
	bl      .__common_lock_update					! Complete the modification
.L.to_call_static_glue:
	addi    r4, r4, 4						! Skip the first instr
	mtspr   CTR, r4
	or      r11, r7, r7						! Put snippet RA in r11
	bcctr   BO_ALWAYS, CR0_LT
	endproc._interpreterUnresolvedStaticGlue:

#ifdef AIXPPC
._interpreterUnresolvedSpecialGlue:
	.function ._interpreterUnresolvedSpecialGlue,startproc._interpreterUnresolvedSpecialGlue,16,0,(endproc._interpreterUnresolvedSpecialGlue-startproc._interpreterUnresolvedSpecialGlue)
	startproc._interpreterUnresolvedSpecialGlue:
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
	laddr	r6, TOCjitResolveSpecialMethod(RTOC)
	laddr	r0, 0(r6)						! Load the callee address
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedSpecialGlue):
	startproc._interpreterUnresolvedSpecialGlue:
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCjitResolveSpecialMethod@toc(RTOC)
#else
	laddr	r6, TOCjitResolveSpecialMethod@toc(RTOC)
	laddr	r0, 0(r6)						! Load the callee address
#endif
#else
_interpreterUnresolvedSpecialGlue:
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
	laddr	r0, jitResolveSpecialMethod@got(RTOC)			! Load the callee address
#endif
	mfspr   r7, LR							! Preserve the snippet RA
	laddr	r3, 0(r7)						! Load code cache RA
	laddr	r4, (2*ALen+8)(r7)					! Load constant pool literal
	lwz	r5, (2*ALen+4)(r7)					! Load cp index
	mtspr   CTR, r0							! Move callee address to CTR
	rlwinm  r6, r5, 8, 0x000000ff					! Table offset in r6
	rlwinm  r5, r5, 0, 0x007fffff					! Mask off the offset
	bcctrl  BO_ALWAYS, CR0_LT					! Call to resolve: r3-5 can be
	b       .L22.common_code					!   modified, r3 is result.
	endproc._interpreterUnresolvedSpecialGlue:

#ifdef AIXPPC
._interpreterUnresolvedDirectVirtualGlue:
	.function ._interpreterUnresolvedDirectVirtualGlue,startproc._interpreterUnresolvedDirectVirtualGlue,16,0,(endproc._interpreterUnresolvedDirectVirtualGlue-startproc._interpreterUnresolvedDirectVirtualGlue)
	startproc._interpreterUnresolvedDirectVirtualGlue:
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
	laddr	r6, TOCjitResolveSpecialMethod(RTOC)
	laddr	r0, 0(r6)						! Load the callee address
#elif defined(LINUXPPC64)
FUNC_LABEL(_interpreterUnresolvedDirectVirtualGlue):
	startproc._interpreterUnresolvedDirectVirtualGlue:
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCjitResolveSpecialMethod@toc(RTOC)
#else
	laddr	r6, TOCjitResolveSpecialMethod@toc(RTOC)
	laddr	r0, 0(r6)						! Load the callee address
#endif
#else
_interpreterUnresolvedDirectVirtualGlue:
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
	laddr	r0, jitResolveSpecialMethod@got(RTOC)			! Load the callee address
#endif
	mfspr   r7, LR							! Preserve the snippet RA
	laddr	r3, 0(r7)						! Load code cache RA
	laddr	r4, 2*ALen+8(r7)					! Load constant pool literal
	lwz	r5, 2*ALen+4(r7)					! Load cp index
	mtspr   CTR, r0							! Move callee address to CTR
	rlwinm  r6, r5, 8, 0x000000ff					! Table offset in r6
	rlwinm  r5, r5, 0, 0x007fffff					! Mask off the offset
	bcctrl  BO_ALWAYS, CR0_LT					! Call to resolve: r3-5 can be
	b       .L22.common_code					!   modified, r3 is result.
	endproc._interpreterUnresolvedDirectVirtualGlue:

#ifdef AIXPPC
.__refreshHelper:
	.function .__refreshHelper, startproc.__refreshHelper, 16, 0, (endproc.__refreshHelper-startproc.__refreshHelper)
	startproc.__refreshHelper:		! ARGS:	r3, r4, r5         SAVE: r4, r5, r6, r7, r10, r11, LR
#elif defined(LINUXPPC64)
FUNC_LABEL(__refreshHelper):
	startproc.__refreshHelper:		! ARGS:	r3, r4, r5         SAVE: r4, r5, r6, r7, r10, r11, LR
#else
__refreshHelper:
.__refreshHelper:
#endif
	mfspr	r8, LR							! save LR
	subf	r9, r5, r4
#if defined(TR_HOST_64BIT)
	sradi.	r0, r9, 25
#else
	srawi.	r0, r9, 25
#endif
	beq	cr0, .L11withinLimit
	cmpi	cr0, CmpAddr, r0, -1
	beq	cr0, .L11withinLimit
	staddr  r5, -5*ALen(J9SP)                                       ! Replace staddru r5, -5*ALen(J9SP) for P6 perf
        addi    J9SP, J9SP, -5*ALen                                     ! Performs update of replaced staddru
        staddr	r3, ALen(J9SP)
	staddr	r4, 3*ALen(J9SP)
	staddr	r5, 4*ALen(J9SP)
#if defined(AIXPPC)
	laddr	r4, TOCjitCallCFunction(RTOC)
	laddr	r3, TOCmcc_lookupHelperTrampoline_unwrapper(RTOC)
	laddr	r4, 0(r4)
#elif defined(LINUXPPC64)
	laddr	r4, TOCjitCallCFunction@toc(RTOC)
	laddr	r3, TOCmcc_lookupHelperTrampoline_unwrapper@toc(RTOC)
#if !defined(__LITTLE_ENDIAN__)
	laddr	r4, 0(r4)
#endif
#else
	laddr	r4, jitCallCFunction@got(RTOC)
	laddr	r3, mcc_lookupHelperTrampoline_unwrapper@got(RTOC)
#endif
	addi	r5, J9SP, 2*ALen
	mtctr	r4
	mr	r4, J9SP
	bctrl
	laddr	r4, 3*ALen(J9SP)
	laddr	r5, 4*ALen(J9SP)
	laddr	r3, 2*ALen(J9SP)
	addi	J9SP, J9SP, 5*ALen
	subf	r9, r5, r3						! distance in r9
.L11withinLimit:
	lis	r3, 0x4800
	addi	r0, r3, 0x0001						! Materialize bl
	rlwimi	r0, r9, 0, 0x03fffffc					! New instruction
        ori     r9, r5, 0x0
	stw	r0, 0(r9)
	or	r9, r5, r5
	bl	.__code_synchronization
	mtspr	LR, r8
	blr
	endproc.__refreshHelper:

#ifdef TR_TARGET_64BIT
#define VirtualRAOffset       1*ALen-4
#define VirtualCPPOffset      2*ALen-4
#define VirtualJ9MethodOffset 4*ALen-4
#define VirtualJ2IThunkOffset 5*ALen-4
#define VirtualLockwordOffset 6*ALen-4
#else
#define VirtualRAOffset       1*ALen
#define VirtualCPPOffset      2*ALen
#define VirtualJ9MethodOffset 4*ALen
#define VirtualJ2IThunkOffset 5*ALen
#define VirtualLockwordOffset 6*ALen
#endif


#ifdef AIXPPC
._virtualUnresolvedHelper:
	.function ._virtualUnresolvedHelper,startproc._virtualUnresolvedHelper,16,0,(endproc._virtualUnresolvedHelper-startproc._virtualUnresolvedHelper)
#elif defined(LINUXPPC64)
FUNC_LABEL(_virtualUnresolvedHelper):
#else
_virtualUnresolvedHelper:
#endif
	startproc._virtualUnresolvedHelper:
	mfspr   r11, LR							! Preserve LR, r3 -- r10
        staddr  r10, -8*ALen(J9SP)                                      ! Replaced staddru r10, -8*ALen(J9SP) for P6 perf
        addi    J9SP, J9SP, -8*ALen                                     ! Performs update of replaced staddru
        staddr  r9, 1*ALen(J9SP)
        staddr  r8, 2*ALen(J9SP)
        staddr  r7, 3*ALen(J9SP)
        staddr  r6, 4*ALen(J9SP)
        staddr  r5, 5*ALen(J9SP)
        staddr  r4, 6*ALen(J9SP)
        staddr  r3, 7*ALen(J9SP)
        laddr   r9, VirtualJ9MethodOffset(r11)                          ! Load the J9Method
        or.     r9, r9, r9                                              ! Check if J9Method is null
        bc      BO_IF_NOT, CR0_EQ, .L.callPrivate                       ! If not null, this is a prevously resolved private method
#ifdef AIXPPC
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
	laddr	r5, TOCjitResolveVirtualMethod(RTOC)
	laddr	r0, 0(r5)						! Load the target addr
#elif defined(LINUXPPC64)
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCjitResolveVirtualMethod@toc(RTOC)
#else
	laddr	r5, TOCjitResolveVirtualMethod@toc(RTOC)
	laddr	r0, 0(r5)						! Load the target addr
#endif
#else
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
	laddr	r0, jitResolveVirtualMethod@got(RTOC)			! Load the callee address
#endif
	addi	r3, r11, VirtualCPPOffset				! Load address of [CPP:idx] pair
	laddr	r4, VirtualRAOffset(r11)				! Load code cache RA
	mtspr   CTR, r0							! Set up to jump
	bcctrl  BO_ALWAYS, CR0_LT					! Call to resolution, return
									!   vtable offset in gr3
	or.	r3, r3, r3						! If 0, means exception
	bc      BO_IF, CR0_EQ, .L.commonMethodLookupException
									! Require: J9SP-96, RTOC, r11
        andi.   r9, r3, J9TR_J9_VTABLE_INDEX_DIRECT_METHOD_FLAG         ! Check if result is tagged with J9TR_J9_VTABLE_INDEX_DIRECT_METHOD_FLAG
        bc      BO_IF, CR0_EQ, .L.callVirtual                           ! If it is not, go to the original path
        xor     r9, r3, r9                                              ! r9 currently equals 0x1 so this will clear the direct method flag bit
        staddr  r9, VirtualJ9MethodOffset(r11)                          ! stores the J9Method for future calls to this helper
.L.callPrivate:
        laddr   r8, J9TR_MethodPCStartOffset(r9)                        ! load startPC/extra field
        andi.   r10, r8, J9TR_MethodNotCompiledBit                      ! Check to see if the method has already been compiled
        bc      BO_IF_NOT, CR0_EQ, .L.interpretedPrivate                ! If not compiled, handle interpreted case
        lwz     r10, -4(r8)                                             ! Load offset of jit --> jit
        rlwinm  r10, r10, 16, 0x0000FFFF                                ! shift right to get the bits we want
        add     r10, r10, r8                                            ! Addr of jit --> jit in r10 to jump to
        b       .L.setupForCallout
.L.interpretedPrivate:
        ori     r12, r9, J9TR_J9_VTABLE_INDEX_DIRECT_METHOD_FLAG        ! put tagged J9Method into r12
        laddr   r10, VirtualJ2IThunkOffset(r11)                         ! put thunk into r10 to jump to
.L.setupForCallout:
        laddr   r3, 7*ALen(J9SP)                                        ! Restore object ptr: this
        mtspr   CTR, r10                                                ! move r10 to ctr to jump to later
        mtspr   LR, r11                                                 ! Set up the return addr to the b instruction inside the snippet
        b       .L.callout
.L.callVirtual:
	addi    r10, r11, VirtualLockwordOffset				! Lock word addr in gr10
	addi	r9, 0, LOCKED_VALUE					! Lock value
	bl      .__common_lock_check					! Try to lock
	or.     r8, r8, r8						! Grab the lock successfully?
	or      r5, r3, r3
	bc      BO_IF_NOT, CR0_EQ, .L.wait11
	rlwinm  r3, r3, 17, 0x00000001					! gr5{16} in gr3
	srawi   r6, r5, 16						! gr5{0:15} in gr6
	add     r6, r6, r3						! upper half in gr6
	rlwinm  r6, r6, 0, 0x0000ffff					! Mask off any overflow bits
	laddr	r3, VirtualRAOffset(r11)				! Load code cache RA
#ifdef TR_HOST_64BIT
	lis	r7, 0xffffffffffffe98c					! Binary: ld gr12, 0(gr12)
#else
	lis	r7, 0xffff818c						! Binary: lwz gr12, 0(gr12)
#endif
	rlwimi  r7, r5, 0, 0x0000ffff					! lower half in the offset
	addi    r9, r3, -12						! addr of the second instr
	stw     r7, 0(r9)						! Modify that instruction
	bl      .__code_synchronization
	or.     r3, r6, r6
	addis   r7, 0, 0x00005000					! Binary: 0x4ffffb82
#ifdef TR_HOST_64BIT
	addi    r7, r7, 0xfffffffffffffb82				! cror cr31,cr31,cr31
#else
	addi    r7, r7, 0xfffffb82					! cror cr31,cr31,cr31
#endif
	bc      BO_IF, CR0_EQ, .L.is_zero11
	addis   r7, 0, 0x00003d8c					! Binary: addis gr12, gr12, 0
	rlwimi  r7, r6, 0, 0x0000ffff					! upper half in offset
.L.is_zero11:
	addi    r9, r9, -4						! addr of the first instr
	stw     r7, 0(r9)						! Modify the first instr
	bl      .__code_synchronization
	addi    r9, 0, SNIPPET_COMPLETION
	bl      .__common_lock_update
	b       .L.directDispatch
.L.wait11:								! Fixup code needs fixed cache
	bl      .__spin_for_update
.L.directDispatch:							! J9SP-96,r5(offset),r11,RTOC
	laddr	r3, 7*ALen(J9SP)					! Restore object ptr: this
	laddr	r0, VirtualRAOffset(r11)				! Load code cache RA
#ifdef OMR_GC_COMPRESSED_POINTERS
        lwz     r6, J9TR_J9Object_class(r3)                                               ! Load class offset
        ! may need to convert class offset to J9Class
#else
	laddr	r6, J9TR_J9Object_class(r3)						! Load class pointer
#endif
	maskVFT(r6)
	mtspr   LR, r0							! Set up the return addr
	laddrx	r8, r6, r5						! Load the vtable entry
	mtspr   CTR, r8							! Set up the jump target
.L.callout:
	laddr   r4, 6*ALen(J9SP)					! Restore r4 -- r10
	laddr   r5, 5*ALen(J9SP)
	laddr   r6, 4*ALen(J9SP)
	laddr   r7, 3*ALen(J9SP)
	laddr   r8, 2*ALen(J9SP)
	laddr   r9, 1*ALen(J9SP)
	laddr   r10, 0*ALen(J9SP)
	addi    J9SP, J9SP, 8*ALen
	bcctr   BO_ALWAYS, CR0_LT					! Jump and no return
.L.commonMethodLookupException:
	addi    J9SP, J9SP, 8*ALen					! Restore J9SP
#ifdef AIXPPC
	laddr	r6, TOCjitThrowException(RTOC)
	laddr	r0, 0(r6)
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r0, TOCjitThrowException@toc(RTOC)
#else
	laddr	r6, TOCjitThrowException@toc(RTOC)
	laddr	r0, 0(r6)
#endif
#else
	laddr	r0, jitThrowException@got(RTOC)				! Load the callee address
#endif
	laddr	r5, VirtualRAOffset(r11)				! Load code cache RA
	mtspr   LR, r5							! As if called from code cache
	laddr	r3, J9TR_VMThreadCurrentException(J9VM_STRUCT)
	mtspr   CTR, r0
	bcctr   BO_ALWAYS, CR0_LT
	endproc._virtualUnresolvedHelper:

#ifdef AIXPPC
._interfaceCallHelper:
	.function ._interfaceCallHelper,startproc._interfaceCallHelper,16,0,(endproc._interfaceCallHelper-startproc._interfaceCallHelper)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interfaceCallHelper):
#else
_interfaceCallHelper:
#endif
	startproc._interfaceCallHelper:
	mfspr	r11, LR						! Preserve LR, r3 -- r10
	staddr	r10, -8*ALen(J9SP)
	addi	J9SP, J9SP, -8*ALen
	staddr	r9, 1*ALen(J9SP)
	staddr	r8, 2*ALen(J9SP)
	staddr	r7, 3*ALen(J9SP)
	staddr	r6, 4*ALen(J9SP)
	staddr	r5, 5*ALen(J9SP)
	staddr	r4, 6*ALen(J9SP)
	staddr	r3, 7*ALen(J9SP)
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
	laddr	r5, 5*ALen(r11)					! first cache class
	cmpi	cr0, CmpAddr, r5, -1
	isync							! Make sure none -1 is seen
	bc	BO_IF_NOT, CR0_EQ, .L.continueLookup
	laddr	r5, 4*ALen(r11)					! Load ITable Index
	andi.	r5, r5, J9TR_J9_ITABLE_OFFSET_DIRECT		! Check if J9TR_J9_ITABLE_OFFSET_DIRECT flag is set
	bc	BO_IF, CR0_EQ, .L.callResolve			! If not set, need to call jitResolveInterfaceMethod
	laddr	r5, 3*ALen(r11)					! Load Interface Class Pointer
	or.	r5, r5, r5					! Check if Interface Class Pointer is null
	bc	BO_IF_NOT, CR0_EQ, .L.typeCheckAndDirectDispatch	! If not null, this is a known private interface call
.L.callResolve:
	addi	r3, r11, ALen
	mr	r4, r11						! Load code cache RA
#ifdef AIXPPC
	laddr	r5, TOCjitResolveInterfaceMethod(RTOC)
	laddr	r5, 0(r5)					! Load target address
#elif defined(LINUXPPC64)
	laddr	r5, TOCjitResolveInterfaceMethod@toc(RTOC)
#if !defined(__LITTLE_ENDIAN__)
	laddr	r5, 0(r5)					! Load target address
#endif
#else
	laddr	r5, jitResolveInterfaceMethod@got(RTOC)		! Load the callee address
#endif
	mtspr	CTR, r5						! Prepare for long jump
	bcctrl	BO_ALWAYS, CR0_LT					! Call for resolution
	sync
	laddr	r5, 4*ALen(r11)					! Load ITable Index
	andi.	r5, r5, J9TR_J9_ITABLE_OFFSET_DIRECT		! Check if J9TR_J9_ITABLE_OFFSET_DIRECT flag is set
	bc	BO_IF, CR0_EQ, .L.callInterface			! If not set, this does not need a direct dispatch
.L.typeCheckAndDirectDispatch:
#ifdef AIXPPC
	laddr	r5, TOCjitInstanceOf(RTOC)
	laddr	r5, 0(r5)					! Load target address
#elif defined(LINUXPPC64)
	laddr	r5, TOCjitInstanceOf@toc(RTOC)
#if !defined(__LITTLE_ENDIAN__)
	laddr	r5, 0(r5)					! Load target address
#endif
#else
	laddr	r5, jitInstanceOf@got(RTOC)			! Load the callee address
#endif
	laddr	r3, 3*ALen(r11)					! Load Interface Class Pointer
	laddr	r4, 7*ALen(J9SP)				! Load this pointer
	mtspr	CTR, r5
	bcctrl	BO_ALWAYS, CR0_LT				! Branch to jitInstanceOf
	or.	r3, r3, r3					! Check if jitInstanceOf returned null
	bc	BO_IF_NOT, CR0_EQ, .L.directDispatchInterface	! If not null, continue on to direct dispatch
#ifdef AIXPPC
	laddr	r5, TOCjitLookupInterfaceMethod(RTOC)
	laddr	r5, 0(r5)					! Load target address
#elif defined(LINUXPPC64)
	laddr	r5, TOCjitLookupInterfaceMethod@toc(RTOC)
#if !defined(__LITTLE_ENDIAN__)
	laddr	r5, 0(r5)					! Load target address
#endif
#else
	laddr	r5, jitLookupInterfaceMethod@got(RTOC)		! Load the callee address
#endif
	mtspr	CTR, r5						! Prepare for long jump
#ifdef OMR_GC_COMPRESSED_POINTERS
	lwz	r3, J9TR_J9Object_class(r4)				! Load the class offset
#else
	laddr	r3, J9TR_J9Object_class(r4)				! Load the class
#endif
	maskVFT(r3)
	addi	r4, r11, 3*ALen					! Address of interface table&slot number
	mr	r5, r11						! Load original RA for use inside jitLookupInterfaceMethod
	bcctr	BO_ALWAYS, CR0_LT				! Branch to jitLookupInterfaceMethod to trigger exception
								! The code will not return here after the branch.
.L.directDispatchInterface:
	laddr	r5, 4*ALen(r11)					! Load ITable Index. This is actually a J9Method.
	xori	r5, r5, J9TR_J9_ITABLE_OFFSET_DIRECT		! Clear J9TR_J9_ITABLE_OFFSET_DIRECT flag.
	laddr	r6, J9TR_MethodPCStartOffset(r5)		! load startPC/extra field
	andi.	r7, r6, J9TR_MethodNotCompiledBit		! Check to see if the method has already been compiled
	bc	BO_IF_NOT, CR0_EQ, .L.interpretedDispatch	! If not compiled, handle interpreted case
	lwz	r7, -4(r6)					! Load offset of jit --> jit
	rlwinm	r7, r7, 16, 0x0000FFFF				! shift right to get the bits we want
	add	r7, r7, r6					! Addr of jit --> jit in r7 to jump to
	b	.L.setupCTRforCallout
.L.interpretedDispatch:
	ori	r12, r5, J9TR_J9_VTABLE_INDEX_DIRECT_METHOD_FLAG	! put tagged J9Method into r12
	laddr	r7, 9*ALen(r11)					! put thunk into r7 to jump to
.L.setupCTRforCallout:
	laddr	r3, 7*ALen(J9SP)				! Restore object ptr: this
	mtspr	CTR, r7						! move r7 to ctr to jump to later
	b	.L.calloutInterface
.L.callInterface:
	li	r3, 5*ALen
	li	r5, 0
.L.loopToSetZero:
#ifdef TR_HOST_64BIT
	ldarx	r4, r11, r3
	cmpi	cr0, 1, r4, -1
	bc	BO_IF_NOT, CR0_EQ, .L.continueLookup
	stdcx.	r5, r11, r3
	bc	BO_IF_NOT, CR0_EQ, .L.loopToSetZero
#else
	lwarx	r4, r11, r3
	cmpi	cr0, 0, r4, -1
	bc	BO_IF_NOT, CR0_EQ, .L.continueLookup
	stwcx.	r5, r11, r3
	bc	BO_IF_NOT, CR0_EQ, .L.loopToSetZero
#endif
.L.continueLookup:
#ifdef AIXPPC
	laddr	r5, TOCjitLookupInterfaceMethod(RTOC)
	laddr	r5, 0(r5)					! Load target address
#elif defined(LINUXPPC64)
	laddr	r5, TOCjitLookupInterfaceMethod@toc(RTOC)
#if !defined(__LITTLE_ENDIAN__)
	laddr	r5, 0(r5)					! Load target address
#endif
#else
	laddr	r5, jitLookupInterfaceMethod@got(RTOC)		! Load the callee address
#endif
	laddr	r6, 7*ALen(J9SP)					! Load:  this
	mtspr	CTR, r5						! Prepare for long jump
	mr	r5, r11						! Load code cache RA
	addi	r4, r11, 3*ALen					! Address of interface table&slot number
#ifdef OMR_GC_COMPRESSED_POINTERS
	lwz	r3, J9TR_J9Object_class(r6)				! Load the class offset
#else
	laddr	r3, J9TR_J9Object_class(r6)				! Load the class
#endif
	maskVFT(r3)
	bcctrl	BO_ALWAYS, CR0_LT					! Call to look up method
	laddr	r5, 7*ALen(J9SP)					! Load:  this
#ifdef OMR_GC_COMPRESSED_POINTERS
	lwz	r6, J9TR_J9Object_class(r5)				! Load the class offset
	! may need to convert class offset to J9Class
#else
	laddr	r6, J9TR_J9Object_class(r5)				! Load the class
#endif
	maskVFT(r6)
	laddrx	r7, r6, r3					! Load method pointer
	laddr	r8, J9TR_MethodPCStartOffset(r7)			! Load startPC field
	andi.	r4, r8, J9TR_MethodNotCompiledBit
	bc	BO_IF_NOT, CR0_EQ, .L.commonJitDispatch
	lwz	r4, -4(r8)					! Load offset of jit --> jit
	rlwinm	r4, r4, 16, 0x0000FFFF
	add	r8, r8, r4					! Addr of jit --> jit
	li	r5, 5*ALen					! class1 offset
.L.tryToComplete:
#ifdef TR_HOST_64BIT
	ldarx	r4, r11, r5					! either zero or class
	cmpi	cr0, 1, r4, 0
	bc	BO_IF_NOT, CR0_EQ, .L.commonJitDispatch
	stdcx.	r6, r11, r5
	bc	BO_IF_NOT, CR0_EQ, .L.tryToComplete
#else
	lwarx	r4, r11, r5					! either zero or class
	cmpi	cr0, 0, r4, 0
	bc	BO_IF_NOT, CR0_EQ, .L.commonJitDispatch
	stwcx.	r6, r11, r5
	bc	BO_IF_NOT, CR0_EQ, .L.tryToComplete
#endif
	staddr	r8, 6*ALen(r11)					! store target1
	sync
#ifdef AIXPPC
	laddr	r5, TOC_interfaceCompeteSlot2(RTOC)
	laddr	r4, 0(r5)					! Load address of slot2 helper
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r4, TOC_interfaceCompeteSlot2@toc(RTOC)
#else
	laddr	r5, TOC_interfaceCompeteSlot2@toc(RTOC)
	laddr	r4, 0(r5)					! Load address of slot2 helper
#endif
#else
	laddr	r4, _interfaceCompeteSlot2@got(RTOC)			! Load the callee address
#endif
	ori	r6, r3, 0					! Preserve r3 in r6
	li	r3, TR_PPCinterfaceCompeteSlot2
	addi	r5, r11, -4					! Location of bl instruction
#if defined(LINUXPPC64)
	bl	FUNC_LABEL(__refreshHelper)
#else
	bl	.__refreshHelper					! save:	RTOC, r6, r10, r11
#endif
	laddr	r4, 5*ALen(r11)					! Load slot1 class
#ifdef OMR_GC_COMPRESSED_POINTERS
        ! may need to convert class offset to J9Class pointer
#endif
	laddr	r5, 3*ALen(r11)					! Resolved class
	laddr	r7, J9TR_J9Class_classLoader(r4)
	laddr	r8, J9TR_J9Class_classLoader(r5)
	cmpl	cr0, CmpAddr, r7, r8				! Same classLoader?
	ori	r3, r6, 0					! Restore r3
	addi	r6, r11, 5*ALen
	bcl	BO_IF_NOT, CR0_EQ, .__picRegistration
.L.commonJitDispatch:						! interpVtable offset in r3
	neg	r4, r3
	addi	r12, r4,J9TR_InterpVTableOffset			! Must set it up in r12
	laddr	r3, 7*ALen(J9SP)					! Restore "this"
#ifdef OMR_GC_COMPRESSED_POINTERS
	lwz	r5, J9TR_J9Object_class(r3)				! class offset
        ! may need to convert class offset to J9Class pointer
#else
	laddr	r5, J9TR_J9Object_class(r3)				! class pointer
#endif
	maskVFT(r5)
	laddrx	r4, r5, r12
	mtspr	CTR, r4						! set up callee addr
.L.calloutInterface:
	mtspr	LR, r11						! Set up to return
	laddr	r4, 6*ALen(J9SP)					! Restore r4 -- r10
	laddr	r5, 5*ALen(J9SP)
	laddr	r6, 4*ALen(J9SP)
	laddr	r7, 3*ALen(J9SP)
	laddr	r8, 2*ALen(J9SP)
	laddr	r9, 1*ALen(J9SP)
	laddr	r10, 0*ALen(J9SP)
	addi	J9SP, J9SP, 8*ALen
	bcctr   BO_ALWAYS, CR0_LT					! Call: does not return here
	endproc._interfaceCallHelper:

#ifdef AIXPPC
._interfaceCompeteSlot2:
	.function ._interfaceCompeteSlot2,startproc._interfaceCompeteSlot2,16,0,(endproc._interfaceCompeteSlot2-startproc._interfaceCompeteSlot2)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interfaceCompeteSlot2):
#else
_interfaceCompeteSlot2:
#endif
	startproc._interfaceCompeteSlot2:
	mfspr	r11, LR						! Preserve LR, r3 -- r10
	staddr	r10, -8*ALen(J9SP)
	addi	J9SP, J9SP, -8*ALen
	staddr	r9, 1*ALen(J9SP)
	staddr	r8, 2*ALen(J9SP)
	staddr	r7, 3*ALen(J9SP)
	staddr	r6, 4*ALen(J9SP)
	staddr	r5, 5*ALen(J9SP)
	staddr	r4, 6*ALen(J9SP)
	staddr	r3, 7*ALen(J9SP)
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
#ifdef AIXPPC
	laddr	r5, TOCjitLookupInterfaceMethod(RTOC)
	laddr	r5, 0(r5)					! Load target address
#elif defined(LINUXPPC64)
	laddr	r5, TOCjitLookupInterfaceMethod@toc(RTOC)
#if !defined(__LITTLE_ENDIAN__)
	laddr	r5, 0(r5)					! Load target address
#endif
#else
	laddr	r5, jitLookupInterfaceMethod@got(RTOC)		! Load the callee address
#endif
	laddr	r6, 7*ALen(J9SP)					! Load "this"
#ifdef OMR_GC_COMPRESSED_POINTERS
	lwz	r3, J9TR_J9Object_class(r6)				! Load the class offset
#else
	laddr	r3, J9TR_J9Object_class(r6)				! Load the class
#endif
	maskVFT(r3)
	addi	r4, r11, 3*ALen					! Address of interface info
	mtspr	CTR, r5						! Prepare for long jump
	mr	r5, r11						! Load code cache RA
	bcctrl	BO_ALWAYS, CR0_LT					! Call to look up
	laddr	r5, 7*ALen(J9SP)					! Load:  this
#ifdef OMR_GC_COMPRESSED_POINTERS
	lwz	r6, J9TR_J9Object_class(r5)				! Load the class offset
        ! may need to convert class offset to J9Class
#else
	laddr	r6, J9TR_J9Object_class(r5)				! Load the class
#endif
	maskVFT(r6)
	laddrx	r7, r6, r3					! Load method pointer
	laddr	r5, J9TR_MethodPCStartOffset(r7)			! Load startPC/extra field
	andi.	r8, r5, J9TR_MethodNotCompiledBit
	bc	BO_IF_NOT, CR0_EQ, .L.commonJitDispatch		! Require:J9SP-8s,r11,r3(voff)
	laddr	r4, 5*ALen(r11)
	cmp	cr0, CmpAddr, r6, r4
	bc	BO_IF, CR0_EQ, .L.commonJitDispatch
	lwz	r8, -4(r5)					! Offset to jit-->jit
	rlwinm	r8, r8, 16, 0x0000FFFF
	add	r8, r5, r8					! addr of jit-->jit
	li	r5, 7*ALen					! class2 offset
.L.tryToCompleteSlot2:
#ifdef TR_HOST_64BIT
	ldarx	r4, r11, r5					! either -1 or class
	cmpi	cr0, 1, r4, -1
	bc	BO_IF_NOT, CR0_EQ, .L.commonJitDispatch
	stdcx.	r6, r11, r5
	bc	BO_IF_NOT, CR0_EQ, .L.tryToCompleteSlot2
#else
	lwarx	r4, r11, r5					! either -1 or class
	cmpi	cr0, 0, r4, -1
	bc	BO_IF_NOT, CR0_EQ, .L.commonJitDispatch
	stwcx.	r6, r11, r5
	bc	BO_IF_NOT, CR0_EQ, .L.tryToCompleteSlot2
#endif
	staddr	r8, 8*ALen(r11)					! Modify Slot2 target addr
	sync
#ifdef AIXPPC
	laddr	r5, TOC_interfaceSlotsUnavailable(RTOC)
	laddr	r4, 0(r5)					! Load address of final helper
#elif defined(LINUXPPC64)
#if defined(__LITTLE_ENDIAN__)
	laddr	r4, TOC_interfaceSlotsUnavailable@toc(RTOC)
#else
	laddr	r5, TOC_interfaceSlotsUnavailable@toc(RTOC)
	laddr	r4, 0(r5)					! Load address of final helper
#endif
#else
	laddr	r4, _interfaceSlotsUnavailable@got(RTOC)		! Load address of final helper
#endif
	or	r6, r3, r3					! Preserve r3
	li	r3, TR_PPCinterfaceSlotsUnavailable
	addi	r5, r11, -4					! Location of bl instruction
#if defined(LINUXPPC64)
	bl	FUNC_LABEL(__refreshHelper)
#else
	bl	.__refreshHelper					! save:	RTOC, r6, r10, r11
#endif
	or	r3, r6, r6					! Restore r3
	laddr	r4, 7*ALen(r11)					! Load slot2 class
#ifdef OMR_GC_COMPRESSED_POINTERS
        ! may need to convert class offset to J9Class pointer
#endif
	laddr	r5, 3*ALen(r11)					! Resolved class
	laddr	r7, J9TR_J9Class_classLoader(r4)
	laddr	r8, J9TR_J9Class_classLoader(r5)
	cmpl	cr0, CmpAddr, r7, r8				! Same classLoader?
	addi	r6, r11, 7*ALen
	bcl	BO_IF_NOT, CR0_EQ, .__picRegistration
	b	.L.commonJitDispatch				! Require:J9SP-8s,r11,r3(voff)
	endproc._interfaceCompeteSlot2:


#ifdef AIXPPC
.__picRegistration:
	.function .__picRegistration,startproc.__picRegistration,16,0,(endproc.__picRegistration-startproc.__picRegistration)
#elif defined(LINUXPPC64)
.__picRegistration:
#else
__picRegistration:
.__picRegistration:
#endif
	startproc.__picRegistration:
	mfspr	r5, LR					! Save return address and allocate space for frame
	staddru	SP, -24*ALen(SP)
	staddr	r5, 19*ALen(SP)
	staddr	r11, 17*ALen(SP)
	staddr	r3, 16*ALen(SP)
	mr	r3, r4
	mr	r4, r6
#if defined(TR_HOST_64BIT) && !defined(__LITTLE_ENDIAN__)
	addi	r4, r4, 4					! Patch the last 4 bytes
#endif
#ifdef AIXPPC
	laddr	r12, TOC_jitAddPicToPatchOnClassUnload(RTOC)		! TOC entry for function ptr
	laddr	r12, 0(r12)					! Load the function addr
#elif defined(LINUXPPC64)
	laddr	r12, TOC_jitAddPicToPatchOnClassUnload@toc(RTOC)	! TOC entry for function ptr
#if !defined(__LITTLE_ENDIAN__)
	laddr	r12, 0(r12)					! Load the function addr
#endif
#else
	laddr	r12, jitAddPicToPatchOnClassUnload@got(RTOC)		! Load the address of backing storage
#endif
	mtctr	r12
	bctrl
	laddr	r5, 19*ALen(SP)
	mtlr	r5
	laddr	r3, 16*ALen(SP)
	laddr	r11, 17*ALen(SP)
	addi	SP, SP, 24*ALen
	blr
	endproc.__picRegistration:


#ifdef AIXPPC
._interfaceSlotsUnavailable:
	.function ._interfaceSlotsUnavailable,startproc._interfaceSlotsUnavailable,16,0,(endproc._interfaceSlotsUnavailable-startproc._interfaceSlotsUnavailable)
#elif defined(LINUXPPC64)
FUNC_LABEL(_interfaceSlotsUnavailable):
#else
_interfaceSlotsUnavailable:
#endif
	startproc._interfaceSlotsUnavailable:
	mfspr	r11, LR						! Preserve LR content
	staddr	r10, -8*ALen(J9SP)				! Replaced staddru r10, -8*ALen(J9SP) for P6 perf
	staddr	r9, -7*ALen(J9SP)
#ifndef NO_HELPER_LASTITABLE_CHECK
        ! Before going to the VM helper, check if the receiver class lastITable matches the interface class
        ! of the method being called and if so, use it to quickly look up the vtable offset and make the call
#ifdef OMR_GC_COMPRESSED_POINTERS
        lwz     r10, J9TR_J9Object_class(r3)                    ! Load class
#else  
        laddr   r10, J9TR_J9Object_class(r3)                    ! Load class
#endif
        maskVFT(r10)
        laddr   r12, 3*ALen(r11)                                ! Load the interface class of the method from the snippet
        laddr   r9, J9TR_J9Class_lastITable(r10)                ! Load the cached last ITable
        laddr   r0, J9TR_J9ITable_interfaceClass(r9)            ! Load the interface class whose ITable this is
        cmpl    cr0, CmpAddr, r12, r0
        bne     .L.callHelper
        ! lastITable is a match
        laddr   r12, 4*ALen(r11)                                ! Load the itable offset from the snippet
        andis.  r11,r12,J9TR_J9_ITABLE_OFFSET_TAG_BITS          ! Call the helper if the itable offset is tagged
        bne     .L.callHelper
        laddrx  r12, r9, r12                                    ! Load the interpreter vft offset
        neg     r12, r12
        addi    r12, r12, J9TR_InterpVTableOffset               ! Convert to a JIT vft offset
        laddrx  r11, r10, r12                                   ! Load the method
        mtspr   CTR, r11
	laddr	r10, -8*ALen(J9SP)				! Restore
	laddr	r9, -7*ALen(J9SP)				! Restore

        bcctr   BO_ALWAYS, CR0_LT                               ! Call the method (control does not return here)
.L.callHelper:
#endif /* ~NO_HELPER_LASTITABLE_CHECK */
	addi	J9SP, J9SP, -8*ALen			! Performs update of replaced staddru
	staddr	r8, 2*ALen(J9SP)
	staddr	r7, 3*ALen(J9SP)
	staddr	r6, 4*ALen(J9SP)
	staddr	r5, 5*ALen(J9SP)
	staddr	r4, 6*ALen(J9SP)
	staddr	r3, 7*ALen(J9SP)
	laddr	RTOC, J9TR_VMThreadRTOCOffset(J9VM_STRUCT)		! Restore TOC register
#ifdef AIXPPC
	laddr	r5, TOCjitLookupInterfaceMethod(RTOC)
	laddr	r5, 0(r5)					! Load target address
#elif defined(LINUXPPC64)
	laddr	r5, TOCjitLookupInterfaceMethod@toc(RTOC)
#if !defined(__LITTLE_ENDIAN__)
	laddr	r5, 0(r5)					! Load target address
#endif
#else
	laddr	r5, jitLookupInterfaceMethod@got(RTOC)		! Load address of final helper
#endif
#ifdef OMR_GC_COMPRESSED_POINTERS
	lwz	r3, J9TR_J9Object_class(r3)				! Load class
#else
	laddr	r3, J9TR_J9Object_class(r3)				! Load class
#endif
	maskVFT(r3)
	addi	r4, r11, 3*ALen					! Address of interface info
	mtspr	CTR, r5						! Prepare for long jump
	mr	r5, r11						! Load code cache RA
	bcctrl	BO_ALWAYS, CR0_LT					! Call to look up
	b	.L.commonJitDispatch				! Require: J9SP-8s, r11
								!   r3(vtable offset)
	endproc._interfaceSlotsUnavailable:


! .data section
#ifdef AIXPPC
	.toc
TOC__j9_smp_flag:
	.tc       __j9_smp_flag[TC],__j9_smp_flag
TOC__staticGlueTable:
	.tc       __staticGlueTable[TC],__staticGlueTable
TOCjitResolveField:
	.tc       jitResolveField[TC],jitResolveField
TOCjitResolveFieldSetter:
	.tc	  jitResolveFieldSetter[TC],jitResolveFieldSetter
TOCjitResolveClass:
	.tc       jitResolveClass[TC],jitResolveClass
TOCjitResolveClassFromStaticField:
	.tc       jitResolveClass[TC],jitResolveClassFromStaticField
TOCjitResolveString:
	.tc       jitResolveString[TC],jitResolveString
TOCjitResolveConstantDynamic:
	.tc       jitResolveConstantDynamic[TC],jitResolveConstantDynamic
TOCjitResolveMethodType:
	.tc       jitResolveMethodType[TC],jitResolveMethodType
TOCjitResolveMethodHandle:
	.tc       jitResolveMethodHandle[TC],jitResolveMethodHandle
TOCjitResolveInvokeDynamic:
	.tc       jitResolveInvokeDynamic[TC],jitResolveInvokeDynamic
TOCjitResolveHandleMethod:
	.tc       jitResolveHandleMethod[TC],jitResolveHandleMethod
TOCjitResolveStaticField:
	.tc       jitResolveStaticField[TC],jitResolveStaticField
TOCjitResolvedFieldIsVolatile:
	.tc       jitResolvedFieldIsVolatile[TC],jitResolvedFieldIsVolatile
TOCjitResolveStaticFieldSetter:
	.tc	  jitResolveStaticFieldSetter[TC],jitResolveStaticFieldSetter
TOCjitResolveStaticMethod:
	.tc       jitResolveStaticMethod[TC],jitResolveStaticMethod
TOCjitResolveSpecialMethod:
	.tc       jitResolveSpecialMethod[TC],jitResolveSpecialMethod
TOCjitMethodIsNative:
	.tc       jitMethodIsNative[TC],jitMethodIsNative
TOCjitMethodIsSync:
	.tc       jitMethodIsSync[TC],jitMethodIsSync
TOC_nativeStaticHelperForUnresolvedGlue:
	.tc       _nativeStaticHelperForUnresolvedGlue[TC],_nativeStaticHelperForUnresolvedGlue
TOC_nativeStaticHelper:
	.tc       _nativeStaticHelper[TC],_nativeStaticHelper
TOCj2iTransition:
	.tc 	  j2iTransition[TC],j2iTransition
TOCicallVMprJavaSendNativeStatic:
	.tc       icallVMprJavaSendNativeStatic[TC],icallVMprJavaSendNativeStatic
TOCicallVMprJavaSendStatic0:
	.tc       icallVMprJavaSendStatic0[TC],icallVMprJavaSendStatic0
TOCicallVMprJavaSendStatic1:
	.tc       icallVMprJavaSendStatic1[TC],icallVMprJavaSendStatic1
TOCicallVMprJavaSendStaticJ:
	.tc       icallVMprJavaSendStaticJ[TC],icallVMprJavaSendStaticJ
TOCicallVMprJavaSendStaticF:
	.tc       icallVMprJavaSendStaticF[TC],icallVMprJavaSendStaticF
TOCicallVMprJavaSendStaticD:
	.tc       icallVMprJavaSendStaticD[TC],icallVMprJavaSendStaticD
TOCicallVMprJavaSendStaticSync0:
	.tc       icallVMprJavaSendStaticSync0[TC],icallVMprJavaSendStaticSync0
TOCicallVMprJavaSendStaticSync1:
	.tc       icallVMprJavaSendStaticSync1[TC],icallVMprJavaSendStaticSync1
TOCicallVMprJavaSendStaticSyncJ:
	.tc       icallVMprJavaSendStaticSyncJ[TC],icallVMprJavaSendStaticSyncJ
TOCicallVMprJavaSendStaticSyncF:
	.tc       icallVMprJavaSendStaticSyncF[TC],icallVMprJavaSendStaticSyncF
TOCicallVMprJavaSendStaticSyncD:
	.tc       icallVMprJavaSendStaticSyncD[TC],icallVMprJavaSendStaticSyncD
TOCjitResolveVirtualMethod:
	.tc       jitResolveVirtualMethod[TC],jitResolveVirtualMethod
TOCjitThrowException:
	.tc       jitThrowException[TC],jitThrowException
TOCjitResolveInterfaceMethod:
	.tc       jitResolveInterfaceMethod[TC],jitResolveInterfaceMethod
TOCjitLookupInterfaceMethod:
	.tc       jitLookupInterfaceMethod[TC],jitLookupInterfaceMethod
TOC_interfaceCompeteSlot2:
	.tc       _interfaceCompteteSlot2[TC],_interfaceCompeteSlot2{DS}
TOC_interfaceSlotsUnavailable:
	.tc       _interfaceSlotsUnavailable[TC],_interfaceSlotsUnavailable{DS}
TOC_jitAddPicToPatchOnClassUnload:
	.tc       jitAddPicToPatchOnClassUnload[TC],jitAddPicToPatchOnClassUnload
TOCjitCallCFunction:
	.tc       jitCallCFunction[TC],jitCallCFunction
TOCjitInstanceOf:
	.tc       jitInstanceOf[TC],jitInstanceOf
TOCmcc_callPointPatching_unwrapper:
	.tc       mcc_callPointPatching_unwrapper[TC],mcc_callPointPatching_unwrapper
TOCmcc_reservationAdjustment_unwrapper:
	.tc       mcc_reservationAdjustment_unwrapper[TC],mcc_reservationAdjustment_unwrapper
TOCmcc_lookupHelperTrampoline_unwrapper:
	.tc       mcc_lookupHelperTrampoline_unwrapper[TC],mcc_lookupHelperTrampoline_unwrapper

	.csect    PicBuilder_DATA{RW}
__staticGlueTable:
	ADDR     ._interpreterVoidStaticGlue
	ADDR     ._interpreterGPR3StaticGlue
	ADDR     ._interpreterGPR3GPR4StaticGlue
	ADDR     ._interpreterFPR0FStaticGlue
	ADDR     ._interpreterFPR0DStaticGlue
	ADDR     ._interpreterSyncVoidStaticGlue
	ADDR     ._interpreterSyncGPR3StaticGlue
	ADDR     ._interpreterSyncGPR3GPR4StaticGlue
	ADDR     ._interpreterSyncFPR0FStaticGlue
	ADDR     ._interpreterSyncFPR0DStaticGlue
! End   csect     PicBuilder_DATA{RW}

	.csect	  __refreshHelper{DS}
	ADDR	  .__refreshHelper
	ADDR 	  TOC{TC0}
	ADDR	  0x00000000
!End	csect	  __refreshHelper{DS}

	.csect    _interpreterUnresolvedInstanceDataGlue{DS}
	ADDR      ._interpreterUnresolvedInstanceDataGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedInstanceDataGlue{DS}

	.csect    _interpreterUnresolvedInstanceDataStoreGlue{DS}
	ADDR      ._interpreterUnresolvedInstanceDataStoreGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedInstanceDataStoreGlue{DS}

	.csect    _interpreterUnresolvedClassGlue2{DS}
	ADDR      ._interpreterUnresolvedClassGlue2
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedClassGlue2{DS}

	.csect    _interpreterUnresolvedClassGlue{DS}
	ADDR      ._interpreterUnresolvedClassGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedClassGlue{DS}

	.csect    _interpreterUnresolvedStringGlue{DS}
	ADDR      ._interpreterUnresolvedStringGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedStringGlue{DS}

	.csect    _interpreterUnresolvedConstantDynamicGlue{DS}
	ADDR      ._interpreterUnresolvedConstantDynamicGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedConstantDynamicGlue{DS}

	.csect    _interpreterUnresolvedMethodTypeGlue{DS}
	ADDR      ._interpreterUnresolvedMethodTypeGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedMethodTypeGlue{DS}

	.csect    _interpreterUnresolvedMethodHandleGlue{DS}
	ADDR      ._interpreterUnresolvedMethodHandleGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedMethodHandleGlue{DS}

	.csect    _interpreterUnresolvedCallSiteTableEntryGlue{DS}
	ADDR      ._interpreterUnresolvedCallSiteTableEntryGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedCallSiteTableEntryGlue{DS}

	.csect    _interpreterUnresolvedMethodTypeTableEntryGlue{DS}
	ADDR      ._interpreterUnresolvedMethodTypeTableEntryGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedMethodTypeTableEntryGlue{DS}

	.csect    MTUnresolvedInt32Load{DS}
	ADDR      .MTUnresolvedInt32Load
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     MTUnresolvedInt32Load{DS}

	.csect    MTUnresolvedInt64Load{DS}
	ADDR      .MTUnresolvedInt64Load
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     MTUnresolvedInt64Load{DS}

	.csect    MTUnresolvedFloatLoad{DS}
	ADDR      .MTUnresolvedFloatLoad
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     MTUnresolvedFloatLoad{DS}

	.csect    MTUnresolvedDoubleLoad{DS}
	ADDR      .MTUnresolvedDoubleLoad
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     MTUnresolvedDoubleLoad{DS}

	.csect    MTUnresolvedAddressLoad{DS}
	ADDR      .MTUnresolvedAddressLoad
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     MTUnresolvedAddressLoad{DS}

	.csect    MTUnresolvedInt32Store{DS}
	ADDR      .MTUnresolvedInt32Store
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     MTUnresolvedInt32Store{DS}

	.csect    MTUnresolvedInt64Store{DS}
	ADDR      .MTUnresolvedInt64Store
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     MTUnresolvedInt64Store{DS}

	.csect    MTUnresolvedFloatStore{DS}
	ADDR      .MTUnresolvedFloatStore
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     MTUnresolvedFloatStore{DS}

	.csect    MTUnresolvedDoubleStore{DS}
	ADDR      .MTUnresolvedDoubleStore
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     MTUnresolvedDoubleStore{DS}

	.csect    MTUnresolvedAddressStore{DS}
	ADDR      .MTUnresolvedAddressStore
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     MTUnresolvedAddressStore{DS}

	.csect    _interpreterUnresolvedStaticDataGlue{DS}
	ADDR      ._interpreterUnresolvedStaticDataGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedStaticDataGlue{DS}

	.csect    _interpreterUnresolvedStaticDataStoreGlue{DS}
	ADDR      ._interpreterUnresolvedStaticDataStoreGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedStaticDataStoreGlue{DS}

	.csect    _interpreterVoidStaticGlue{DS}
	ADDR      ._interpreterVoidStaticGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterVoidStaticGlue{DS}

	.csect    _interpreterSyncVoidStaticGlue{DS}
	ADDR      ._interpreterSyncVoidStaticGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterSyncVoidStaticGlue{DS}

	.csect    _interpreterGPR3StaticGlue{DS}
	ADDR      ._interpreterGPR3StaticGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterGPR3StaticGlue{DS}

	.csect    _interpreterSyncGPR3StaticGlue{DS}
	ADDR      ._interpreterSyncGPR3StaticGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterSyncGPR3StaticGlue{DS}

	.csect    _interpreterGPR3GPR4StaticGlue{DS}
	ADDR      ._interpreterGPR3GPR4StaticGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterGPR3GPR4StaticGlue{DS}

	.csect    _interpreterSyncGPR3GPR4StaticGlue{DS}
	ADDR      ._interpreterSyncGPR3GPR4StaticGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterSyncGPR3GPR4StaticGlue{DS}

	.csect    _interpreterFPR0FStaticGlue{DS}
	ADDR      ._interpreterFPR0FStaticGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterFPR0FStaticGlue{DS}

	.csect    _interpreterSyncFPR0FStaticGlue{DS}
	ADDR      ._interpreterSyncFPR0FStaticGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterSyncFPR0FStaticGlue{DS}

	.csect    _interpreterFPR0DStaticGlue{DS}
	ADDR      ._interpreterFPR0DStaticGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterFPR0DStaticGlue{DS}

	.csect    _interpreterSyncFPR0DStaticGlue{DS}
	ADDR      ._interpreterSyncFPR0DStaticGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterSyncFPR0DStaticGlue{DS}

	.csect    _interpreterUnresolvedStaticGlue{DS}
	ADDR      ._interpreterUnresolvedStaticGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedStaticGlue{DS}

	.csect    _interpreterUnresolvedSpecialGlue{DS}
	ADDR      ._interpreterUnresolvedSpecialGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedSpecialGlue{DS}

	.csect    _interpreterUnresolvedDirectVirtualGlue{DS}
	ADDR      ._interpreterUnresolvedDirectVirtualGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interpreterUnresolvedDirectVirtualGlue{DS}

	.csect    _virtualUnresolvedHelper{DS}
	ADDR      ._virtualUnresolvedHelper
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _virtualUnresolvedHelper{DS}

	.csect    _interfaceCallHelper{DS}
	ADDR      ._interfaceCallHelper
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interfaceCallHelper{DS}

	.csect    _interfaceCompeteSlot2{DS}
	ADDR      ._interfaceCompeteSlot2
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interfaceCompeteSlot2{DS}

	.csect    _interfaceSlotsUnavailable{DS}
	ADDR      ._interfaceSlotsUnavailable
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _interfaceSlotsUnavailable{DS}

	.csect    _nativeStaticHelperForUnresolvedGlue{DS}
	ADDR      ._nativeStaticHelperForUnresolvedGlue
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _nativeStaticHelperForUnresolvedGlue{DS}

	.csect    _nativeStaticHelper{DS}
	ADDR      ._nativeStaticHelper
	ADDR      TOC{TC0}
	ADDR      0x00000000
! End   csect     _nativeStaticHelper{DS}

#elif defined(LINUXPPC64)
	.section ".toc"
TOC__j9_smp_flag:
	.tc       __j9_smp_flag[TC],__j9_smp_flag
TOC__staticGlueTable:
	.tc       __staticGlueTable[TC],__staticGlueTable
TOCjitResolveField:
	.tc       jitResolveField[TC],jitResolveField
TOCjitResolveFieldSetter:
	.tc	  jitResolveFieldSetter[TC],jitResolveFieldSetter
TOCjitResolveClass:
	.tc       jitResolveClass[TC],jitResolveClass
TOCjitResolveClassFromStaticField:
	.tc       jitResolveClass[TC],jitResolveClassFromStaticField
TOCjitResolveString:
	.tc       jitResolveString[TC],jitResolveString
TOCjitResolveConstantDynamic:
	.tc       jitResolveConstantDynamic[TC],jitResolveConstantDynamic
TOCjitResolveMethodType:
	.tc       jitResolveMethodType[TC],jitResolveMethodType
TOCjitResolveMethodHandle:
	.tc       jitResolveMethodHandle[TC],jitResolveMethodHandle
TOCjitResolveInvokeDynamic:
	.tc       jitResolveInvokeDynamic[TC],jitResolveInvokeDynamic
TOCjitResolveHandleMethod:
	.tc       jitResolveHandleMethod[TC],jitResolveHandleMethod
TOCjitResolveStaticField:
	.tc       jitResolveStaticField[TC],jitResolveStaticField
TOCjitResolvedFieldIsVolatile:
	.tc       jitResolvedFieldIsVolatile[TC],jitResolvedFieldIsVolatile
TOCjitResolveStaticFieldSetter:
	.tc	  jitResolveStaticFieldSetter[TC],jitResolveStaticFieldSetter
TOCjitResolveStaticMethod:
	.tc       jitResolveStaticMethod[TC],jitResolveStaticMethod
TOCjitResolveSpecialMethod:
	.tc       jitResolveSpecialMethod[TC],jitResolveSpecialMethod
TOCjitMethodIsNative:
	.tc       jitMethodIsNative[TC],jitMethodIsNative
TOCjitMethodIsSync:
	.tc       jitMethodIsSync[TC],jitMethodIsSync
TOC_nativeStaticHelperForUnresolvedGlue:
	.tc       _nativeStaticHelperForUnresolvedGlue[TC],_nativeStaticHelperForUnresolvedGlue
TOC_nativeStaticHelper:
	.tc       _nativeStaticHelper[TC],_nativeStaticHelper
TOCj2iTransition:
	.tc 	  j2iTransition[TC],j2iTransition
TOCicallVMprJavaSendNativeStatic:
	.tc       icallVMprJavaSendNativeStatic[TC],icallVMprJavaSendNativeStatic
TOCicallVMprJavaSendStatic0:
	.tc       icallVMprJavaSendStatic0[TC],icallVMprJavaSendStatic0
TOCicallVMprJavaSendStatic1:
	.tc       icallVMprJavaSendStatic1[TC],icallVMprJavaSendStatic1
TOCicallVMprJavaSendStaticJ:
	.tc       icallVMprJavaSendStaticJ[TC],icallVMprJavaSendStaticJ
TOCicallVMprJavaSendStaticF:
	.tc       icallVMprJavaSendStaticF[TC],icallVMprJavaSendStaticF
TOCicallVMprJavaSendStaticD:
	.tc       icallVMprJavaSendStaticD[TC],icallVMprJavaSendStaticD
TOCicallVMprJavaSendStaticSync0:
	.tc       icallVMprJavaSendStaticSync0[TC],icallVMprJavaSendStaticSync0
TOCicallVMprJavaSendStaticSync1:
	.tc       icallVMprJavaSendStaticSync1[TC],icallVMprJavaSendStaticSync1
TOCicallVMprJavaSendStaticSyncJ:
	.tc       icallVMprJavaSendStaticSyncJ[TC],icallVMprJavaSendStaticSyncJ
TOCicallVMprJavaSendStaticSyncF:
	.tc       icallVMprJavaSendStaticSyncF[TC],icallVMprJavaSendStaticSyncF
TOCicallVMprJavaSendStaticSyncD:
	.tc       icallVMprJavaSendStaticSyncD[TC],icallVMprJavaSendStaticSyncD
TOCjitResolveVirtualMethod:
	.tc       jitResolveVirtualMethod[TC],jitResolveVirtualMethod
TOCjitThrowException:
	.tc       jitThrowException[TC],jitThrowException
TOCjitResolveInterfaceMethod:
	.tc       jitResolveInterfaceMethod[TC],jitResolveInterfaceMethod
TOCjitLookupInterfaceMethod:
	.tc       jitLookupInterfaceMethod[TC],jitLookupInterfaceMethod
TOC_interfaceCompeteSlot2:
	.tc       _interfaceCompteteSlot2[TC],_interfaceCompeteSlot2
TOC_interfaceSlotsUnavailable:
	.tc       _interfaceSlotsUnavailable[TC],_interfaceSlotsUnavailable
TOC_jitAddPicToPatchOnClassUnload:
	.tc       jitAddPicToPatchOnClassUnload[TC],jitAddPicToPatchOnClassUnload
TOCjitCallCFunction:
	.tc       jitCallCFunction[TC],jitCallCFunction
TOCjitInstanceOf:
	.tc       jitInstanceOf[TC],jitInstanceOf
TOCmcc_callPointPatching_unwrapper:
	.tc       mcc_callPointPatching_unwrapper[TC],mcc_callPointPatching_unwrapper
TOCmcc_reservationAdjustment_unwrapper:
	.tc       mcc_reservationAdjustment_unwrapper[TC],mcc_reservationAdjustment_unwrapper
TOCmcc_lookupHelperTrampoline_unwrapper:
	.tc       mcc_lookupHelperTrampoline_unwrapper[TC],mcc_lookupHelperTrampoline_unwrapper

	.section  ".data"
	.align   4
        .type    __staticGlueTable,@object
        .size    __staticGlueTable,160
__staticGlueTable:
	ADDR     FUNC_LABEL(_interpreterVoidStaticGlue)
	ADDR     FUNC_LABEL(_interpreterGPR3StaticGlue)
	ADDR     FUNC_LABEL(_interpreterGPR3GPR4StaticGlue)
	ADDR     FUNC_LABEL(_interpreterFPR0FStaticGlue)
	ADDR     FUNC_LABEL(_interpreterFPR0DStaticGlue)
	ADDR     FUNC_LABEL(_interpreterSyncVoidStaticGlue)
        ADDR     FUNC_LABEL(_interpreterSyncGPR3StaticGlue)
	ADDR     FUNC_LABEL(_interpreterSyncGPR3GPR4StaticGlue)
	ADDR     FUNC_LABEL(_interpreterSyncFPR0FStaticGlue)
	ADDR     FUNC_LABEL(_interpreterSyncFPR0DStaticGlue)

#if !defined(__LITTLE_ENDIAN__)
	.section  ".opd","aw"
	.align    3
	.globl    __refreshHelper
	.size     __refreshHelper,24
__refreshHelper:
	.quad     .__refreshHelper
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterUnresolvedInstanceDataGlue
        .size     _interpreterUnresolvedInstanceDataGlue,24
_interpreterUnresolvedInstanceDataGlue:
        .quad     ._interpreterUnresolvedInstanceDataGlue
        .quad     .TOC.@tocbase
        .long     0x00000000
        .long     0x00000000

	.globl    _interpreterUnresolvedInstanceDataStoreGlue
	.size     _interpreterUnresolvedInstanceDataStoreGlue,24
_interpreterUnresolvedInstanceDataStoreGlue:
	.quad     ._interpreterUnresolvedInstanceDataStoreGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterUnresolvedClassGlue
	.size     _interpreterUnresolvedClassGlue,24
_interpreterUnresolvedClassGlue:
	.quad     ._interpreterUnresolvedClassGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterUnresolvedClassGlue2
	.size     _interpreterUnresolvedClassGlue2,24
_interpreterUnresolvedClassGlue2:
	.quad     ._interpreterUnresolvedClassGlue2
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterUnresolvedStringGlue
	.size     _interpreterUnresolvedStringGlue,24
_interpreterUnresolvedStringGlue:
	.quad     ._interpreterUnresolvedStringGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterUnresolvedConstantDynamicGlue
	.size     _interpreterUnresolvedConstantDynamicGlue,24
_interpreterUnresolvedConstantDynamicGlue:
	.quad     ._interpreterUnresolvedConstantDynamicGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterUnresolvedMethodTypeGlue
	.size     _interpreterUnresolvedMethodTypeGlue,24
_interpreterUnresolvedMethodTypeGlue:
	.quad     ._interpreterUnresolvedMethodTypeGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterUnresolvedMethodHandleGlue
	.size     _interpreterUnresolvedMethodHandleGlue,24
_interpreterUnresolvedMethodHandleGlue:
	.quad     ._interpreterUnresolvedMethodHandleGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterUnresolvedCallSiteTableEntryGlue
	.size     _interpreterUnresolvedCallSiteTableEntryGlue,24
_interpreterUnresolvedCallSiteTableEntryGlue:
	.quad     ._interpreterUnresolvedCallSiteTableEntryGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterUnresolvedMethodTypeTableEntryGlue
	.size     _interpreterUnresolvedMethodTypeTableEntryGlue,24
_interpreterUnresolvedMethodTypeTableEntryGlue:
	.quad     ._interpreterUnresolvedMethodTypeTableEntryGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    MTUnresolvedInt32Load
	.size     MTUnresolvedInt32Load,24
MTUnresolvedInt32Load:
	.quad     .MTUnresolvedInt32Load
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    MTUnresolvedInt64Load
	.size     MTUnresolvedInt64Load,24
MTUnresolvedInt64Load:
	.quad     .MTUnresolvedInt64Load
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    MTUnresolvedFloatLoad
	.size     MTUnresolvedFloatLoad,24
MTUnresolvedFloatLoad:
	.quad     .MTUnresolvedFloatLoad
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    MTUnresolvedDoubleLoad
	.size     MTUnresolvedDoubleLoad,24
MTUnresolvedDoubleLoad:
	.quad     .MTUnresolvedDoubleLoad
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    MTUnresolvedAddressLoad
	.size     MTUnresolvedAddressLoad,24
MTUnresolvedAddressLoad:
	.quad     .MTUnresolvedAddressLoad
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    MTUnresolvedInt32Store
	.size     MTUnresolvedInt32Store,24
MTUnresolvedInt32Store:
	.quad     .MTUnresolvedInt32Store
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    MTUnresolvedInt64Store
	.size     MTUnresolvedInt64Store,24
MTUnresolvedInt64Store:
	.quad     .MTUnresolvedInt64Store
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    MTUnresolvedFloatStore
	.size     MTUnresolvedFloatStore,24
MTUnresolvedFloatStore:
	.quad     .MTUnresolvedFloatStore
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    MTUnresolvedDoubleStore
	.size     MTUnresolvedDoubleStore,24
MTUnresolvedDoubleStore:
	.quad     .MTUnresolvedDoubleStore
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    MTUnresolvedAddressStore
	.size     MTUnresolvedAddressStore,24
MTUnresolvedAddressStore:
	.quad     .MTUnresolvedAddressStore
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterUnresolvedStaticDataGlue
	.size     _interpreterUnresolvedStaticDataGlue,24
_interpreterUnresolvedStaticDataGlue:
	.quad     ._interpreterUnresolvedStaticDataGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterUnresolvedStaticDataStoreGlue
	.size     _interpreterUnresolvedStaticDataStoreGlue,24
_interpreterUnresolvedStaticDataStoreGlue:
	.quad     ._interpreterUnresolvedStaticDataStoreGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterVoidStaticGlue
	.size     _interpreterVoidStaticGlue,24
_interpreterVoidStaticGlue:
	.quad     ._interpreterVoidStaticGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterSyncVoidStaticGlue
	.size     _interpreterSyncVoidStaticGlue,24
_interpreterSyncVoidStaticGlue:
	.quad     ._interpreterSyncVoidStaticGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterGPR3StaticGlue
	.size     _interpreterGPR3StaticGlue,24
_interpreterGPR3StaticGlue:
	.quad     ._interpreterGPR3StaticGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterSyncGPR3StaticGlue
	.size     _interpreterSyncGPR3StaticGlue,24
_interpreterSyncGPR3StaticGlue:
	.quad     ._interpreterSyncGPR3StaticGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterGPR3GPR4StaticGlue
	.size     _interpreterGPR3GPR4StaticGlue,24
_interpreterGPR3GPR4StaticGlue:
	.quad     ._interpreterGPR3GPR4StaticGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterSyncGPR3GPR4StaticGlue
	.size     _interpreterSyncGPR3GPR4StaticGlue,24
_interpreterSyncGPR3GPR4StaticGlue:
	.quad     ._interpreterSyncGPR3GPR4StaticGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterFPR0FStaticGlue
	.size     _interpreterFPR0FStaticGlue,24
_interpreterFPR0FStaticGlue:
	.quad     ._interpreterFPR0FStaticGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterSyncFPR0FStaticGlue
	.size     _interpreterSyncFPR0FStaticGlue,24
_interpreterSyncFPR0FStaticGlue:
	.quad     ._interpreterSyncFPR0FStaticGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

        .globl    _interpreterFPR0DStaticGlue
        .size     _interpreterFPR0DStaticGlue,24
_interpreterFPR0DStaticGlue:
        .quad     ._interpreterFPR0DStaticGlue
        .quad     .TOC.@tocbase
        .long     0x00000000
        .long     0x00000000

        .globl    _interpreterSyncFPR0DStaticGlue
        .size     _interpreterSyncFPR0DStaticGlue,24
_interpreterSyncFPR0DStaticGlue:
        .quad     ._interpreterSyncFPR0DStaticGlue
        .quad     .TOC.@tocbase
        .long     0x00000000
        .long     0x00000000

	.globl    _interpreterUnresolvedStaticGlue
	.size     _interpreterUnresolvedStaticGlue,24
_interpreterUnresolvedStaticGlue:
	.quad     ._interpreterUnresolvedStaticGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterUnresolvedSpecialGlue
	.size     _interpreterUnresolvedSpecialGlue,24
_interpreterUnresolvedSpecialGlue:
	.quad     ._interpreterUnresolvedSpecialGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interpreterUnresolvedDirectVirtualGlue
	.size     _interpreterUnresolvedDirectVirtualGlue,24
_interpreterUnresolvedDirectVirtualGlue:
	.quad     ._interpreterUnresolvedDirectVirtualGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _virtualUnresolvedHelper
	.size     _virtualUnresolvedHelper,24
_virtualUnresolvedHelper:
	.quad     ._virtualUnresolvedHelper
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interfaceCallHelper
	.size     _interfaceCallHelper,24
_interfaceCallHelper:
	.quad     ._interfaceCallHelper
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interfaceCompeteSlot2
	.size     _interfaceCompeteSlot2,24
_interfaceCompeteSlot2:
	.quad     ._interfaceCompeteSlot2
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _interfaceSlotsUnavailable
	.size     _interfaceSlotsUnavailable,24
_interfaceSlotsUnavailable:
	.quad     ._interfaceSlotsUnavailable
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _nativeStaticHelperForUnresolvedGlue
	.size     _nativeStaticHelperForUnresolvedGlue,24
_nativeStaticHelperForUnresolvedGlue:
	.quad     ._nativeStaticHelperForUnresolvedGlue
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000

	.globl    _nativeStaticHelper
	.size     _nativeStaticHelper,24
_nativeStaticHelper:
	.quad     ._nativeStaticHelper
	.quad     .TOC.@tocbase
	.long     0x00000000
	.long     0x00000000
#endif

#elif defined(LINUX)
#if defined(LINUX)
   .data
#endif
staticGlueTable:
	ADDR     _interpreterVoidStaticGlue
	ADDR     _interpreterGPR3StaticGlue
	ADDR     _interpreterGPR3GPR4StaticGlue
	ADDR     _interpreterFPR0FStaticGlue
	ADDR     _interpreterFPR0DStaticGlue
	ADDR     _interpreterSyncVoidStaticGlue
	ADDR     _interpreterSyncGPR3StaticGlue
	ADDR     _interpreterSyncGPR3GPR4StaticGlue
	ADDR     _interpreterSyncFPR0FStaticGlue
	ADDR     _interpreterSyncFPR0DStaticGlue
#endif

! .bss section
	.comm     __j9_smp_flag, 4

